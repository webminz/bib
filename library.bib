@inproceedings{AlanenPorres2003,
	author    = {Marcus Alanen and
	Ivan Porres},
	editor    = {Perdita Stevens and
	Jon Whittle and
	Grady Booch},
	title     = {Difference and Union of Models},
	booktitle = {UML 2003 - The Unified Modeling Language,
	Modeling Languages and Applications, 6th International Conference},
	series    = {LNCS},
	volume    = {2863},
	pages     = {2--17},
	publisher = {Springer},
	year      = {2003},
	doi       = {10.1007/978-3-540-45221-8\_2},
	timestamp = {Mon, 29 May 2017 16:53:44 +0200},
	biburl    = {https://dblp.org/rec/bib/conf/uml/AlanenP03},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Petr2013,
annote = {Interesting READ over the application of UML in practice},
author = {Petre, M},
booktitle = {2013 35th International Conference on Software Engineering (ICSE)},
doi = {10.1109/ICSE.2013.6606618},
issn = {0270-5257},
keywords = {Analytical models,Companies,Context,Industries,Interviews,Software,UML,Unified Modeling Language,Unified modeling language,empirical studies,lingua franca of software engineering,notation,professional software engineers,software design,software development,software engineering},
month = {may},
pages = {722--731},
title = {{UML in practice}},
year = {2013}
}

@inproceedings{HutchinsonWhittleRK2011,
address = {New York, NY, USA},
annote = {Another interesting read for practice of MDSE.},
author = {Hutchinson, John and Whittle, Jon and Rouncefield, Mark and Kristoffersen, Steinar},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
doi = {10.1145/1985793.1985858},
isbn = {978-1-4503-0445-0},
keywords = {empirical software engineering,model driven engineering},
pages = {471--480},
publisher = {ACM},
series = {ICSE '11},
title = {{Empirical Assessment of MDE in Industry}},
url = {http://doi.acm.org/10.1145/1985793.1985858},
year = {2011}
}
@article{WhittleHutchinsonR2014,
annote = {MUST READ to know more about the current state of MDSE in practice},
author = {Whittle, J and Hutchinson, J and Rouncefield, M},
doi = {10.1109/MS.2013.65},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {MDE,model driven engineering practice,model-driven engineering,software design,software design methodologies,software engineering},
month = {may},
number = {3},
pages = {79--85},
title = {{The State of Practice in Model-Driven Engineering}},
volume = {31},
year = {2014}
}
@inproceedings{DiskinDingel2006,
address = {Berlin, Heidelberg},
annote = {Mandatory Read for Sketches as well},
author = {Diskin, Zinovy and Dingel, Juergen},
booktitle = {Proceedings of the 9th International Conference on Model Driven Engineering Languages and Systems},
doi = {10.1007/11880240_17},
isbn = {3-540-45772-0, 978-3-540-45772-5},
pages = {230--244},
publisher = {Springer-Verlag},
series = {MoDELS'06},
title = {{Mappings, Maps and Tables: Towards Formal Semantics for Associations in UML2}},
url = {http://dx.doi.org/10.1007/11880240{\_}17},
year = {2006}
}
@inproceedings{DiskinWolter2008,
author = {Diskin, Zinovy and Wolter, Uwe},
booktitle = {ACCAT '07},
pages = {19--41},
title = {{A diagrammatic logic for object-oriented visual modeling}},
year = {2007}
}
@incollection{Diskin2003,
address = {Dordrecht},
annote = {A mandatory cite for generalized sketches},
author = {Diskin, Zinovy},
booktitle = {Practical Foundations of Business System Specifications},
doi = {10.1007/978-94-017-2740-2_8},
pages = {145--178},
publisher = {Springer Netherlands},
title = {{Mathematics of UML}},
url = {http://link.springer.com/10.1007/978-94-017-2740-2{\_}8},
year = {2003}
}
@article{SendallKozaczynski2003,
address = {Los Alamitos, CA, USA},
annote = {Classic concerning model transformation},
author = {Sendall, Shane and Kozaczynski, Wojtek},
doi = {10.1109/MS.2003.1231150},
issn = {0740-7459},
journal = {IEEE Softw.},
month = {sep},
number = {5},
pages = {42--45},
publisher = {IEEE Computer Society Press},
title = {{Model Transformation: The Heart and Soul of Model-Driven Software Development}},
url = {http://dx.doi.org/10.1109/MS.2003.1231150},
volume = {20},
year = {2003}
}
@inproceedings{EllisKeddaraR1995,
address = {New York, NY, USA},
annote = {The classic about dapting running process instances},
author = {Ellis, Clarence and Keddara, Karim and Rozenberg, Grzegorz},
booktitle = {Proceedings of Conference on Organizational Computing Systems},
doi = {10.1145/224019.224021},
isbn = {0-89791-706-5},
pages = {10--21},
publisher = {ACM},
series = {COCS '95},
title = {{Dynamic Change Within Workflow Systems}},
url = {http://doi.acm.org/10.1145/224019.224021},
year = {1995}
}
@article{RinderleReichertD2004,
address = {Amsterdam, The Netherlands, The Netherlands},
annote = {Some classic about adapting processes},
author = {Rinderle, Stefanie and Reichert, Manfred and Dadam, Peter},
doi = {10.1016/j.datak.2004.01.002},
issn = {0169-023X},
journal = {Data Knowl. Eng.},
keywords = {adaptive systems,correctness criteria,dynamic workflow changes,workflow management},
month = {jul},
number = {1},
pages = {9--34},
publisher = {Elsevier Science Publishers B. V.},
title = {{Correctness Criteria for Dynamic Changes in Workflow Systems: A Survey}},
url = {http://dx.doi.org/10.1016/j.datak.2004.01.002},
volume = {50},
year = {2004}
}
@article{Seidewitz2003,
address = {Los Alamitos, CA, USA},
annote = {A classic about models},
author = {Seidewitz, Ed},
doi = {10.1109/MS.2003.1231147},
issn = {0740-7459},
journal = {IEEE Softw.},
month = {sep},
number = {5},
pages = {26--32},
publisher = {IEEE Computer Society Press},
title = {{What Models Mean}},
url = {http://dx.doi.org/10.1109/MS.2003.1231147},
volume = {20},
year = {2003}
}
@article{RutleRossiniLW2012,
author = {Rutle, Adrian and Rossini, Alessandro and Lamo, Yngve and Wolter, Uwe},
issn = {1567-8326},
journal = {JLAMP},
number = {4},
pages = {422--457},
publisher = {North-Holland},
title = {{A formal approach to the specification and transformation of constraints in MDE}},
volume = {81},
year = {2012}
}
@inproceedings{WangRutleL2015,
  author    = {Xiaoliang Wang and
               Adrian Rutle and
               Yngve Lamo},
  editor    = {Michalis Famelis and
               Daniel Ratiu and
               Martina Seidl and
               Gehan M. K. Selim},
  title     = {Towards User-Friendly and Efficient Analysis with Alloy},
  booktitle = {Proceedings of the 12th Workshop on Model-Driven Engineering, Verification
               and Validation co-located with {ACM/IEEE} 18th International Conference
               on Model Driven Engineering Languages and Systems, MoDeVVa@MoDELS
               2015, Ottawa, Canada, September 29, 2015},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {1514},
  pages     = {28--37},
  publisher = {CEUR-WS.org},
  year      = {2015},
  url       = {http://ceur-ws.org/Vol-1514/paper4.pdf},
  timestamp = {Wed, 12 Feb 2020 16:44:15 +0100},
  biburl    = {https://dblp.org/rec/conf/models/WangRL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{BeckerKellerS2002,
author = {Beckert, Bernhard and Keller, Uwe and Schmitt, Peter H},
booktitle = {Proc. of the VERIFY Workshop at Federated Logic Conferences (FLoC)},
pages = {113--123},
title = {{Translating the Object Constraint Language into first-order predicate logic}},
year = {2002}
}
@misc{EU2015,
author = {EU Comission},
title = {{Horizon 2020 calls for eHealth projects}},
url = {http://ec.europa.eu/digital-single-market/en/news/first-horizon-2020-calls-ehealth-projects-launched},
howpublished={\url{http://ec.europa.eu/digital-single-market/en/news/first-horizon-2020-calls-ehealth-projects-launched}, Last Accessed: 08.11.2017},
urldate = {2017-11-04},
year={2015}
}
@misc{USBoLS2016,
author = "{U.S. Bureau of Labor Statistics}",
title = {{Medical Records and Health Information Technicians Job Outlook}},
url = {https://www.bls.gov/ooh/healthcare/medical-records-and-health-information-technicians.htm{\#}tab-6},
howpublished={\url{https://www.bls.gov/ooh/healthcare/medical-records-and-health-information-technicians.htm{\#}tab-6}, Last Accessed: 04.11.2017}
}
@incollection{Clarke2008,
address = {Berlin, Heidelberg},
author = {Clarke, Edmund M},
booktitle = {25 Years of Model Checking: History, Achievements, Perspectives},
doi = {10.1007/978-3-540-69850-0_1},
editor = {Grumberg, Orna and Veith, Helmut},
isbn = {978-3-540-69849-4},
pages = {1--26},
publisher = {Springer-Verlag},
title = {{The Birth of Model Checking}},
url = {http://dx.doi.org/10.1007/978-3-540-69850-0{\_}1},
year = {2008}
}
@misc{EU2017EHealth,
author = "{EU Comission}",
title = {{2017 CEF Telecom Call - eHealth (CEF-TC-2017-2)}},
url = {https://ec.europa.eu/inea/en/connecting-europe-facility/cef-telecom/apply-funding/2017-cef-telecom-call-ehealth-cef-tc-2017-2},
urldate = {2017-11-04},
year = {2017}
}
@misc{OMG2012OCL,
author = "{Object Management Group}",
title = {{Object Constraint Language (OCL) v.2.3.1}},
url = {http://www.omg.org/spec/OCL/2.3.1/},
year = {2012}
}
@misc{OMG2015XMI,
author = "{Object Management Group}",
title = {{XML Metadata Interchange (XMI) v.2.5.1}},
url = {https://www.omg.org/spec/XMI/2.5.1/},
year = {2015},
}
@misc{OECD2010,
author = "{Organisation for Economic Co-operation and Development}",
doi = {http://dx.doi.org/10.1787/9789264084612-en},
title = {{Improving Health Sector Efficiency: The Role of Information and Communication Technologies}},
year = {2010}
}

@inproceedings{VoigtlaenderHuMW2010,
author = {Voigtl{\"{a}}nder, Janis and Hu, Zhenjiang and Matsuda, Kazutaka and Wang, Meng},
booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
organization = {ACM},
pages = {181--192},
title = {{Combining syntactic and semantic bidirectionalization}},
year = {2010},
series = {ICFP '10}
}
@inproceedings{Vellecillo2008,
address = {Dagstuhl, Germany},
annote = {Keywords: Model behavio, Time, Model Analysis, Viewpoint Modeling.},
author = {Vallecillo, Antonio},
booktitle = {Perspectives Workshop: Model Engineering of Complex Systems (MECS)},
editor = {A{\ss}mann, Uwe and B{\'{e}}zivin, Jean and Paige, Richard and Rumpe, Bernhard and Schmidt, Douglas C},
issn = {1862-4405},
number = {08331},
publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, Germany},
series = {Dagstuhl Seminar Proceedings},
title = {{A Journey through the Secret Life of Models}},
url = {http://drops.dagstuhl.de/opus/volltexte/2008/1601},
year = {2008}
}
@article{BancilhonSpyratos1981,
address = {New York, NY, USA},
annote = {Some basic paper about schme transformation},
author = {Bancilhon, {François} and Spyratos, Nicolas},
doi = {10.1145/319628.319634},
issn = {0362-5915},
journal = {ACM Trans. Database Syst.},
keywords = {conceptual model,data model,data semantics,database view,relation,relational model database,update translation,view updating},
month = {dec},
number = {4},
pages = {557--575},
publisher = {ACM},
title = {{Update Semantics of Relational Views}},
volume = {6},
year = {1981}
}
@inproceedings{HainautTonneauJC1993,
author = {Hainaut, J-L and Tonneau, Catherine and Joris, Michel and Chandelon, Muriel},
booktitle = {International Conference on Conceptual Modeling},
organization = {Springer},
pages = {364--375},
title = {{Transformation-based database reverse engineering}},
year = {1993}
}
@inproceedings{RutleMacCaullWL2012,
address = {New York, NY, USA},
author = {Rutle, Adrian and MacCaull, Wendy and Wang, Hao and Lamo, Yngve},
booktitle = {Proceedings of the Fourth Workshop on Behaviour Modelling - Foundations and Applications},
doi = {10.1145/2325276.2325281},
isbn = {978-1-4503-1187-8},
keywords = {diagrammatic modelling,dynamic semantics,metamodelling,model and (graph) transformations,transition systems,workflow modelling},
pages = {5:1----5:10},
publisher = {ACM},
series = {BM-FA '12},
title = {{A Metamodelling Approach to Behavioural Modelling}},
url = {http://doi.acm.org/10.1145/2325276.2325281},
year = {2012}
}
@misc{OMG2014MDA,
author = "{Object Management Group}",
file = {:Users/past/Downloads/ormsc-14-06-01.pdf:pdf},
number = {June},
pages = {1--15},
title = {{MDA Guide rev. 2.0}},
url = {http://www.omg.org/cgi-bin/doc?omg/03-06-01},
volume = {2.0},
year = {2014}
}
@article{RutleRabbiML2013,
author = {Rutle, Adrian and Rabbi, Fazle and MacCaull, Wendy and Lamo, Yngve},
journal = {Procedia Computer Science},
pages = {317--326},
publisher = {Elsevier},
title = {{A user-friendly tool for model checking healthcare workflows}},
volume = {21},
year = {2013}
}
@book{ArenasBarceloLM2010,
author = {Arenas, Marcelo and Barcelo, Pablo and Libkin, Leonid and Murlak, Filip},
booktitle = {Synthesis Lectures on Data Management},
publisher = {Morgan {\&} Claypool Publishers},
title = {{Relational and XML data exchange}},
year = {2010}
}
@inproceedings{BerdagauerCunhaPV2007,
author = {Berdaguer, Pablo and Cunha, Alcino and Pacheco, Hugo and Visser, Joost},
booktitle = {PADL},
organization = {Springer},
pages = {290--304},
title = {{Coupled schema transformation and data conversion for XML and SQL}},
volume = {4354},
year = {2007}
}
@article{HuSchuerr2011,
author = {Hu, Zhenjiang and Sch{\"{u}}rr, Andy and Stevens, Perdita and Terwilliger, James F.},
journal = {ACM SIGMOD Record},
number = {1},
pages = {35},
publisher = {ACM},
title = {{Dagstuhl seminar on bidirectional transformations (BX)}},
url = {http://portal.acm.org/citation.cfm?doid=2007206.2007217},
volume = {40},
year = {2011}
}
@phdthesis{Rutle2011,
author = {Rutle, Adrian},
school = {University of Bergen},
title = {{Diagram Predicate Framework: A Formal Approach to MDE}},
year = {2010}
}
@phdthesis{Wang2016,
author = {Wang, Xiaoliang},
school = {University of Bergen},
title = {{Towards Correct Modelling and Model Transformation in DPF}},
year = {2016}
}

@article{EhrigHeckelKL1997,
abstract = {The algebraic approaches to graph transformation are based on the concept of gluing of graphs corresponding to pushouts in suitable categor-ies of graphs and graph morphisms. This allows one to give not only an explicit algebraic or set theoretical description of the constructions but also to use concepts and results from category theory in order to build up a rich theory and to give elegant proofs even in complex situations. In the previous chapter we have presented an overview of the ba-sic notions and problems common to the two algebraic approaches, the double-pushout (DPO) approach and the single-pushout (SPO) approach, and their solutions in the DPO-approach. In this chapter we introduce the SPO-approach to graph transformation and some of its main results. We study application conditions for graph productions and the transforma-tion of more general structures than graphs in the SPO-approach, where similar generalizations have been or could be studied also in the DPO-approach. Finally, we present a detailed comparison of the DPO-and the SPO-approach, especially concerning the solutions to the problems discussed for both approaches in the previous chapter.},
author = {Ehrig, H and Heckel, R and Korff, M and Owe, M L and Ribeiro, L and Wagner, A},
journal = {Algebraic Approaches to Graph Transformation},
title = {{Single Pushout Approach and Comparison with Double Pushout Approach}},
url = {https://s3.amazonaws.com/academia.edu.documents/2160073/njaf33c8ww3m2v.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A{\&}Expires=1509553365{\&}Signature={\%}2BnWYg3t30WFlTeLUZtI9nmTa7oM{\%}3D{\&}response-content-disposition=inline{\%}3B filename{\%}3DAlgebraic{\_}Approaches{\_}to{\_}Graph{\_}Tr},
year = {1997}
}
@book{EhrigEhrigPT2006,
abstract = {Graphs are widely used to represent structural information in the form of objects and connections between them. Graph transformation is the rule-based manipulation of graphs, an increasingly important concept in computer science and related fields. This is the first textbook treatment of the algebraic approach to graph transformation, based on algebraic structures and category theory. Part I is an introduction to the classical case of graph and typed graph transformation. In Part II, basic and advanced results are first shown for an abstract form of replacement systems, so-called adhesive high. General Introduction; Graphs, Typed Graphs, and the Gluing Construction; Graph Transformation Systems; Adhesive High-Level Replacement Categories; Adhesive High-Level Replacement Systems; Embedding and Local Confluence; Constraints and Application Conditions; Typed Attributed Graphs; Typed Attributed Graph Transformation Systems; Embedding and Local Confluence for Typed AGT Systems; Adhesive HLR Categories for Typed Attributed Graphs; Constraints, Application Conditions and Termination for Typed AGT Systems; Typed Attributed Graph Transformation with Inheritance.},
author = {Ehrig, Hartmut. and Ehrig, K. and Prange, U. and Taentzer, G.},
isbn = {978-3-540-31187-4},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Fundamentals of algebraic graph transformation}},
year = {2006},
doit = {10.1007/3-540-31188-2},
edition = {1}
}
@incollection{Schurr1999,
author = {Sch{\"{u}}rr, A and Winter, A.J. and Z{\"{u}}ndorf, A},
booktitle = {Handbook of graph grammars and computing by graph transformation},
isbn = {9810240201},
pages = {487--550},
publisher = {World Scientific},
title = {{The PROGRES approach: language and environment}},
url = {https://dl.acm.org/citation.cfm?id=328617},
year = {1999}
}

@inproceedings{CzarneckiHelsen2003,
author = {Czarnecki, Krzysztof and Helsen, Simon},
booktitle = {Proceedings of the 2nd OOPSLA Workshop on Generative Techniques in the Context of the Model Driven Architecture},
title = {{Classification of model transformation approaches}},
year = {2003}
}
@book{EhrigKreowskiUR1999,
author = {Ehrig, H and Kreowski, H-J and Montanari, U and Rozenberg, G},
doi = {10.1142/4181},
isbn = {978-981-02-4021-9},
month = {aug},
publisher = {WORLD SCIENTIFIC},
title = {{Handbook of Graph Grammars and Computing by Graph Transformation, Volume 3., Concurrency, parallelism and distribution}},
url = {http://www.worldscientific.com/worldscibooks/10.1142/4181},
year = {1999}
}
@book{EhrigEngelsKR1999,
author = {Ehrig, H and Engels, G and Kreowski, H-J and Rozenberg, G},
doi = {10.1142/4180},
isbn = {978-981-02-4020-2},
month = {oct},
publisher = {WORLD SCIENTIFIC},
title = {{Handbook of Graph Grammars and Computing by Graph Transformation, Volume 2. Applications, Languages and Tools}},
url = {http://www.worldscientific.com/worldscibooks/10.1142/4180},
year = {1999}
}
@book{Rozenberg1997,
abstract = {Graph grammars originated in the late 60s, motivated by considerations about pattern recognition and compiler construction. Since then the list of areas which have interacted with the development of graph grammars has grown quite impressively. Besides the aforementioned areas it includes software specification and development, VLSI layout schemes, database design, modeling of concurrent systems, massively parallel computer architectures, logic programming, computer animation, developmental biology, music composition, visual languages, and many others.The area of graph grammars and graph transformations generalizes formal language theory based on strings and the theory of term rewriting based on trees. As a matter of fact within the area of graph grammars, graph transformation is considered a fundamental programming paradigm where computation includes specification, programming, and implementation.Over the last 25-odd years graph grammars have developed at a steady pace into a theoretically attractive and well-motivated research field. In particular, they are now based on very solid foundations, which are presented in this volume. Volume 1 of the indispensable Handbook of Graph Grammars and Computing by Graph Transformations includes a state-of-the-art presentation of the foundations of all the basic approaches to rule-based graph specification and transformation: algebraic approach, logic approach, node-based rewriting, (hyper)edge-based rewriting, programmed graph rewriting, and 2-structures. The book has been written in a tutorial/survey style to enhance its usefulness.},
author = {Rozenberg, Grzegorz.},
isbn = {9810228848},
publisher = {World Scientific},
title = {{Handbook of graph grammars and computing by graph transformation, Volume 1.}},
year = {1997}
}
@misc{ChinookHypertensionGuide,
author = "{The Chinook Primary Care Network}",
file = {:Users/past/Documents/phd/use{\_}cases/BloodPressure.pdf:pdf},
pages = {1--37},
title = {{Hypertension {\&} Vascular Protection}},
url = {www.chinookprimarycarenetwork.ab.ca/extranet/docs/guides/7.pdf},
howpublished={\url{http://www.chinookprimarycarenetwork.ab.ca/extranet/docs/guides/7.pdf}},
year = {2006}
}
@misc{OMG2014BPMN,
author = "{Object Management Group}",
title = {{Business Process Model And Notation (BPMN) v.2.0.2}},
url = {http://www.omg.org/spec/BPMN},
urldate = {14.01.2013},
year = {2014}
}
@misc{OMG2019DMN,
author = "{Object Management Group}",
title = {{Decision Model and Notation (DMN) v.1.2}},
url = {https://www.omg.org/spec/DMN/About-DMN/},
urldate = {07.10.2019},
year = {2019}
}
@article{KopanitsaVeseliY2001,
author = {Kopanitsa, Georgy and Veseli, Hasan and Yampolsky, Vladimir},
issn = {1532-0464},
journal = {Journal of Biomedical Informatics},
pages = {196--205},
publisher = {Academic Press},
title = {{Development, implementation and evaluation of an information model for archetype based user responsive medical data visualization}},
url = {http://www.academia.edu/24016650/Development{\_}implementation{\_}and{\_}evaluation{\_}of{\_}an{\_}information{\_}model{\_}for{\_}archetype{\_}based{\_}user{\_}responsive{\_}medical{\_}data{\_}visualization},
volume = {55},
year = {2001}
}
@article{BirdGoodchildT2003,
author = {Bird, L. and Goodchild, A. and Tun, Z.},
journal = {Journal of Research and Practice in Information Technology},
keywords = {electronic health record    two-level modelling ap},
title = {{Experiences with a Two-Level Modelling Approach to Electronic Health Records}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.463},
volume = {35},
year = {2003}
}
@article{RabbiLamoMC2014,
abstract = {Due to their complexity and the plethora of requirements placed upon them, healthcare systems so far have not been adequately modeled for the purpose of software development. As a result, the healthcare software suffers from high development costs and lack of flexibility. Model driven software engineering (MDSE) is an emerging methodology for software development, targeting productivity, flexibility and reliability of systems; metamodelling is at the core of most MDSE approaches. In previous work, we proposed a multi metamodelling approach that captures the complexity of these systems by using a metamodelling hierarchy, built from individually defined metamodels, each capturing different aspects of a healthcare domain, namely, user access modelling, health process modelling, process monitoring, user interface modelling and modelling of the data sources. Here, we formalize the co-ordination among metamodels, using a linguistic extension of the metamodelling hierarchy. This linguistic extension is an added metalevel which models the integration of two or more different aspects of the system. We focus on two features essential to the co-ordination of healthcare metamodels, namely the integration of process and data, modelling data-aware processes, and the integration of process and user, modelling both user access as well as inheritance of user access to tasks.},
author = {Rabbi, Fazle and Lamo, Yngve and MacCaull, Wendy},
doi = {10.1016/J.PROCS.2014.08.071},
issn = {1877-0509},
journal = {Procedia Computer Science},
keywords = {co-ordination among metamodels,healthcare information systems,linguistic extension,model driven software engineering,multi metamodelling},
month = {jan},
pages = {473--480},
publisher = {Elsevier},
title = {{Co-ordination of Multiple Metamodels, with Application to Healthcare Systems}},
volume = {37},
year = {2014}
}
@article{RaghupathiUmar2008,
abstract = {Objective To explore the potential of the model-driven architecture (MDA) in health care information systems development. Methods An MDA is conceptualized and developed for a health clinic system to track patient information. A prototype of the MDA is implemented using an advanced MDA tool. The UML provides the underlying modeling support in the form of the class diagram. The PIM to PSM transformation rules are applied to generate the prototype application from the model. Results The result of the research is a complete MDA methodology to developing health care information systems. Additional insights gained include development of transformation rules and documentation of the challenges in the application of MDA to health care. Design guidelines for future MDA applications are described. The model has the potential for generalizability. The overall approach supports limited interoperability and portability. Conclusion The research demonstrates the applicability of the MDA approach to health care information systems development. When properly implemented, it has the potential to overcome the challenges of platform (vendor) dependency, lack of open standards, interoperability, portability, scalability, and the high cost of implementation.},
author = {Raghupathi, Wullianallur and Umar, Amjad},
doi = {10.1016/J.IJMEDINF.2007.04.009},
issn = {1386-5056},
journal = {International Journal of Medical Informatics},
keywords = {Health care information system,Interoperability,Model-driven architecture,Open standard,Platform-independent model,Platform-specific model,Vendor lock-in},
month = {may},
number = {5},
pages = {305--314},
publisher = {Elsevier},
title = {{Exploring a model-driven architecture (MDA) approach to health care information systems development}},
url = {http://www.sciencedirect.com/science/article/pii/S1386505607000925{\#}bib16},
volume = {77},
year = {2008}
}
@misc{USGov2005,
author = "{U.S. Government Accountability}",
number = {GAO-05-309R},
title = {{Health and Human Services' Estimate of Health Care Cost Savings Resulting from the Use of Information Technology}},
url = {http://www.gao.gov/products/GAO-05-309R},
howpublished={\url{http://www.gao.gov/products/GAO-05-309R}, Last Accessed: 08.11.2017},
year={2005}
}
@misc{USGov2004,
author = "{U.S. Government Accountability}",
number = {GAO-04-947T},
title = {{Health Care: National Strategy Needed to Accelerate the Implementation of Information Technology}},
howpublished = {\url{http://www.gao.gov/products/GAO-04-947T}, Last Accessed: 08.11.2017},
url = {http://www.gao.gov/products/GAO-04-947T},
year={2004}
}
@article{PelegTuB2003,
author = {Peleg, M. and Tu, S. and Bury, J. and Ciccarese, P. and Fox, J. and Greenes, R. A. and Hall, R. and Johnson, P. D. and Jones, N. and Kumar, A. and Miksch, S. and Quaglini, S. and Seyfang, A. and Shortliffe, E. H. and Stefanelli, M.},
doi = {10.1197/jamia.M1135},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
month = {jan},
number = {1},
pages = {52--68},
publisher = {Oxford University Press},
title = {{Comparing Computer-interpretable Guideline Models: A Case-study Approach}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1197/jamia.M1135},
volume = {10},
year = {2003}
}
@incollection{RutleRossiniLW2009,
author = {Rutle, Adrian and Rossini, Alessandro and Lamo, Yngve and Wolter, Uwe},
pages = {37--56},
publisher = {Springer, Berlin, Heidelberg},
title = {{A Diagrammatic Formalisation of MOF-Based Modelling Languages}},
bookTitle="TOOLS EUROPE 2009",
year = {2009}
}
@book{BarrWells1990,
author = {Barr, Michael and Wells, Charles},
isbn = {0131204866},
pages = {432},
publisher = {Prentice Hall},
title = {{Category theory for computing science}},
year = {1990}
}
@techreport{WolterDiskin2007,
address = {Bergen},
author = {Wolter, Uwe and Diskin, Zinovy},
institution = {Department of Informatics, University of Bergen},
title = {{The Next Hundred Diagrammatic Specification Techniques — An Introduction to Generalized Sketches —}},
url = {http://www.ii.uib.no/publikasjoner/texrap/pdf/2007-358.pdf},
year = {2007}
}
@misc{OMG2015UML,
author = "{Object Management Group}",
title = {{Unified Modeling Language (UML) v.2.4.1}},
url = {http://www.omg.org/spec/UML},
year = {2015}
}
@misc{OMG2016MOF,
author = "{Object Management Group}",
title = {{Meta Object Facility (MOF) Core Specification v. 2.4.1}},
url = {http://www.omg.org/spec/MOF},
year = {2016}
}
@article{SchlieterBurwitzSB2015,
abstract = {Failed software projects are often the result of an unsystematic trans-fer of business requirements to the implementation. This deficit led to the speci-fication of the Model Driven Architecture (MDA). It claims a consistent use of conceptual models for the software development process from requirement analysis to technical specification of software. The MDA reduces the gap be-tween the business level and the information technology (IT) level by defining a methodological framework to link these levels (Business-IT alignment). We will present the use of an MDA in health care domain. For this purpose, we show how the paradigm of MDA can be configured to implement medical ap-plication software based on a telemedical IT platform (telehealth platform). Ad-ditionally to the conceptual structure of the developed approach and the do-main-specific alignment, lessons learned from the experiences gathered during design process will be formulated as assistance for similar projects and substan-tiated with an exemplary application. Since the introduction of the case-based compensation model, care providers face the conflict between increasing the quality of care (I), transparency of medical services (II) and the purpose of a resource efficient care system (III) [1]. To efficiently master the challenge of the increasing complexity of medical care processes, Clinical Path-ways (CP) have been established in recent years. They are specific, standardized de-scriptions of clinical processes for defined combinations of symptoms that are adapted to clinical conditions [2]. They are geared to the entire multidisciplinary care process of a patient type [3]. As Panella {\&} Vanhaecht stated, CPs are more than only the structure of a care process and even more than a part of the patient record. They are " a patient-focused concept, a tool to model the care, a quality and efficiency improve-ment process and a product in the patient record " [4].},
author = {Schlieter, Hannes and Burwitz, Martin and Benedict, Martin and Sch{\"{o}}nherr, Oliver},
keywords = {Clinical Pathway,Conceptual Modeling,Health Care,Method Engineering,Model Driven Architecture},
pages = {497--511},
title = {{Towards Model Driven Architecture in Health Care Information System Development 1 Potentials of Model-Driven Software Development}},
url = {http://www.wi2015.uni-osnabrueck.de/Files/WI2015-D-14-00264.pdf}
}
@book{KellyTolvanen2008,
abstract = {Illustrating examples from various fields of software product development, this book offers an introduction to Domain-Specific Modeling (DSM). It addresses the guidelines for implementing DSM: how to identify the language constructs, options available for code generation and what tools are available to provide tool support for DSM language. DOMAIN-SPECIFIC MODELING; CONTENTS; FOREWORD; PREFACE; ACKNOWLEDGMENTS; PART I: BACKGROUND AND MOTIVATION; 1 INTRODUCTION; 2 BUSINESS VALUE; PART II: FUNDAMENTALS; 3 DSM DEFINED; 4 ARCHITECTURE OF DSM; PART III: DSM EXAMPLES; 5 IP TELEPHONY AND CALL PROCESSING; 6 INSURANCE PRODUCTS; 7 HOME AUTOMATION; 8 MOBILE PHONE APPLICATIONS USING A PYTHON FRAMEWORK; 9 DIGITAL WRISTWATCH; PART IV: CREATING DSM SOLUTIONS; 10 DSM LANGUAGE DEFINITION; 11 GENERATOR DEFINITION; 12 DOMAIN FRAMEWORK; 13 DSM DEFINITION PROCESS; 14 TOOLS FOR DSM; 15 DSM IN USE; 16 CONCLUSION; APPENDIX A: METAMODELING LANGUAGE.},
author = {Kelly, Steven. and Tolvanen, Juha-Pekka.},
isbn = {0470036664},
pages = {427},
publisher = {Wiley-Interscience},
title = {{Domain-specific modeling : enabling full code generation}},
year = {2008}
}
@article{ChristensenEllingsen2017,
author = {Christensen, Bente and Ellingsen, Gunnar},
doi = {10.1016/J.IJMEDINF.2016.02.004},
journal = {International Journal of Medical Informatics},
month = {may},
pages = {43--54},
publisher = {Elsevier},
title = {{Evaluating Model-Driven Development for large-scale EHRs through the openEHR approach}},
url = {http://www.sciencedirect.com/science/article/pii/S1386505616300247?via{\%}3Dihub},
volume = {89},
year = {2016}
}
@inproceedings{Beale2002,
annote = {READ on 17.09.2017:
classical information systems: domain concepts hardcoded into software and database models (single model approach)
={\textgreater} quick development but hard to modify and extend
even in object-oriented systems (model is clearer), a problem remains, since domain concepts are changing
={\textgreater} solution include an untyped black box


New approach:
-remove domain concepts from concrete software and database models into standardised vocabularies and domain concept models
-Re-engineer software to use a generic reference object model, designed to process information by extarnally supplied domain definitions

Standardised vocabulary development has existed in healthcare for a long time

Archetype (original model, prototype, specimen)
- knowledge level interoperability
- smaller models, describing domain concepts

Purpose of an information system: The creation an processing of instances of concepts

Figure1: interesting vizualization of classical software development
ooa yieals a domain classes, with abstract concepts in inheritance hierarchy (usual "party" modeling problem)
problems:
- only current requirements
- models containing generic and domain concepts in the same inheritance hierarchy
- fragile base class ?
- problem of "completion" of a model
- semantic fitness: behavior and constraints

concrete large scale modelling often falls short:

Semi-structured models to the reescue, i.e. make the model more generic
new problems:
- partially concrete, i.e. some properties are more important than others
- more complex structure than lists might be needed.
- how to specify needed information
- strong typing is lost
- How much should be converted from structured to unstructured

how to make sense of the models of the domain: look at the common terminology
={\textgreater} use a "dual model" methodology

How to express domain concepts?
From AI an ontology is a formalisation of knowledge of the domain

Level 0 
vocabulary and stable concepts
medicine has domain knowledge in a computable form (SNOMED)
Level 1
specific to particular users
composition of level 0 strucutre into content structures (ubiquituos or use-case)
example: blood pressure combines systolic and diastolic
example: family subject history
Level 2
organisation: relating the items
Level 3
storage: how to strucutre the information
Level 4
How to structure information for sharing


Use a template language to describe concepts, with its features and invariants
problems:
- mapping, using different names for the same concepts ={\textgreater} can be handled e.g. RegEx
- additional information (optional through multiplicities)
- protocol (optional through multiplicities)

Reference: Knowledge Interchange Format (KIF)

Example: A variable of an object might be subject to a complex state machine described behavior.

Variability in domain concepts:
- Free text names
- Coded Terms
- Values, e.g. quantities
- types, e.g. value constraints
- structure
- relationships
- behavior


An archetype is a constraint based concept definition, a constellation of valid combinations of ROM objects for a domain concept, a concept marks a boundary in an information construction space.

Typical Base Types:
-Types of the formalism: String, Integer, Boolean, Real
in health: 
-Time Types: 
-Quantity Types
-Money
-Special Text
-Internet related types: email, links, 
-Multi-media types: images, ...

OT ideas: Base type is only a constraint, set valued relationships are funtcions List: Int -{\textgreater} T, Timeseries: Time -{\textgreater} T, Table: (Int, Int) -{\textgreater} T

The archetype - ROM relationship has not been extensively studied},
author = {Beale, Thomas},
booktitle = {OOPSLA 2002 workshop on behavioural semantics},
title = {{Archetypes: Constraint-based domain models for future-proof information systems}},
volume = {105},
year = {2002}
}

@article{DiskinXiongC2011,
author = {Diskin, Zinovy and Xiong, Yingfei and Czarnecki, Krzysztof},
journal = {JOT 10},
pages = {1--25},
title = {{From State- to Delta-based Bidirectional Model Transformations: The Asymmetric Case}},
year = {2011}
}

@book{BarrWells,
abstract = {This book is a textbook in basic category theory, written specifically to be read by researchers and students in computing science. The authors expound the constructions basic to category theory in the context of examples and applications to computing science. Some categorical ideas and constructions are already used heavily in computing sciences and many of these use are described. Other ideas, in particular the concept of adjoint have not appeared as widely in the computing science literature. The authors give an elementary exposition of those ideas they believe to be basic categorical tools, with pointers to possible application. Michael Barr is Peter Redpath Professor in the Department of Mathematics and Statistics at McGill University in Montreal, Quebec. Charles Wells is Professor of Mathematics at Case Western Reserve University in Cleveland, Ohio. This new edition contains all the material from the first and second editions, including the four chapters excised from the second edition and the solutions to all the exercises, as well as added material on factorization systems, monoidal categories, and other topics. All errors known to the authors have been corrected.},
author = {Barr, Michael and Wells, Charles},
booktitle = {Computing},
file = {:Users/past/Documents/phd/literature/articles/books/BarrWells.pdf:pdf},
isbn = {0131204866},
pages = {556},
title = {{Category Theory for Computing Science}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Category+Theory+for+Computing+Science{\#}0},
volume = {1},
year = {1998}
}
@article{Buneman:2002:OPDAtV,
annote = {Reference for BX criteria minimality of changes},
author = {Buneman, Peter and Khanna, Sanjeev and Tan, Wang-Chiew},
doi = {10.1145/543613.543633},
file = {:Users/past/Documents/phd/literature/articles/articles/Buneman{\_}2002{\_}OPDAtV.pdf:pdf},
isbn = {1581135076},
journal = {Proceedings of the twenty-first ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems - PODS '02},
pages = {150},
title = {{On propagation of deletions and annotations through views}},
url = {http://portal.acm.org/citation.cfm?doid=543613.543633},
year = {2002}
}
@article{Greenwald:2003:ALfBTT,
abstract = {Publication View. 43428312. - (2007).},
annote = {UNREAD, seems to be the principal paper about BX},
author = {Greenwald, M and Moore, J and Pierce, B and Schmitt, A},
file = {:Users/past/Documents/phd/literature/articles/articles/Greenwald{\_}2003{\_}ALfBTT.pdf:pdf},
journal = {En.Scientificcommons.Org},
keywords = {lenses},
pages = {1--42},
title = {{A Language for Bi-Directional Tree Transformations}},
url = {http://en.scientificcommons.org/43428312},
year = {2007}
}
@book{BrambillaCabotW2017,
author = {Brambilla, Marco and Cabot, Jordi and Wimmer, Manuel},
edition = {2nd},
isbn = {1608458822, 9781608458820},
publisher = {Morgan {\&} Claypool Publishers},
title = {{Model-Driven Software Engineering in Practice}},
year = {2017}
}
@article{Voigtlander2009,
address = {New York, NY, USA},
annote = {UNREAD, but seems to be very interesting},
author = {Voigtl{\"{a}}nder, Janis},
doi = {10.1145/1594834.1480904},
file = {:Users/past/Documents/phd/literature/articles/articles/Voigtlander{\_}2009{\_}BfF.pdf:pdf},
issn = {0362-1340},
journal = {SIGPLAN Not.},
keywords = {bidirectionalization,free theorems,generic programming,haskell,program transformation,relational parametricity,view-update problem},
month = {jan},
number = {1},
pages = {165--176},
publisher = {ACM},
title = {{Bidirectionalization for Free! (Pearl)}},
url = {http://doi.acm.org/10.1145/1594834.1480904},
volume = {44},
year = {2009}
}
@article{Antkiewicz:2008:DSoHS,
abstract = {This tutorial explores the design space of heterogeneous synchronization, which is concerned with establishing consistency among artifacts that conform to different schemas or are expressed in different languages. Our main application scenario is synchronization of software artifacts, such as code, models, and configuration files. We classify heterogeneous synchronizers according to the cardinality of the relation that they enforce between artifacts, their directionality, their incrementality, and whether they support reconciliation of concurrent updates. We then provide a framework of artifact operators that describes different ways of building heterogeneous synchronizers, such as synchronizers based on artifact or update translation. The design decisions within the framework are described using feature models. We present 16 concrete instances of the framework, discuss tradeoffs among them, and identify sample implementations for some of them. We also explore additional design decisions such as representation of updates, establishing correspondence among model elements, and strategies for selecting a single synchronization result from a set of alternatives. Finally, we discuss related fields including data synchronization, inconsistency management in software engineering, model management, and model transformation.},
annote = {UNREAD; concerned with BX in MDSE},
author = {Antkiewicz, M. and Czarnecki, Krzysztof},
doi = {10.1007/978-3-540-88643-3-1},
file = {:Users/past/Documents/phd/literature/articles/articles/Antkiewicz{\_}2008{\_}DSoHS.pdf:pdf},
isbn = {3540886427},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {Gttse},
pages = {3--46},
title = {{Design space of heterogeneous synchronization}},
volume = {5235 LNCS},
year = {2008}
}
@inproceedings{Green:2009:RD,
annote = {Needed reference for BX criteria "incrementality"},
author = {Green, Todd J. and Ives, Zachary G. and Tannan, Val},
booktitle = {Proceedings of the 12th International Conference on Database Theory},
file = {:Users/past/Documents/phd/literature/articles/articles/Green{\_}2009{\_}RD.pdf:pdf},
isbn = {9781605584232},
pages = {212--224},
title = {{Reconcilable differences}},
volume = {12},
year = {2009}
}
@inproceedings{Berdaguer:2007:CSTaDT,
address = {Berlin, Heidelberg},
author = {Berdaguer, Pablo and Cunha, Alcino and Pacheco, Hugo and Visser, Joost},
booktitle = {Proceedings of the 9th International Conference on Practical Aspects of Declarative Languages},
doi = {10.1007/978-3-540-69611-7_19},
file = {:Users/past/Documents/phd/literature/articles/articles/Berdaguer{\_}2007{\_}CSTaDT.pdf:pdf},
isbn = {3-540-69608-3, 978-3-540-69608-7},
keywords = {Haskell,SQL,XML,transformation},
pages = {290--304},
publisher = {Springer-Verlag},
series = {PADL'07},
title = {{Coupled Schema Transformation and Data Conversion for XML and SQL}},
url = {http://dx.doi.org/10.1007/978-3-540-69611-7{\_}19},
year = {2007}
}
@article{Bancilhon:1981:USoRV,
address = {New York, NY, USA},
annote = {UNREAD, BX in Databases},
author = {Bancilhon, F and Spyratos, N},
doi = {10.1145/319628.319634},
file = {:Users/past/Documents/phd/literature/articles/articles/Bancilhon{\_}1989{\_}USoRV.pdf:pdf},
issn = {0362-5915},
journal = {ACM Trans. Database Syst.},
keywords = {conceptual model,data model,data semantics,database view,relation,relational model database,update translation,view updating},
month = {dec},
number = {4},
pages = {557--575},
publisher = {ACM},
title = {{Update Semantics of Relational Views}},
url = {http://doi.acm.org/10.1145/319628.319634},
volume = {6},
year = {1981}
}
@inproceedings{Yokoyama:2008:PoaRPL,
address = {New York, NY, USA},
author = {Yokoyama, Tetsuo and Axelsen, Holger Bock and Gl{\"{u}}ck, Robert},
booktitle = {Proceedings of the 5th Conference on Computing Frontiers},
doi = {10.1145/1366230.1366239},
file = {:Users/past/Documents/phd/literature/articles/articles/Yokoyama{\_}2008{\_}PoaRPL.pdf:pdf},
isbn = {978-1-60558-077-7},
keywords = {backward determinism,fast fourier transform,inverse semantics,reversible computing,turing completeness},
pages = {43--54},
publisher = {ACM},
series = {CF '08},
title = {{Principles of a Reversible Programming Language}},
url = {http://doi.acm.org/10.1145/1366230.1366239},
year = {2008}
}
@techreport{Pierce:2003LaVUT,
author = {Pierce, Benjamin C and Schmitt, Alan},
file = {:Users/past/Documents/phd/literature/articles/articles/Pierce{\_}2003{\_}LaVUT.pdf:pdf},
pages = {1--7},
title = {{Lenses and View Update Translation}},
year = {2003}
}
@inproceedings{Diskin:2008:AMB,
address = {Berlin, Heidelberg},
author = {Diskin, Zinovy},
booktitle = {Proceedings of the 11th International Conference on Model Driven Engineering Languages and Systems},
doi = {10.1007/978-3-540-87875-9_2},
isbn = {978-3-540-87874-2},
pages = {21--36},
publisher = {Springer-Verlag},
series = {MoDELS '08},
title = {{Algebraic Models for Bidirectional Model Synchronization}},
url = {https://doi.org/10.1007/978-3-540-87875-9{\_}2},
year = {2008}
}
@article{Taentzer:2005:MTbGTACS,
abstract = {Graph transformation has been widely used for expressing model transformations. Especially transformations of visual models can be naturally formulated by graph transformations, since graphs are well suited to describe the underlying structures of models. Based on a common sample model transformation, four different model transformation approaches are presented which all perform graph transformations. At first, a basic solution is presented and crucial points of model transformations are indicated. Subsequent solutions focus mainly on the indicated problems. Finally, a first comparison of the chosen approaches to model transformation is presented where the main ingredients of each approach are summarized},
author = {Taentzer, Gabriele and Ehrig, Karsten and Guerra, Esther and Lara, Juan De and Levendovszky, Tiham{\'{e}}r and Prange, Ulrike and Varro, Daniel and Varro-Gyapay, Szilvia},
file = {:Users/past/Documents/phd/literature/articles/articles/Taentzer{\_}2005{\_}MTbGTACS.pdf:pdf},
issn = {19666608},
journal = {Model Transformations in Practice Workshop at MODELS 2005, Montego},
title = {{Model Transformation by Graph Transformation : A Comparative Study}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.2827{\&}rep=rep1{\&}type=pdf},
year = {2005}
}
@inproceedings{CzarneckiFosterHLST2009,
abstract = {The GRACE International Meeting on Bidirectional Trans-formations was held in December 2008 near Tokyo, Japan. The meeting brought together researchers and practitioners from a variety of sub-disciplines of computer science to share research efforts and help create a new community. In this report, we survey the state of the art and summarize the technical presentations delivered at the meeting. We also describe some insights gathered from our discussions and introduce a new effort to establish a benchmark for bidirectional transformations.},
annote = {Read on 2.10.2017; Very interesting overview about BX in different discilplines; might be a god foundation for my work; has also a lot of references to applications of BX},
author = {Czarnecki, Krzysztof and Foster, Nathan and Hu, Zhenjiang and L{\"{a}}mmel, Ralf and Sch{\"{u}}rr, Andy and Terwilliger, James F},
booktitle = {ICMT 2009},
file = {:Users/past/Documents/phd/literature/articles/articles/Czarnecki{\_}2009{\_}BXCD.pdf:pdf},
keywords = {BX,Bidirectional transformation},
pages = {193--204},
title = {{Bidirectional Transformations: A Cross-Discipline Perspective}},
year = {2009}
}
@inproceedings{Stevens2017,
 author={Stevens, Perdita},
  booktitle={2017 ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems (MODELS)}, 
  title={Bidirectional Transformations in the Large}, 
  year={2017},
  volume={},
  number={},
  pages={1-11},
  doi={10.1109/MODELS.2017.8}
 }
@article{Lammel2006,
abstract = {Whatever programming paradigm for data processing we choose, data has the tendency to live on the other side or to eventually end up there. The major paradigms for data processing are Cobol, object, relational and XML; each paradigm offers many facets and many versions; each paradigm provides specific forms of data models (object models, relational schemas, XML schemas, etc.). Each data-processing application depends on a horde of interrelated data models and artifacts that are derived from data models (such as data-access layers). Such conglomerations of data models are challenging due to paradigmatic impedance mismatches, performance requirements, loose-coupling requirements, and others. This ubiquitous problem calls for a good understanding of techniques for mappings between data models, actual data, and operations on data. This tutorial lists and discusses mapping scenarios, mapping techniques, impedance mismatches and research challenges regarding mappings.},
annote = {Unread, might be an interesting read though as its very hands on and closer on the code},
author = {L{\"{a}}mmel, Ralf and Meijer, Erik},
doi = {10.1007/11877028_6},
file = {:Users/past/Documents/phd/literature/articles/articles/Laemmel{\_}2006{\_}MDPGR.pdf:pdf},
isbn = {3-540-45778-X, 978-3-540-45778-7},
issn = {16113349},
journal = {Gttse},
keywords = {cross paradigm impedance mismatch,data access,data mod,data processing,eling,loose coupling,mapping,object relational mapping,object xml map,ping,software evolution,xml data binding},
pages = {169--218},
title = {{Mappings Make Data Processing Go ' Round An Inter-paradigmatic Mapping Tutorial}},
url = {http://www.springerlink.com/content/v460555157322w87/},
year = {2006}
}

@incollection{Diskin2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Model {Synchronization}: {Mappings}, {Tiles}, and {Categories}},
	isbn = {978-3-642-18023-1},
	shorttitle = {Model {Synchronization}},
	abstract = {The paper presents a novel algebraic framework for specification and design of model synchronization tools. The basic premise is that synchronization procedures, and hence algebraic operations modeling them, are diagrammatic: they take a configuration (diagram) of models and mappings as their input and produce a diagram as the output. Many important synchronization scenarios are based on diagram operations of square shape. Composition of such operations amounts to their tiling, and complex synchronizers can thus be assembled by tiling together simple synchronization blocks. This gives rise to a visually suggestive yet precise notation for specifying synchronization procedures and reasoning about them.},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {{GTTSE} 2009},
	publisher = {Springer Berlin Heidelberg},
	author = {Diskin, Zinovy},
	editor = {Fernandes, João M. and Lämmel, Ralf and Visser, Joost and Saraiva, João},
	year = {2009},
	doi = {10.1007/978-3-642-18023-1_3},
	keywords = {Class Diagram, Model Synchronization, Diagram Operation, Graph Mapping, Synchronization Procedure, DiskinModelMM},
	pages = {92--165},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/TVP4QVU2/Diskin - 2011 - Model Synchronization Mappings, Tiles, and Catego.pdf:application/pdf}
}
@inproceedings{SabetzadehEasterbrook2005,
abstract = {View merging is an important activity in any conceptual modeling language. It is often desirable to combine a set of views to gain a unified perspective, to test hypotheses about how views are related, or to perform various types of analysis. A major challenge for view merging is toleration of incompleteness and inconsistency: views may be inconclusive, and may have conflicts over the concepts being modeled or how they are structured. Drawing on the theory developed in our earlier work (2003), we present a view merging tool, called iVuBlender, that allows for explicit modeling of incompleteness and inconsistency and provides a framework for interconnecting and merging incomplete and inconsistent views.},
annote = {UNREAD, might be very interesting as this seems to be the principal paper employing view merging},
author = {Sabetzadeh, M and Easterbrook, Steve},
file = {:Users/past/Documents/phd/literature/articles/articles/Sabetzadeh{\_}2005{\_}AFMIIV.pdf:pdf},
booktitle = {RE 2005},
keywords = {Modeling},
pages = {306--315},
title = {{An Algebraic Framework for Merging Incomplete and Inconsistent Views}},
year = {2005}
}
@article{Amrani_2015:FVTATD,
author = {Amrani, Moussa and Combemale, Benoit and L{\'{u}}cio, Levi and Selim, Gehan M K and Dingel, J{\"{u}}rgen and {Le Traon}, Yves and Vangheluwe, Hans and Cordy, James R},
file = {:Users/past/Documents/phd/literature/articles/articles/Amrani{\_}2015{\_}FVATD.pdf:pdf},
journal = {Journal of Object Technology},
number = {3},
publisher = {Association Internationale pour les Technologies Objets},
title = {{Formal verification techniques for model transformations: A tridimensional classification}},
volume = {14},
year = {2015}
}
@article{DiskinEasterbrookD2008,
abstract = {Association between classes is a central construct in OO modeling. However, precise semantics of associations has not been defined, and only the most basic types are implemented in modern forward and reverse engineering tools. In this paper, we present a novel mathematical framework and build a precise semantics for several association constructs, whose implementation has been considered problematic. We also identify a number of patterns for using associations in practical applications, which cannot be modeled (reverse engineered) in UML.},
annote = {Concerned with semantics of associations,might be interesting for the RE questions},
author = {Diskin, Zinovy and Easterbrook, Steve and Dingel, Juergen},
journal = {Objects, Components, Models and Patterns},
pages = {336--355},
title = {{Engineering Associations: From Models to Code and Back through Semantics}},
year = {2008}
}
@article{Lamo2013,
annote = {Seems pretty interesting, to learn more about graph transformations and is also concerned with bidirectionality},
author = {Lamo, Yngve and Mantz, Florian and Rutle, Adrian and de Lara, Juan},
file = {:Users/past/Documents/phd/literature/articles/articles/Lamo{\_}2013{\_}DBTA.pdf:pdf},
isbn = {9781450321549},
journal = {PPDP '13},
keywords = {bidirectionality,category theory,declarative model transforma-,model-driven engineering,tions},
pages = {1--12},
title = {{A declarative and bidirectional model transformation approach based on graph co-spans}},
year = {2013}
}
@article{Taentzer2017,
annote = {Partly read before the interview

might be sometime interesting for a second look and and check out model transformation and how they assure consistency preservation},
author = {Taentzer, Gabriele and Ohrndorf, Manuel and Lamo, Yngve and Rutle, Adrian},
doi = {10.1007/978-3-662-54494-5_16},
file = {:Users/past/Documents/phd/literature/articles/articles/Taentzer{\_}2017{\_}CPMR.pdf:pdf},
isbn = {9783662544938},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Graph transformation,Model repair,Model-based engineering},
pages = {283--299},
title = {{Change-preserving model repair}},
volume = {10202 LNCS},
year = {2017}
}
@article{Egyed2007,
abstract = {Changes are inevitable during software development and so are their unintentional side effects. The focus of this paper is on UML design models, where unintentional side effects lead to inconsistencies. We demonstrate that a tool can assist the designer in discovering unintentional side effects, locating choices for fixing inconsistencies, and then in changing the design model. Our techniques are "on-line, " applied as the designer works, and non-intrusive, without overwhelming the designer. This is a significant improvement over the state-of-the-art. Our tool is fully integrated with the design tool IBM Rational Rosetrade. It was empirically evaluated on 48 case studies.},
annote = {Read before the interview

Seems to be somewhat a classic to refer to when dealing with the multi-view-model world.},
author = {Egyed, Alexander},
doi = {10.1109/ICSE.2007.38},
file = {:Users/past/Documents/phd/literature/articles/articles/Egyed{\_}2007{\_}FIiUMLDM.pdf:pdf},
isbn = {0769528287},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
pages = {292--301},
title = {{Fixing inconsistencies in UML design models}},
year = {2007}
}
@article{Lopez-Herrejon2010,
abstract = {Multi-View Modeling (MVM) is a common modeling practice that advocates the use of multiple, different and yet related models to represent the needs of diverse stakeholders. Of crucial importance in MVM is consistency checking — the description and verification of semantic relationships amongst the views. Variability is the capacity of software artifacts to vary, and its effective management is a core tenet of the research in Software Product Lines (SPL). MVM has proven useful for developing one-of-a-kind systems; however, to reap the potential benefits of MVM in SPL it is vital to provide consistency checking mechanisms that cope with variability. In this paper we describe how to address this need by applying Safe Composition — the guarantee that all programs of a product line are type safe. We evaluate our approach with a case study.},
annote = {Read before the intervew

General its about software product lines, and how to check consistencies (Horn Formulas) on them},
author = {Lopez-Herrejon, Roberto Erick and Egyed, Alexander},
doi = {10.1007/978-3-642-13595-8_18},
file = {:Users/past/Documents/phd/literature/articles/articles/Herrejon{\_}2010{\_}DIMVM.pdf:pdf},
isbn = {3642135943},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {217--232},
title = {{Detecting inconsistencies in multi-view models with variability}},
volume = {6138 LNCS},
year = {2010}
}
@inproceedings{Lammel2004,
abstract = {We identify the category of coupled software transfor- mations, which comprises transformation scenarios involv- ing two or more artifacts that are coupled in the following sense: transformation at one end necessitates reconciling transformations at other ends such that global consistency is reestablished. We describe the essence of coupled trans- formations. We substantiate that coupled transformation problems are widespread and diverse.},
author = {L{\"{a}}mmel, Ralf},
booktitle = {Proceedings 1st International Workshop on Software Evolution Transformations},
file = {:Users/past/Documents/phd/literature/articles/articles/Laemmel{\_}2014{\_}CX.pdf:pdf},
pages = {31--35},
title = {{Coupled software transformations (Extended Abstract)}},
year = {2014}
}
@article{MantzTaentzerLW2015,
abstract = {Model-driven engineering focuses on models as primary artifacts of the software development process, which means programs are mainly generated by model-to-code transformations. In particular, modeling languages tailored to specific domains promise to increase the productivity of software developers and the quality of generated software. Modeling languages, however, evolve over time and therefore, existing models have to be migrated accordingly. The manual migration of models tends to be tedious and error-prone, therefore tools have been developed to (partly) automate this process. Nevertheless, the migration results may not always be well-defined. In this article, we provide a formal framework for model migration which is independent of specific modeling approaches. We treat modeling languages, formalized by metamodels, as well as models as graphs and consider their co-evolutions as coupled graph transformations. In the same line, we study the conditions under which model migrations are well-defined. Existing solutions to model migration are either handwritten or default solutions that can hardly be customized. Here, we introduce a high-level specification approach, called model migration schemes, that supports automation and customization. Starting from a meta-model evolution rule, a default migration scheme can be automatically deduced and customized.},
annote = {Unread; seems to be a shorter explanation of the coupled transformations from Florian Mantzs phd thesis},
author = {Mantz, Florian and Taentzer, Gabriele and Lamo, Yngve and Wolter, Uwe},
doi = {10.1016/j.scico.2015.01.002},
isbn = {01676423 (ISSN)},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {Graph transformation,Meta-model evolution,Model migration},
number = {1},
pages = {2--43},
publisher = {Elsevier B.V.},
title = {{Co-evolving meta-models and their instance models: A formal approach based on graph transformation}},
volume = {104},
year = {2015}
}
@article{Johnson:2017:SDaADL,
abstract = {Bidirectional Transformations provide mechanisms for main- taining synchronization between updatable data sources. Lenses are cer- tain mathematically specified bidirectional transformations. As part of a project to unify the treatment of symmetric lenses (of various kinds) as equivalence classes of spans of asymmetric lenses (of corresponding kinds), we relate symmetric delta lenses with spans of asymmetric delta lenses. Because delta lenses are based on state spaces which are categories rather than sets, there is further structure that needs to be accounted for. One of the main findings in this paper is that the required equivalence rela- tion among spans is compatible with, but coarser than, the one expected. The main result is an isomorphism of categories between a category whose morphisms are equivalence classes of symmetric delta lenses (here called fb-lenses) and the category of spans of delta lenses modulo the new equiv- alence.},
annote = {UNREAD, might be a very interisting read as well to understand Harald better},
author = {Johnson, Michael and Rosebrugh, Robert},
doi = {10.5381/jot.2017.16.1.a2},
file = {:Users/past/Documents/phd/literature/articles/articles/Johnson{\_}2017{\_}SDaADL.pdf:pdf},
issn = {1660-1769},
journal = {The Journal of Object Technology},
number = {1},
pages = {2:1},
title = {{Symmetric delta lenses and spans of asymmetric delta lenses.}},
url = {http://www.jot.fm/contents/issue{\_}2017{\_}01/article2.html},
volume = {16},
year = {2017}
}
@article{DiskinKokalyM2013,
abstract = {Megamodeling is the activity of specifying systems of models and mappings, their properties, and operations over them. The latter functionality is the most important for applications, and megamodels are often used as an abstract workflow language for model processing. To be independent of a particular modeling language, typical megamodels reduce relationships between models to unstructured edges encoding nothing but a labeled pair of models, thus creating a significant gap between megamodels and code implementing them. To bridge the gap, we propose mapping-aware megamodels, which treat edges as model mappings: structured sets of links (pairs of model elements) rather than pairs of models. The workflow can then be represented as an algebraic term built from elementary operations with models and model mappings.},
author = {Diskin, Zinovy and Kokaly, Sahar and Maibaum, Tom},
doi = {10.1007/978-3-319-02654-1\_18},
isbn = {9783319026534},
issn = {03029743},
journal = {LNCS},
pages = {322--343},
title = {{Mapping-aware megamodeling: Design patterns and laws}},
volume = {8225},
year = {2013}
}
@misc{OMG2016QVT,
author = "{Object Management Group}",
file = {:Users/past/Documents/phd/literature/articles/misc/omg{\_}2016{\_}qvt.pdf:pdf},
title = {{Meta Object Facility (MOF) 2.0 Query/View/Transformation (QVT) v.1.3}},
howpublished={\url{http://www.omg.org/spec/QVT/1.3}},
url = {http://www.omg.org/spec/QVT/1.3},
year = {2016}
}
@inproceedings{Lammel:2016:CSTr,
address = {New York, NY, USA},
annote = {Read on 15.09.2017
---------------------------

notes in printed copy on desk, needs maybe a 2nd view},
author = {L{\"{a}}mmel, Ralf},
booktitle = {ICSLE 2016},
isbn = {978-1-4503-4447-0},
keywords = {BX,Bidirectional transformation,CX,Coupled software transformation,Linguistic architecture,Logic programming,Megamodeling,Predicate logic,Testing},
pages = {239--252},
publisher = {ACM},
series = {SLE 2016},
title = {{Coupled Software Transformations Revisited}},
year = {2016}
}
@inproceedings{Petersen:2008:SMSE,
address = {Swindon, UK},
annote = {Read on 12.09.2017
---------------------------},
author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
booktitle = {Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering},
file = {:Users/past/Documents/phd/literature/articles/articles/Petersen{\_}2008{\_}SMSE.pdf:pdf},
keywords = {evidence based software engineering,systematic mapping studies,systematic reviews},
pages = {68--77},
publisher = {BCS Learning {\&} Development Ltd.},
series = {EASE'08},
title = {{Systematic Mapping Studies in Software Engineering}},
year = {2008}
}
@inproceedings{KoenigDiskin2017,
abstract = {Software design normally requires a collection of interdependent models conforming to different metamodels. These multi-models present different views of interest and may be consistent only if they simultaneously satisfy a set of inter-model constraints. A straightforward approach to inter-model consistency checking is to run constraint validations on the model union (merge). If, in model repairing scenarios, single constraints are (re-)checked, these validations are carried out on a small view (localization) of a big model merge. This ``merge-prior-to-localization''-approach is not efficient, because of considerable matching and merging workload. We propose to perform early localization in order to reduce the data space being subject to commonality search. The algorithm is based on a new method to formally specify the inter-relation of an arbitrary number of heterogeneously typed models.},
annote = {Very early read, even before the application

Improvement of an ealier paper by Koenig and Diskin which promotes the usage of early localization for checking of inter model constraints in an n-ary scenario},
author = {K{\"{o}}nig, Harald and Diskin, Zinovy},
booktitle = {ECMFA 2017},
file = {:Users/past/Documents/phd/literature/articles/articles/Koenig{\_}2017{\_}ECCoIM.pdf:pdf},
isbn = {978-3-319-61482-3},
pages = {161--178},
title = {{Efficient Consistency Checking of Interrelated Models}},
year = {2017},
doi = {10.1007/978-3-319-61482-3_10}
}

@article{Stevens2008,
abstract = {We consider the OMG's queries, views and transformations standard as applied to the specification of bidirectional transformations between models. We discuss what is meant by bidirectional transformations, and the model-driven development scenarios in which they are needed. We analyse the fundamental requirements on tools which support such transformations, and discuss some semantic issues which arise. In particular, we show that any transformation language sufficient to the needs of model-driven development would have to be able to express non-bijective transformations. We argue that a considerable amount of basic research is needed before suitable tools will be fully realisable, and suggest directions for this future research.},
author = {Stevens, Perdita},
doi = {10.1007/s10270-008-0109-9},
issn = {1619-1374},
journal = {Software {\&} Systems Modeling},
month = {dec},
number = {1},
pages = {7},
title = {{Bidirectional model transformations in QVT: semantic issues and open questions}},
url = {https://doi.org/10.1007/s10270-008-0109-9},
volume = {9},
year = {2008}
}
@article{BroyFeilkasHMR2010,
abstract = {More than 20 years of research has created a large body of ideas, concepts, and theories for model-based development of embedded software-intensive systems. These approaches have been implemented by several tools and successfully applied to various development projects. However, the everyday use of model-based approaches in the automotive and avionic industries is still limited. Most of the time, the engineers work with a predefined set of isolated tools, and therefore adapt their engineering methods and process to the available tools. Today, the industry achieves tool integration by demand-driven, pragmatic, and ad-hoc composed chains of a priori existent commercial tools. Nevertheless, these tool chains are not (and cannot be) seamless, since the integration that can be achieved is not deep enough. This hampers the reuse and refinement of models, which subsequently leads to problems like redundancy, inconsistency, and lack of automation. In the end, these deficiencies decrease both the productivity and quality that could be provided by model-based approaches. To overcome these problems, a deep, coherent, and comprehensive integration of models and tools is required. Such an integration can be achieved by the following three ingredients: 1) a comprehensive modeling theory that serves as a semantic domain for the models, 2) an integrated architectural model that holistically describes the product and process, and 3) a manner to build tools that conform to the modeling theory and allow the authoring of the product model. We show that from a scientific point of view, all ingredients are at our hands to do a substantial step into an integrated process and tool world. Further, we illustrate why such a solution has not been achieved so far, and discuss what is to be done to get a step closer to seamless model-based engineering.},
annote = {Early read during the interview
---------------------------------------

Proposes integrated modeling environments to facialite the usage of MDSE in practice

Might be worth a second read for references and after having a stronger theoretic background},
author = {Broy, M and Feilkas, M and Herrmannsdoerfer, M and Merenda, S and Ratiu, D},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Aerospace electronics,Automation,Automotive engineering,Common model repository,Design engineering,Embedded system,Productivity,Programming,Refining,Software tools,ad-hoc composed tool chains,automobile industry,automotive industry,avionic industry,avionics,commercial tools,comprehensive modeling theory,embedded software-intensive systems,embedded systems,generic tooling platform,integrated architectural model,integrated engineering environments,integrated model engineering environments,isolated tools,iterative language engineering,model-based development,production engineering computing,seamless model-based development,software engineering,tool building manner,workflow support},
month = {apr},
number = {4},
pages = {526--545},
title = {{Seamless Model-Based Development: From Isolated Tools to Integrated Model Engineering Environments}},
volume = {98},
year = {2010}
}
@inproceedings{Diskin:2011:FStDBXSC,
abstract = {A bidirectional transformation (BX) keeps a pair of interrelated models synchronized. Symmetric BXs are those for which neither model in the pair fully determines the other. We build two algebraic frameworks for symmetric BXs, with one correctly implementing the other, and both being delta-based generalizations of known state-based frameworks. We identify two new algebraic laws-weak undoability and weak invertibility, which capture important semantics of BX and are useful for both state- and delta-based settings. Our approach also provides a flexible tool architecture adaptable to different user's needs.},
address = {Berlin, Heidelberg},
annote = {UNREAD, but important to read to understand what symmetric views are},
author = {Diskin, Zinovy and Xiong, Yingfei and Czarnecki, Krzysztof and Ehrig, Hartmut and Hermann, Frank and Orejas, Fernando},
booktitle = {Model Driven Engineering Languages and Systems: 14th International Conference, MODELS 2011, Wellington, New Zealand, October 16-21, 2011. Proceedings},
doi = {10.1007/978-3-642-24485-8\_22},
editor = {Whittle, Jon and Clark, Tony and K{\"{u}}hne, Thomas},
file = {:Users/past/Documents/phd/literature/articles/articles/Diskin{\_}2011{\_}FStDBXSC.pdf:pdf},
isbn = {978-3-642-24485-8},
pages = {304--318},
publisher = {Springer Berlin Heidelberg},
title = {{From State- to Delta-Based Bidirectional Model Transformations: The Symmetric Case}},
url = {https://doi.org/10.1007/978-3-642-24485-8{\_}22},
year = {2011}
}
@article{FosterGreenwaldMPS2007,
address = {New York, NY, USA},
annote = {UNREAD, is however very interesting as this seems to be one of the principal BX papers},
author = {Foster, J Nathan and Greenwald, Michael B and Moore, Jonathan T and Pierce, Benjamin C and Schmitt, Alan},
doi = {10.1145/1232420.1232424},
file = {:Users/past/Documents/phd/literature/articles/articles/Foster{\_}2007{\_}CBTT.pdf:pdf},
issn = {0164-0925},
journal = {ACM Trans. Program. Lang. Syst.},
keywords = {Bidirectional programming,Harmony,XML,lenses,view update problem},
month = {may},
number = {3},
publisher = {ACM},
title = {{Combinators for Bidirectional Tree Transformations: A Linguistic Approach to the View-update Problem}},
volume = {29},
year = {2007}
}
@inproceedings{KoenigLoeweS2011,
abstract = {Software restructuring and refactoring facilitate the use of models as primary artifacts. Model evolution becomes agile if consistency between evolving models and depending artifacts is spontaneously maintained. In this paper we study endogenous model transformations at medium or fine granularity with impact on data structures and objects. We propose a formal framework in which transformation rules for class models can be formulated, whose application induces automatic migration of corresponding data structures. The main contribution is a correctness criterion for rule-induced instance migration based on initial semantics.},
address = {Berlin, Heidelberg},
author = {K{\"{o}}nig, Harald and L{\"{o}}we, Michael and Schulz, Christoph},
booktitle = {SBMF 2011},
editor = {Simao, Adenilso and Morgan, Carroll},
isbn = {978-3-642-25032-3},
pages = {1--15},
publisher = {Springer Berlin Heidelberg},
title = {{Model Transformation and Induced Instance Migration: A Universal Framework}},
year = {2011}
}
@inproceedings{SabetzedahNejatiLEC2007,
author = {Sabetzadeh, M and Nejati, S and Liaskos, S and Easterbrook, S and Chechik, M},
booktitle = {RE 2007},
file = {:Users/past/Documents/phd/literature/articles/articles/Sabetzedah{\_}2007{\_}CCvMM.pdf:pdf},
issn = {1090-705X},
keywords = {conceptua,formal specification,formal verification},
month = {oct},
pages = {221--230},
title = {{Consistency Checking of Conceptual Models via Model Merging}},
year = {2007}
}
@article{RabbiLamoM2014,
abstract = {Due to their complexity and the plethora of requirements placed upon them, healthcare systems so far have not been adequately modeled for the purpose of software development. As a result, the healthcare software suffers from high development costs and lack of flexibility. Model driven software engineering (MDSE) is an emerging methodology for software development, targeting productivity, flexibility and reliability of systems; metamodelling is at the core of most MDSE approaches. In previous work, we proposed a multi metamodelling approach that captures the complexity of these systems by using a metamodelling hierarchy, built from individually defined metamodels, each capturing different aspects of a healthcare domain, namely, user access modelling, health process modelling, process monitoring, user interface modelling and modelling of the data sources. Here, we formalize the co-ordination among metamodels, using a linguistic extension of the metamodelling hierarchy. This linguistic extension is an added metalevel which models the integration of two or more different aspects of the system. We focus on two features essential to the co-ordination of healthcare metamodels, namely the integration of process and data, modelling data-aware processes, and the integration of process and user, modelling both user access as well as inheritance of user access to tasks.},
author = {Rabbi, Fazle and Lamo, Yngve and MacCaull, Wendy},
doi = {10.1016/j.procs.2014.08.071},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Co-ordination among metamodels,Healthcare information systems,Linguistic extension,Model driven software engineering,Multi metamodelling,Multi-Metamodels,Multimodelling},
number = {1877},
pages = {473--480},
publisher = {Elsevier Masson SAS},
title = {{Co-ordination of multiple metamodels, with application to healthcare systems}},
url = {http://dx.doi.org/10.1016/j.procs.2014.08.071},
volume = {37},
year = {2014}
}
@inproceedings{Favre:2005:FMDEE2,
address = {Dagstuhl, Germany},
annote = {Keywords: models , reverse engineering , transformations},
author = {Favre, Jean-Marie},
booktitle = {Language Engineering for Model-Driven Software Development},
editor = {Bezivin, Jean and Heckel, Reiko},
file = {:Users/past/Documents/phd/literature/articles/articles/Favre{\_}2005{\_}FMDEE2.pdf:pdf},
issn = {1862-4405},
number = {04101},
publisher = {Internationales Begegnungs- und Forschungszentrum f{\"{u}}r Informatik (IBFI), Schloss Dagstuhl, Germany},
series = {Dagstuhl Seminar Proceedings},
title = {{Foundations of Meta-Pyramids: Languages vs. Metamodels -- Episode II: Story of Thotus the Baboon1}},
url = {http://drops.dagstuhl.de/opus/volltexte/2005/21},
year = {2005}
}
@inproceedings{Schuerr1994,
author="Sch{\"u}rr, Andy",
editor="Mayr, Ernst W.
and Schmidt, Gunther
and Tinhofer, Gottfried",
title="Specification of graph translators with triple graph grammars",
booktitle="Graph-Theoretic Concepts in Computer Science",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="151--163",
abstract="Data integration is a key issue for any integrated set of software tools. A typical CASE environment, for instance, offers tools for the manipulation of requirements and software design documents, and it provides more or less sophisticated assistance for keeping these documents in a consistent state. Up to now, almost all data consistency observing or preserving integration tools are hand-crafted due to the lack of generic implementation frameworks and the absence of adequate specification formalisms. Triple graph grammars are intended to fill this gap and to support the specification of interdependencies between graph-like data structures on a very high level. Furthermore, they are the fundamentals of a new machinery for the production of batch-oriented as well as incrementally working data integration tools.",
isbn="978-3-540-49183-5",
doi = {10.1007/3-540-59071-4_45}
}

@inproceedings{Favre:2005:FMDEE1,
address = {Dagstuhl, Germany},
author = {Favre, Jean-Marie},
booktitle = {Language Engineering for Model-Driven Software Development},
editor = {Bezivin, Jean and Heckel, Reiko},
file = {:Users/past/Documents/phd/literature/articles/articles/Favre{\_}2005{\_}FMDEE1.pdf:pdf},
issn = {1862-4405},
number = {04101},
publisher = {Internationales Begegnungs- und Forschungszentrum f{\"{u}}r Informatik (IBFI), Schloss Dagstuhl, Germany},
series = {Dagstuhl Seminar Proceedings},
title = {{Foundations of Model (Driven) (Reverse) Engineering : Models -- Episode I: Stories of The Fidus Papyrus and of The Solarus}},
url = {http://drops.dagstuhl.de/opus/volltexte/2005/13},
year = {2005}
}
@techreport{Kitchenham:2007:GfSLRiSE,
address = {Software Engineering Group School of Computer Science and Mathematics Keele University Keele, Staffs ST5 5BG, UK},
author = {Kitchenham, Barbara and Charters, Stuart and Budgen, David and Brereton, Pearl and Turner, Mark and Linkman, Steve and J{\o}rgensen, Magne and Mendes, Emilia and Visaggio, Guiseppe},
institution = {Evidence Based Software Engineering},
keywords = {"Methodology","Software Engineering","Systematic Literature Review"},
month = {jul},
number = {1},
title = {{Guidelines for performing Systematic Literature Reviews in Software Engineering}},
type = {techreport},
year = {2007}
}
@inproceedings{BoronatKnappMW2009,
abstract = {In large software projects often multiple modeling languages are used in order to cover the different domains and views of the application and the language skills of the developers appropriately. Such ``multi-modeling'' raises many methodological and semantical questions, ranging from semantic consistency of the models written in different sublanguages to the correctness of model transformations between the sublanguages. We provide a first formal basis for answering such questions by proposing semantically well-founded notions of a multi-modeling language and of semantic correctness for model transformations. In our approach, a multi-modeling language consists of a set of sublanguages and correct model transformations between some of the sublanguages. The abstract syntax of the sublanguages is given by MOF meta-models. The semantics of a multi-modeling language is given by associating an institution, i.e., an appropriate logic, to each of its sublanguages. The correctness of model transformations is defined by semantic connections between the institutions.},
address = {Berlin, Heidelberg},
annote = {Early read during the interview process


Might be interesting to take a second look especially for the references},
author = {Boronat, Artur and Knapp, Alexander and Meseguer, Jos{\'{e}} and Wirsing, Martin},
booktitle = {WADT 2008},
file = {:Users/past/Documents/phd/literature/articles/articles/Boronat{\_}2009{\_}WIMML.pdf:pdf},
pages = {71--87},
publisher = {Springer Berlin Heidelberg},
title = {{What Is a Multi-modeling Language?}},
year = {2009}
}
@article{HidakaTisiCH2016,
address = {Secaucus, NJ, USA},
author = {Hidaka, Soichiro and Tisi, Massimo and Cabot, Jordi and Hu, Zhenjiang},
issn = {1619-1366},
journal = {Softw. Syst. Model.},
keywords = {Bidirectional transformation,Domain analysis,Feature model},
month = {jul},
number = {3},
pages = {907--928},
publisher = {Springer-Verlag New York, Inc.},
title = {{Feature-based Classification of Bidirectional Transformation Approaches}},
volume = {15},
year = {2016}
}
@misc{Budgen::UsMSiSE,
author = {Budgen, David and Turner, Mark and Brereton, Pearl and Kitchenham, Barbara},
keywords = {evidence based software engineering,methodology,systematic mapping studies},
title = {{Using Mapping Studies in Software Engineering}}
}
@inproceedings{Bailey:2007:ErOOSDS,
author = {Bailey, John and Budgen, David and Turner, Mark},
booktitle = {Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2007.58},
publisher = {IEEE},
title = {{Evidence relating to Object-Oriented software design: A survey}},
year = {2007}
}
@inproceedings{DiskinXiongC2010a,
abstract = {Software development often involves a set of models defined in different metamodels, each model capturing a specific view of the system. We call this set a multimodel, and its elements partial or local models. Since partial models overlap, they may be consistent or inconsistent wrt. a set of global constraints.},
author = {Diskin, Zinovy and Xiong, Yingfei and Czarnecki, Krzysztof},
booktitle = {MDI@MODELS 2010},
file = {:Users/past/Documents/phd/literature/articles/articles/Diskin{\_}2011{\_}SOoHMfGCC.pdf:pdf},
pages = {165--179},
title = {{Specifying Overlaps of Heterogeneous Models for Global Consistency Checking}},
year = {2011}
}
@inproceedings{KoenigDiskin2016,
abstract = {Software design requires deployment of interdependent models conforming to different metamodels. This set of models is called a multimodel, and it must satisfy a set of global constraints regulating interaction of the multimodel components. A straightforward approach to global consistency checking would require merging component metamodels modulo their overlap, adding, perhaps, new global constraints to this merge, merging component models modulo their overlap, and checking the latter merge against the constraints in the former one. Being a natural definition for global consistency, these steps can not be used algorithmically because of two major practical drawbacks: they involve costly (meta)model matching to specify overlaps, and require building big and unfeasible merged metamodels and models.},
author = {K{\"{o}}nig, Harald and Diskin, Zinovy},
booktitle = {ECMFA 2016},
file = {:Users/past/Documents/phd/literature/articles/articles/Koenig{\_}2016{\_}ALCCofGCiHM.pdf:pdf},
isbn = {978-3-319-42061-5},
pages = {19--35},
doi = {10.1007/978-3-319-42061-5_2},
title = {{Advanced Local Checking of Global Consistency in Heterogeneous Multimodeling}},
year = {2016}
}
@article{FavreNGuyen2005,
annote = {Proceedings of the Workshop on Software Evolution through Transformations: Model-based vs. Implementation-level Solutions (SETra 2004)},
author = {Favre, Jean-Marie and NGuyen, Tam},
doi = {https://doi.org/10.1016/j.entcs.2004.08.034},
file = {:Users/past/Documents/phd/literature/articles/articles/Favre{\_}2005{\_}TMSETT.pdf:pdf},
issn = {1571-0661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {mda,megamodel,meta-model,model driven engineering,software evolution},
number = {3},
pages = {59--74},
title = {{Towards a Megamodel to Model Software Evolution Through Transformations}},
volume = {127},
year = {2005}
}
@inproceedings{BezivinJouaultRVAAR2005,
abstract = {As part of the AMMA project (ATLAS Model Management Architecture), we are currently building several model management tools to support the tasks of modeling in the large and of modeling in the small. The basic idea is to define an experimental framework based on the principle of models as first class entities. This allows us to investigate issues of conceptual and practical interest in the field of model management applied to data-intensive applications. By modeling in the small, we mean dealing with model and metamodel elements and the relations between them. In this sense, ATL (ATLAS Transformation Language) allows expressing automatic model transformations. We also motivate the need for the ``ModelWeaver'' which handles fine-grained relationships between elements of different metamodels with a different purpose than automatic model transformation. By modeling in the large, we mean globally dealing with models, metamodels and their properties and relations. We use the notion of a ``MegaModel'' to describe a registry for models and metamodels. This paper proposes a lightweight architectural style for a model-engineering platform as well as a first prototype implementation demonstrating its feasibility.},
address = {Berlin, Heidelberg},
author = {B{\'{e}}zivin, Jean and Jouault, Fr{\'{e}}d{\'{e}}ric and Rosenthal, Peter and Valduriez, Patrick},
booktitle = {Model Driven Architecture: European MDA Workshops: Foundations and Applications, MDAFA 2003 and MDAFA 2004},
doi = {10.1007/11538097_3},
editor = {A{\ss}mann, Uwe and Aksit, Mehmet and Rensink, Arend},
isbn = {978-3-540-31819-4},
pages = {33--46},
publisher = {Springer Berlin Heidelberg},
title = {{Modeling in the Large and Modeling in the Small}},
year = {2005}
}


@book{Goldblatt2006,
	edition = {Revised},
	title = {Topoi: {The} {Categorial} {Analysis} of {Logic}},
	isbn = {978-0-486-45026-1},
	shorttitle = {Topoi},
	abstract = {A classic introduction to mathematical logic from the perspective of category theory, this text is suitable for advanced undergraduates and graduate students and accessible to both philosophically and mathematically oriented readers. Its approach moves always from the particular to the general, following through the steps of the abstraction process until the abstract concept emerges naturally.Beginning with a survey of set theory and its role in mathematics, the text proceeds to definitions and examples of categories and explains the use of arrows in place of set-membership. The introduction to topos structure covers topos logic, algebra of subobjects, and intuitionism and its logic, advancing to the concept of functors, set concepts and validity, and elementary truth. Explorations of categorial set theory, local truth, and adjointness and quantifiers conclude with a study of logical geometry.},
	language = {English},
	publisher = {Dover Publications},
	author = {Goldblatt, Robert},
	month = apr,
	year = {2006}
}


@book{MacLane1998,
	title = {Categories for the {Working} {Mathematician}},
	abstract = {Categories for the Working Mathematician provides an array of general ideas useful in a wide variety of fields. Starting from the foundations, this book illuminates the concepts of category, functor, natural transformation, and duality. The book then turns to adjoint functors, which provide a description of universal constructions, an analysis of the representations of functors by sets of morphisms, and a means of manipulating direct and inverse limits. These categorical concepts are extensively illustrated in the remaining chapters, which include many applications of the basic existence theorem for adjoint functors. The categories of algebraic systems are constructed from certain adjoint-like data and characterized by Beck's theorem. After considering a variety of applications, the book continues with the construction and exploitation of Kan extensions. This second edition includes a number of revisions and additions, including two new chapters on topics of active interest. One is on symmetric monoidal categories and braided monoidal categories and the coherence theorems for them. The second describes 2-categories and the higher dimensional categories which have recently come into prominence. The bibliography has also been expanded to cover some of the many other recent advances concerning categories.},
	language = {en},
	publisher = {Springer},
	author = {Mac Lane, Saunders},
	year = {1998},
	keywords = {Mathematics / Algebra / Abstract, Mathematics / Algebra / General, Mathematics / Topology}
}


@book{ArbibManes1975,
	address = {New York},
	edition = {1st},
	title = {Arrows, {Structures}, and {Functors}: {The} {Categorical} {Imperative}},
	isbn = {978-0-12-059060-5},
	shorttitle = {Arrows, {Structures}, and {Functors}},
	abstract = {This book attempts to build up sufficient perspective on category theory without demanding more of the reader than a basic knowledge of sets and matrix theory.},
	language = {English},
	publisher = {Academic Pr.},
	author = {Arbib, Michael A. and Manes, Ernest G.},
	month = feb,
	year = {1975}
}

@article{Loewe1993,
	title = {Algebraic approach to single-pushout graph transformation},
	volume = {109},
	issn = {0304-3975},
	abstract = {The single-pushout approach to graph transformation interprets a double-pushout transformation rule of the classical algebraic approach which consists of two total graph morphisms as a single partial morphism from the left- to the right-hand side. The notion of a double-pushout diagram for the transformation process can then be substituted by a single-pushout diagram in an appropriate category of partial morphisms. It can be shown that this kind of transformation generalizes the double-pushout framework. Hence, the classical approach can be seen as a special (and very important) case of the new concept. It can be reobtained from the single-pushout approach by imposing an application condition on the redices which formulates the gluing conditions in the new setting. On the other hand, single-pushout transformations are always possible even if the gluing conditions for the redex are violated. The simpler structure of a direct transformation (one pushout diagram instead of two) simplifies many proofs. Hence, the whole theory for double-pushout transformations including sequential composition, parallel composition, and amalgamation can be reformulated and generalized in the new framework. Some constructions provide new effects and properties which are discussed in detail.},
	number = {1},
	urldate = {2017-12-13},
	journal = {Theoretical Computer Science},
	author = {Löwe, Michael},
	month = mar,
	year = {1993},
	pages = {181--224},
	doi = {10.1016/0304-3975(93)90068-5}
}



@article{HuSchuerrST2011,
	title = {Dagstuhl seminar on bidirectional transformations ({BX})},
	volume = {40},
	issn = {01635808},
	number = {1},
	journal = {ACM SIGMOD Record},
	author = {Hu, Zhenjiang and Schürr, Andy and Stevens, Perdita and Terwilliger, James F.},
	month = jul,
	year = {2011},
	pages = {35}
}


@article{BancilhonSpyratos1989,
	title = {Update {Semantics} of {Relational} {Views}},
	volume = {6},
	issn = {0362-5915},
	number = {4},
	journal = {ACM Trans. Database Syst.},
	author = {Bancilhon, Francois and Spyratos, Nicolas},
	year = {1981},
	keywords = {conceptual model, data model, data semantics, database view, relation, relational model database, update translation, view updating},
	pages = {557--575}
}


@inproceedings{VoigtlanderHuMW2010,
	title = {Combining syntactic and semantic bidirectionalization},
	booktitle = {{ICFP} '10},
	publisher = {ACM},
	author = {Voigtländer, Janis and Hu, Zhenjiang and Matsuda, Kazutaka and Wang, Meng},
	year = {2010},
	pages = {181--192}
}



@inproceedings{RomeroJaenV2009,
	address = {Piscataway, NJ, USA},
	title = {Realizing {Correspondences} in {Multi}-viewpoint {Specifications}},
	isbn = {978-1-4244-4773-2},
	abstract = {Viewpoint modeling is an effective technique for specifying complex software systems in terms of a set of independent viewpoints and correspondences between them. Each viewpoint focuses on a particular aspect of the system, abstracting away from the rest of the concerns. Correspondences specify the relationships between the elements in different views, together with the constraints that guarantee the consistency among these elements. However, most Architectural Frameworks, which follow a multi-viewpoint approach, either do not consider the explicit specification of correspondences, or do it in a very simplistic way. This paper proposes a generic model-driven approach to the specification and realization of correspondences between viewpoints. In particular, we show how correspondences can be modeled both extensionally and intensionally, and propose the use of model transformations to connect these two approaches. As a proof-of-concept, we show how our proposal can be implemented in the context of the RM-ODP and UML4ODP, and present a tool to support the realization of correspondences between ODP views. This proposal can be extended to any other Architectural Framework that uses models to represent their views.},
	urldate = {2018-01-02},
	booktitle = {{EDOC}'09},
	publisher = {IEEE Press},
	author = {Romero, José Raúl and Jaén, Juan Ignacio and Vallecillo, Antonio},
	year = {2009},
	pages = {138--147},
	doi = {10.1109/EDOC.2009.23}
}


@article{DiskinGholizadehWC2016,
	title = {A three-dimensional taxonomy for bidirectional model synchronization},
	volume = {111},
	issn = {0164-1212},
	abstract = {Early model-driven engineering (MDE) assumed simple pipeline-like scenarios specified by the Model-Driven Architecture approach: platform-independent models that describe a software system at a high-level of abstraction are transformed stepwise to platform-dependent models from which executable source code is generated. Modern applications require a shift toward networks of models related in various ways, whose synchronization often needs to be incremental and bidirectional. This new situation demands new features from transformation tools, and a solid semantic foundation to understand and classify these features. We address the problem by presenting a taxonomy of model synchronization types, organized into a 3D-space. Each point in the space refers to a specific synchronization semantics with an underlying algebraic model and the respective requirements for the change propagation operations and their properties. The taxonomy aims to help with identifying and communicating a proper specification for the synchronization problem at hand and for the available solutions offered by tools.},
	urldate = {2017-12-31},
	journal = {J. Syst. Softw},
	author = {Diskin, Zinovy and Gholizadeh, Hamid and Wider, Arif and Czarnecki, Krzysztof},
	month = jan,
	year = {2016},
	keywords = {Taxonomy, Formal semantics, Model synchronization},
	pages = {298--322},
	doi = {10.1016/j.jss.2015.06.003}
}

@inproceedings{AnjorinDiskinJKLW2017,
	title = {BenchmarX reloaded: {A} practical benchmark framework for bidirectional transformations},
	booktitle = {{BX@ETAPS 2017}},
	author = {Anjorin, Anthony and Diskin, Zinovy and Jouault, Frédéric and Ko, Hsiang-Shang and Leblebici, Erhan and Westfechtel, Bernahrd},
	year = {2017}
}


@article{Roddick1992,
	title = {Schema {Evolution} in {Database} {Systems}: {An} {Annotated} {Bibliography}},
	volume = {21},
	issn = {0163-5808},
	shorttitle = {Schema {Evolution} in {Database} {Systems}},
	abstract = {Schema Evolution is the ability of a database system to respond to changes in the real world by allowing the schema to evolve. In many systems this property also implies a retaining of past states of the schema. This latter property is necessary if data recorded during the lifetime of one version of the schema is not to be made obsolete as the schema changes. This annotated bibliography investigates current published research with respect to the handling of changing schemas in database systems.},
	number = {4},
	urldate = {2018-01-04},
	journal = {SIGMOD Rec.},
	author = {Roddick, John F.},
	month = dec,
	year = {1992},
	pages = {35--40}
}



@inproceedings{RutleWolterL2008,
	address = {New York, NY, USA},
	title = {A {Diagrammatic} {Approach} to {Model} {Transformations}},
	isbn = {978-1-59593-988-3},
	abstract = {The raise of the abstraction level of programming languages has resulted in the usage of models and model transformations in software development processes. As a consequence of the usage of models as input to model transformation tools, there is a need for formal modeling languages and formal transformation definition techniques which can be employed to automatically translate between (and integrate) models. Therefore, a major focus of our research is on the formalization of modeling and model transformation in the generic formalism, Diagrammatic Predicate Logic (DPL). In this paper, we discuss a formalization approach to model transformation definitions based on DPL. Then, based on this formalization, some features of model transformations such as traceability, bidirectionality and compositionality are discussed.},
	urldate = {2018-01-03},
	booktitle = {EATIS 2008},
	publisher = {ACM},
	author = {Rutle, Adrian and Wolter, Uwe and Lamo, Yngve},
	year = {2008},
	keywords = {diagrammatic specifications, eclipse modeling framework, meta object facility, model driven architecture, model transformations, modeling, unified modeling language},
	pages = {18:1--18:8}
}


@inproceedings{DiskinKadishPJ2000,
	title = {Universal {Arrow} {Foundations} for {Visual} {Modeling}},
	abstract = {The goal of the paper is to explicate some common formal logic underlying various notational systems used in visual modeling. The idea is to treat the notational diversity as the diversity of visualizations of the same basic specificational format. It is argued that the task can be well approached in the arrow-diagram logic framework where specifications are directed graphs carrying a structure of diagram predicates and operations.},
	booktitle = {Diagrams '00},
	author = {Diskin, Zinovy and Kadish, Boris and Piessens, Frank and Johnson, Michael},
	pages = {345--360},
	year={2000}
}


@article{Silva2015,
	title = {Model-driven engineering: {A} survey supported by the unified conceptual model},
	volume = {43},
	issn = {1477-8424},
	shorttitle = {Model-driven engineering},
	abstract = {During the last decade a new trend of approaches has emerged, which considers models not just documentation artefacts, but also central artefacts in the software engineering field, allowing the creation or automatic execution of software systems starting from those models. These proposals have been classified generically as Model-Driven Engineering (MDE) and share common concepts and terms that need to be abstracted, discussed and understood. This paper presents a survey on MDE based on a unified conceptual model that clearly identifies and relates these essential concepts, namely the concepts of system, model, metamodel, modeling language, transformations, software platform, and software product. In addition, this paper discusses the terminologies relating MDE, MDD, MDA and others. This survey is based on earlier work, however, contrary to those, it intends to give a simple, broader and integrated view of the essential concepts and respective terminology commonly involved in the MDE, answering to key questions such as: What is a model? What is the relation between a model and a metamodel? What are the key facets of a modeling language? How can I use models in the context of a software development process? What are the relations between models and source code artefacts and software platforms? and What are the relations between MDE, MDD, MDA and other MD approaches?},
	urldate = {2017-12-28},
	journal = {Computer Languages, Systems \& Structures},
	author = {Rodrigues da Silva, Alberto},
	month = oct,
	year = {2015},
	keywords = {Metamodel, Model, Model-driven approaches, Model-driven engineering, Modeling language, Software system},
	pages = {139--155},
	file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/W9EDACYP/S1477842415000408.html:text/html}
}



@article{KoenigsSchuerr2006,
	title = {{MDI}: {A} {Rule}-based {Multi}-document and {Tool} {Integration} {Approach}},
	volume = {5},
	shorttitle = {{MDI}},
	language = {en},
	number = {4},
	journal = {Software \& Systems Modeling},
	author = {Königs, Alexander and Schürr, Andy},
	year = {2006},
	pages = {349--368},
	file = {Full Text PDF:/Users/past/Zotero/storage/VDDRS2MA/Königs and Schürr - 2006 - MDI A Rule-based Multi-document and Tool Integrat.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/Q3XVH6Q7/s10270-006-0016-x.html:text/html}
}


@inproceedings{RabbiLamoYK2015,
 author    = {Fazle Rabbi and
               Yngve Lamo and
               Ingrid Chieh Yu and
               Lars Michael Kristensen},
  title     = {A Diagrammatic Approach to Model Completion},
  booktitle = {Proceedings of the 4th Workshop on the Analysis of Model Transformations
               co-located with the 18th International Conference on Model Driven
               Engineering Languages and Systems {(MODELS} 2015), Ottawa, Canada,
               September 28, 2015},
  pages     = {56--65},
  editor    = {J{\"{u}}rgen Dingel and
               Sahar Kokaly and
               Levi Lucio and
               Rick Salay and
               Hans Vangheluwe},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {1500},
  publisher = {CEUR-WS.org},
  year      = {2015}
}

@inproceedings{MacedoCunhaP2014,
  author    = {Nuno Macedo and
               Alcino Cunha and
               Hugo Pacheco},
  title     = {Towards a Framework for Multidirectional Model Transformations},
  booktitle = {{EDBT/ICDT} 2014},
  pages     = {71--74},
  year      = {2014},
  timestamp = {Tue, 16 Jan 2018 17:46:10 +0100},
  biburl    = {http://dblp.org/rec/bib/conf/edbt/MacedoCP14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@InProceedings{TrollmannAlbayrak2015,
author="Trollmann, Frank
and Albayrak, Sahin",
editor="Kolovos, Dimitris
and Wimmer, Manuel",
title="Extending Model to Model Transformation Results from Triple Graph Grammars to Multiple Models",
booktitle="Theory and Practice of Model Transformations",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="214--229",
abstract="Triple graph grammars are a formally well-founded and widely used technique for model transformation. Due to their formal foundation several transformation approaches and analysis methods exists. However, triple graphs are restricted to represent two models at a time. In this paper we describe how the formalism of triple graphs can be generalised to enable a representation of multiple models and relations. We show that basic results from triple graph grammars can also be extended. The results in this paper provide a foundation for the generalisation of other results in model transformation, integration and synchronisation to multiple models.",
isbn="978-3-319-21155-8",
doi= {10.1007/978-3-319-21155-8_16}
}


@InProceedings{BoubakirChaoui2016,
author="Boubakir, Mohammed
and Chaoui, Allaoua",
title="A Pairwise Approach for Model Merging",
booktitle="Modelling and Implementation of Complex Systems",
year="2016",
publisher="Springer",
pages="327--340"
}


@inproceedings{DiskinKoenigL2018,
	series = {LNCS},
	title = {Multiple {Model} {Synchronization} with {Multiary} {Delta} {Lenses}},
	isbn = {978-3-319-89363-1},
	abstract = {Multiple (more than 2) model synchronization is ubiquitous and important for MDE, but its theoretical underpinning gained much less attention than the binary case. Specifically, the latter was extensively studied by the bx community in the framework of algebraic models for update propagation called lenses. Now we make a step to restore the balance and propose a notion of multiary delta lens. Besides multiarity, our lenses feature reflective updates, when consistency restoration requires some amendment of the update that violated consistency. We emphasize the importance of various ways of lens composition for practical applications of the framework, and prove several composition results.},
	language = {en},
	booktitle = {{FASE}'18 Proceedings},
	publisher = {Springer International Publishing},
	author = {Diskin, Zinovy and König, Harald and Lawford, Mark},
	editor = {Russo, Alessandra and Schürr, Andy},
	year = {2018},
	pages = {21--37},
}

@book{Fidaeiro2005,
	title = {Categories for {Software} {Engineering}},
	abstract = {This book provides a gentle, software engineering oriented introduction to category theory. Assuming only a minimum of mathematical preparation, this book explores the use of categorical constructions from the point of view of the methods and techniques that have been proposed for the engineering of complex software systems: object-oriented development, software architectures, logical and algebraic specification techniques, models of concurrency, inter alia. After two parts in which basic and more advanced categorical concepts and techniques are introduced, the book illustrates their application to the semantics of CommUnity – a language for the architectural design of interactive systems. "For computer scientists, this unique book presents Category Theory in a manner tailored to their interests and with examples to which they can relate." Ira Forman, IBM "This book applies little-known yet quite powerful formal tools from category theory to software structures: designs, architectures, patterns, and styles. Rather than focus on issues at the level of computational models and semantics, it instead applies these tools to some of the problems facing the sophisticated software architect. The terminology and mind set (Parts 1 and 2), while different from many common approaches, can provide startlingly concise expression of key properties of software systems (Part 3), and give rigorous meaning to entire families of box-and-line architecture drawings. It is applicable to the formal specification, decomposition, and composition of service-oriented architectures." Desmond D'Souza, Kinetium},
	language = {en},
	publisher = {Springer},
	author = {Fiadeiro, Jose Luiz},
	year = {2005},
	file = {Snapshot:/Users/past/Zotero/storage/A6G54Y8C/9783540209096.html:text/html}
}



@article{EramoMalavoltaMPP2012,
	title = {A model-driven approach to automate the propagation of changes among {Architecture} {Description} {Languages}},
	volume = {11},
	issn = {1619-1366, 1619-1374},
	abstract = {As it is widely recognized, a universal notation accepted by any software architect cannot exist. This caused a proliferation of architecture description languages (ADLs) each focussing on a specific application domain, analysis type, or modelling environment, and with its own specific notations and tools. Therefore, the production of a software architecture description often requires the use of multiple ADLs, each satisfying some stakeholder’s concerns. When dealing with multiple notations, suitable techniques are required in order to keep models in a consistent state. Several solutions have been proposed so far but they lack in convergence and scalability. In this paper, we propose a convergent change propagation approach between multiple architectural languages. The approach is generic since it depends neither on the notations to synchronize nor on their corresponding models. It is implemented within the Eclipse modelling framework and we demonstrate its usability and scalability by experimenting it on well known architectural languages.},
	language = {en},
	number = {1},
	journal = {Software \& Systems Modeling},
	author = {Eramo, Romina and Malavolta, Ivano and Muccini, Henry and Pelliccione, Patrizio and Pierantonio, Alfonso},
	month = feb,
	year = {2012},
	pages = {29--53},
	doi = {10.1007/s10270-010-0170-z}
}


@article{RahmBernstein2001,
	title = {A {Survey} of {Approaches} to {Automatic} {Schema} {Matching}},
	volume = {10},
	abstract = {Schema matching is a basic problem in many database application domains, such as data integration, E-business, data warehousing, and semantic query processing. In current implementations, schema matching is typically performed manually, which has significant limitations. On the other hand, previous research papers have proposed many techniques to achieve a partial automation of the match operation for specific application domains. We present a taxonomy that covers many of these existing approaches, and we describe the approaches in some detail. In particular, we distinguish between schema-level and instance-level, element-level and structure-level, and language-based and constraint-based matchers. Based on our classification we review some previous match implementations thereby indicating which part of the solution space they cover. We intend our taxonomy and review of past work to be useful when comparing different approaches to schema matching, when developing a new match algorithm, and when implementing a schema matching component.},
	number = {4},
	urldate = {2018-01-01},
	journal = {The VLDB Journal},
	author = {Rahm, Erhard and Bernstein, Philip A.},
	year = {2001},
	keywords = {Graph matching, Machine learning, Model management, Schema integration, Schema matching},
	pages = {334--350}
}



@inproceedings{NentwichEmmerichF2003,
	title = {Consistency {Management} with {Repair} {Actions}},
	abstract = {Comprehensive consistency management requires a strong mechanism for repair once inconsistencies have been detected. In this paper we present a repair framework for inconsistent distributed documents. The core piece of the framework is a new method for generating interactive repairs from full first order logic formulae that constrain these documents. We present a full implementation of the components in our repair framework, as well as their application to the UML and related heterogeneous documents such as EJB deployment descriptors. We describe how our approach can be used as an infrastructure for building higher-level, domain specific frameworks and provide an overview of related work in the database and software development environment community.},
	urldate = {2018-02-26},
	booktitle = {{ICSE} '03},
	author = {Nentwich, Christian and Emmerich, Wolfgang and Finkelsteiin, Anthony},
	year = {2003},
	pages = {455--464},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/A9IK3JU3/Nentwich et al. - 2003 - Consistency Management with Repair Actions.pdf:application/pdf}
}


@article{TeoreyYangF1986,
	title = {A {Logical} {Design} {Methodology} for {Relational} {Databases} {Using} the {Extended} {Entity}-relationship {Model}},
	volume = {18},
	abstract = {A database design methodology is defined for the design of large relational databases. First, the data requirements are conceptualized using an extended entity-relationship model, with the extensions being additional semantics such as ternary relationships, optional relationships, and the generalization abstraction. The extended entity-relationship model is then decomposed according to a set of basic entity-relationship constructs, and these are transformed into candidate relations. A set of basic transformations has been developed for the three types of relations: entity relations, extended entity relations, and relationship relations. Candidate relations are further analyzed and modified to attain the highest degree of normalization desired.
The methodology produces database designs that are not only accurate representations of reality, but flexible enough to accommodate future processing requirements. It also reduces the number of data dependencies that must be analyzed, using the extended ER model conceptualization, and maintains data integrity through normalization. This approach can be implemented manually or in a simple software package as long as a "good" solution is acceptable and absolute optimality is not required.},
	number = {2},
	journal = {ACM Comput. Surv.},
	author = {Teorey, Toby J. and Yang, Dongqing and Fry, James P.},
	year = {1986},
	pages = {197--222},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/MXQQQS88/Teorey et al. - 1986 - A Logical Design Methodology for Relational Databa.pdf:application/pdf}
}

@book{Plato-381,
	title = {Republic},
	author = {Plato}
}

@book{Aristotle,
	title={Categories},
	author = {Aristotle}
}

@book{Frege1879,
	title = {Begriffsschrift},
	author = {Frege, Gottlob},
	year = 1879}

@book{Hume1740,
	title= {A Treatise of Human Nature},
	author = {Hume, David},
	year = {1740}
}

@book{Kant1787,
	title = {Kritik der Reinen Vernunft},
	author = {Kant, Immanuel},
	year = 1787
}

@book{Kant1788,
	title = {Kritik der Praktischen Vernunft},
	author = {Kant, Immanuel},
	year = 1788
}

@book{Bentham1768,
	title = " An Essay on the First Principles of Government",
	author = {Bentham, Jeremy},
	year = 1768
}

@book{Mill1870,
  title={Utilitarianism},
  author={Mill, J.S.},
  series={Utilitarianism},
  year={1870},
  publisher={Longmans, Green}
}


@book{Hobbes1651,
	title = {Leviathan or The Matter, Forme and Power of a Common-Wealth Ecclesiasticall and Civil},
	author = {Hobbes, Thomas},
	year = 1651
}

@article{Turing1937,
  author = {Turing, Alan},
  journal = {Proceedings of the London Mathematical Society},
  keywords = {halting},
  number = 42,
  pages = {230--265},
  title = {On Computable Numbers, with an Application to the {E}ntscheidungsproblem},
  volume = 2,
  year = 1937
}

@article{Carnap1932,
year = {1932},
journal = {Erkenntnis},
author = {Rudolf Carnap},
title = {The Elimination of Metaphysics Through Logical Analysis of Language},
publisher = {The Free Press},
pages = {60--81} 
}

@article{Goedel1931, 
   author = {Gödel, Kurt}, 
   title = {{Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I}}, 
   publisher = {Springer-Verlag GmbH}, 
   journal = {Monatshefte für Mathematik und Physik}, 
   volume = {38}, 
   number = {1}, 
   pages = {173--198}, 
   year = {1931}, 
   address = {Wien}, 
   url = {http://www.springerlink.com/content/p03501kn35215860/}, 
   quality = {5}, 
   note = {}
 }

@book{Popper1935,
 	author = {Popper, Karl},
 	title = {Logik der Forschung},
 	year = {1935},
 	publihser = {Julius Springer, Hutchinson \& Co}
 }


@book{Kuhn1970,
  address = {Chicago},
  author = {Kuhn, Thomas S.},
  booktitle = {The Structure of Scientific Revolutions},
  keywords = {science},
  publisher = {University of Chicago Press},
  title = {The structure of scientific revolutions},
  year = 1970
}

@book{SWEBOK,
author = {Bourque, Pierre and Fairley, Richard E. and IEEE Computer Society},
title = {Guide to the Software Engineering Body of Knowledge (SWEBOK(R)): Version 3.0},
year = {2014},
isbn = {0769551661},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
edition = {3rd},
abstract = {In the Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), the IEEE
Computer Society establishes a baseline for the body of knowledge for the field of
software engineering, and the work supports the Societys responsibility to promote
the advancement of both theory and practice in this field. It should be noted that
the Guide does not purport to define the body of knowledge but rather to serve as
a compendium and guide to the knowledge that has been developing and evolving over
the past four decades. Now in Version 3.0, the Guides 15 knowledge areas summarize
generally accepted topics and list references for detailed information. The editors
for Version 3.0 of the SWEBOK Guide are Pierre Bourque (cole de technologie suprieure
(TS), Universit du Qubec) and Richard E. (Dick) Fairley (Software and Systems Engineering
Associates (S2EA)).}
}


@article{JoergensenSjoeberg2004,
  title={Generalization and theory-building in software engineering research},
  author={J{\o}rgensen, Magne and Sj{\o}berg, Dag},
  journal={Empirical Assessment in Software Eng. Proc},
  pages={29--36},
  year={2004},
  publisher={IET}
}


@book{WhiteheadRussell1910,
  title = {Principia {Mathematica}},
  isbn = {978-0-521-06791-1},
  author = {Whitehead, Alfred North and Russell, Bertrand},
  year = {1910},
  pulisher = {Camebridge University Press}
}




@book{CreswellCreswell2017,
  title = {Research {Design}: {Qualitative}, {Quantitative}, and {Mixed} {Methods} {Approaches}},
  isbn = {978-1-5063-8669-0},
  shorttitle = {Research {Design}},
  abstract = {This best-selling text pioneered the comparison of qualitative, quantitative, and mixed methods research design. For all three approaches, John W. Creswell and new co-author J. David Creswell include a preliminary consideration of philosophical assumptions, key elements of the research process, a review of the literature, an assessment of the use of theory in research applications, and reflections about the importance of writing and ethics in scholarly inquiry.   The Fifth Edition includes more coverage of: epistemological and ontological positioning in relation to the research question and chosen methodology; case study, PAR, visual and online methods in qualitative research; qualitative and quantitative data analysis software; and in quantitative methods more on power analysis to determine sample size, and more coverage of experimental and survey designs; and updated with the latest thinking and research in mixed methods.  SHARE this Comparison of Research Approaches poster with your students to help them navigate the distinction between the three approaches to research.},
  language = {en},
  publisher = {SAGE Publications},
  author = {Creswell, John W. and Creswell, J. David},
  month = nov,
  year = {2017},
  keywords = {Reference / Research, Social Science / Methodology, Social Science / Research}
}


@Inbook{Crnkovic2010,
author="Crnkovic, Gordana Dodig",
editor="Magnani, Lorenzo
and Carnielli, Walter
and Pizzi, Claudio",
title="Constructive Research and Info-computational Knowledge Generation",
bookTitle="Model-Based Reasoning in Science and Technology: Abduction, Logic, and Computational Discovery",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="359--380",
abstract="It is usual when writing on research methodology in dissertations and thesis work within Software Engineering to refer to Empirical Methods, Grounded Theory and Action Research. Analysis of Constructive Research Methods which are fundamental for all knowledge production and especially for concept formation, modeling and the use of artifacts is seldom given, so the relevant first-hand knowledge is missing. This article argues for introducing of the analysis of Constructive Research Methods, as crucial for understanding of research process and knowledge production. The paper provides characterization of the Constructive Research Method and its relations to Action Research and Grounded Theory. Illustrative examples from Software Engineering, Cognitive Science and Brain Simulation are presented. Finally, foundations of Constructive Research are analyzed within the framework of Info-Computationalism.",
isbn="978-3-642-15223-8",
doi="10.1007/978-3-642-15223-8_20",
url="https://doi.org/10.1007/978-3-642-15223-8_20"
}

@INPROCEEDINGS{Goguen1999,
    author = {Joseph Goguen},
    title = {Tossing Algebraic Flowers down the Great Divide},
    booktitle = {In People and Ideas in Theoretical Computer Science},
    year = {1999},
    pages = {93--129},
    publisher = {Springer}
}


@techreport{NENTETIKK,
type = {Guidelines},
isbn = {978-82-7682-075-1},
year = {2016},
title = {GUIDELINES FOR RESEARCH ETHICS IN SCIENCE AND TECHNOLOGY},
address = {Oslo, NO},
institution = {The Norwegian National Research Ethics Committees}
}

@book{Resnik1998,
  title={The Ethics of Science: An Introduction},
  author={Resnik, D.B.},
  isbn={9780415166980},
  lccn={97040514},
  series={Philosophical issues in science},
  year={1998},
  publisher={Routledge}
}


@book{Schwab2017,
  title = {The {Fourth} {Industrial} {Revolution}},
  isbn = {978-0-241-98053-8},
  abstract = {The founder and executive chairman of the World Economic Forum on how the impending technological revolution will change our livesWe are on the brink of the Fourth Industrial Revolution. And this one will be unlike any other in human history.Characterized by new technologies fusing the physical, digital and biological worlds, the Fourth Industrial Revolution will impact all disciplines, economies and industries - and it will do so at an unprecedented rate. World Economic Forum data predicts that by 2025 we will see: commercial use of nanomaterials 200 times stronger than steel and a million times thinner than human hair; the first transplant of a 3D-printed liver; 10\% of all cars on US roads being driverless; and much more besides.In The Fourth Industrial Revolution, Schwab outlines the key technologies driving this revolution, discusses the major impacts on governments, businesses, civil society and individuals, and offers bold ideas for what can be done to shape a better future for all.},
  language = {en},
  publisher = {Penguin UK},
  author = {Schwab, Klaus},
  month = jan,
  year = {2017},
  note = {Google-Books-ID: OetrDQAAQBAJ},
  keywords = {Business \& Economics / Business Ethics, Business \& Economics / E-Commerce / General, Business \& Economics / Finance / General, Business \& Economics / General, Business \& Economics / Industries / Computers \& Information Technology, Business \& Economics / International / Economics, Business \& Economics / International / General, Business \& Economics / Investments \& Securities / Futures, Business \& Economics / Money \& Monetary Policy, Computers / Social Aspects, Political Science / International Relations / Diplomacy, Political Science / International Relations / General, Political Science / Political Freedom, Science / Philosophy \& Social Aspects, Social Science / Future Studies, Technology \& Engineering / General}
}



@BOOK{NASNAEIM2009,
  author    = "National Academy of Sciences and National Academy of Engineering and Institute of Medicine",
  title     = "On Being a Scientist: A Guide to Responsible Conduct in Research: Third Edition",
  isbn      = "978-0-309-11970-2",
  doi       = "10.17226/12192",
  abstract  = "The scientific research enterprise is built on a foundation of trust. Scientists trust that the results reported by others are valid. Society trusts that the results of research reflect an honest attempt by scientists to describe the world accurately and without bias. But this trust will endure only if the scientific community devotes itself to exemplifying and transmitting the values associated with ethical scientific conduct.\n\nOn Being a Scientist was designed to supplement the informal lessons in ethics provided by research supervisors and mentors. The book describes the ethical foundations of scientific practices and some of the personal and professional issues that researchers encounter in their work. It applies to all forms of research--whether in academic, industrial, or governmental settings-and to all scientific disciplines. \n\nThis third edition of On Being a Scientist reflects developments since the publication of the original edition in 1989 and a second edition in 1995. A continuing feature of this edition is the inclusion of a number of hypothetical scenarios offering guidance in thinking about and discussing these scenarios.\n\nOn Being a Scientist is aimed primarily at graduate students and beginning researchers, but its lessons apply to all scientists at all stages of their scientific careers.\n ",
  url       = "https://www.nap.edu/catalog/12192/on-being-a-scientist-a-guide-to-responsible-conduct-in",
  year      = 2009,
  publisher = "The National Academies Press",
  address   = "Washington, DC"
}

@book{Rawls2005,
  title={A Theory of Justice},
  author={Rawls, John},
  isbn={9780674017726},
  lccn={2004060697},
  series={Oxford Paperbacks 301 301},
  year={2005},
  publisher={Harvard University Press}
}



@article{Chen1976,
	title = {The {Entity}-relationship {Model}—{Toward} a {Unified} {View} of {Data}},
	volume = {1},
	issn = {0362-5915},
	url = {http://doi.acm.org/10.1145/320434.320440},
	doi = {10.1145/320434.320440},
	abstract = {A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information about the real world. A special diagrammatic technique is introduced as a tool for database design. An example of database design and description using the model and the diagrammatic technique is given. Some implications for data integrity, information retrieval, and data manipulation are discussed.
The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented.},
	number = {1},
	urldate = {2018-01-23},
	journal = {ACM Trans. Database Syst.},
	author = {Chen, Peter Pin-Shan},
	month = mar,
	year = {1976},
	keywords = {Data Base Task Group, data definition and manipulation, data integrity and consistency, data models, database design, entity set model, entity-relationship model, logigcal view of data, network model, relational model, semantics of data},
	pages = {9--36},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/889X8J8T/Chen - 1976 - The Entity-relationship Model—Toward a Unified Vie.pdf:application/pdf}
}


@book{HopheWoolf2012,
  title={Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions},
  author={Hohpe, G. and Woolf, B.},
  isbn={9780133065107},
  series={Addison-Wesley Signature Series (Fowler)},
  year={2012},
  publisher={Pearson Education}
}




@inproceedings{StuenkelKoenigLR2018,
author = {St\"{u}nkel, Patrick and K\"{o}nig, Harald and Lamo, Yngve and Rutle, Adrian},
title = {Multimodel Correspondence through Inter-Model Constraints},
year = {2018},
isbn = {9781450355131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3191697.3191715},
booktitle = {Conference Companion of the 2nd International Conference on Art, Science, and Engineering of Programming},
pages = {9–17},
numpages = {9},
keywords = {Bidirectional Transformations, Inter-Model Constraints, Modeling Languages},
location = {Nice, France},
series = {Programming’18 Companion}
}



@inproceedings{Stevens2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Landscape} of {Bidirectional} {Model} {Transformations}},
	isbn = {978-3-540-88642-6 978-3-540-88643-3},
	doi = {10.1007/978-3-540-88643-3\_10},
	abstract = {Model transformations are a key element in the OMG’s Model Driven Development agenda. They did not begin here: the fundamental idea of transforming, automatically, one model into another is at least as old as the computer, provided that we take a sufficiently broad view of what a model is. In many contexts, people have encountered the need for bidirectional transformations. In this survey paper we discuss the various notions of bidirectional transformation, and their motivation from the needs of software engineering. We discuss the state of the art in work targeted specifically at the OMG’s MDD initiative, and also, briefly, related work from other communities. We point out some areas which are so far relatively under-researched, and propose research topics for the future.},
	language = {en},
	urldate = {2018-01-04},
	booktitle = {Generative and {Transformational} {Techniques} in {Software} {Engineering} {II}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Stevens, Perdita},
	month = jul,
	year = {2007},
	pages = {408--424},
	file = {Snapshot:/Users/past/Zotero/storage/LXHAC5XR/978-3-540-88643-3_10.html:text/html}
}


@article{JohnsonRosebrugh2017,
	title = {Symmetric delta lenses and spans of asymmetric delta lenses.},
	volume = {16},
	issn = {1660-1769},
	doi = {10.5381/jot.2017.16.1.a2},
	abstract = {Bidirectional Transformations provide mechanisms for main- taining synchronization between updatable data sources. Lenses are cer- tain mathematically specified bidirectional transformations. As part of a project to unify the treatment of symmetric lenses (of various kinds) as equivalence classes of spans of asymmetric lenses (of corresponding kinds), we relate symmetric delta lenses with spans of asymmetric delta lenses. Because delta lenses are based on state spaces which are categories rather than sets, there is further structure that needs to be accounted for. One of the main findings in this paper is that the required equivalence rela- tion among spans is compatible with, but coarser than, the one expected. The main result is an isomorphism of categories between a category whose morphisms are equivalence classes of symmetric delta lenses (here called fb-lenses) and the category of spans of delta lenses modulo the new equiv- alence.},
	number = {1},
	journal = {The Journal of Object Technology},
	author = {Johnson, Michael and Rosebrugh, Robert},
	year = {2017},
	pages = {2:1}
}

@inproceedings{CorradiniHeindelHK2006, 
author="Corradini, Andrea
and Heindel, Tobias
and Hermann, Frank
and K{\"o}nig, Barbara",
editor="Corradini, Andrea
and Ehrig, Hartmut
and Montanari, Ugo
and Ribeiro, Leila
and Rozenberg, Grzegorz",
title="Sesqui-Pushout Rewriting ",
booktitle="Graph Transformations",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="30--45",
abstract="Sesqui-pushout (SqPO) rewriting---``sesqui'' means ``one and a half'' in Latin---is a new algebraic approach to abstract rewriting in any category. SqPO rewriting is a deterministic and conservative extension of double-pushout (dpo) rewriting, which allows to model ``deletion in unknown context'', a typical feature of single-pushout (spo) rewriting, as well as cloning.",
isbn="978-3-540-38872-2",
doi = {10.1007/11841883_4}
}

 

@article{RuscioIovinoP2012,
	title = {Coupled {Evolution} in {Model}-{Driven} {Engineering}},
	volume = {29},
	issn = {0740-7459},
	abstract = {Model-driven engineering bases a wide range of artifacts on metamodels. When such metamodels evolve, such as a new version of Unified Modeling Language or Business Process Execution Notation or a company-specific metamodel, underlying artifacts often become invalid. In this article, the authors provide an overview of coupled evolution methods and tools to handle such dependencies. I look forward to hearing from both readers and prospective authors about this column and the technologies you want to know more about.},
	number = {6},
	journal = {IEEE Software},
	author = {Ruscio, D. Di and Iovino, L. and Pierantonio, A.},
	month = nov,
	year = {2012},
	keywords = {coupled evolution, metamodel, model-driven engineering, Modeling, Software development, software engineering, Software engineering, software technology, Unified modeling language, Unified Modeling Language},
	pages = {78--84},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/S3DR5L5G/6336727.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/4WTPZIKZ/Ruscio et al. - 2012 - Coupled Evolution in Model-Driven Engineering.pdf:application/pdf}
}


@incollection{KnappMossakowski2018,
	series = {LNCS 10800},
	title = {Multi-view {Consistency} in {UML}: {A} {Survey}},
	isbn = {978-3-319-75395-9 978-3-319-75396-6},
	shorttitle = {Multi-view {Consistency} in {UML}},
	abstract = {We study the question of consistency of multi-view models in UML and OCL. We critically survey the large amount of literature that already exists. We find that only limited subsets of the UML/OCL have been covered so far and that consistency checks mostly only cover structural aspects, whereas only few methods also address behaviour. We also give a classification of different techniques for multi-view UML/OCL consistency: consistency rules, the system model approach, dynamic meta-modelling, universal logic, and heterogeneous transformation. Finally, we briefly outline a possible comprehensive distributed semantics approach to consistency.},
	language = {en},
	urldate = {2018-06-21},
	booktitle = {Graph {Transformation}, {Specifications}, and {Nets}},
	publisher = {Springer, Cham},
	author = {Knapp, Alexander and Mossakowski, Till},
	year = {2018},
	pages = {37--60},
	doi = {10.1007/978-3-319-75396-6_3}
}


@inproceedings{Goguen1992,
	title = {Sheaf {Semantics} for {Concurrent} {Interacting} {Objects}},
	abstract = {: This paper uses concepts from sheaf theory to explicate phenomena in concurrent systems, including object, inheritance, deadlock, and non-interference, as used in computer security. The approach is very general, and applies not only to concurrent object oriented systems, but also to systems of differential equations, electrical circuits, hardware description languges, and much more. Time can be discrete or continuous, linear or branching, and distribution is allowed over space as well as time. Concepts from category theory help to achieve this generality: objects are modeled by sheaves; inheritance by sheaf morphisms; systems by diagrams; and interconnections by diagrams of diagrams. In addition, behaviour is given by limit, and the result of interconnection by colimit. The approach is illustrated with many examples, including a semantics for a simple concurrent object-based programming language. 1 Introduction  Many popular formalisms for concurrent systems are syntactic (or "formal...},
	booktitle = {Mathematical {Structures} in {Computer} {Science}},
	author = {Goguen, Joseph A.},
	year = {1992},
	pages = {159--191}
}



@article{Jackson2002,
	title = {Alloy: {A} {Lightweight} {Object} {Modelling} {Notation}},
	volume = {11},
	issn = {1049-331X},
	shorttitle = {Alloy},
	abstract = {Alloy is a little language for describing structural properties. It offers a declaration syntax compatible with graphical object models, and a set-based formula syntax powerful enough to express complex constraints and yet amenable to a fully automatic semantic analysis. Its meaning is given by translation to an even smaller (formally defined) kernel. This paper presents the language in its entirety, and explains its motivation, contributions and deficiencies.},
	number = {2},
	urldate = {2018-01-04},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Jackson, Daniel},
	month = apr,
	year = {2002},
	keywords = {first-order logic, Object models, Z specification language},
	pages = {256--290}
}


@article{DemuthEhrenleitnerLE2016,
	title = {Co-evolution of metamodels and models through consistent change propagation},
	volume = {111},
	issn = {0164-1212},
	abstract = {In model-driven engineering (MDE), metamodels and domain-specific languages are key artifacts as they are used to define syntax and static semantics of domain models. However, metamodels are evolving over time, requiring existing domain models to be co-evolved. Though approaches have been proposed for performing such co-evolution automatically, those approaches typically support only specific metamodel changes. In this paper, we present a vision of co-evolution between metamodels and models through consistent change propagation. The approach addresses co-evolution issues without being limited to specific metamodels or evolution scenarios. It relies on incremental management of metamodel-based constraints that are used to detect co-evolution failures (i.e., inconsistencies between metamodel and model). After failure detection, the approach automatically generates suggestions for correction (i.e., repairs for inconsistencies). A case study with the UML metamodel and 23 UML models shows that the approach is technically feasible and also scalable.},
	urldate = {2018-07-09},
	journal = {Journal of Systems and Software},
	author = {Demuth, Andreas and Riedl-Ehrenleitner, Markus and Lopez-Herrejon, Roberto E. and Egyed, Alexander},
	month = jan,
	year = {2016},
	keywords = {Consistency checking, Consistent change propagation, Metamodel co-evolution},
	pages = {281--297},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/GJRHEMHR/Demuth et al. - 2016 - Co-evolution of metamodels and models through cons.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/DWM2PMKS/S0164121215000564.html:text/html}
}



@article{RoseHerrmannsdoerferMGPHKKLSW2014,
	title = {Graph and model transformation tools for model migration},
	volume = {13},
	abstract = {We describe the results of the Transformation Tool Contest 2010 workshop, in which nine graph and model transformation tools were compared for specifying model migration. The model migration problem—migration of UML activity diagrams from version 1.4 to version 2.2—is non-trivial and practically relevant. The solutions have been compared with respect to several criteria: correctness, conciseness, understandability, appropriateness, maturity and support for extensions to the core migration task. We describe in detail the comparison method, and discuss the strengths and weaknesses of the solutions with a special focus on the differences between graph and model transformation for model migration. The comparison results demonstrate tool and language features that strongly impact the efficacy of solutions, such as support for retyping of model elements. The results are used to motivate an agenda for future model migration research (including suggestions for areas in which the tools need to be further improved).},
	language = {en},
	number = {1},
	urldate = {2018-07-16},
	journal = {Software \& Systems Modeling},
	author = {Rose, Louis M. and Herrmannsdoerfer, Markus and Mazanek, Steffen and Gorp, Pieter Van and Buchwald, Sebastian and Horn, Tassilo and Kalnina, Elina and Koch, Andreas and Lano, Kevin and Schätz, Bernhard and Wimmer, Manuel},
	month = feb,
	year = {2014},
	pages = {323--359},
	doi = {10.1007/s10270-012-0245-0}
}


@article{Pratt1971,
 author = {Pratt, Terrence W.},
 title = {Pair Grammars, Graph Languages and String-to-graph Translations},
 journal = {J. Comput. Syst. Sci.},
 issue_date = {December, 1971},
 volume = {5},
 number = {6},
 month = dec,
 year = {1971},
 issn = {0022-0000},
 pages = {560--595},
 numpages = {36},
 url = {http://dx.doi.org/10.1016/S0022-0000(71)80016-8},
 doi = {10.1016/S0022-0000(71)80016-8},
 acmid = {1740026},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
} 


@InProceedings{HermannEhrigOCDX2011,
author="Hermann, Frank
and Ehrig, Hartmut
and Orejas, Fernando
and Czarnecki, Krzysztof
and Diskin, Zinovy
and Xiong, Yingfei",
editor="Whittle, Jon
and Clark, Tony
and K{\"u}hne, Thomas",
title="{Correctness of Model Synchronization Based on Triple Graph Grammar}",
booktitle={MODELS 2011},
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="668--682",
abstract="Triple graph grammars (TGGs) have been used successfully to analyze correctness and completeness of bidirectional model transformations, but a corresponding formal approach to model synchronization has been missing. This paper closes this gap by providing a formal synchronization framework with bidirectional update propagation operations. They are generated from a TGG, which specifies the language of all consistently integrated source and target models.",
isbn="978-3-642-24485-8",
doi = {10.1007/978-3-642-24485-8_49}
}

@InProceedings{BiermannErmelT2008,
author="Biermann, Enrico
and Ermel, Claudia
and Taentzer, Gabriele",
editor="Czarnecki, Krzysztof
and Ober, Ileana
and Bruel, Jean-Michel
and Uhl, Axel
and V{\"o}lter, Markus",
title="{Precise Semantics of EMF Model Transformations by Graph Transformation}",
booktitle="MODEL 2008",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="53--67",
doi = {10.1007/978-3-540-87875-9_4},
abstract="Model transformation is one of the key activities in model-driven software development. An increasingly popular technology to define modeling languages is provided by the Eclipse Modeling Framework (EMF). Several EMF model transformation approaches have been developed, focusing on different transformation aspects. To validate model transformations wrt. functional behavior and correctness, a formal foundation is needed. In this paper, we define EMF model transformations as a special kind of typed graph transformations using node type inheritance. Containment constraints of EMF model transformations are translated to a special kind of EMF model transformation rules such that their application leads to consistent transformation results only. Thus, we identify a kind of EMF model transformations which behave like algebraic graph transformations. As a consequence, the rich theory of algebraic graph transformation can be applied to these EMF model transformations to show functional behavior and correctness. We illustrate our approach by selected refactorings of simplified statechart models.",
isbn="978-3-540-87875-9"
}


@inproceedings{AnjorinSchuerrT2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Construction of {Integrity} {Preserving} {Triple} {Graph} {Grammars}},
	isbn = {978-3-642-33654-6},
	abstract = {Triple Graph Grammars (TGGs) are a rule-based technique of specifying a consistency relation over a source, correspondence, and target domain, which can be used for bidirectional model transformation.A current research challenge is increasing the expressiveness of TGGs by ensuring that global constraints in the involved domains are not violated by the transformation. Negative Application Conditions (NACs) can be used to enforce this property, referred to as schema compliance.In previous work, we have presented a polynomial control algorithm for integrity preserving TGGs, using NACs only to ensure schema compliance, meaning that, for efficiency reasons, the usage of NACs must be restricted appropriately. In this paper, we apply the well-known translation of global constraints to application conditions for a given TGG and set of global constraints. We show that the derived set of NACs is indeed sufficient and necessary to ensure schema compliance, i.e., that the TGG together with the derived NACs is integrity preserving by construction.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Anjorin, Anthony and Schürr, Andy and Taentzer, Gabriele},
	editor = {Ehrig, Hartmut and Engels, Gregor and Kreowski, Hans-Jörg and Rozenberg, Grzegorz},
	year = {2012},
	keywords = {bidirectional transformation, integrity preservation, negative application conditions, schema compliance, triple graph grammars},
	pages = {356--370}
}


@article{AnjorinVarroS2012,
	title = {Complex {Attribute} {Manipulation} in {TGGs} with {Constraint}-{Based} {Programming} {Techniques}},
	volume = {49},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/707},
	doi = {10.14279/tuj.eceasst.49.707},
	abstract = {Model transformation plays a central role in Model-Driven Engineering (MDE) and providing bidirectional transformation languages is a current challenge with important applications.  Triple Graph Grammars (TGGs) are a formally founded,  bidirectional model transformation language shown by numerous case studies to be quite promising and successful.  Although TGGs provide adequate support for structural aspects via object  patterns in TGG rules, support for handling complex relationships between different attributes is still missing in current implementations.  For certain applications, such as bidirectional model-to-text transformations, being able to manipulate attributes via string manipulation or arithmetic operations in TGG rules is vital.  Our contribution in this paper is to formalize a TGG extension that provides a means for complex attribute manipulation in TGG rules.  Our extension is compatible with the existing TGG formalization, and retains the "single specification'' philosophy of TGGs.},
	language = {en},
	number = {0},
	urldate = {2018-08-28},
	journal = {Electronic Communications of the EASST},
	author = {Anjorin, Anthony and Varró, Gergely and Schürr, Andy},
	month = jul,
	year = {2012},
	file = {Full Text PDF:/Users/past/Zotero/storage/7XK2PF8V/Anjorin et al. - 2012 - Complex Attribute Manipulation in TGGs with Constr.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/5I29S94Q/707.html:text/html}
}


@article{Kuehne2006,
	title = {Matters of ({Meta}-) {Modeling}},
	volume = {5},
	issn = {1619-1366, 1619-1374},
	doi = {10.1007/s10270-006-0017-9},
	language = {en},
	number = {4},
	urldate = {2017-12-28},
	journal = {Software \& Systems Modeling},
	author = {Kühne, Thomas},
	month = dec,
	year = {2006},
	pages = {369--385},
	file = {Snapshot:/Users/past/Zotero/storage/SV3USH3A/s10270-006-0017-9.html:text/html}
}


@article{GieseWagner2009,
	title = {From model transformation to incremental bidirectional model synchronization},
	volume = {8},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-008-0089-9},
	doi = {10.1007/s10270-008-0089-9},
	abstract = {The model-driven software development paradigm requires that appropriate model transformations are applicable in different stages of the development process. The transformations have to consistently propagate changes between the different involved models and thus ensure a proper model synchronization. However, most approaches today do not fully support the requirements for model synchronization and focus only on classical one-way batch-oriented transformations. In this paper, we present our approach for an incremental model transformation which supports model synchronization. Our approach employs the visual, formal, and bidirectional transformation technique of triple graph grammars. Using this declarative specification formalism, we focus on the efficient execution of the transformation rules and how to achieve an incremental model transformation for synchronization purposes. We present an evaluation of our approach and demonstrate that due to the speedup for the incremental processing in the average case even larger models can be tackled.},
	language = {en},
	number = {1},
	urldate = {2018-08-30},
	journal = {Software \& Systems Modeling},
	author = {Giese, Holger and Wagner, Robert},
	month = feb,
	year = {2009},
	keywords = {Incremental model synchronization, Model transformation, Triple graph grammars},
	pages = {21--43},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/S65J3K9X/Giese and Wagner - 2009 - From model transformation to incremental bidirecti.pdf:application/pdf}
}


@inproceedings{EhrigEhrigHP2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Constraints and {Application} {Conditions}: {From} {Graphs} to {High}-{Level} {Structures}},
	isbn = {978-3-540-30203-2},
	shorttitle = {Constraints and {Application} {Conditions}},
	abstract = {Graph constraints and application conditions are most important for graph grammars and transformation systems in a large variety of application areas. Although different approaches have been presented in the literature already there is no adequate theory up to now which can be applied to different kinds of graphs and high-level structures. In this paper, we introduce an improved notion of graph constraints and application conditions and show under what conditions the basic results can be extended from graph transformation to high-level replacement systems. In fact, we use the new framework of adhesive HLR categories recently introduced as combination of HLR systems and adhesive categories. Our main results are the transformation of graph constraints into right application conditions and the transformation from right to left application conditions in this new framework.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ehrig, Hartmut and Ehrig, Karsten and Habel, Annegret and Pennemann, Karl-Heinz},
	editor = {Ehrig, Hartmut and Engels, Gregor and Parisi-Presicce, Francesco and Rozenberg, Grzegorz},
	year = {2004},
	keywords = {Application Condition, Boolean Formula, Graph Grammar, Graph Transformation, Injective Morphism},
	pages = {287--303}
}

@inproceedings{DBLP:conf/fase/EhrigELTVV05,
  author    = {Hartmut Ehrig and
               Karsten Ehrig and
               Juan de Lara and
               Gabriele Taentzer and
               D{\'{a}}niel Varr{\'{o}} and
               Szilvia Varr{\'{o}}{-}Gyapay},
  title     = {Termination Criteria for Model Transformation},
  booktitle = {Fundamental Approaches to Software Engineering, 8th International
               Conference, {FASE} 2005, Held as Part of the Joint European Conferences
               on Theory and Practice of Software, {ETAPS} 2005, Edinburgh, UK, April
               4-8, 2005, Proceedings},
  pages     = {49--63},
  year      = {2005},
  crossref  = {DBLP:conf/fase/2005},
  url       = {https://doi.org/10.1007/978-3-540-31984-9\_5},
  doi       = {10.1007/978-3-540-31984-9\_5},
  timestamp = {Tue, 26 Jun 2018 14:11:38 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/fase/EhrigELTVV05},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{LeblebiciAnjorinS2017,
	address = {New York, NY, USA},
	title = {Inter-model {Consistency} {Checking} {Using} {Triple} {Graph} {Grammars} and {Linear} {Optimization} {Techniques}},
	isbn = {978-3-662-54493-8},
	doi = {10.1007/978-3-662-54494-5_11},
	abstract = {An important task in Model-Driven Engineering MDE is to check consistency between two concurrently developed yet related models. Practical approaches to consistency checking, however, are scarce in MDE. Triple Graph Grammars TGGs are a rule-based technique to describe the consistency of two models together with correspondences. While TGGs seem promising for consistency checking with their precise consistency notion and explicit traceability information, the substantial search space involved in determining the "optimal" set of rule applications in a consistency check has arguably prevented mature tool support so far. In this paper, we close this gap by combining TGGs with linear optimization techniques. We formulate decisions between single rule applications of a consistency check as integer inequalities, which serve as input for an optimization problem used to detect maximum consistent portions of two models. To demonstrate our approach, we provide an experimental evaluation of the tool support made feasible by this formalization.},
	urldate = {2018-08-30},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Fundamental} {Approaches} to {Software} {Engineering} - {Volume} 10202},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Leblebici, Erhan and Anjorin, Anthony and Sch{\"{u}}rr, Andy},
	year = {2017},
	keywords = {Consistency check, Linear optimization, Traceability},
	pages = {191--207}
}



@article{EhrigEhrigH2008,
	title = {From {Model} {Transformation} to {Model} {Integration} based on the {Algebraic} {Approach} to {Triple} {Graph} {Grammars}},
	volume = {10},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	doi = {10.14279/tuj.eceasst.10.154},
	abstract = {Success and efficiency of software and system design fundamentally relies on its models. The more they are based on formal methods the more they can be automatically transformed to execution models and finally to implementation code.
This paper presents model transformation and model integration as specific problem within bidirectional model transformation, which has shown to support  various purposes, such as analysis, optimization, and code generation.

The main purpose of model integration is to establish correspondence between various models,
especially between source and target models. From the analysis point of view, model integration supports correctness checks of syntactical dependencies between different views and models.

The overall concept is based on the algebraic approach to triple graph grammars, which are widely used for model transformation.
The main result shows the close relationship between model transformation and model integration. For each model transformation sequence there is a unique model integration sequence and vice versa. This is demonstrated by a quasi-standard example for model transformation between class models and relational data base models.},
	language = {en},
	number = {0},
	journal = {Electronic Communications of the EASST},
	author = {Ehrig, Hartmut and Ehrig, Karsten and Hermann, Frank},
	month = jun,
	year = {2008},
}


@inproceedings{LeblebiciAnjorinST2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multi-amalgamated {Triple} {Graph} {Grammars}},
	isbn = {978-3-319-21145-9},
	abstract = {Triple Graph Grammars (TGGs) are a well-known technique for rule-based specification of bidirectional model transformation. TGG rules build up consistent models simultaneously and are operationalized automatically to forward and backward rules describing single transformation steps in the respective direction. These operational rules, however, are of fixed size and cannot describe transformation steps whose size can only be determined at transformation time for concrete models. In particular, transforming an element to arbitrary many elements depending on the transformation context is not supported. To overcome this limitation, we propose the integration of the multi-amalgamation concept from classical graph transformation into TGGs. Multi-Amalgamation formalizes the combination of multiple transformations sharing a common subpart to a single transformation. For TGGs, this enables repeating certain parts of a forward or backward transformation step in a for each loop-like manner depending on concrete models at transformation time.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {Leblebici, Erhan and Anjorin, Anthony and Schürr, Andy and Taentzer, Gabriele},
	editor = {Parisi-Presicce, Francesco and Westfechtel, Bernhard},
	year = {2015},
	keywords = {Amalgamation, Model transformation, Triple graph grammars},
	pages = {87--103}
}


@inproceedings{GreenyerPookR2011,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Preventing {Information} {Loss} in {Incremental} {Model} {Synchronization} by {Reusing} {Elements}},
	isbn = {978-3-642-21470-7},
	abstract = {The development of complex mechatronic systems requires the close collaboration of multiple engineering disciplines. Hence, multidisciplinary system engineering approaches have been developed. However, the refinement of discipline-specific aspects of the system, for example the implementation of software controllers, still requires discipline-specific models and tools. During the development, changes in these discipline-specific models may affect other disciplines’ models. Thus, inconsistencies are likely to occur, leading to increased development time and costs if they remain undetected. Bidirectional model synchronization techniques aim at automatically resolving such inconsistencies. Existing synchronization algorithms today, however, fail in this application scenario, because synchronization steps often unnecessarily destroy and re-create elements, which damages parts of the models that are not subject to the synchronization. In order to solve these issues, we present a novel synchronization technique based on Triple Graph Grammars with improvements regarding the reuse of model elements.},
	language = {en},
	booktitle = {Modelling {Foundations} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Greenyer, Joel and Pook, Sebastian and Rieke, Jan},
	editor = {France, Robert B. and Kuester, Jochen M. and Bordbar, Behzad and Paige, Richard F.},
	year = {2011},
	keywords = {Incremental Model Synchronization, Information Retainment in the Target, Mechatronic System Design, Triple Graph Grammars (TGG)},
	pages = {144--159}
}



@article{HildebrandtLambersGRGSLA2013,
	title = {A {Survey} of {Triple} {Graph} {Grammar} {Tools}},
	volume = {57},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	doi = {10.14279/tuj.eceasst.57.865},
	abstract = {Model transformation plays a central role in Model-Driven Engineering (MDE) and supporting bidirectionality is a current challenge with important applications. Triple Graph Grammars (TGGs) are a formally founded, bidirectional model transformation language shown by numerous case studies to be promising and useful in practice. TGGs have been researched for more than 15 years and multiple TGG tools are under active development. Although a common theoretical foundation is shared, TGG tools differ considerably concerning expressiveness,applicability, efficiency, and the underlying translation algorithm. There currently exists neither a quantitative nor a qualitative overview and comparison of TGG tools and it is quite difficult to understand the different foci and corresponding strengthsand weaknesses. Our contribution in this paper is to develop a set of criteria for comparing TGG tools and to provide a concrete quantitative and qualitative comparison of three TGG tools.},
	language = {en},
	number = {0},
	urldate = {2018-09-01},
	journal = {Electronic Communications of the EASST},
	author = {Hildebrandt, Stephan and Lambers, Leen and Giese, Holger and Rieke, Jan and Greenyer, Joel and Sch{\"a}fer, Wilhelm and Lauder, Marius and Anjorin, Anthony and Sch{\"u}rr, Andy},
	month = sep,
	year = {2013},
	file = {Full Text PDF:/Users/past/Zotero/storage/RVWWPITL/Hildebrandt et al. - 2013 - A Survey of Triple Graph Grammar Tools.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/GZUTCYS7/0.html:text/html}
}


@article{AnjorinLeblebiciS2016,
	title = {20 {Years} of {Triple} {Graph} {Grammars}: {A} {Roadmap} for {Future} {Research}},
	volume = {73},
	copyright = {Copyright (c) 2016 Electronic Communications of the EASST},
	issn = {1863-2122},
	shorttitle = {20 {Years} of {Triple} {Graph} {Grammars}},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/1031},
	doi = {10.14279/tuj.eceasst.73.1031},
	abstract = {Triple graph grammars (TGGs) provide a declarative, rule-based means of specifying binary consistency relationships between different types of graphs. Over the last 20 years, TGGs have been applied successfully in a range of application scenarios including: model neration,conformance testing, bidirectional model transformation, and incremental model synchronisation. In this paper, we review the progress made in TGG research up until now by exploring multiple research dimensions, including both the current frontiers of TGG research as well as important future challenges. Our aim is to provide a roadmap for the coming years of TGG research by stating clearly what we regard as adequately researched, and what we view as still unexplored potential.},
	language = {en},
	number = {0},
	urldate = {2018-09-01},
	journal = {Electronic Communications of the EASST},
	author = {Anjorin, Anthony and Leblebici, Erhan and Schürr, Andy},
	month = apr,
	year = {2016},
	file = {Full Text PDF:/Users/past/Zotero/storage/S5ECDR5Z/Anjorin et al. - 2016 - 20 Years of Triple Graph Grammars A Roadmap for F.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/DZ2C5TBP/1031.html:text/html}
}



@incollection{Loewe2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Model {Transformations} as {Free} {Constructions}},
	isbn = {978-3-319-75396-6},
	url = {https://doi.org/10.1007/978-3-319-75396-6_8},
	abstract = {Hartmut Ehrig was an active researcher in Algebraic Specifications on the one hand and Graph and Model Transformations on the other hand. We demonstrate that these two research fields are closely connected, if we consider generating graph transformations only and use partial algebras instead of total algebras as the underlying category.},
	language = {en},
	urldate = {2018-09-01},
	booktitle = {Graph {Transformation}, {Specifications}, and {Nets}: {In} {Memory} of {Hartmut} {Ehrig}},
	publisher = {Springer International Publishing},
	author = {Löwe, Michael},
	editor = {Heckel, Reiko and Taentzer, Gabriele},
	year = {2018},
	doi = {10.1007/978-3-319-75396-6_8},
	pages = {142--159}
}



@book{Fowler2012,
	title = {Refactoring: {Improving} the {Design} of {Existing} {Code}},
	isbn = {978-0-13-306526-8},
	shorttitle = {Refactoring},
	abstract = {As the application of object technology--particularly the Java programming language--has become commonplace, a new problem has emerged to confront the software development community. Significant numbers of poorly designed programs have been created by less-experienced developers, resulting in applications that are inefficient and hard to maintain and extend. Increasingly, software system professionals are discovering just how difficult it is to work with these inherited, "non-optimal" applications. For several years, expert-level object programmers have employed a growing collection of techniques to improve the structural integrity and performance of such existing software programs. Referred to as "refactoring," these practices have remained in the domain of experts because no attempt has been made to transcribe the lore into a form that all developers could use. . .until now. In  Refactoring: Improving the Design of Existing Code,  renowned object technology mentor Martin Fowler breaks new ground, demystifying these master practices and demonstrating how software practitioners can realize the significant benefits of this new process.    With proper training a skilled system designer can take a bad design and rework it into well-designed, robust code. In this book, Martin Fowler shows you where opportunities for refactoring typically can be found, and how to go about reworking a bad design into a good one. Each refactoring step is simple--seemingly too simple to be worth doing. Refactoring may involve moving a field from one class to another, or pulling some code out of a method to turn it into its own method, or even pushing some code up or down a hierarchy. While these individual steps may seem elementary, the cumulative effect of such small changes can radically improve the design. Refactoring is a proven way to prevent software decay.    In addition to discussing the various techniques of refactoring, the author provides a detailed catalog of more than seventy proven refactorings with helpful pointers that teach you when to apply them; step-by-step instructions for applying each refactoring; and an example illustrating how the refactoring works. The illustrative examples are written in Java, but the ideas are applicable to any object-oriented programming language.},
	language = {en},
	publisher = {Addison-Wesley},
	author = {Fowler, Martin and Beck, Kent and Brant, John and Opdyke, William and Roberts, Don},
	month = mar,
	year = {2012},
	keywords = {Computers / Programming / Object Oriented}
}



@book{Ambler2006,
	title = {Refactoring {Databases}: {Evolutionary} {Database} {Design} (paperback)},
	isbn = {978-0-321-63017-9},
	shorttitle = {Refactoring {Databases}},
	abstract = {Refactoring has proven its value in a wide range of development projects–helping software professionals improve system designs, maintainability, extensibility, and performance. Now, for the first time, leading agile methodologist Scott Ambler and renowned consultant Pramodkumar Sadalage introduce powerful refactoring techniques specifically designed for database systems.   Ambler and Sadalage demonstrate how small changes to table structures, data, stored procedures, and triggers can significantly enhance virtually any database design–without changing semantics. You’ll learn how to evolve database schemas in step with source code–and become far more effective in projects relying on iterative, agile methodologies.   This comprehensive guide and reference helps you overcome the practical obstacles to refactoring real-world databases by covering every fundamental concept underlying database refactoring. Using start-to-finish examples, the authors walk you through refactoring simple standalone database applications as well as sophisticated multi-application scenarios. You’ll master every task involved in refactoring database schemas, and discover best practices for deploying refactorings in even the most complex production environments.    The second half of this book systematically covers five major categories of database refactorings. You’ll learn how to use refactoring to enhance database structure, data quality, and referential integrity; and how to refactor both architectures and methods. This book provides an extensive set of examples built with Oracle and Java and easily adaptable for other languages, such as C\#, C++, or VB.NET, and other databases, such as DB2, SQL Server, MySQL, and Sybase.   Using this book’s techniques and examples, you can reduce waste, rework, risk, and cost–and build database systems capable of evolving smoothly, far into the future.},
	language = {en},
	publisher = {Pearson Education},
	author = {Ambler, Scott W. and Sadalage, Pramod J.},
	month = mar,
	year = {2006},
	keywords = {Computers / Databases / General, Computers / Software Development \& Engineering / General}
}

@techreport{LeitloffSchultchenSSS2017,
address = {Fachhochschule f{\"u}r die Wirtschaft Hannover, Freundallee 15, 30173 Hannover, Germany},
institution = {FHDW Hannover},
month = {may},
number = {2},
title = {DELTA - A tool for database refactoring},
type = {techreport},
year = {2017},
author = {Leitloff, Lisa and Schultchen, Marius and Selent, Florain and Sternheim, Sascha and St{\"u}nkel, Patrick}
}

 @INPROCEEDINGS{CurinoMoonZ2008,
   author = {Carlo A. Curino and Hyun J. Moon and Carlo Zaniolo},
   title = {Graceful database schema evolution: the prism workbench},
   booktitle = {Very Large Data Base (VLDB)},
   year = {2008}
 }



@article{PaigeBrookeO2007,
	title = {Metamodel-based {Model} {Conformance} and {Multiview} {Consistency} {Checking}},
	volume = {16},
	issn = {1049-331X},
	url = {http://doi.acm.org/10.1145/1243987.1243989},
	doi = {10.1145/1243987.1243989},
	abstract = {Model-driven development, using languages such as UML and BON, often makes use of multiple diagrams (e.g., class and sequence diagrams) when modeling systems. These diagrams, presenting different views of a system of interest, may be inconsistent. A metamodel provides a unifying framework in which to ensure and check consistency, while at the same time providing the means to distinguish between valid and invalid models, that is, conformance. Two formal specifications of the metamodel for an object-oriented modeling language are presented, and it is shown how to use these specifications for model conformance and multiview consistency checking. Comparisons are made in terms of completeness and the level of automation each provide for checking multiview consistency and model conformance. The lessons learned from applying formal techniques to the problems of metamodeling, model conformance, and multiview consistency checking are summarized.},
	number = {3},
	urldate = {2018-08-27},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Paige, Richard F. and Brooke, Phillip J. and Ostroff, Jonathan S.},
	month = jul,
	year = {2007},
	keywords = {formal methods, automated verification, Metamodeling, multiview consistency},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/HICII9T9/Paige et al. - 2007 - Metamodel-based Model Conformance and Multiview Co.pdf:application/pdf}
}

@techreport{Koenig2012,
address = {Freundallee 15, 30173 Hannover, Germany},
institution = {FHDW Hannover},
number = {5},
title = {Trouble with Wrong Adjoints},
type = {Techreport},
year = {2012},
author = {K{\"o}nig, Harald}
}



@article{Plump1998,
  author    = {Detlef Plump},
  title     = {Termination of Graph Rewriting is Undecidable},
  journal   = {Fundam. Inform.},
  volume    = {33},
  number    = {2},
  pages     = {201--209},
  year      = {1998},
  url       = {https://doi.org/10.3233/FI-1998-33204},
  doi       = {10.3233/FI-1998-33204},
  timestamp = {Sat, 20 May 2017 00:23:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/fuin/Plump98},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@TECHREPORT{WolterDiskin07TR361UIB,
	author = {Uwe Wolter and Zinovy Diskin},
	title = {{From Indexed to Fibred Semantics -- The Generalized Sketch File}},
	institution = {Department of Informatics, University of Bergen, Norway},
	year = {2007},
	type = {Technical Report},
	number = {361},
	month = {October},
	ee = {http://www.ii.uib.no/publikasjoner/texrap/pdf/2007-361.pdf},
	file = {:./WolterDiskin07TR361UIB.pdf:},
	owner = {aronnax},
	timestamp = {2009.05.02}
}

@article{DBLP:journals/tse/HebigKB17,
  author    = {Regina Hebig and
               Djamel Eddine Khelladi and
               Reda Bendraou},
  title     = {Approaches to Co-Evolution of Metamodels and Models: {A} Survey},
  journal   = {{IEEE} Trans. Software Eng.},
  volume    = {43},
  number    = {5},
  pages     = {396--414},
  year      = {2017},
  url       = {https://doi.org/10.1109/TSE.2016.2610424},
  doi       = {10.1109/TSE.2016.2610424},
  timestamp = {Thu, 15 Jun 2017 21:30:50 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/tse/HebigKB17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Orejas11,
  author    = {Fernando Orejas},
  title     = {Symbolic graphs for attributed graph constraints},
  journal   = {J. Symb. Comput.},
  volume    = {46},
  number    = {3},
  pages     = {294--315},
  year      = {2011},
  url       = {https://doi.org/10.1016/j.jsc.2010.09.009},
  doi       = {10.1016/j.jsc.2010.09.009},
  timestamp = {Wed, 14 Jun 2017 20:37:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/jsc/Orejas11},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}





@article{deClercqBlomKA2004,
	title = {Approaches for creating computer-interpretable guidelines that facilitate decision support},
	volume = {31},
	issn = {0933-3657},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365704000399},
	doi = {10.1016/j.artmed.2004.02.003},
	abstract = {During the last decade, studies have shown the benefits of using clinical guidelines in the practice of medicine. Although the importance of these guidelines is widely recognized, health care organizations typically pay more attention to guideline development than to guideline implementation for routine use in daily care. However, studies have shown that clinicians are often not familiar with written guidelines and do not apply them appropriately during the actual care process. Implementing guidelines in computer-based decision support systems promises to improve the acceptance and application of guidelines in daily practice because the actions and observations of health care workers are monitored and advice is generated whenever a guideline is not followed. Such implementations are increasingly applied in diverse areas such as policy development, utilization management, education, clinical trials, and workflow facilitation. Many parties are developing computer-based guidelines as well as decision support systems that incorporate these guidelines. This paper reviews generic approaches for developing and implementing computer-based guidelines that facilitate decision support. It addresses guideline representation, acquisition, verification and execution aspects. The paper describes five approaches (the Arden Syntax, GuideLine Interchange Format (GLIF), PROforma, Asbru and EON), after the approaches are compared and discussed.},
	number = {1},
	urldate = {2018-11-30},
	journal = {Artificial Intelligence in Medicine},
	author = {de Clercq, Paul A and Blom, Johannes A and Korsten, Hendrikus H. M and Hasman, Arie},
	month = may,
	year = {2004},
	keywords = {Computer-interpretable guidelines, Guideline acquisition, Guideline execution, Guideline representation, Guideline verification},
	pages = {1--27},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/4AVHYG3C/de Clercq et al. - 2004 - Approaches for creating computer-interpretable gui.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/ETDSINNW/S0933365704000399.html:text/html}
}



@article{DaviesGibbonsHC2014,
	series = {Special issue on {Success} {Stories} in {Model} {Driven} {Engineering}},
	title = {The {CancerGrid} experience: {Metadata}-based model-driven engineering for clinical trials},
	volume = {89},
	issn = {0167-6423},
	shorttitle = {The {CancerGrid} experience},
	doi = {10.1016/j.scico.2013.02.010},
	abstract = {The CancerGrid approach to software support for clinical trials is based on two principles: careful curation of semantic metadata about clinical observations, to enable subsequent data integration, and model-driven generation of trial-specific software artefacts from a trial protocol, to streamline the software development process. This paper explains the approach, presents four varied case studies, and discusses the lessons learned.},
	urldate = {2018-11-30},
	journal = {Science of Computer Programming},
	author = {Davies, Jim and Gibbons, Jeremy and Harris, Steve and Crichton, Charles},
	month = sep,
	year = {2014},
	keywords = {Model-driven engineering, Clinical informatics, Electronic government, ISO/IEC11179, Metadata, Semantic frameworks},
	pages = {126--143}
}



@inproceedings{Bernstein2003,
	title = {Applying {Model} {Management} to {Classical} {Meta} {Data} {Problems}},
	abstract = {Model management is a new approach to meta data management that offers a higher level programming interface than current techniques. The main abstractions are models (e.g., schemas, interface definitions) and mappings between models. It treats these abstractions as bulk objects and offers such operators as Match, Merge, Diff, Compose, Apply, and ModelGen. This paper extends earlier treatments of these operators and applies them to three classical meta data management problems: schema integration, schema evolution, and round-trip engineering.},
	booktitle = {{CIDR}},
	author = {Bernstein, Philip A.},
	year = {2003},
	keywords = {Application programming interface, Apply, Round-trip engineering, Schema evolution},
	file = {Full Text PDF:/Users/past/Zotero/storage/DNKPS7GC/Bernstein - 2003 - Applying Model Management to Classical Meta Data P.pdf:application/pdf}
}



@inproceedings{GuerraDeLaraKP2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Inter-modelling: {From} {Theory} to {Practice}},
	isbn = {978-3-642-16145-2},
	shorttitle = {Inter-modelling},
	abstract = {We define inter-modelling as the activity of building models that describe how modelling languages should be related. This includes many common activities in Model Driven Engineering, like the specification of model-to-model transformations, the definition of model matching and model traceability constraints, the development of inter-model consistency maintainers and exogenous model management operators.Recently, we proposed a formal approach to specify the allowed and forbidden relations between two modelling languages by means of bidirectional declarative patterns. Such specifications were used to generate graph rewriting rules able to enforce the relations in (forward and backward) model-to-model transformation scenarios. In this paper we extend the usage of patterns for two further inter-modelling scenarios – model matching and model traceability – and report on an EMF-based tool implementing them. The tool allows a high-level analysis of specifications based on the theory developed so far, as well as manipulation of traces by compilation of patterns into the Epsilon Object Language.},
	language = {en},
	booktitle = {{MODELS} '10},
	publisher = {Springer Berlin Heidelberg},
	author = {Guerra, Esther and de Lara, Juan and Kolovos, Dimitrios S. and Paige, Richard F.},
	editor = {Petriu, Dorina C. and Rouquette, Nicolas and Haugen, {\O}ystein},
	year = {2010},
	keywords = {Design Pattern, Main Constraint, Model Match, Model Traceability, Triple Pattern},
	pages = {376--391}
}



@inproceedings{BruneliereCabotCFB2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {Model} {Driven} {Tool} {Interoperability}: {Bridging} {Eclipse} and {Microsoft} {Modeling} {Tools}},
	isbn = {978-3-642-13595-8},
	shorttitle = {Towards {Model} {Driven} {Tool} {Interoperability}},
	abstract = {Successful application of model-driven engineering approaches requires interchanging a lot of relevant data among the tool ecosystem employed by an engineering team (e.g., requirements elicitation tools, several kinds of modeling tools, reverse engineering tools, development platforms and so on). Unfortunately, this is not a trivial task. Poor tool interoperability makes data interchange a challenge even among tools with a similar scope. This paper presents a model-based solution to overcome such interoperability issues. With our approach, the internal schema/s (i.e., metamodel/s) of each tool are explicited and used as basis for solving syntactic and semantic differences between the tools. Once the corresponding metamodels are aligned, model-to-model transformations are (semi)automatically derived and executed to perform the actual data interchange. We illustrate our approach by bridging the Eclipse and Microsoft (DSL Tools and SQL Server Modeling) modeling tools.},
	language = {en},
	booktitle = {Modelling {Foundations} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Brunelière, Hugo and Cabot, Jordi and Clasen, Cauê and Jouault, Frédéric and Bézivin, Jean},
	editor = {Kühne, Thomas and Selic, Bran and Gervais, Marie-Pierre and Terrier, François},
	year = {2010},
	keywords = {Concrete Syntax, Eclipse Modeling Framework, Eclipse Modeling Framework Model, Requirement Elicitation, Virtual Machine},
	pages = {32--47}
}



@inproceedings{PaigeKolovosRDP2009,
	address = {Washington, DC, USA},
	series = {{ICECCS} '09},
	title = {The {Design} of a {Conceptual} {Framework} and {Technical} {Infrastructure} for {Model} {Management} {Language} {Engineering}},
	isbn = {978-0-7695-3702-3},
	doi = {10.1109/ICECCS.2009.14},
	abstract = {Model management is the discipline of managing artefacts used in Model-Driven Engineering (MDE). A model management framework defines and implements the operations (such as transformation or code generation) required to manipulate MDE artefacts. Modern approaches to model management generally implement these operations via domain-specific languages (DSLs). This paper presents and compares the principles behind three approaches to implementing DSLs for model management and identifies some of the key differences between DSL engineering in general and for model management. It then shows how theory relates to practice by illustrating how DSL design and implementation approaches have been used in practice to build working languages from the Epsilon model management framework. A set of questions for guiding the development of new model management DSLs is summarised, and data on development costs for the different approaches is presented.},
	urldate = {2019-02-01},
	booktitle = {Proceedings of the 2009 14th {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems}},
	publisher = {IEEE Computer Society},
	author = {Paige, Richard F. and Kolovos, Dimitrios S. and Rose, Louis M. and Drivalos, Nicholas and Polack, Fiona A. C.},
	year = {2009},
	keywords = {domain-specific languages, model management, Model-Driven Engineering},
	pages = {162--171}
}

@misc{PhilosophyEncyclopediaModels,
author = {{Jeffrey Koperski}},
title = {{Models} in {\em The Internet Encyclopedia of Philosophy}},
booktitle = {The Internet Encyclopedia of Philosophy},
url = {https://www.iep.utm.edu/models/},
issn= {2161-0002},
urldate = {2019-02-04}
}


@article{HebigKhelladiB2017,
	title = {Approaches to {Co}-{Evolution} of {Metamodels} and {Models}: {A} {Survey}},
	volume = {43},
	issn = {0098-5589},
	shorttitle = {Approaches to {Co}-{Evolution} of {Metamodels} and {Models}},
	doi = {10.1109/TSE.2016.2610424},
	abstract = {Modeling languages, just as all software artifacts, evolve. This poses the risk that legacy models of a company get lost, when they become incompatible with the new language version. To address this risk, a multitude of approaches for metamodel-model co-evolution were proposed in the last 10 years. However, the high number of solutions makes it difficult for practitioners to choose an appropriate approach. In this paper, we present a survey on 31 approaches to support metamodel-model co-evolution. We introduce a taxonomy of solution techniques and classify the existing approaches. To support researchers, we discuss the state of the art, in order to better identify open issues. Furthermore, we use the results to provide a decision support for practitioners, who aim to adopt solutions from research.},
	number = {5},
	journal = {IEEE Transactions on Software Engineering},
	author = {Hebig, R. and Khelladi, D. E. and Bendraou, R.},
	month = may,
	year = {2017},
	keywords = {Companies, Unified modeling language, Productivity, software engineering, Taxonomy, Atmospheric modeling, Biological system modeling, coevolution approaches, decision support, design notations and documentation, Libraries, metamodel-model coevolution, metamodels, models, solution technique taxonomy, Survey, \#SURVEY},
	pages = {396--414},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/2PMZFQC6/7569018.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/PXTBVB3M/Hebig et al. - 2017 - Approaches to Co-Evolution of Metamodels and Model.pdf:application/pdf}
}


@inproceedings{DiskinMaibaumCzarnecki2012,
	series = {LNCS},
	title = {Intermodeling, {Queries}, and {Kleisli} {Categories}},
	isbn = {978-3-642-28872-2},
	abstract = {Specification and maintenance of relationships between models are vital for MDE. We show that a wide class of such relationships can be specified in a compact and precise manner, if intermodel mappings are allowed to link derived model elements computed by corresponding queries. Composition of such mappings is not straightforward and requires specialized algebraic machinery. We present a formal framework, in which such machinery can be defined generically for a wide class of metamodel definitions. This enables algebraic specification of practical intermodeling scenarios, e.g., model merge.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Diskin, Zinovy and Maibaum, Tom and Czarnecki, Krzysztof},
	editor = {de Lara, Juan and Zisman, Andrea},
	year = {2012},
	keywords = {Category Theory, Query Language, Query Mechanism, Triple Graph, View Model},
	pages = {163--177},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/BEH45VF4/Diskin et al. - 2012 - Intermodeling, Queries, and Kleisli Categories.pdf:application/pdf}
}



@book{IEEE1990,
	series = {{ANSI} / {IEEE} {Std}},
	title = {{IEEE} {Standard} {Computer} {Dictionary}: {A} {Compilation} of {IEEE} {Standard} {Computer} {Glossaries}, 610},
	isbn = {978-1-55937-079-0},
	url = {https://books.google.no/books?id=xycFAQAACAAJ},
	publisher = {IEEE},
	author = {Committee, IEEE Computer Society Standards Coordinating},
	year = {1990},
	lccn = {90086306}
}


@article{BatiniLenzeriniN1986,
	title = {A {Comparative} {Analysis} of {Methodologies} for {Database} {Schema} {Integration}},
	volume = {18},
	issn = {0360-0300},
	doi = {10.1145/27633.27634},
	abstract = {One of the fundamental principles of the database approach is that a database allows a nonredundant, unified representation of all data managed in an organization. This is achieved only when methodologies are available to support integration across organizational and application boundaries.
Methodologies for database design usually perform the design activity by separately producing several schemas, representing parts of the application, which are subsequently merged. Database schema integration is the activity of integrating the schemas of existing or proposed databases into a global, unified schema.
The aim of the paper is to provide first a unifying framework for the problem of schema integration, then a comparative review of the work done thus far in this area. Such a framework, with the associated analysis of the existing approaches, provides a basis for identifying strengths and weaknesses of individual methodologies, as well as general guidelines for future improvements and extensions.},
	number = {4},
	urldate = {2019-02-20},
	journal = {ACM Comput. Surv.},
	author = {Batini, C. and Lenzerini, M. and Navathe, S. B.},
	month = dec,
	year = {1986},
	pages = {323--364},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/RWLQU5IG/Batini et al. - 1986 - A Comparative Analysis of Methodologies for Databa.pdf:application/pdf}
}


@book{EuzenatShvaiko2013,
	address = {Berlin Heidelberg},
	edition = {2},
	title = {Ontology {Matching}},
	isbn = {978-3-642-38720-3},
	abstract = {Ontologies tend to be found everywhere. They are viewed as the silver bullet for many applications, such as database integration, peer-to-peer systems, e-commerce, semantic web services, or social networks. However, in open or evolving systems, such as the semantic web, different parties would, in general, adopt different ontologies. Thus, merely using ontologies, like using XML, does not reduce heterogeneity: it just raises heterogeneity problems to a higher level.Euzenat and Shvaiko’s book is devoted to ontology matching as a solution to the semantic heterogeneity problem faced by computer systems. Ontology matching aims at finding correspondences between semantically related entities of different ontologies. These correspondences may stand for equivalence as well as other relations, such as consequence, subsumption, or disjointness, between ontology entities. Many different matching solutions have been proposed so far from various viewpoints, e.g., databases, information systems, and artificial intelligence.The second edition of Ontology Matching has been thoroughly revised and updated to reflect the most recent advances in this quickly developing area, which resulted in more than 150 pages of new content. In particular, the book includes a new chapter dedicated to the methodology for performing ontology matching. It also covers emerging topics, such as data interlinking, ontology partitioning and pruning, context-based matching, matcher tuning, alignment debugging, and user involvement in matching, to mention a few. More than 100 state-of-the-art matching systems and frameworks were reviewed.With Ontology Matching, researchers and practitioners will find a reference book that presents currently available work in a uniform framework. In particular, the work and the techniques presented in this book can be equally applied to database schema matching, catalog integration, XML schema matching and other related problems. The objectives of the book include presenting (i) the state of the art and (ii) the latest research results in ontology matching by providing a systematic and detailed account of matching techniques and matching systems from theoretical, practical and application perspectives.},
	language = {en},
	urldate = {2019-02-20},
	publisher = {Springer-Verlag},
	author = {Euzenat, Jérôme and Shvaiko, Pavel},
	year = {2013}
}



@inproceedings{deSousaLopesCA2009,
	series = {Lecture {Notes} in {Business} {Information} {Processing}},
	title = {A {Step} {Forward} in {Semi}-automatic {Metamodel} {Matching}: {Algorithms} and {Tool}},
	isbn = {978-3-642-01347-8},
	shorttitle = {A {Step} {Forward} in {Semi}-automatic {Metamodel} {Matching}},
	abstract = {In recent years the complexity of producing softwares systems has increased due the continuous evolution of the requirements, the creation of new technologies and integration with legacy systems. When complexity increases the phases of software development, maintenance and evolution become more difficult to deal with, i.e. they became more subject to error-prone factors. Recently, Model Driven Architecture (MDA) has made the management of this complexity possible thanks to models and the transformation of Platform-Independent Model (PIM) in Platform-Specific Models (PSM). However, the manual creation of transformation definitions is a programming activity which is error-prone because it is a manual task. In the MDA context, the solution is to provide semi-automatic creation of a mapping specification that can be used to generate transformation definitions in a specific transformation language. In this paper, we present an algorithm to match metamodels and enhancements in the MT4MDE and SAMT4MDE tool in order to implement this matching algorithm.},
	language = {en},
	booktitle = {Enterprise {Information} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {de Sousa, José and Lopes, Denivaldo and Claro, Daniela Barreiro and Abdelouahab, Zair},
	editor = {Filipe, Joaquim and Cordeiro, José},
	year = {2009},
	keywords = {Algorithm, Mapping specification, Metamodel matching},
	pages = {137--148}
}


@article{delFabroValduriez2009,
	title = {Towards the efficient development of model transformations using model weaving and matching transformations},
	volume = {8},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-008-0094-z},
	doi = {10.1007/s10270-008-0094-z},
	abstract = {Model transformations can be used in many different application scenarios, for instance, to provide interoperability between models of different size and complexity. As a consequence, they are becoming more and more complex. However, model transformations are typically developed manually. Several code patterns are implemented repetitively, thus increasing the probability of programming errors and reducing code reusability. There is not yet a complete solution that automates the development of model transformations. In this paper, we present a novel approach that uses matching transformations and weaving models to semi-automate the development of transformations. Weaving models are models that contain different kinds of relationships between model elements. These relationships capture different transformation patterns. Matching transformations are a special kind of transformations that implement methods that create weaving models. We present a practical solution that enables the creation and the customization of different creation methods in an efficient way. We combine different methods, and present a metamodel-based method that exploits metamodel data to automatically produce weaving models. The weaving models are derived into model integration transformations. To validate our approach, we present an experiment using metamodels with distinct size and complexity, which show the feasibility and scalability of our solution.},
	language = {en},
	number = {3},
	urldate = {2019-02-20},
	journal = {Software \& Systems Modeling},
	author = {Didonet Del Fabro, Marcos and Valduriez, Patrick},
	month = jul,
	year = {2009},
	keywords = {Matching transformations, Model engineering, Model weaving},
	pages = {305--324},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/MLFM9E2B/Didonet Del Fabro and Valduriez - 2009 - Towards the efficient development of model transfo.pdf:application/pdf}
}


@inproceedings{VoigtHeinze2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Metamodel {Matching} {Based} on {Planar} {Graph} {Edit} {Distance}},
	isbn = {978-3-642-13688-7},
	abstract = {A prerequisite for implementing a model transformation is a mapping between metamodel elements. A mapping consists of matches and requires the task of discovering semantic correspondences between elements. This task is called metamodel matching. Recently, semi-automatic matching has been proposed to support transformation development by mapping generation.However, current matching approaches utilize labels, types and similarity propagation approaches rather than graph isomorphism as structural matching. In constrast, we propose to apply an efficient approximate graph edit distance algorithm and present the necessary adjustments and extensions of the general algorithm as well as an optimization with ranked partial seed mappings. We evaluated the algorithm using 20 large-size mappings demonstrating effectively the improvements, especially regarding the correctness of matches found.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Voigt, Konrad and Heinze, Thomas},
	editor = {Tratt, Laurence and Gogolla, Martin},
	year = {2010},
	keywords = {Edit Distance, Ontology Match, Planar Embedding, Planar Graph, Seed Match},
	pages = {245--259}
}


@inproceedings{KappelKapsammerKKRRSW2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Lifting {Metamodels} to {Ontologies}: {A} {Step} to the {Semantic} {Integration} of {Modeling} {Languages}},
	isbn = {978-3-540-45773-2},
	shorttitle = {Lifting {Metamodels} to {Ontologies}},
	abstract = {The use of different modeling languages in software development makes their integration a must. Most existing integration approaches are metamodel-based with these metamodels representing both an abstract syntax of the corresponding modeling language and also a data structure for storing models. This implementation specific focus, however, does not make explicit certain language concepts, which can complicate integration tasks. Hence, we propose a process which semi-automatically lifts metamodels into ontologies by making implicit concepts in the metamodel explicit in the ontology. Thus, a shift of focus from the implementation of a certain modeling language towards the explicit reification of the concepts covered by this language is made. This allows matching on a solely conceptual level, which helps to achieve better results in terms of mappings that can in turn be a basis for deriving implementation specific transformation code.},
	language = {en},
	booktitle = {Model {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kappel, Gerti and Kapsammer, Elisabeth and Kargl, Horst and Kramler, Gerhard and Reiter, Thomas and Retschitzegger, Werner and Schwinger, Wieland and Wimmer, Manuel},
	editor = {Nierstrasz, Oscar and Whittle, Jon and Harel, David and Reggio, Gianna},
	year = {2006},
	keywords = {Abstract Syntax, Class Class, Eclipse Modeling Framework, Modeling Language, Object Property},
	pages = {528--542}
}


@inproceedings{KolovosRuscioPP2009,
	address = {Washington, DC, USA},
	series = {{CVSM} '09},
	title = {Different {Models} for {Model} {Matching}: {An} {Analysis} of {Approaches} to {Support} {Model} {Differencing}},
	isbn = {978-1-4244-3714-6},
	shorttitle = {Different {Models} for {Model} {Matching}},
	doi = {10.1109/CVSM.2009.5071714},
	abstract = {Calculating differences between models is an important and challenging task in Model Driven Engineering. Model differencing involves a number of steps starting with identifying matching model elements, calculating and representing their differences, and finally visualizing them in an appropriate way. In this paper, we provide an overview of the fundamental steps involved in the model differencing process and summarize the advantages and shortcomings of existing approaches for identifying matching model elements. To assist potential users in selecting one of the existing methods for the problem at stake, we investigate the trade-offs these methods impose in terms of accuracy and effort required to implement each one of them.},
	urldate = {2019-02-20},
	booktitle = {Proceedings of the 2009 {ICSE} {Workshop} on {Comparison} and {Versioning} of {Software} {Models}},
	publisher = {IEEE Computer Society},
	author = {Kolovos, Dimitrios S. and Di Ruscio, Davide and Pierantonio, Alfonso and Paige, Richard F.},
	year = {2009},
	pages = {1--6},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/3ME567PS/Kolovos et al. - 2009 - Different Models for Model Matching An Analysis o.pdf:application/pdf}
}


@inproceedings{WilliamsPaigeP2012,
	address = {New York, NY, USA},
	title = {Searching for {Model} {Migration} {Strategies}},
	isbn = {978-1-4503-1798-6},
	doi = {10.1145/2523599.2523607},
	abstract = {Metamodels, like many software artefacts, are subject to evolution. If a metamodel evolves, models that previously conformed to the metamodel may become non-conformant, and must be migrated to reestablish conformance. Manually migrating models can be tedious and error prone, and a number of solutions have arisen to aid in the creation of a migration strategy - a model transformation which automates the migration. This paper asks whether we can make use of research in the field of Search-Based Software Engineering to automatically discover migration strategies, and discusses the challenges involved. In particular, we explore how tools that provide coupled evolution of metamodels and models provide a suitable platform for which to apply search techniques.},
	urldate = {2019-02-20},
	booktitle = {{ME} '12},
	publisher = {ACM},
	author = {Williams, James R. and Paige, Richard F. and Polack, Fiona A. C.},
	year = {2012},
	pages = {39--44},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/LWR4P4VA/Williams et al. - 2012 - Searching for Model Migration Strategies.pdf:application/pdf}
}


@inproceedings{RiveraValecillo2008,
	series = {Lecture {Notes} in {Business} {Information} {Processing}},
	title = {Representing and {Operating} with {Model} {Differences}},
	isbn = {978-3-540-69824-1},
	abstract = {Models and metamodels play a cornerstone role in Model-Driven Software Development (MDSD). Models conform to metamodels, which usually specify domain-specific languages that allow to represent the various facets of a system in terms of models. This paper discusses the problem of calculating differences between models conforming to arbitrary metamodels, something essential in any MDSD environment for dealing with the management of changes and evolution of software models. We present a metamodel for representing the differences as models, too, following the MDSD “everything is a model” principle. The Difference Metamodel, together with the difference and other related operations (do, undo and composition) presented here have been specified in Maude and integrated in an Eclipse-developed environment.},
	language = {en},
	booktitle = {Objects, {Components}, {Models} and {Patterns}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rivera, José E. and Vallecillo, Antonio},
	editor = {Paige, Richard F. and Meyer, Bertrand},
	year = {2008},
	keywords = {Maude, model comparison, model difference, model evolution, Model-driven software development, object matching},
	pages = {141--160},
	doi = {10.1007/978-3-540-69824-1_9}
}


@inproceedings{Narain2005,
	address = {Berkeley, CA, USA},
	series = {{LISA} '05},
	title = {Network {Configuration} {Management} via {Model} {Finding}},
	abstract = {Complex, end-to-end network services are set up via the configuration method: each component has a finite number of configuration parameters each of which is set to a definite value. End-to-end network service requirements can be on connectivity, security, performance and fault-tolerance. However, there is a large conceptual gap between end-to-end requirements and detailed component configurations. To bridge this gap, a number of subsidiary requirements are created that constrain, for example, the protocols to be used, and the logical structures and associated policies to be set up at different protocol layers. By performing different types of reasoning with these requirements, different configuration tasks are accomplished. These include configuration synthesis, configuration error diagnosis, configuration error fixing, reconfiguration as requirements or components are added and deleted, and requirement verification. However, such reasoning is currently ad hoc. Network requirements are not even precisely specified hence automation of reasoning is impossible. This is a major reason for the high cost of network management and total cost of ownership. This paper shows how to formalize and automate such reasoning using a new logical system called Alloy. Alloy is based on the concept of model finding. Given a first-order logic formula and a domain of interpretation, Alloy tries to find whether the formula is satisfiable in that domain, i.e., whether it has a model. Alloy is used to build a Requirement Solver that takes as input a set of network components and requirements upon their configurations and determines component configurations satisfying those requirements. This Solver is used in different ways to accomplish the above reasoning tasks. The Solver is illustrated in depth by carrying out a variety of these tasks in the context of a realistic fault-tolerant virtual private network with remote access. Alloy uses modern satisfiability solvers that solve millions of constraints in millions of variables in seconds. However, poor requirements can easily nullify such speeds. The paper outlines approaches for writing efficient requirements. Finally, it outlines directions for future research.},
	urldate = {2019-02-20},
	booktitle = {{LISA} '05},
	publisher = {USENIX Association},
	author = {Narain, Sanjai},
	year = {2005},
	pages = {15--15}
}



@article{MintonJohnstonPL1992,
	title = {Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems},
	volume = {58},
	issn = {0004-3702},
	shorttitle = {Minimizing conflicts},
	doi = {10.1016/0004-3702(92)90007-K},
	abstract = {The paper describes a simple heuristic approach to solving large-scale constraint satisfaction and scheduling problems. In this approach one starts with an inconsistent assignment for a set of variables and searches through the space of possible repairs. The search can be guided by a value-ordering heuristic, the min-conflicts heuristic, that attempts to minimize the number of constraint violations after each step. The heuristic can be used with a variety of different search strategies. We demonstrate empirically that on the n-queens problem, a technique based on this approach performs orders of magnitude better than traditional backtracking techniques. We also describe a scheduling application where the approach has been used successfully. A theoretical analysis is presented both to explain why this method works well on certain types of problems and to predict when it is likely to be most effective.},
	number = {1},
	urldate = {2019-02-20},
	journal = {Artificial Intelligence},
	author = {Minton, Steven and Johnston, Mark D. and Philips, Andrew B. and Laird, Philip},
	month = dec,
	year = {1992},
	pages = {161--205},
	file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/YTWRN2D4/000437029290007K.html:text/html}
}


@book{Knuth2011,
	edition = {1st},
	title = {The {Art} of {Computer} {Programming}: {Combinatorial} {Algorithms}, {Part} 1},
	isbn = {978-0-201-03804-0},
	shorttitle = {The {Art} of {Computer} {Programming}},
	abstract = {Finally, after a wait of more than thirty-five years, the first part of Volume 4 is at last ready for publication. Check out the boxed set that brings together Volumes 1 - 4A in one elegant case, and offers the purchaser a \$50 discount off the price of buying the four volumes individually. The Art of Computer Programming, Volumes 1-4A Boxed Set, 3/e ISBN: 0321751043 The Art of Computer Programming, Volume 4A: Combinatorial Algorithms, Part 1 Knuths multivolume analysis of algorithms is widely recognized as the definitive description of classical computer science. The first three volumes of this work have long comprised a unique and invaluable resource in programming theory and practice. Scientists have marveled at the beauty and elegance of Knuths analysis, while practicing programmers have successfully applied his cookbook solutions to their day-to-day problems. The level of these first three volumes has remained so high, and they have displayed so wide and deep a familiarity with the art of computer programming, that a sufficient review of future volumes could almost be: Knuth, Volume n has been published. Data Processing Digest Knuth, Volume n has been published, where n = 4A. In this long-awaited new volume, the old master turns his attention to some of his favorite topics in broadword computation and combinatorial generation (exhaustively listing fundamental combinatorial objects, such as permutations, partitions, and trees), as well as his more recent interests, such as binary decision diagrams. The hallmark qualities that distinguish his previous volumes are manifest here anew: detailed coverage of the basics, illustrated with well-chosen examples; occasional forays into more esoteric topics and problems at the frontiers of research; impeccable writing peppered with occasional bits of humor; extensive collections of exercises, all with solutions or helpful hints; a careful attention to history; implementations of many of the algorithms in his classic step-by-step form. There is an amazing amount of information on each page. Knuth has obviously thought long and hard about which topics and results are most central and important, and then, what are the most intuitive and succinct ways of presenting that material. Since the areas that he covers in this volume have exploded since he first envisioned writing about them, it is wonderful how he has managed to provide such thorough treatment in so few pages. Frank Ruskey, Department of Computer Science, University of Victoria The book is Volume 4A, because Volume 4 has itself become a multivolume undertaking. Combinatorial searching is a rich and important topic, and Knuth has too much to say about it that is new, interesting, and useful to fit into a single volume, or two, or maybe even three. This book alone includes approximately 1500 exercises, with answers for self-study, plus hundreds of useful facts that cannot be found in any other publication. Volume 4A surely belongs beside the first three volumes of this classic work in every serious programmers library.},
	publisher = {Addison-Wesley Professional},
	author = {Knuth, Donald E.},
	year = {2011}
}


@article{KahaniBCDV2018,
	title = {Survey and classification of model transformation tools},
	issn = {1619-1374},
	doi = {10.1007/s10270-018-0665-6},
	abstract = {Model transformation lies at the very core of model-driven engineering, and a large number of model transformation languages and tools have been proposed over the last few years. These tools can be used to develop, transform, merge, exchange, compare, and verify models and metamodels. In this paper, we present a comprehensive catalog of existing metamodel-based transformation tools and compare them using a qualitative framework. We begin by organizing the 60 tools we identified into a general classification based on the transformation approach used. We then compare these tools using a number of particular facets, where each facet belongs to one of six different categories and may contain several attributes. The results of the study are discussed in detail and made publicly available in a companion website with a capability to search for tools using the specified facets as search criteria. Our study provides a thorough picture of the state-of-the-art in model transformation techniques and tools. Our results are potentially beneficial to many stakeholders in the modeling community, including practitioners, researchers, and transformation tool developers.},
	language = {en},
	urldate = {2019-02-20},
	journal = {Software \& Systems Modeling},
	author = {Kahani, Nafiseh and Bagherzadeh, Mojtaba and Cordy, James R. and Dingel, Juergen and Varró, Daniel},
	month = mar,
	year = {2018},
	keywords = {Classification, Metamodel, Model transformation tools, Model-driven development, Survey},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/T4FYALSG/Kahani et al. - 2018 - Survey and classification of model transformation .pdf:application/pdf}
}



@inproceedings{Gruschko2007,
	title = {Towards {Synchronizing} {Models} with {Evolving} {Metamodels}},
	abstract = {Metamodel evolution poses a threat to the applicability of Model-Driven Development to large scale projects. The problem is caused by incompatibilities between metamodel revisions. These render models that conform to the older version of the metamodel non-conformant to the newer version. An approach to addressing this problem is co-evolution of models with their respective metamodels. I n this paper we introduce the problem of synchronizing models with evolving metamodels and outline an approach to addressing it efficiently. The aim of the proposed approach is to minimize the effort required to perform model migration in face of metamodel changes. To provide deeper insights into the envisioned approach, we demonstrate prelim inary solutions to the problem of change detection between two metamodel revisions. Furthermore, we present an approach to model-to-model transformations, using a conservative copying algorithm, which regulates the retainment o f instances during model migration.},
	author = {Gruschko, Boris and Kolovos, Dimitrios and Paige, Richard},
	year = {2007},
	booktitle = {MODSE 2007},
	keywords = {Algorithm, cell transformation, Metamodeling, Model-driven engineering, Model-driven integration},
	file = {Full Text PDF:/Users/past/Zotero/storage/PUVRUHJS/Gruschko - 2007 - Towards Synchronizing Models with Evolving Metamod.pdf:application/pdf}
}



@incollection{AbouSalehCheneyGMS2018,
	series = {LNCS},
	title = {Introduction to {Bidirectional} {Transformations}},
	isbn = {978-3-319-79108-1},
	abstract = {Bidirectional transformations (BX) serve to maintain consistency between different representations of related and often overlapping information, translating changes in one representation to the others. We present a brief introduction to the field, in order to provide some common background to the remainder of this volume, which constitutes the lecture notes from the Summer School on Bidirectional Transformations, held in Oxford in July 2016 as one of the closing activities of the UK EPSRC-funded project A Theory of Least Change for Bidirectional Transformations.},
	language = {en},
	urldate = {2019-02-20},
	booktitle = {Bidirectional {Transformations}: {International} {Summer} {School}, 2016},
	publisher = {Springer International Publishing},
	author = {Abou-Saleh, Faris and Cheney, James and Gibbons, Jeremy and McKinna, James and Stevens, Perdita},
	editor = {Gibbons, Jeremy and Stevens, Perdita},
	year = {2018},
	doi = {10.1007/978-3-319-79108-1\_1},
	pages = {1--28},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/EUMYYPSA/Abou-Saleh et al. - 2018 - Introduction to Bidirectional Transformations.pdf:application/pdf}
}



@article{BernsteinHaas2008,
	title = {Information {Integration} in the {Enterprise}},
	volume = {51},
	issn = {0001-0782},
	doi = {10.1145/1378727.1378745},
	abstract = {A guide to the tools and core technologies for merging information from disparate sources.},
	number = {9},
	urldate = {2019-02-22},
	journal = {Commun. ACM},
	author = {Bernstein, Philip A. and Haas, Laura M.},
	month = sep,
	year = {2008},
	pages = {72--79}
}



@article{SobocinskiHeindel2011,
	title = {Being {Van} {Kampen} is a universal property},
	volume = {7},
	issn = {18605974},
	doi = {10.2168/LMCS-7(1:14)2011},
	abstract = {Colimits that satisfy the Van Kampen condition have interesting exactness properties. We show that the elementary presentation of the Van Kampen condition is actually a characterisation of a universal property in the associated bicategory of spans. The main theorem states that Van Kampen cocones are precisely those diagrams in a category that induce bicolimit diagrams in its associated bicategory of spans, provided that the category has pullbacks and enough colimits.},
	number = {1},
	urldate = {2019-02-22},
	journal = {Logical Methods in Computer Science},
	author = {Sobocinski, Pawel and Heindel, Tobias},
	month = apr,
	year = {2011},
	note = {arXiv: 1101.4594},
	keywords = {Computer Science - Programming Languages, cs.PL, Mathematics - Category Theory}
}



@inproceedings{Woolman2011,
	series = {{MIXHS} '11},
	title = {Challenges of {Managing} {Interoperability} in {Regional} {Healthcare} {Organisations}},
	isbn = {978-1-4503-0954-7},
	doi = {10.1145/2064747.2064749},
	abstract = {This talk presents observations taken from initiatives in different countries which aimed toward regional or country wide integration or interoperability solutions. There are many existing publications and decades of talks related to the micro-scale interoperability challenges. Much published material is related to small R\&D projects, individual commercial, academic or locally developed solutions. Some authors have commented on the theory of the larger scale, of how things "could be" on a regional scale if only everyone cooperated and developed solutions and operated them in a particular theoretical solution. This talk instead will be focussing on the macro-scale embracing multi-vendor, multi-health organisations in large regions. It will bring out real life experiences, much from the UK including Scotland and will indicate where real challenges lie and will point to existing solutions that work, and some that don't work. The talk will bring in standards, technical and business process, some that are widely used, and some that are theoretical dinosaurs. The author will bring in knowledge management challenges, particularly focussing on data and terminology standards. The talk will be delivered in the typical 'hold no punches' style of the author tempered with the political astuteness gained in more recent years working for a Government.},
	urldate = {2019-02-25},
	booktitle = {{MIXHS} '11},
	publisher = {ACM},
	author = {Woolman, Paul S.},
	year = {2011},
	keywords = {interoperability, standards},
	pages = {1--2},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/5I4HHB9U/Woolman - 2011 - Challenges of Managing Interoperability in Regiona.pdf:application/pdf}
}



@book{WarmerKleppe1999,
	address = {Boston, MA, USA},
	title = {The {Object} {Constraint} {Language}: {Precise} {Modeling} with {UML}},
	isbn = {978-0-201-37940-2},
	shorttitle = {The {Object} {Constraint} {Language}},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Warmer, Jos and Kleppe, Anneke},
	year = {1999}
}



@article{DyckhoffTholen1987,
	title = {Exponentiable {Morphisms}, {Partial} {Products} and {Pullback} {Complements}},
	volume = {49},
	issn = {0022-4049},
	language = {English},
	journal = {Journal of Pure and Applied Algebra},
	author = {Dyckhoff, Roy and Tholen, W.},
	year = {1987},
	pages = {103--116}
}



@article{KoenigWolter2017,
	title = {Van {Kampen} {Colimits} and {Path} {Uniqueness}},
	doi = {10.23638/LMCS-14(2:5)2018},
	abstract = {Fibred semantics is the foundation of the model-instance pattern of software engineering. Software models can often be formalized as objects of presheaf topoi, i.e, categories of objects that can be represented as algebras as well as coalgebras, e.g., the category of directed graphs. Multimodeling requires to construct colimits of models, decomposition is given by pullback. Compositionality requires an exact interplay of these operations, i.e., diagrams must enjoy the Van Kampen property. However, checking the validity of the Van Kampen property algorithmically based on its definition is often impossible. In this paper we state a necessary and sufficient yet efficiently checkable condition for the Van Kampen property to hold in presheaf topoi. It is based on a uniqueness property of path-like structures within the defining congruence classes that make up the colimiting cocone of the models. We thus add to the statement "Being Van Kampen is a Universal Property" by Heindel and Soboci{\textbackslash}'\{n\}ski the fact that the Van Kampen property reveals a presheaf-based structural uniqueness feature.},
	urldate = {2019-03-06},
	journal = {Logical Methods in Computer Science},
	volume = 14,
	author = {König, Harald and Wolter, Uwe},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.09784},
	keywords = {18A15, 18A25, Mathematics - Category Theory},
	file = {arXiv\:1710.09784 PDF:/Users/past/Zotero/storage/DMHRFJ3E/König and Wolter - 2017 - Van Kampen Colimits and Path Uniqueness.pdf:application/pdf;arXiv.org Snapshot:/Users/past/Zotero/storage/2XYCEYCZ/1710.html:text/html}
}



@inproceedings{MensWermelingerDDHJ2005,
	title = {Challenges in software evolution},
	doi = {10.1109/IWPSE.2005.7},
	abstract = {Today's information technology society increasingly relies on software at all levels. Nevertheless, software quality generally continues to fall short of expectations, and software systems continue to suffer from symptoms of aging as they are adapted to changing requirements and environments. The only way to overcome or avoid the negative effects of software aging is by placing change and evolution in the center of the software development process. In this article we describe what we believe to be some of the most important research challenges in software evolution. The goal of this document is to provide novel research directions in the software evolution domain.},
	booktitle = {{IWPSE}'05},
	author = {Mens, T. and Wermelinger, M. and Ducasse, S. and Demeyer, S. and Hirschfeld, R. and Jazayeri, M.},
	month = sep,
	year = {2005},
	keywords = {Aging, Business, Collaborative software, Computer industry, Conferences, formal specification, formal verification, Information technology, information technology society, Programming, requirements analysis, software aging, software development process, software evolution, software maintenance, software quality, Software quality, software system, Software systems, Software tools},
	pages = {13--22},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/NNKWG8AK/1572302.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/6AYNCIE4/Mens et al. - 2005 - Challenges in software evolution.pdf:application/pdf}
}



@article{Codd1970,
	title = {A {Relational} {Model} of {Data} for {Large} {Shared} {Data} {Banks}},
	volume = {13},
	issn = {0001-0782},
	doi = {10.1145/362384.362685},
	abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information.
Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.},
	number = {6},
	urldate = {2019-02-04},
	journal = {Commun. ACM},
	author = {Codd, E. F.},
	month = jun,
	year = {1970},
	keywords = {data integrity, composition, consistency, data bank, data base, data organization, data structure, derivability, hierarchies of data, join, networks of data, predicate calculus, redundancy, relations, retrieval language, security},
	pages = {377--387},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/YFVUKW8G/Codd - 1970 - A Relational Model of Data for Large Shared Data B.pdf:application/pdf}
}



@article{DSilvaKroeningW2008,
	title = {A {Survey} of {Automated} {Techniques} for {Formal} {Software} {Verification}},
	volume = {27},
	issn = {0278-0070},
	doi = {10.1109/TCAD.2008.923410},
	abstract = {The quality and the correctness of software are often the greatest concern in electronic systems. Formal verification tools can provide a guarantee that a design is free of specific flaws. This paper surveys algorithms that perform automatic static analysis of software to detect programming errors or prove their absence. The three techniques considered are static analysis with abstract domains, model checking, and bounded model checking. A short tutorial on these techniques is provided, highlighting their differences when applied to practical problems. This paper also surveys tools implementing these techniques and describes their merits and shortcomings.},
	number = {7},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {D'Silva, V. and Kroening, D. and Weissenbacher, G.},
	month = jul,
	year = {2008},
	keywords = {program verification, Software performance, Software quality, Software systems, Algorithm design and analysis, abstract domains, automated techniques, Automatic programming, automatic static analysis, Automatic testing, bounded model checking, Bounded model checking (BMC), electronic engineering computing, electronic systems, formal software verification, Formal verification, formal verification tools, Hardware, model checking, Performance analysis, predicate abstraction, program diagnostics, programming error detection, Software algorithms, software verification, static analysis},
	pages = {1165--1178},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/UBVZPS68/4544862.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/X6Z9PPS4/D'Silva et al. - 2008 - A Survey of Automated Techniques for Formal Softwa.pdf:application/pdf}
}



@inproceedings{FinkelsteiinSpanoudakisT1996,
	address = {New York, NY, USA},
	title = {Managing {Interference}},
	isbn = {978-0-89791-867-1},
	doi = {10.1145/243327.243646},
	urldate = {2019-03-07},
	booktitle = {{ISAW} '96 and {Viewpoints} '96 on {SIGSOFT} '96 {Workshops}},
	publisher = {ACM},
	author = {Finkelsteiin, Anthony and Spanoudakis, George and Till, David},
	year = {1996},
	pages = {172--174}
}


@inproceedings{SpanoudakisZisman2000,
	title = {Inconsistency {Management} in {Software} {Engineering}: {Survey} and {Open} {Research} {Issues}},
	shorttitle = {Inconsistency {Management} in {Software} {Engineering}},
	abstract = {The development of complex software systems is a complex and lengthy activity that involves the participation and collaboration of many stakeholders (e.g. customers, users, analysts, designers, and developers). This results in many partial models of the developing system. These models can be inconsistent with each other since they describe the system from different perspectives and reflects the views of the stakeholders involved in their construction. Inconsistent software models can have negative and positive effects in the software development life-cycle. On the negative side, inconsistencies can delay and increase the cost of system development; do not guarantee some properties of the system, such as safety and reliability; and generate difficulties on system maintenance. On the positive side, inconsistencies can facilitate identification of some aspects of the system that need further analysis, assist with the specification of alternatives for the development of the system, and support elicitation of information about it. The software engineering community has proposed many techniques and methods to support the management of inconsistencies in various software models. In this paper, we present a survey of these techniques and methods. The survey is organized according to a conceptual framework which views inconsistency management as a process composed of six activities. These activities are the detection of overlaps, detection of inconsistencies, diagnosis of inconsistencies, handling of inconsistencies, tracking of inconsistencies, and specification and application of a management policy for inconsistencies. This paper also presents the main contributions of the research work that has been conducted to support each of the above activities and identifies the issues which are still open to further research.},
	author = {Spanoudakis, George and Zisman, Andrea},
	year = {2001},
	booktitle = {Handbook of Software Engineering and Knowledge Engineering},
	pages = {329--380},
	doi = {10.1142/9789812389718_0015},
	keywords = {Software system, Software engineering, Consistency (database systems), Handling (Psychology), Open research, Software development process}
}


@article{MacedoJorgeC2017,
	title = {A {Feature}-{Based} {Classification} of {Model} {Repair} {Approaches}},
	volume = {43},
	issn = {0098-5589},
	doi = {10.1109/TSE.2016.2620145},
	abstract = {Consistency management, the ability to detect, diagnose and handle inconsistencies, is crucial during the development process in Model-driven Engineering (MDE). As the popularity and application scenarios of MDE expanded, a variety of different techniques were proposed to address these tasks in specific contexts. Of the various stages of consistency management, this work focuses on inconsistency handling in MDE, particularly in model repair techniques. This paper proposes a feature-based classification system for model repair techniques, based on an systematic literature review of the area. We expect this work to assist developers and researchers from different disciplines in comparing their work under a unifying framework, and aid MDE practitioners in selecting suitable model repair approaches.},
	number = {7},
	journal = {IEEE Transactions on Software Engineering},
	author = {Macedo, N. and Jorge, T. and Cunha, A.},
	month = jul,
	year = {2017},
	keywords = {Context, Unified modeling language, MDE, consistency management, Feature extraction, feature-based classification system, Maintenance engineering, model repair approach, model-driven engineering, Model-driven engineering, consistency management, inconsistency handling, model repair, pattern classification, Software engineering, software maintenance, Systematics, Taxonomy, \#SURVEY},
	pages = {615--640},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/4NZARZ7E/7605502.html:text/html}
}


@incollection{AbrialSchumanMeyer1980,
	title = {Specification {Language}},
	booktitle = {On the {Construction} of {Programs}},
	author = {Abrial, Jean-Raymond and Schuman, Stephen A. and Meyer, Bertrand},
	year = {1980},
	pages = {343--410},
  publisher = {Cambridge university press}
}


@inproceedings{Abrial1988,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {B} tool ({Abstract})},
	isbn = {978-3-540-45955-2},
	language = {en},
	booktitle = {{VDM} '88 {VDM} — {The} {Way} {Ahead}},
	publisher = {Springer Berlin Heidelberg},
	author = {Abrial, J. R.},
	editor = {Bloomfield, Robin E. and Marshall, Lynn S. and Jones, Roger B.},
	year = {1988},
	pages = {86--87}
}


@incollection{BekicBjornerHJL1984,
	series = {LNCS},
	title = {A formal definition of a {PL}/{I} subset},
	isbn = {978-3-540-38933-0},
	abstract = {This report provides a formal definition of large portions of the ECMA/ANSI proposed Standard PL/I language. The metalanguage used is described in the style of the "Mathematical Semantics". That is, the definition of PL/I is given by generating a function from a source program. A commentary is also provided to cover the less clear parts of the chosen model. For the convenience of the reader who wishes to have the commentary side by side with the formulae, the report is divided into two parts: Part I contains the description of the notation, the commentary and a cross-reference; Part II contains all the formulae.},
	language = {en},
	urldate = {2019-03-14},
	booktitle = {Programming {Languages} and {Their} {Definition}: {H}. {Bekič} (1936–1982)},
	publisher = {Springer Berlin Heidelberg},
	author = {Bekić, H. and Bjørner, D. and Henhapl, W. and Jones, C. B. and Lucas, P.},
	editor = {Jones, C. B.},
	year = {1984},
	doi = {10.1007/BFb0048942},
	keywords = {Abstract Syntax, Concrete Syntax, Context Condition, Type Clause, Vary String},
	pages = {107--155}
}


@book{Jackson2016,
	title = {Software {Abstractions}: {Logic}, {Language}, and {Analysis}},
	isbn = {978-0-262-52890-0},
	shorttitle = {Software {Abstractions}},
	abstract = {In Software Abstractions Daniel Jackson introduces an approach to software design that draws on traditional formal methods but exploits automated tools to find flaws as early as possible. This approach -- which Jackson calls "lightweight formal methods" or "agile modeling" -- takes from formal specification the idea of a precise and expressive notation based on a tiny core of simple and robust concepts but replaces conventional analysis based on theorem proving with a fully automated analysis that gives designers immediate feedback. Jackson has developed Alloy, a language that captures the essence of software abstractions simply and succinctly, using a minimal toolkit of mathematical notions. This revised edition updates the text, examples, and appendixes to be fully compatible with Alloy 4.},
	publisher = {The MIT Press},
	author = {Jackson, Daniel},
	year = {2016}
}


@book{Frisendal2016,
	title = {Graph {Data} {Modeling} for {NoSQL} and {SQL}: {Visualize} {Structure} and {Meaning}},
	isbn = {978-1-63462-123-6},
	publisher = {Technics Publications},
	author = {Frisendal, T.},
	year = {2016}
}


@inproceedings{RederEgyed2012,
	title = {Computing repair trees for resolving inconsistencies in design models},
	doi = {10.1145/2351676.2351707},
	abstract = {Resolving inconsistencies in software models is a complex task because the number of repairs grows exponentially. Existing approaches thus emphasize on selected repairs only but doing so diminishes their usefulness. This paper copes with the large number of repairs by focusing on what caused an inconsistency and presenting repairs as a linearly growing repair tree. The cause is computed by examining the run-time evaluation of the inconsistency to understand where and why it failed. The individual changes that make up repairs are then modeled in a repair tree as alternatives and sequences reflecting the syntactic structure of the inconsistent design rule. The approach is automated and tool supported. Its scalability was empirically evaluated on 29 UML models and 18 OCL design rules where we show that the approach computes repair trees in milliseconds on average. We believe that the approach is applicable to arbitrary modeling and constraint languages.},
	booktitle = {2012 {Proceedings} of the 27th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	author = {Reder, A. and Egyed, A.},
	month = sep,
	year = {2012},
	keywords = {Unified Modeling Language, software engineering, UML models, arbitrary modeling, constraint languages, design models, design rule syntactic structure, Inconsistency Management, inconsistency resolving, inconsistency run-time evaluation, OCL design rules, repair trees computation, Repairing Inconsistencies, software models, trees (mathematics), ModelAnalyzer, RepairTool},
	pages = {220--229},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/84LR88ZU/6494921.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/M7JM8D4X/Reder and Egyed - 2012 - Computing repair trees for resolving inconsistenci.pdf:application/pdf}
}



@inproceedings{MatsudaHuNHT2007,
	title = {Bidirectionalization {Transformation} {Based} on {Automatic} {Derivation} of {View} {Complement} {Functions}},
	isbn = {978-1-59593-815-2},
	doi = {10.1145/1291151.1291162},
	abstract = {Bidirectional transformation is a pair of transformations: a view function and a backward transformation. A view function maps one data structure called source onto another called view. The corresponding backward transformation reflects changes in the view to the source. Its practically useful applications include replicated data synchronization, presentation-oriented editor development, tracing software development, and view updating in the database community. However, developing a bidirectional transformation is hard, because one has to give two mappings that satisfy the bidirectional properties for system consistency. In this paper, we propose a new framework for bidirectionalization that can automatically generate a useful backward transformation from a view function while guaranteeing that the two transformations satisfy the bidirectional properties. Our framework is based on two known approaches to bidirectionalization, namely the constant complement approach from the database community and the combinator approach from the programming language community, but it has three new features: (1) unlike the constant complement approach, it can deal with transformations between algebraic data structures rather than just tables; (2) unlike the combinator approach, in which primitive bidirectional transformations have to be explicitly given, it can derive them automatically; (3) it generates a view update checker to validate updates on views, which has not been well addressed so far. The new framework has been implemented and the experimental results show that our framework has promise.},
	booktitle = {{ICFP} '07},
	publisher = {ACM},
	author = {Matsuda, Kazutaka and Hu, Zhenjiang and Nakano, Keisuke and Hamana, Makoto and Takeichi, Masato},
	year = {2007},
	keywords = {view updating, program transformation, bidirectional transformation, automatic program generation, program inversion},
	pages = {47--58},
	file = {Submitted Version:/Users/past/Zotero/storage/8LC7WD8X/Matsuda et al. - 2007 - Bidirectionalization Transformation Based on Autom.pdf:application/pdf}
}



@inproceedings{KoZanH2016,
	title = {{BiGUL}: {A} {Formally} {Verified} {Core} {Language} for {Putback}-based {Bidirectional} {Programming}},
	isbn = {978-1-4503-4097-7},
	shorttitle = {{BiGUL}},
	doi = {10.1145/2847538.2847544},
	abstract = {Putback-based bidirectional programming allows the programmer to write only one putback transformation, from which the unique corresponding forward transformation is derived for free. The logic of a putback transformation is more sophisticated than that of a forward transformation and does not always give rise to well-behaved bidirectional programs; this calls for more robust language design to support development of well-behaved putback transformations. In this paper, we design and implement a concise core language BiGUL for putback-based bidirectional programming to serve as a foundation for higher-level putback-based languages. BiGUL is completely formally verified in the dependently typed programming language Agda to guarantee that any putback transformation written in BiGUL is well-behaved.},
	booktitle = {{PEPM} '16},
	publisher = {ACM},
	author = {Ko, Hsiang-Shang and Zan, Tao and Hu, Zhenjiang},
	year = {2016},
	keywords = {formal verification, dependent types, Putback-based bidirectional transformations},
	pages = {61--72},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/NNTZMI5K/Ko et al. - 2016 - BiGUL A Formally Verified Core Language for Putba.pdf:application/pdf}
}


@incollection{FosterMatsudaV012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Three {Complementary} {Approaches} to {Bidirectional} {Programming}},
	isbn = {978-3-642-32202-0},
	abstract = {This paper surveys three distinct approaches to bidirectional programming. The first approach, syntactic bidirectionalization, takes a program describing the forward transformation as input and calculates a well-behaved reverse transformation. The second approach, semantic bidirectionalization, is similar, but takes the forward transformation itself as input rather than a program describing it. It requires the transformation to be a polymorphic function and uses parametricity and free theorems in the proof of well-behavedness. The third approach, based on bidirectional combinators, focuses on the use of types to ensure well-behavedness and special constructs for dealing with alignment problems. In presenting these approaches, we pay particular attention to use of complements, which are structures that represent the information discarded by the transformation in the forward direction.},
	language = {en},
	booktitle = {Generic and {Indexed} {Programming}: {International} {Spring} {School}, {SSGIP} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Foster, Nate and Matsuda, Kazutaka and Voigtländer, Janis},
	editor = {Gibbons, Jeremy},
	year = {2012},
	doi = {10.1007/978-3-642-32202-0_1},
	keywords = {Complement Function, Complementary Approach, Functional Language, List Item, Tree Automaton},
	pages = {1--46}
}


@inproceedings{MossakowskiMaederL2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Heterogeneous} {Tool} {Set}, {Hets}},
	isbn = {978-3-540-71209-1},
	abstract = {Heterogeneous specification becomes more and more important because complex systems are often specified using multiple viewpoints, involving multiple formalisms (see Fig. 1). Moreover, a formal software development process may lead to a change of formalism during the development.Some of the current heterogeneous approaches deliberately stay informal, like UML. Current formal integration approaches have the drawback that they are uni-lateral in the sense that typically there is one logic (and one theorem prover) which serves as the central integration device, even if this central logic may not be needed or desired in particular applications.By contrast, the heterogeneous tool set is a both flexible,multi-lateral and formal (i.e. based on a mathematical semantics) integration tool, providing parsing, static analysis and proof management for heterogeneous multi-logic specifications by combining various tools for individual specification languages. Unlike other tools, it treats logic translations (e.g. codings between logics) as first-class citizens. The architecture of the heterogeneous tool set is shown in Fig. 2. In the sequel, we will explain the details of this figure.},
	language = {en},
	booktitle = {Tools and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Mossakowski, Till and Maeder, Christian and Lüttich, Klaus},
	editor = {Grumberg, Orna and Huth, Michael},
	year = {2007},
	pages = {519--522}
}


@book{Mosses2004,
	address = {Berlin Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CASL} {Reference} {Manual}: {The} {Complete} {Documentation} of the {Common} {Algebraic} {Specification} {Language}},
	isbn = {978-3-540-21301-7},
	shorttitle = {{CASL} {Reference} {Manual}},
	url = {https://www.springer.com/gp/book/9783540213017},
	abstract = {CASL, the Common Algebraic Specification Language, was designed by the members of CoFI, the Common Framework Initiative for algebraic specification and development, and is a general-purpose language for practical use in software development for specifying both requirements and design. CASL is already regarded as a de facto standard, and various sublanguages and extensions are available for specific tasks. This reference manual presents a detailed documentation of the CASL specification formalism. It reviews the main underlying concepts, and carefully summarizes the intended meaning of each construct of CASL. The book formally defines both the syntax and semantics of CASL, and presents a logic for reasoning about CASL specifications. Furthermore, extensive libraries of CASL specifications of basic data types are provided as well as a comprehensive annotated bibliography of CoFI publications. As a separate, complementary book LNCS 2900 presents a tutorial introduction to CASL, the CASL User Manual.},
	language = {en},
	urldate = {2019-06-03},
	publisher = {Springer-Verlag},
	editor = {Mosses, Peter D.},
	year = {2004}
}



@book{EhrigMahr1985,
	address = {Berlin Heidelberg},
	series = {Monographs in {Theoretical} {Computer} {Science}. {An} {EATCS} {Series}},
	title = {Fundamentals of {Algebraic} {Specification} 1: {Equations} and {Initial} {Semantics}},
	isbn = {978-3-642-69964-1},
	shorttitle = {Fundamentals of {Algebraic} {Specification} 1},
	url = {https://www.springer.com/gp/book/9783642699641},
	abstract = {The aim of this book is to present fundamentals of algebraic specifications with respect to the following three aspects: fundamentals in the sense of a carefully motivated introduction to algebraic specifications, which is easy to understand for computer scientists and mathematicians; fundamentals in the sense of mathematical theories which are the basis for precise definitions, constructions, results, and correctness proofs; and fundamentals in the sense of concepts, which are introduced on a conceptual level and formalized in mathematical terms. The book is equally suitableas a text book for graduate courses and as a reference for researchers and system developers.},
	language = {en},
	urldate = {2019-05-29},
	publisher = {Springer-Verlag},
	author = {Ehrig, Hartmut and Mahr, Bernd},
	year = {1985}
}

@book{EhrigMahr1990,
	address = {Berlin, Heidelberg},
	title = {Fundamentals of {Algebraic} {Specification} 2: {Module} {Specifications} and {Constraints}},
	isbn = {978-0-387-51799-5},
	shorttitle = {Fundamentals of {Algebraic} {Specification} 2},
	publisher = {Springer-Verlag},
	author = {Ehrig, H. and Mahr, Bernd},
	year = {1990}
}



@article{UlrichKernTKUIL2019,
	title = {{QL}4MDR: a {GraphQL} query language for {ISO} 11179-based metadata repositories},
	volume = {19},
	issn = {1472-6947},
	shorttitle = {{QL}4MDR},
	doi = {10.1186/s12911-019-0794-z},
	abstract = {Heterogeneous healthcare instance data can hardly be integrated without harmonizing its schema-level metadata. Many medical research projects and organizations use metadata repositories to edit, store and reuse data elements. However, existing metadata repositories differ regarding software implementation and have shortcomings when it comes to exchanging metadata. This work aims to define a uniform interface with a technical interlingua between the different MDR implementations in order to enable and facilitate the exchange of metadata, to query over distributed systems and to promote cooperation. To design a unified interface for multiple existing MDRs, a standardized data model must be agreed on. The ISO 11179 is an international standard for the representation of metadata, and since most MDR systems claim to be at least partially compliant, it is suitable for defining an interface thereupon. Therefore, each repository must be able to define which parts can be served and the interface must be able to handle highly linked data. GraphQL is a data access layer and defines query techniques designed to navigate easily through complex data structures.},
	number = {1},
	urldate = {2019-06-07},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Ulrich, H. and Kern, J. and Tas, D. and Kock-Schoppenhauer, A. K. and Ückert, F. and Ingenerf, J. and Lablans, M.},
	month = mar,
	year = {2019},
	pages = {45}
}



@inproceedings{HartigPerez2018,
	address = {Republic and Canton of Geneva, Switzerland},
	title = {Semantics and {Complexity} of {GraphQL}},
	isbn = {978-1-4503-5639-8},
	doi = {10.1145/3178876.3186014},
	abstract = {GraphQL is a recently proposed, and increasingly adopted, conceptual framework for providing a new type of data access interface on the Web. The framework includes a new graph query language whose semantics has been specified informally only. This has prevented the formal study of the main properties of the language. We embark on the formalization and study of GraphQL. To this end, we first formalize the semantics of GraphQL queries based on a labeled-graph data model. Thereafter, we analyze the language and show that it admits really efficient evaluation methods. In particular, we prove that the complexity of the GraphQL evaluation problem is NL-complete. Moreover, we show that the enumeration problem can be solved with constant delay. This implies that a server can answer a GraphQL query and send the response byte-by-byte while spending just a constant amount of time between every byte sent. Despite these positive results, we prove that the size of a GraphQL response might be prohibitively large for an internet scenario. We present experiments showing that current practical implementations suffer from this issue. We provide a solution to cope with this problem by showing that the total size of a GraphQL response can be computed in polynomial time. Our results on polynomial-time size computation plus the constant-delay enumeration can help developers to provide more robust GraphQL interfaces on the Web.},
	urldate = {2019-06-07},
	booktitle = {{WWW} '18},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Hartig, Olaf and Pérez, Jorge},
	year = {2018},
	keywords = {GraphQL, JSON, query language, web queries},
	pages = {1155--1164}
}

@misc{GraphQLSpec,
	title = {{GraphQL} {Specification}},
	url = {https://graphql.github.io/graphql-spec/June2018/},
	urldate = {2019-06-07},
	author = "{Facebook Inc.}",
	year = {2018},
	month = jun
}


@book{Neumann1995,
	address = {New York, NY, USA},
	title = {Computer {Related} {Risks}},
	isbn = {0-201-55805-X},
	publisher = {ACM Press/Addison-Wesley Publishing Co.},
	author = {Neumann, Peter G.},
	year = {1995}
}

@article{LevesonTurner1993, 
	author={N. G. {Leveson} and C. S. {Turner}}, 
	journal={Computer}, 
	title={An investigation of the Therac-25 accidents}, 
	year={1993}, 
	volume={26}, 
	number={7}, 
	pages={18-41}, 
	keywords={accidents;government policies;linear accelerators;medical computing;radiation therapy;software engineering;systems engineering;system operation;accidents;Therac-25 medical electron accelerator;radiation overdoses;software-related overdoses;system development;system engineering;software engineering;government regulation;safety-critical systems;Accidents;Software safety;Food manufacturing;Computer industry;Food industry;Electron accelerators;Biomedical applications of radiation;Injuries;History;Drugs}, 
	doi={10.1109/MC.1993.274940}, 
	ISSN={0018-9162}, 
	month={July}
}



@article{Dowson1997,
	title = {The {Ariane} 5 {Software} {Failure}},
	volume = {22},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/251880.251992},
	doi = {10.1145/251880.251992},
	number = {2},
	journal = {SIGSOFT Softw. Eng. Notes},
	author = {Dowson, Mark},
	month = mar,
	year = {1997},
	pages = {84--}
}


@article{WhittleHutchinsonRBH2017,
	title = {A taxonomy of tool-related issues affecting the adoption of model-driven engineering},
	volume = {16},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-015-0487-8},
	doi = {10.1007/s10270-015-0487-8},
	abstract = {Although poor tool support is often blamed for the low uptake of model-driven engineering (MDE), recent studies have shown that adoption problems are as likely to be down to social and organizational factors as with tooling issues. This article discusses the impact of tools on MDE adoption and practice and does so while placing tooling within a broader organizational context. The article revisits previous data on MDE use in industry (19 in-depth interviews with MDE practitioners) and reanalyzes that data through the specific lens of MDE tools in an attempt to identify and categorize the issues that users had with the tools they adopted. In addition, the article presents new data: 20 new interviews in two specific companies—and analyzes it through the same lens. A key contribution of the paper is a loose taxonomy of tool-related considerations, based on empirical industry data, which can be used to reflect on the tooling landscape as well as inform future research on MDE tools.},
	number = {2},
	journal = {Software \& Systems Modeling},
	author = {Whittle, Jon and Hutchinson, John and Rouncefield, Mark and Burden, Håkan and Heldal, Rogardt},
	month = may,
	year = {2017},
	pages = {313--331}
}


@book{Pierce1991,
	address = {Cambridge, MA, USA},
	title = {Basic {Category} {Theory} for {Computer} {Scientists}},
	isbn = {978-0-262-66071-6},
	publisher = {MIT Press},
	author = {Pierce, Benjamin C.},
	year = {1991}
}

@unpublished{StuenkelKoenigLRUnp,
	title = {A Roadmap for {Multimodel} {Consistency} {Management}},
	author = {St{\"u}nkel, Patrick and K{\"o}nig, Harald and Lamo, Yngve and Rutle, Adrian},
	journal = {JLAMP},
	year = {\textbf{Submitted} to JLAMP, 2019}
}

@inproceedings{BarrigaRutleH18,
  author    = {Angela Barriga and
               Adrian Rutle and
               Rogardt Heldal},
  title     = {Automatic model repair using reinforcement learning},
  booktitle = {Proceedings of {MODELS} 2018 Workshops: ModComp, MRT, OCL, FlexMDE,
               EXE, COMMitMDE, MDETools, GEMOC, MORSE, MDE4IoT, MDEbug, MoDeVVa,
               ME, MULTI, HuFaMo, AMMoRe, {PAINS} co-located with {ACM/IEEE} 21st
               International Conference on Model Driven Engineering Languages and
               Systems {(MODELS} 2018), Copenhagen, Denmark, October, 14, 2018.},
  pages     = {781--786},
  year      = {2018},
  url       = {http://ceur-ws.org/Vol-2245/ammore\_paper\_1.pdf},
  timestamp = {Tue, 28 May 2019 16:23:34 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/models/BarrigaRH18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{BezivinJoaultV2004,
	address = {Vancouver, Canada},
	title = {On the {Need} for {Megamodels}},
	url = {https://hal.archives-ouvertes.fr/hal-01222947},
	abstract = {This note presents a preliminary view of what we call a "megamodel" i.e. some kind of registry for models and metamodels. A megamodel is a model of which at least some elements represent and/or refer to models or metamodels. An initial charac-terization of these megamodels as well as a de-scription of some of their potential usages is provided. We are presently experimenting with the concept of megamodel in our AMMP envi-ronment (ATLAS Model Management Platform). Some initial application of the concept of mega-model in the design of such model-driven soft-ware development platforms will be presented. Besides argumenting for the need to use mega-models in a variety of situations, the paper argues on the importance of this concept as an essential part of any model-driven software development platform.},
	urldate = {2019-09-05},
	booktitle = {Proceedings of the {OOPSLA}/{GPCE}: {Best} {Practices} for {Model}-{Driven} {Software} {Development} workshop, 19th {Annual} {ACM} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications},(2004)},
	author = {Bézivin, Jean and Jouault, Frédéric and Valduriez, Patrick},
	month = oct,
	year = {2004}
}


@article{CleveKindlerSZ2019,
	title = {Multidirectional {Transformations} and {Synchronisations} ({Dagstuhl} {Seminar} 18491)},
	volume = {8},
	issn = {2192-5283},
	doi = {10.4230/DagRep.8.12.1},
	number = {12},
	urldate = {2019-09-05},
	journal = {Dagstuhl Reports},
	author = {Cleve, Anthony and Kindler, Ekkart and Stevens, Perdita and Zaytsev, Vadim},
	editor = {Cleve, Anthony and Kindler, Ekkart and Stevens, Perdita and Zaytsev, Vadim},
	year = {2019},
	keywords = {bidirectional transformation, synchronisation},
	pages = {1--48}
}


@techreport{HebigGieseBLZYW2015,
	title = {Development of {AUTOSAR} standard documents at {Carmeq} {GmbH}},
	url = {https://publishup.uni-potsdam.de/frontdoor/index/index/docId/7153},
	abstract = {This report documents the captured MDE history of Carmeq GmbH, in context of the project Evolution of MDE Settings in Practice. 
The goal of the project is the elicitation of MDE approaches and their evolution.},
	language = {en},
	number = {92},
	urldate = {2019-09-06},
	institution = {Universitätsverlag Potsdam},
	author = {Hebig, Regina and Giese, Holger and Batoulis, Kimon and Langer, Philipp and Zamani Farahani, Armin and Yao, Gary and Wolowyk, Mychajlo},
	year = {2015}
}



@inproceedings{WeberKuziemsky2019,
	address = {Piscataway, NJ, USA},
	series = {{SEH} '19},
	title = {Pragmatic {Interoperability} for {Ehealth} {Systems}: {The} {Fallback} {Workflow} {Patterns}},
	shorttitle = {Pragmatic {Interoperability} for {Ehealth} {Systems}},
	url = {https://doi.org/10.1109/SEH.2019.00013},
	doi = {10.1109/SEH.2019.00013},
	abstract = {Despite decades of research and development on interoperability standards, semantic interoperability among electronic health (eHealth) systems has largely remained an elusive goal. Interoperability functionality that has been implemented as part of national or provincial initiatives often ends up being considered unreliable in practice. We believe that a stronger focus on workflows and other pragmatic aspects of interoperability functions may be a key to overcoming these difficulties. Specifically, we argue that eHealth system interoperability should be modelled as dynamically evolving socio-technical processes, rather than as technical functions of certified devices. In this paper, we explore the example of patient referrals to highlight common problems with eHealth system interoperability. We define a system-theoretic model of the socio-technical e-referral system to derive two pragmatic interoperability workflow patterns to address these problems. The presented research is carried out in collaboration with industry.},
	urldate = {2019-09-13},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Software} {Engineering} for {Healthcare}},
	publisher = {IEEE Press},
	author = {Weber, Jens H. and Kuziemsky, Craig},
	year = {2019},
	note = {event-place: Montreal, Quebec, Canada},
	keywords = {e-referrals, eHealth systems, fallback interoperability, interoperability, workflow},
	pages = {29--36}
}



@book{Segen1992,
	title = {The {Dictionary} of {Modern} {Medicine}},
	isbn = {978-1-85070-321-1},
	abstract = {This dictionary of modern medical terms and jargon offers detailed descriptions of over 15,000 currently used medical terms that are either not included in ordinary medical dictionaries or which are only very briefly and inadequately defined. Some terms are not defined anywhere else.},
	language = {en},
	publisher = {CRC Press},
	author = {Segen, J. C.},
	month = feb,
	year = {1992},
	keywords = {Medical / General}
}



@article{OrejasBoronatEHS2013,
	title = {On {Propagation}-{Based} {Concurrent} {Model} {Synchronization}},
	volume = {57},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/871},
	doi = {10.14279/tuj.eceasst.57.871},
	abstract = {The aim of concurrent model synchronization is to merge pairs of updates  on interrelated models. For instance, this situation may occur in the context of model driven software development when the work is distributed between different teams. A first problem is that, if the updates are in conflict, this conflict is never explicit. The reason is that the updates do not interfere directly since they are assumed to modify different models. For this reason, detecting and solving conflicts becomes already more difficult than in the more standard case of synchronizing concurrent updates over a given model. Existing general approaches define the solution to this problem in terms of the solution to the simpler  problem of update propagation in bidirectional model transformation. We call these approaches {\textbackslash}emph\{propagation based\}.In this paper, we first state some properties that, in our opinion, must be satisfied by a concurrent synchronization procedure to be considered correct. Then, we show how to check whether the given updates are conflict-free and, in this case, we present a correct synchronization procedure based on this check. Finally, we  consider the case where the given updates are in conflict and we show how we can build solutions that satisfy some of the correctness properties but, in general, not all of them. Specifically, we present counter-examples that show how some of these properties may fail.},
	language = {en},
	number = {0},
	urldate = {2019-08-27},
	journal = {Electronic Communications of the EASST},
	author = {Orejas, Fernando and Boronat, Artur and Ehrig, Hartmut and Hermann, Frank and Schölzel, Hanna},
	month = sep,
	year = {2013},
	keywords = {Model integration},
	file = {Full Text PDF:/Users/past/Zotero/storage/3TZ3DS3M/Orejas et al. - 2013 - On Propagation-Based Concurrent Model Synchronizat.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/FMAYCJBI/871.html:text/html}
}

@book{Goodfellow2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}



@incollection{CabotGogolla2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Object {Constraint} {Language} ({OCL}): {A} {Definitive} {Guide}},
	isbn = {978-3-642-30982-3},
	shorttitle = {Object {Constraint} {Language} ({OCL})},
	url = {https://doi.org/10.1007/978-3-642-30982-3_3},
	abstract = {The Object Constraint Language (OCL) started as a complement of the UML notation with the goal to overcome the limitations of UML (and in general, any graphical notation) in terms of precisely specifying detailed aspects of a system design. Since then, OCL has become a key component of any model-driven engineering (MDE) technique as the default language for expressing all kinds of (meta)model query, manipulation and specification requirements. Among many other applications, OCL is frequently used to express model transformations (as part of the source and target patterns of transformation rules), well-formedness rules (as part of the definition of new domain-specific languages), or code-generation templates (as a way to express the generation patterns and rules).This chapter pretends to provide a comprehensive view of this language, its many applications and available tool support as well as the latest research developments and open challenges around it.},
	language = {en},
	urldate = {2019-08-21},
	booktitle = {Formal {Methods} for {Model}-{Driven} {Engineering}: 12th {International} {School} on {Formal} {Methods} for the {Design} of {Computer}, {Communication}, and {Software} {Systems}, {SFM} 2012, {Bertinoro}, {Italy}, {June} 18-23, 2012. {Advanced} {Lectures}},
	publisher = {Springer Berlin Heidelberg},
	author = {Cabot, Jordi and Gogolla, Martin},
	editor = {Bernardo, Marco and Cortellessa, Vittorio and Pierantonio, Alfonso},
	year = {2012},
	doi = {10.1007/978-3-642-30982-3_3},
	keywords = {Class Diagram, Derivation Rule, Object Constraint Language, Object Management Group, Query Operation},
	pages = {58--90},
	file = {Submitted Version:/Users/past/Zotero/storage/EXF4I262/Cabot and Gogolla - 2012 - Object Constraint Language (OCL) A Definitive Gui.pdf:application/pdf}
}



@article{GogollaBuettnerR2007,
	series = {Special issue on {Experimental} {Software} and {Toolkits}},
	title = {{USE}: {A} {UML}-based specification environment for validating {UML} and {OCL}},
	volume = {69},
	issn = {0167-6423},
	shorttitle = {{USE}},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642307001608},
	doi = {10.1016/j.scico.2007.01.013},
	abstract = {The Unified Modeling Language (UML) is accepted today as an important standard for developing software. UML tools however provide little support for validating and checking models in early development phases. There is also no substantial support for the Object Constraint Language (OCL). We present an approach for the validation of UML models and OCL constraints based on animation and certification. The USE tool (UML-based Specification Environment) supports analysts, designers and developers in executing UML models and checking OCL constraints and thus enables them to employ model-driven techniques for software production.},
	number = {1},
	urldate = {2019-09-19},
	journal = {Science of Computer Programming},
	author = {Gogolla, Martin and B{\"u}ttner, Fabian and Richters, Mark},
	month = dec,
	year = {2007},
	keywords = {Constraint, Invariant, Model, Model certification, Model execution, Model validation, OCL, Pre- and post-conditions, UML},
	pages = {27--34},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/P43C4WTP/Gogolla et al. - 2007 - USE A UML-based specification environment for val.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/7MR98BC2/S0167642307001608.html:text/html}
}


@book{SannellaTarlecki2012,
	address = {Berlin Heidelberg},
	series = {Monographs in {Theoretical} {Computer} {Science}. {An} {EATCS} {Series}},
	title = {Foundations of {Algebraic} {Specification} and {Formal} {Software} {Development}},
	isbn = {978-3-642-17335-6},
	url = {https://www.springer.com/de/book/9783642173356},
	abstract = {This book provides foundations for software specification and formal software development from the perspective of work on algebraic specification, concentrating on developing basic concepts and studying their fundamental properties. These foundations are built on a solid mathematical basis, using elements of universal algebra, category theory and logic, and this mathematical toolbox provides a convenient language for precisely formulating the concepts involved in software specification and development. Once formally defined, these notions become subject to mathematical investigation, and this interplay between mathematics and software engineering yields results that are mathematically interesting, conceptually revealing, and practically useful. The theory presented by the authors has its origins in work on algebraic specifications that started in the early 1970s, and their treatment is comprehensive. This book contains five kinds of material: the requisite mathematical foundations; traditional algebraic specifications; elements of the theory of institutions; formal specification and development; and proof methods. While the book is self-contained, mathematical maturity and familiarity with the problems of software engineering is required; and in the examples that directly relate to programming, the authors assume acquaintance with the concepts of functional programming. The book will be of value to researchers and advanced graduate students in the areas of programming and theoretical computer science.},
	language = {en},
	urldate = {2019-08-27},
	publisher = {Springer-Verlag},
	author = {Sannella, Donald and Tarlecki, Andrzej},
	year = {2012},
	file = {Snapshot:/Users/past/Zotero/storage/QFL46HWV/9783642173356.html:text/html}
}


@inproceedings{DiskinXiongC2010b,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {From {State}- to {Delta}-{Based} {Bidirectional} {Model} {Transformations}},
	isbn = {978-3-642-13688-7},
	abstract = {Existing bidirectional model transformation languages are mainly state-based: a transformation is considered composed from functions whose inputs and outputs only consist of original and updated models, but alignment relationships between the models are not specified. In the paper we identify and discuss three major problems caused by this under-specification. We then propose a novel formal framework based on a graphical language: models are nodes and updates are arrows, and show how the three problems can be fixed.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Diskin, Zinovy and Xiong, Yingfei and Czarnecki, Krzysztof},
	editor = {Tratt, Laurence and Gogolla, Martin},
	year = {2010},
	keywords = {Edit Sequence, Model Transformation, Sequential Composition, Source Model, Source Space},
	pages = {61--76},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/JUACEVX6/Diskin et al. - 2010 - From State- to Delta-Based Bidirectional Model Tra.pdf:application/pdf}
}


@inproceedings{DiskinXiongCEHO2011,
	address = {Berlin, Heidelberg},
	series = {{MODELS}'11},
	title = {From {State}- to {Delta}-based {Bidirectional} {Model} {Transformations}: {The} {Symmetric} {Case}},
	isbn = {978-3-642-24484-1},
	shorttitle = {From {State}- to {Delta}-based {Bidirectional} {Model} {Transformations}},
	url = {http://dl.acm.org/citation.cfm?id=2050655.2050685},
	abstract = {A bidirectional transformation (BX) keeps a pair of interrelated models synchronized. Symmetric BXs are those for which neither model in the pair fully determines the other. We build two algebraic frameworks for symmetric BXs, with one correctly implementing the other, and both being delta-based generalizations of known state-based frameworks. We identify two new algebraic laws--weak undoability and weak invertibility, which capture important semantics of BX and are useful for both state- and delta-based settings. Our approach also provides a flexible tool architecture adaptable to different user's needs.},
	urldate = {2019-09-24},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Diskin, Zinovy and Xiong, Yingfei and Czarnecki, Krzysztof and Ehrig, Hartmut and Hermann, Frank and Orejas, Fernando},
	year = {2011},
	note = {event-place: Wellington, New Zealand},
	pages = {304--318}
}



@inproceedings{HofmannPierceW2012,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {Edit {Lenses}},
	isbn = {978-1-4503-1083-3},
	doi = {10.1145/2103656.2103715},
	abstract = {A lens is a bidirectional transformation between a pair of connected data structures, capable of translating an edit on one structure into an appropriate edit on the other. Many varieties of lenses have been studied, but none, to date, has offered a satisfactory treatment of how edits are represented. Many foundational accounts only consider edits of the form "overwrite the whole structure," leading to poor behavior in many situations by failing to track the associations between corresponding parts of the structures when elements are inserted and deleted in ordered lists, for example. Other theories of lenses do maintain these associations, either by annotating the structures themselves with change information or using auxiliary data structures, but every extant theory assumes that the entire original source structure is part of the information passed to the lens. We offer a general theory of edit lenses, which work with descriptions of changes to structures, rather than with the structures themselves. We identify a simple notion of "editable structure"--a set of states plus a monoid of edits with a partial monoid action on the states--and construct a semantic space of lenses between such structures, with natural laws governing their behavior. We show how a range of constructions from earlier papers on "state-based" lenses can be carried out in this space, including composition, products, sums, list operations, etc. Further, we show how to construct edit lenses for arbitrary containers in the sense of Abbott, Altenkirch, and Ghani. Finally, we show that edit lenses refine a well-known formulation of state-based lenses, in the sense that every state-based lens gives rise to an edit lens over structures with a simple overwrite-only edit language, and conversely every edit lens on such structures gives rise to a state-based lens.},
	urldate = {2019-09-25},
	booktitle = {Proceedings of the 39th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Hofmann, Martin and Pierce, Benjamin and Wagner, Daniel},
	year = {2012},
	keywords = {algebra, bidirectional programming, edit, lens, symmetric},
	pages = {495--508}
}



@inproceedings{HofmannPierceW2011,
	address = {New York, NY, USA},
	series = {{POPL} '11},
	title = {Symmetric {Lenses}},
	isbn = {978-1-4503-0490-0},
	url = {http://doi.acm.org/10.1145/1926385.1926428},
	doi = {10.1145/1926385.1926428},
	abstract = {Lenses--bidirectional transformations between pairs of connected structures--have been extensively studied and are beginning to find their way into industrial practice. However, some aspects of their foundations remain poorly understood. In particular, most previous work has focused on the special case of asymmetric lenses, where one of the structures is taken as primary and the other is thought of as a projection, or view. A few studies have considered symmetric variants, where each structure contains information not present in the other, but these all lack the basic operation of composition. Moreover, while many domain-specific languages based on lenses have been designed, lenses have not been thoroughly explored from an algebraic perspective. We offer two contributions to the theory of lenses. First, we present a new symmetric formulation, based on complements, an old idea from the database literature. This formulation generalizes the familiar structure of asymmetric lenses, and it admits a good notion of composition. Second, we explore the algebraic structure of the space of symmetric lenses. We present generalizations of a number of known constructions on asymmetric lenses and settle some longstanding questions about their properties---in particular, we prove the existence of (symmetric monoidal) tensor products and sums and the non-existence of full categorical products or sums in the category of symmetric lenses. We then show how the methods of universal algebra can be applied to build iterator lenses for structured data such as lists and trees, yielding lenses for operations like mapping, filtering, and concatenation from first principles. Finally, we investigate an even more general technique for constructing mapping combinators, based on the theory of containers.},
	urldate = {2019-09-25},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Hofmann, Martin and Pierce, Benjamin and Wagner, Daniel},
	year = {2011},
	note = {event-place: Austin, Texas, USA},
	keywords = {algebra, category theory, lens, view-update},
	pages = {371--384}
}


@inproceedings{AlvarezPicalloOng2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Change {Actions}: {Models} of {Generalised} {Differentiation}},
	isbn = {978-3-030-17127-8},
	shorttitle = {Change {Actions}},
	abstract = {Change structures, introduced by Cai et al., have recently been proposed as a semantic framework for incremental computation. We generalise change actions, an alternative to change structures, to arbitrary cartesian categories and propose the notion of change action model as a categorical model for (higher-order) generalised differentiation. Change action models naturally arise from many geometric and computational settings, such as (generalised) cartesian differential categories, group models of discrete calculus, and Kleene algebra of regular expressions. We show how to build canonical change action models on arbitrary cartesian categories, reminiscent of the Fàa di Bruno construction.},
	language = {en},
	booktitle = {Foundations of {Software} {Science} and {Computation} {Structures}},
	publisher = {Springer International Publishing},
	author = {Alvarez-Picallo, Mario and Ong, C.-H. Luke},
	editor = {Bojańczyk, Mikołaj and Simpson, Alex},
	year = {2019},
	pages = {45--61},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/EY88JYFX/Alvarez-Picallo and Ong - 2019 - Change Actions Models of Generalised Differentiat.pdf:application/pdf}
}



@inproceedings{CaiGiarrussoRO2014,
	address = {New York, NY, USA},
	series = {{PLDI} '14},
	title = {A {Theory} of {Changes} for {Higher}-order {Languages}: {Incrementalizing} \${\textbackslash}{Lambda}\$-calculi by {Static} {Differentiation}},
	isbn = {978-1-4503-2784-8},
	shorttitle = {A {Theory} of {Changes} for {Higher}-order {Languages}},
	url = {http://doi.acm.org/10.1145/2594291.2594304},
	doi = {10.1145/2594291.2594304},
	abstract = {If the result of an expensive computation is invalidated by a small change to the input, the old result should be updated incrementally instead of reexecuting the whole computation. We incrementalize programs through their derivative. A derivative maps changes in the program's input directly to changes in the program's output, without reexecuting the original program. We present a program transformation taking programs to their derivatives, which is fully static and automatic, supports first-class functions, and produces derivatives amenable to standard optimization. We prove the program transformation correct in Agda for a family of simply-typed λ-calculi, parameterized by base types and primitives. A precise interface specifies what is required to incrementalize the chosen primitives. We investigate performance by a case study: We implement in Scala the program transformation, a plugin and improve performance of a nontrivial program by orders of magnitude.},
	urldate = {2019-09-26},
	booktitle = {Proceedings of the 35th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Cai, Yufei and Giarrusso, Paolo G. and Rendel, Tillmann and Ostermann, Klaus},
	year = {2014},
	note = {event-place: Edinburgh, United Kingdom},
	keywords = {Agda, first-class functions, formalization, incremental computation, performance},
	pages = {145--155},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/JFE59MNP/Cai et al. - 2014 - A Theory of Changes for Higher-order Languages In.pdf:application/pdf}
}


@inproceedings{RubinChechik2013,
	address = {New York, NY, USA},
	title = {N-way {Model} {Merging}},
	isbn = {978-1-4503-2237-9},
	doi = {10.1145/2491411.2491446},
	abstract = {Model merging is widely recognized as an essential step in a variety of software development activities. During the process of combining a set of related products into a product line or consolidating model views of multiple stakeholders, we need to merge multiple input models into one; yet, most of the existing approaches are applicable to merging only two models. In this paper, we define the n-way merge problem. We show that it can be reduced to the known and widely studied NP-hard problem of weighted set packing. Yet, the approximation solutions for that problem do not scale for real-sized software models. We thus evaluate alternative approaches of merging models that incrementally process input models in small subsets and propose our own algorithm that considerably improves precision over such approaches without sacrificing performance.},
	urldate = {2019-08-21},
	booktitle = {{ESEC}/{FSE} 2013},
	publisher = {ACM},
	author = {Rubin, Julia and Chechik, Marsha},
	year = {2013},
	keywords = {Model merging, combining multiple models, weighted set packing},
	pages = {301--311}
}


@article{ReulingLochauK2019,
	title = {From {Imprecise} {N}-{Way} {Model} {Matching} to {Precise} {N}-{Way} {Model} {Merging}},
	volume = {18},
	issn = {1660-1769},
	url = {http://www.jot.fm/contents/issue_2019_02/article8.html},
	doi = {10.5381/jot.2019.18.2.a8},
	number = {2},
	journal = {Journal of Object Technology},
	author = {Reuling, Dennis and Lochau, Malte and Kelter, Udo},
	editor = {Combemale, Benoit and Shaukat, Ali},
	month = jul,
	year = {2019},
	pages = {8:1--20}
}


@inproceedings{JohnsonRosebrugh2016,
	series = {{CEUR} {Workshop} {Proceedings}},
	title = {Unifying {Set}-{Based}, {Delta}-{Based} and {Edit}-{Based} {Lenses}},
	volume = {1571},
	urldate = {2018-05-23},
	booktitle = {{Bx}@{ETAPS} 2016},
	publisher = {CEUR-WS.org},
	author = {Johnson, Michael and Rosebrugh, Robert D.},
	editor = {Anjorin, Anthony and Gibbons, Jeremy},
	year = {2016},
	pages = {1--13}
}


@article{JohnsonRosebrugh2012,
	title = {Lens put-put laws: monotonic and mixed},
	volume = {49},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	shorttitle = {Lens put-put laws},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/729},
	doi = {10.14279/tuj.eceasst.49.729},
	abstract = {Many authors have argued, for good reasons, that in a range of applications the lens put-put law is too strong.  On the other hand, the present authors have shown that very well behaved lenses, which do satisfy the put-put law by definition, are algebras for a certain monad, and that this viewpoint admits fruitful generalisations of the lens concept to a variety of base categories.  In the algebra approach to lenses, the put-put law corresponds to the associativity axiom, and so is fundamentally important. Thus we have a dilemma.  The put-put law seems inappropriate for many applications, but is fundamental to the mathematical development that can support an extended range of applications. In this paper we resolve this dilemma.  We outline monotonic put-put laws and introduce a new mixed put-put law that appears to be immune to many of the objections to the classical put-put law, and still supports a very satisfactory mathematical foundation.},
	language = {en},
	number = {0},
	urldate = {2019-09-27},
	journal = {Electronic Communications of the EASST},
	author = {Johnson, Michael and Rosebrugh, Robert},
	month = jul,
	year = {2012},
	file = {Full Text PDF:/Users/past/Zotero/storage/GWK2TVQR/Johnson and Rosebrugh - 2012 - Lens put-put laws monotonic and mixed.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/7LUA9EUT/729.html:text/html}
}



@inproceedings{Diskin2017,
	series = {{CEUR} {Workshop} {Proceedings}},
	title = {Compositionality of {Update} {Propagation}: {Lax} {PutPut}},
	volume = {1827},
	shorttitle = {Compositionality of {Update} {Propagation}},
	url = {http://ceur-ws.org/Vol-1827/paper12.pdf},
	urldate = {2019-09-24},
	booktitle = {Proceedings of the 6th {International} {Workshop} on {Bidirectional} {Transformations} co-located with {The} {European} {Joint} {Conferences} on {Theory} and {Practice} of {Software}, {BX}@{ETAPS} 2017, {Uppsala}, {Sweden}, {April} 29, 2017},
	publisher = {CEUR-WS.org},
	author = {Diskin, Zinovy},
	editor = {Eramo, Romina and Johnson, Michael},
	year = {2017},
	pages = {74--89}
}



@inproceedings{Rensink2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Representing {First}-{Order} {Logic} {Using} {Graphs}},
	isbn = {978-3-540-30203-2},
	abstract = {We show how edge-labelled graphs can be used to represent first-order logic formulae. This gives rise to recursively nested structures, in which each level of nesting corresponds to the negation of a set of existentials. The model is a direct generalisation of the negative application conditions used in graph rewriting, which count a single level of nesting and are thereby shown to correspond to the fragment ∃ ¬ ∃ of first-order logic. Vice versa, this generalisation may be used to strengthen the notion of application conditions. We then proceed to show how these nested models may be flattened to (sets of) plain graphs, by allowing some structure on the labels. The resulting formulae-as-graphs may form the basis of a unification of the theories of graph transformation and predicate transformation.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rensink, Arend},
	editor = {Ehrig, Hartmut and Engels, Gregor and Parisi-Presicce, Francesco and Rozenberg, Grzegorz},
	year = {2004},
	keywords = {Application Condition, Depth Indicator, Graph Condition, Graph Grammar, Graph Transformation},
	pages = {319--335},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/H72P5MHR/Rensink - 2004 - Representing First-Order Logic Using Graphs.pdf:application/pdf}
}



@inproceedings{EhrigEhrigEHT2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Information {Preserving} {Bidirectional} {Model} {Transformations}},
	isbn = {978-3-540-71289-3},
	abstract = {Within model-driven software development, model transformation has become a key activity. It refers to a variety of operations modifying a model for various purposes such as analysis, optimization, and code generation. Most of these transformations need to be bidirectional to e.g. report analysis results, or keep coherence between models. In several application-oriented papers it has been shown that triple graph grammars are a promising approach to bidirectional model transformations. But up to now, there is no formal result showing under which condition corresponding forward and backward transformations are inverse to each other in the sense of information preservation. This problem is solved in this paper based on general results for the theory of algebraic graph transformations. The results are illustrated by a transformation of class models to relational data base models which has become a quasi-standard example for model transformation.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ehrig, Hartmut and Ehrig, Karsten and Ermel, Claudia and Hermann, Frank and Taentzer, Gabriele},
	editor = {Dwyer, Matthew B. and Lopes, Antónia},
	year = {2007},
	keywords = {Bijective Correspondence, Forward Transformation, Graph Transformation, Model Transformation, Transformation Sequence},
	pages = {72--86},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/CTPCHD6M/Ehrig et al. - 2007 - Information Preserving Bidirectional Model Transfo.pdf:application/pdf}
}


@incollection{Courcelle1997,
	address = {River Edge, NJ, USA},
	title = {The expression of graph properties and graph transformations in monadic second-order logic},
	isbn = {978-981-02-2884-2},
	urldate = {2019-10-01},
	booktitle = {Handbook of graph grammars and computing by graph transformation},
	publisher = {World Scientific Publishing Co., Inc.},
	author = {Courcelle, B.},
	editor = {Rozenberg, Grzegorz},
	year = {1997},
	pages = {313--400}
}



@inproceedings{TrollmannAlbayrak2016,
author="Trollmann, Frank
and Albayrak, Sahin",
editor="Van Gorp, Pieter
and Engels, Gregor",
title="Extending Model Synchronization Results from Triple Graph Grammars to Multiple Models",
booktitle="Theory and Practice of Model Transformations",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="91--106",
abstract="Triple graph grammars are a formally well-founded and widely used technique for model transformation and model synchronization. In previous work we have shown that basic model transformation results from triple graph grammars can be extended to multiple models and relations on the basis of a formalism called graph diagrams. In this paper we extend this theory to model synchronization by generalizing results from model synchronization for triple graphs to graph diagrams. This extension is the basis for the implementation and analysis of model synchronization in future work.",
isbn="978-3-319-42064-6",
doi = {10.1007/978-3-319-42064-6_7}
}


@inproceedings{Stevens2008b,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards an {Algebraic} {Theory} of {Bidirectional} {Transformations}},
	isbn = {978-3-540-87405-8},
	abstract = {Bidirectional transformations are important for model-driven development, and are also of wide interest in computer science. In this paper we present early work on an algebraic presentation of bidirectional transformations. In general, a bidirectional transformation must maintain consistency between two models, either of which may be edited, and each of which may incorporate information not represented in the other. Our main focus here is on lenses [2,1,3] which provide a particularly well-understood special case, in which one model is an abstraction of the other, and either the abstraction or the full model may be edited. We show that there is a correspondence between lenses and short exact sequences of monoids of edits. We go on to show that if we restrict attention to invertible edits, very well-behaved lenses correspond to split short exact sequences of groups; this helps to elucidate the structure of the edit groups.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Stevens, Perdita},
	editor = {Ehrig, Hartmut and Heckel, Reiko and Rozenberg, Grzegorz and Taentzer, Gabriele},
	year = {2008},
	keywords = {Algebraic Theory, Graph Grammar, Graph Transformation, Short Exact Sequence, Transformation Language},
	pages = {1--17},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/7TCXDM35/Stevens - 2008 - Towards an Algebraic Theory of Bidirectional Trans.pdf:application/pdf}
}


@inproceedings{MacedoCunha2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Implementing {QVT}-{R} {Bidirectional} {Model} {Transformations} {Using} {Alloy}},
	isbn = {978-3-642-37057-1},
	abstract = {QVT Relations (QVT-R) is the standard language proposed by the OMG to specify bidirectional model transformations. Unfortunately, in part due to ambiguities and omissions in the original semantics, acceptance and development of effective tool support has been slow. Recently, the checking semantics of QVT-R has been clarified and formalized. In this paper we propose a QVT-R tool that complies to such semantics. Unlike any other existing tool, it also supports meta-models enriched with OCL constraints (thus avoiding returning ill-formed models), and proposes an alternative enforcement semantics that works according to the simple and predictable “principle of least change”. The implementation is based on an embedding of both QVT-R transformations and UML class diagrams (annotated with OCL) in Alloy, a lightweight formal specification language with support for automatic model finding via SAT solving.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Macedo, Nuno and Cunha, Alcino},
	editor = {Cortellessa, Vittorio and Varró, Dániel},
	year = {2013},
	keywords = {Domain Pattern, Edit Operation, Graph Edit Distance, Object Constraint Language, Object Management Group},
	pages = {297--311},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/BSSYWXGA/Macedo and Cunha - 2013 - Implementing QVT-R Bidirectional Model Transformat.pdf:application/pdf}
}


@inproceedings{deLaraGuerra2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Formal {Support} for {QVT}-{Relations} with {Coloured} {Petri} {Nets}},
	isbn = {978-3-642-04425-0},
	abstract = {QVT is the OMG standard language for specifying model-to-model transformations in MDA. Even though it plays a crucial role in model driven development, there are scarce tools supporting the execution of its sublanguage QVT-Relations, and none for its analysis or verification. In order to alleviate this situation, this paper provides a formal semantics for QVT-Relations through its compilation into Coloured Petri nets, enabling the execution and validation of QVT specifications. The theory of Petri nets provides useful techniques to analyse transformations (e.g. reachability, model-checking, boundedness and invariants) and to determine their confluence and termination given a starting model. We also report on using CPNTools for the execution, debugging, and analysis of transformations, and on a tool chain to transform QVT-Relations specifications into the input format of CPNTools.},
	language = {en},
	booktitle = {Model {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {de Lara, Juan and Guerra, Esther},
	editor = {Schürr, Andy and Selic, Bran},
	year = {2009},
	keywords = {Formal Support, Model Check, Model Drive Development, Substitution Transition, Tool Chain},
	pages = {256--270},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/Y6YWHS9N/de Lara and Guerra - 2009 - Formal Support for QVT-Relations with Coloured Pet.pdf:application/pdf}
}



@article{AnjorinBuchmannWDKEHSZ2019,
	title = {Benchmarking bidirectional transformations: theory, implementation, application, and assessment},
	issn = {1619-1374},
	shorttitle = {Benchmarking bidirectional transformations},
	doi = {10.1007/s10270-019-00752-x},
	abstract = {Bidirectional transformations (bx) are relevant for a wide range of application domains. While bx problems may be solved with unidirectional languages and tools, maintaining separate implementations of forward and backward synchronizers with mutually consistent behavior can be difficult, laborious, and error-prone. To address the challenges involved in handling bx problems, dedicated languages and tools for bx have been developed. Due to their heterogeneity, however, the numerous and diverse approaches to bx are difficult to compare, with the consequence that fundamental differences and similarities are not yet well understood. This motivates the need for suitable benchmarks that facilitate the comparison of bx approaches. This paper provides a comprehensive treatment of benchmarking bx, covering theory, implementation, application, and assessment. At the level of theory, we introduce a conceptual framework that defines and classifies architectures of bx tools. At the level of implementation, we describe Benchmarx, an infrastructure for benchmarking bx tools which is based on the conceptual framework. At the level of application, we report on a wide variety of solutions to the well-known Families-to-Persons benchmark, which were developed and compared with the help of Benchmarx. At the level of assessment, we reflect on the usefulness of the Benchmarx approach to benchmarking bx, based on the experiences gained from the Families-to-Persons benchmark.},
	language = {en},
	urldate = {2019-09-18},
	journal = {Software and Systems Modeling},
	author = {Anjorin, Anthony and Buchmann, Thomas and Westfechtel, Bernhard and Diskin, Zinovy and Ko, Hsiang-Shang and Eramo, Romina and Hinkel, Georg and Samimi-Dehkordi, Leila and Zündorf, Albert},
	month = sep,
	year = {2019},
	keywords = {Benchmark, Bidirectional transformation, Framework, Model synchronization},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/QDJBIF3I/Anjorin et al. - 2019 - Benchmarking bidirectional transformations theory.pdf:application/pdf}
}




@article{MacedoCunha2016,
	title = {Least-change bidirectional model transformation with {QVT}-{R} and {ATL}},
	volume = {15},
	issn = {1619-1374},
	doi = {10.1007/s10270-014-0437-x},
	abstract = {QVT Relations (QVT-R) is the standard language proposed by the OMG to specify bidirectional model transformations. Unfortunately, in part due to ambiguities and omissions in the original semantics, acceptance and development of effective tool support have been slow. Recently, the checking semantics of QVT-R has been clarified and formalized. In this article, we propose a QVT-R tool that complies to such semantics. Unlike any other existing tool, it also supports meta-models enriched with OCL constraints (thus avoiding returning ill-formed models) and proposes an alternative enforcement semantics that works according to the simple and predictable “principle of least change.” The implementation is based on an embedding of both QVT-R transformations and UML class diagrams (annotated with OCL) in Alloy, a lightweight formal specification language with support for automatic model finding via SAT solving. We also show how this technique can be applied to bidirectionalize ATL, a popular (but unidirectional) model transformation language.},
	language = {en},
	number = {3},
	urldate = {2019-08-21},
	journal = {Software \& Systems Modeling},
	author = {Macedo, Nuno and Cunha, Alcino},
	month = jul,
	year = {2016},
	keywords = {ATL, Bidirectional transformation, Model transformation, Alloy, Least-change principle, QVT-R},
	pages = {783--810},
	file = {Submitted Version:/Users/past/Zotero/storage/DXED6IQM/Macedo and Cunha - 2016 - Least-change bidirectional model transformation wi.pdf:application/pdf}
}




@article{SamimiDehkordiZamaniK2018,
	title = {{EVL}+{Strace}: a novel bidirectional model transformation approach},
	volume = {100},
	issn = {0950-5849},
	shorttitle = {{EVL}+{Strace}},
	doi = {10.1016/j.infsof.2018.03.011},
	abstract = {Context: Model transformation, as one of the cornerstones of Model-Driven Engineering (MDE) paradigm, produces target models from source models. In most of the practical cases, both source and target models are changed independently and it is essential to preserve the consistency between them. Bidirectional transformation (Bx) provides a mechanism to re-establish this inter-model consistency. Bx approaches suffer from several limitations, such as lack of a comprehensive implementation, low learnability, and mismanagement of update conflicts. Objective: To alleviate the aforementioned drawbacks, we propose a novel Bx approach, called EVL+Strace, which is built using the Epsilon Validation Language (EVL) on a domain-specific trace metamodel (Strace). Furthermore, an Eclipse-based toolkit, called MoDEBiTE, is developed to automatically produce the EVL+Strace artifacts including the specific trace metamodel and transformation code. Method: EVL+Strace exploits the ability of EVL to transform user updates on models from source to target and vice versa, simultaneously. The applied trace metamodel should be specific to the domains of source and target metamodels that prevents illegitimate trace elements. Additionally, it enables developers to specify the transformation concepts more precisely. A running example is applied to explain the components of EVL+Strace and application of MoDEBiTE. Result: EVL+Strace is the first practical interactive approach that can provide important bidirectional features, such as preservation and propagation. A feature model of Bx approaches is applied to compare EVL+Strace with the well-known Bx languages. To show the superiority of EVL+Strace and applicability of MoDEBiTE, a comprehensive evaluation on six case studies is performed. Conclusion: EVL+Strace provides an interactive transformation system to manage update conflicts. It uses the EVL language for defining Bx transformation that has an easy-to-learn syntax. It is developed based on Epsilon, which is a comprehensive and actively updated framework.},
	urldate = {2019-05-29},
	journal = {Information and Software Technology},
	author = {Samimi-Dehkordi, Leila and Zamani, Bahman and Kolahdouz-Rahimi, Shekoufeh},
	month = aug,
	year = {2018},
	keywords = {Bidirectional model transformation, Traceability, Epsilon Validation Language, Model-Driven development},
	pages = {47--72},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/EPJ3EMXR/Samimi-Dehkordi et al. - 2018 - EVL+Strace a novel bidirectional model transforma.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/LL9QI6J8/S0950584917300629.html:text/html}
}




@article{EhrigEhrigHermann2008,
	title = {From {Model} {Transformation} to {Model} {Integration} based on the {Algebraic} {Approach} to {Triple} {Graph} {Grammars}},
	volume = {10},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/154},
	doi = {10.14279/tuj.eceasst.10.154},
	abstract = {Success and efficiency of software and system design fundamentally relies on its models. The more they are based on formal methods the more they can be automatically transformed to execution models and finally to implementation code.
This paper presents model transformation and model integration as specific problem within bidirectional model transformation, which has shown to support  various purposes, such as analysis, optimization, and code generation.

The main purpose of model integration is to establish correspondence between various models,
especially between source and target models. From the analysis point of view, model integration supports correctness checks of syntactical dependencies between different views and models.

The overall concept is based on the algebraic approach to triple graph grammars, which are widely used for model transformation.
The main result shows the close relationship between model transformation and model integration. For each model transformation sequence there is a unique model integration sequence and vice versa. This is demonstrated by a quasi-standard example for model transformation between class models and relational data base models.},
	language = {en},
	number = {0},
	urldate = {2018-08-30},
	journal = {Electronic Communications of the EASST},
	author = {Ehrig, Hartmut and Ehrig, Karsten and Hermann, Frank},
	month = jun,
	year = {2008},
	keywords = {\#ModelMatching},
	file = {Full Text PDF:/Users/past/Zotero/storage/QBWPMGU8/Ehrig et al. - 2008 - From Model Transformation to Model Integration bas.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/AI8T7SQ6/154.html:text/html}
}



@inproceedings{WilleWehlingSPS2017,
	address = {New York, NY, USA},
	series = {{SPLC} '17},
	title = {Variability {Mining} of {Technical} {Architectures}},
	isbn = {978-1-4503-5221-5},
	url = {http://doi.acm.org/10.1145/3106195.3106202},
	doi = {10.1145/3106195.3106202},
	abstract = {Technical architectures (TAs) represent the computing infrastructure of a company with all its hardware and software components. Over the course of time, the number of TAs grows with the companies' requirements and usually a large variety of TAs has to be maintained. Core challenge is the missing information on relations between the existing variants of TAs, which complicates reuse of solutions across systems. However, identifying these relations is an expensive task as architects have to manually analyze each TA individually. Restructuring the existing TAs poses severe risks as often sufficient information is not available (e.g., due to time constraints). To avoid failures in productive systems and resulting loss of profit, companies continue to create new solutions without restructuring existing ones. This increased variability in TAs represents technical debt. In this paper, we adapt the idea of variability mining from the software product line domain and present an efficient and automatic mining algorithm to identify the common and varying parts of TAs by analyzing a potentially arbitrary number of TAs in parallel. Using the identified variability information, architects are capable of analyzing the relations of TAs, identifying reuse potential, and making well-founded maintenance decisions. We show the feasibility and scalability of our approach by applying it to a real-world industrial case study with large sets of TAs.},
	urldate = {2019-10-08},
	booktitle = {Proceedings of the 21st {International} {Systems} and {Software} {Product} {Line} {Conference} - {Volume} {A}},
	publisher = {ACM},
	author = {Wille, David and Wehling, Kenny and Seidl, Christoph and Pluchator, Martin and Schaefer, Ina},
	year = {2017},
	note = {event-place: Sevilla, Spain},
	keywords = {enterprise architecture, technical architecture, variability mining},
	pages = {39--48},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/2XH52729/Wille et al. - 2017 - Variability Mining of Technical Architectures.pdf:application/pdf}
}



@inproceedings{AtkinsonStollB2010,
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Orthographic {Software} {Modeling}: {A} {Practical} {Approach} to {View}-{Based} {Development}},
	isbn = {978-3-642-14819-4},
	shorttitle = {Orthographic {Software} {Modeling}},
	abstract = {Although they are significantly different in how they decompose and conceptualize software systems, one thing that all advanced software engineering paradigms have in common is that they increase the number of different views involved in visualizing a system. Managing these different views can be challenging even when a paradigm is used independently, but when they are used together the number of views and inter-dependencies quickly becomes overwhelming. In this paper we present a novel approach for organizing and generating the different views used in advanced software engineering methods that we call Orthographic Software Modeling (OSM). This provides a simple metaphor for integrating different development paradigms and for leveraging domain specific languages in software engineering. Development environments that support OSM essentially raise the level of abstraction at which developers interact with their tools by hiding the idiosyncrasies of specific editors, storage choices and artifact organization policies. The overall benefit is to significantly simplify the use of advanced software engineering methods.},
	language = {en},
	booktitle = {ENASE 2009},
	publisher = {Springer Berlin Heidelberg},
	author = {Atkinson, Colin and Stoll, Dietmar and Bostan, Philipp},
	editor = {Maciaszek, Leszek A. and González-Pérez, César and Jablonski, Stefan},
	year = {2010},
	keywords = {Atlas Transformation Language, Mobile Tourist, Platform Independent Model, Product Line Engineering, Storage Choice},
	pages = {206--219},
	doi= {10.1007/978-3-642-14819-4_15}
}



@inproceedings{BrunetChechikENNS2006,
	address = {New York, NY, USA},
	title = {A {Manifesto} for {Model} {Merging}},
	isbn = {978-1-59593-410-9},
	doi = {10.1145/1138304.1138307},
	abstract = {If a modeling task is distributed, it will frequently be necessary to merge models developed by different team members. Existing approaches to model merging make assumptions about the types of model to be merged, and the nature of the relationship between them. This makes it hard to compare approaches. In this paper, we present a manifesto for research on model merging. We propose a framework for comparing different approaches to merging, by treating merge as an algebraic operator over models and model relationships. We specify the algebraic properties of an idealized merge operator, as well as related operators such as match, diff, split, and slice. We then show how our framework can be used to compare existing approaches by applying it to two of our own research projects on model merging. We show how this analysis permits a detailed comparison of approaches, reveals the key features of each, and identifies weaknesses that require further research. Most importantly, the framework emphasizes the need to make explicit all assumptions about the relationships between models, and indeed to treat model relationships as first class objects.},
	urldate = {2019-10-08},
	booktitle = {{GaMMa} '06},
	publisher = {ACM},
	author = {Brunet, Greg and Chechik, Marsha and Easterbrook, Steve and Nejati, Shiva and Niu, Nan and Sabetzadeh, Mehrdad},
	year = {2006},
	keywords = {distributed development, model management, nconsistency},
	pages = {5--12}
}



@inproceedings{Klare2018,
	address = {New York, NY, USA},
	series = {{MODELS} '18},
	title = {Multi-model {Consistency} {Preservation}},
	isbn = {978-1-4503-5965-8},
	url = {http://doi.acm.org/10.1145/3270112.3275335},
	doi = {10.1145/3270112.3275335},
	abstract = {Modern software systems are developed using multiple models to represent different properties of the system. Since these models contain dependent information, keeping them consistent is crucial for producing correctly operating software. This process can be automated with model transformations, and has been researched mainly for binary transformations that define consistency preservation for pairs of metamodels. If more than two metamodels are involved, the combination of several binary transformations leads to problems such as interoperability issues and occurring trade-off decisions. Therefore, we investigate these problems in multi-model consistency preservation in our thesis. We first analyze the interoperability of binary transformations that have been independently developed and derive patterns for non-intrusive transformation interoperability. Furthermore, we introduce an approach for decomposing consistency relations and concept metamodels that make relations explicit. This is supposed to reduce the necessity for trade-off decisions regarding challenges such as compatibility of dependent transformations and modularity of used metamodels and transformations, as well as comprehensibility and evolvability. The proposed benefit of our approach is that independently developed binary transformations can be combined, omitting interoperability issues without the necessity to know about each other, to achieve multi-model consistency. We will evaluate our approach with case studies from component-based and object-oriented software, as well as with industrial case studies for embedded automotive software and production systems.},
	urldate = {2019-10-04},
	booktitle = {Proceedings of the 21st {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}: {Companion} {Proceedings}},
	publisher = {ACM},
	author = {Klare, Heiko},
	year = {2018},
	note = {event-place: Copenhagen, Denmark},
	keywords = {model transformation, consistency management, domain-specific languages, consistency preservation, multi-model consistency},
	pages = {156--161},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/9P2WHWL8/Klare - 2018 - Multi-model Consistency Preservation.pdf:application/pdf}
}


@inproceedings{BarbosaCretinFGP2010,
	address = {New York, NY, USA},
	title = {Matching {Lenses}: {Alignment} and {View} {Update}},
	isbn = {978-1-60558-794-3},
	shorttitle = {Matching {Lenses}},
	doi = {10.1145/1863543.1863572},
	abstract = {Bidirectional programming languages are a practical approach to the view update problem. Programs in these languages, called lenses, define both a view and an update policy - i.e., every program can be read as a function mapping sources to views as well as one mapping updated views back to updated sources. One thorny issue that has not received sufficient attention in the design of bidirectional languages is alignment. In general, to correctly propagate an update to a view, a lens needs to match up the pieces of the view with the corresponding pieces of the underlying source, even after data has been inserted, deleted, or reordered. However, existing bidirectional languages either support only simple strategies that fail on many examples of practical interest, or else propose specific strategies that are baked deeply into the underlying theory. We propose a general framework of matching lenses that parameterizes lenses over arbitrary heuristics for calculating alignments. We enrich the types of lenses with "chunks" identifying reorderable pieces of the source and view that should be re-aligned after an update, and we formulate behavioral laws that capture essential constraints on the handling of chunks. We develop a core language of matching lenses for strings, together with a set of "alignment combinators" that implement a variety of alignment strategies.},
	urldate = {2019-10-09},
	booktitle = {{ICFP} '10},
	publisher = {ACM},
	author = {Barbosa, Davi M.J. and Cretin, Julien and Foster, Nate and Greenberg, Michael and Pierce, Benjamin C.},
	year = {2010},
	keywords = {alignment, bidirectional languages, boomerang, lenses, view update problem},
	pages = {193--204},
}


@book{GammaHelmJV1995,
	address = {Boston, MA, USA},
	title = {Design {Patterns}: {Elements} of {Reusable} {Object}-oriented {Software}},
	isbn = {978-0-201-63361-0},
	shorttitle = {Design {Patterns}},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
	year = {1995}
}


@techreport{RFC2396,
  author = {Tim Berners-Lee and Roy T. Fielding and Larry Masinter},
  title = {Uniform Resource Identifiers (URI): Generic Syntax},
  howpublished = {Internet Requests for Comments},
  type = {RFC},
  number = {2396},
  year = {1998},
  month = {August},
  issn = {2070-1721},
  publisher = {IETF},
  institution = {IETF},
  url = {https://www.ietf.org/rfc/rfc2396.txt}
}


@inproceedings{LackSobocinski2004,
author="Lack, Stephen
and Soboci{\'{n}}ski, Pawe{\l}",
editor="Walukiewicz, Igor",
title="Adhesive Categories",
booktitle="Foundations of Software Science and Computation Structures",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="273--288",
abstract="We introduce adhesive categories, which are categories with structure ensuring that pushouts along monomorphisms are well-behaved. Many types of graphical structures used in computer science are shown to be examples of adhesive categories. Double-pushout graph rewriting generalises well to rewriting on arbitrary adhesive categories.",
isbn="978-3-540-24727-2",
doi = {10.1007/978-3-540-24727-2_20}
}




@inproceedings{HermannEhrigEO2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Concurrent {Model} {Synchronization} with {Conflict} {Resolution} {Based} on {Triple} {Graph} {Grammars}},
	isbn = {978-3-642-28872-2},
	abstract = {Triple graph grammars (TGGs) have been used successfully to analyse correctness of bidirectional model transformations. Recently, also a corresponding formal approach to model synchronization has been presented, where updates on a given domain (either source or target) can be correctly (forward or backward) propagated to the other model. However, a corresponding formal approach of concurrent model synchronization, where a source and a target modification have to be synchronized simultaneously, has not yet been presented and analysed. This paper closes this gap taking into account that the given and propagated source or target model modifications are in conflict with each other. Our conflict resolution strategy is semi-automatic, where a formal resolution strategy – known from previous work – can be combined with a user-specific strategy.As first result, we show correctness of concurrent model synchronization, that is, each result of our nondeterministic concurrent update leads to a consistent correspondence between source and target models, where consistency is defined by the TGG. As second result, we show compatibility of concurrent with basic model synchronization: concurrent model synchronization can realize both forward and backward propagation. The results are illustrated by a running example on updating organizational models.},
	language = {en},
	booktitle = {FASE 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Hermann, Frank and Ehrig, Hartmut and Ermel, Claudia and Orejas, Fernando},
	editor = {de Lara, Juan and Zisman, Andrea},
	year = {2012},
	keywords = {correctness, triple graph grammars, model versioning, model synchronization, Model integration, bidirectional model transformation, conflict resolution},
	pages = {178--193},
	doi = {10.1007/978-3-642-28872-2_13}
}



@inproceedings{HermannEhrigErmel2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Transformation of {Type} {Graphs} with {Inheritance} for {Ensuring} {Security} in {E}-{Government} {Networks}},
	isbn = {978-3-642-00593-0},
	abstract = {E-government services usually process large amounts of confidential data. Therefore, security requirements for the communication between components have to be adhered in a strict way. Hence, it is of main interest that developers can analyze their modularized models of actual systems and that they can detect critical patterns. For this purpose, we present a general and formal framework for critical pattern detection and user-driven correction as well as possibilities for automatic analysis and verification at meta-model level. The technique is based on the formal theory of graph transformation, which we extend to transformations of type graphs with inheritance within a type graph hierarchy. We apply the framework to specify relevant security requirements.The extended theory is shown to fulfil the conditions of a weak adhesive HLR category allowing us to transfer analysis techniques and results shown for this abstract framework of graph transformation. In particular, we discuss how confluence analysis and parallelization can be used to enable parallel critical pattern detection and elimination.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hermann, Frank and Ehrig, Hartmut and Ermel, Claudia},
	editor = {Chechik, Marsha and Wirsing, Martin},
	year = {2009},
	keywords = {Critical Pair, Graph Transformation, Proxy Node, Security Requirement, Type Graph},
	pages = {325--339},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/NK9A48BS/Hermann et al. - 2009 - Transformation of Type Graphs with Inheritance for.pdf:application/pdf}
}

@MISC{ICD10,
	author = "{World Health Organization}",
	title = {ICD-10 : international statistical classification of diseases and related health problems : tenth revision},
	year = {2004},
	edition = {2nd ed},
	publisher = {World Health Organization}
}



@article{JouaultAllilaireBK2008,
	series = {Special {Issue} on {Second} issue of experimental software and toolkits ({EST})},
	title = {{ATL}: {A} model transformation tool},
	volume = {72},
	issn = {0167-6423},
	shorttitle = {{ATL}},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642308000439},
	doi = {10.1016/j.scico.2007.08.002},
	abstract = {In the context of Model Driven Engineering, models are the main development artifacts and model transformations are among the most important operations applied to models. A number of specialized languages have been proposed, aimed at specifying model transformations. Apart from the software engineering properties of transformation languages, the availability of high quality tool support is also of key importance for the industrial adoption and ultimate success of MDE. In this paper we present ATL: a model transformation language and its execution environment based on the Eclipse framework. ATL tools provide support for the major tasks involved in using a language: editing, compiling, executing, and debugging.},
	number = {1},
	urldate = {2019-10-15},
	journal = {Science of Computer Programming},
	author = {Jouault, Frédéric and Allilaire, Freddy and Bézivin, Jean and Kurtev, Ivan},
	month = jun,
	year = {2008},
	keywords = {M2M (model-to-model transformation), Model engineering, Model transformation},
	pages = {31--39},
}


@article{FeldmannKernschmidtWV2019,
	title = {Managing inter-model inconsistencies in model-based systems engineering: {Application} in automated production systems engineering},
	volume = {153},
	issn = {0164-1212},
	shorttitle = {Managing inter-model inconsistencies in model-based systems engineering},
	doi = {10.1016/j.jss.2019.03.060},
	abstract = {To cope with the challenge of managing the complexity of automated production systems, model-based approaches are applied increasingly. However, due to the multitude of different disciplines involved in automated production systems engineering, e.g., mechanical, electrical, and software engineering, several modeling languages are used within a project to describe the system from different perspectives. To ensure that the resulting system models are not contradictory, the necessity to continuously diagnose and handle inconsistencies within and in between models arises. This article proposes a comprehensive approach that allows stakeholders to specify, diagnose, and handle inconsistencies in model-based systems engineering. In particular, to explicitly capture the dependencies and consistency rules that must hold between the disparate engineering models, a dedicated graphical modeling language is proposed. By means of this language, stakeholders can specify, diagnose, and handle inconsistencies in the accompanying inconsistency management framework. The approach is implemented based on the Eclipse Modeling Framework (EMF) and evaluated based on a demonstrator project as well as a small user experiment. First findings indicate that the approach is expressive enough to capture typical dependencies and consistency rules in the automated production system domain and that it requires less effort compared to manually developing inter-model inconsistency management solutions.},
	urldate = {2019-10-17},
	journal = {Journal of Systems and Software},
	author = {Feldmann, S. and Kernschmidt, K. and Wimmer, M. and Vogel-Heuser, B.},
	month = jul,
	year = {2019},
	keywords = {Automated production systems, Inconsistency management, Model-based systems engineering},
	pages = {105--134},
}



@book{AdamekHerrlichS1990,
	series = {Pure and applied mathematics},
	title = {Abstract and concrete categories: the joy of cats},
	isbn = {978-0-471-60922-3},
	publisher = {Wiley},
	author = {Ad\'{a}mek, J. and Herrlich, H. and Strecker, G.E.},
	year = {1990},
	lccn = {89014835}
}



@inproceedings{Stevens2018,
	address = {New York, NY, USA},
	series = {{MODELS} '18},
	title = {Towards {Sound}, {Optimal}, and {Flexible} {Building} from {Megamodels}},
	isbn = {978-1-4503-4949-9},
	doi = {10.1145/3239372.3239378},
	abstract = {The model-driven development of systems involves multiple models, metamodels and transformations. Transformations -- which may be bidirectional -- specify, and provide means to enforce, desired "consistency" relationships between models. We can describe the whole configuration using a megamodel. As development proceeds, and various models are modified, we need to be able to restore consistency in the megamodel, so that the consequences of decisions first recorded in one model are appropriately reflected in the others. At the same time, we need to minimise the amount of recomputation needed; in particular, we would like to avoid reapplying a transformation when no relevant changes have occurred in the models it relates. In general, however, different results are obtained depending on which models are allowed to be modified and on the order and direction of transformation application. In this paper we propose using an orientation model to make important choices explicit. We explain the relationship between software build systems and the megamodel consistency problem. We show how to extend the formalised build system pluto to provide a means of restoring consistency in a megamodel that is, in appropriate senses, flexible, sound and optimal.},
	urldate = {2019-10-01},
	booktitle = {Proceedings of the 21th {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {ACM},
	author = {Stevens, Perdita},
	year = {2018},
	keywords = {model transformation, bidirectionality, megamodel, build system, orientation model},
	pages = {301--311},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/Y7EFSCV6/Stevens - 2018 - Towards Sound, Optimal, and Flexible Building from.pdf:application/pdf}
}



@article{AizenbudReshefNolan2006,
	title = {Model traceability},
	volume = {45},
	doi = {10.1147/sj.453.0515},
	abstract = {Traceability relationships help stakeholders understand the many associations and dependencies that exist among software artifacts created during a software development project. The extent of traceability practice is viewed as a measure of system quality and process maturity and is mandated by many standards. This paper introduces model traceability, reviews the current state of the art, and highlights open problems. One issue that impedes wide adoption of traceability is the overhead incurred in manually creating and maintaining relationships. We review the latest research advancements that address this issue through the automatic discovery of trace relationships. Model driven development provides new opportunities for establishing and using traceability information. We discuss automatic generation of trace information through transformations and the use of traceability relationships to maintain consistency and synchronize model artifacts. We conclude with a discussion of the implementation and utilization challenges that lie ahead.},
	number = {3},
	journal = {IBM Systems Journal},
	author = {Aizenbud-Reshef, N. and Nolan, B. T. and Rubin, J. and Shaham-Gafni, Y.},
	year = {2006},
	pages = {515--526},
}



@inproceedings{EhrigHabelPP2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adhesive {High}-{Level} {Replacement} {Categories} and {Systems}},
	isbn = {978-3-540-30203-2},
	abstract = {Adhesive high-level replacement (HLR) categories and systems are introduced as a new categorical framework for graph transformation in a broad sense, which combines the well-known concept of HLR systems with the new concept of adhesive categories introduced by Lack and Sobociński.In this paper we show that most of the HLR properties, which had been introduced ad hoc to generalize some basic results from the category of graphs to high-level structures, are valid already in adhesive HLR categories. As a main new result in a categorical framework we show the Critical Pair Lemma for local confluence of transformations. Moreover we present a new version of embeddings and extensions for transformations in our framework of adhesive HLR systems.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ehrig, Hartmut and Habel, Annegret and Padberg, Julia and Prange, Ulrike},
	editor = {Ehrig, Hartmut and Engels, Gregor and Parisi-Presicce, Francesco and Rozenberg, Grzegorz},
	year = {2004},
	pages = {144--160}
}



@article{EhrigHabelKP1991b,
	title = {Parallelism and concurrency in high-level replacement systems},
	volume = {1},
	issn = {1469-8072, 0960-1295},
	doi = {10.1017/S0960129500001353},
	abstract = {High-level replacement systems are formulated in an axiomatic algebraic framework based on categories pushouts. This approach generalizes the well-known algebraic approach to graph grammars and several other types of replacement systems, especially the replacement of algebraic specifications which was recently introduced for a rule-based approach to modular system design.in this paper basic notions like productions, derivations, parellel and sequential independence are introduced for high-level replacement syetms leading to Church-Rosser, Parallelism and concurrency Theorems previously shown in the literature for special cases only. In the general case of high-level replacement systems specific conditions, called HLR1- and HLR2-conditions, are formulated in order to obtain these results.Several examples of high-level replacement systems are discussed and classified w.r.t. HLR1- and HLR2-conditions showing which of the results are valid in each case.},
	language = {en},
	number = {3},
	urldate = {2019-10-21},
	journal = {Mathematical Structures in Computer Science},
	author = {Ehrig, Hartmut and Habel, Annegret and Kreowski, Hans-Jörg and Parisi-Presicce, Francesco},
	month = nov,
	year = {1991},
	pages = {361--404}
}



@incollection{CorradiniMontanariREHL1997,
	title = {Algebraic {Approaches} to {Graph} {Transformation}, {Part} {I}: {Basic} {Concepts} and {Double} {Pushout} {Approach}},
	volume = {1},
	shorttitle = {Algebraic {Approaches} to {Graph} {Transformation}, {Part} {I}},
	abstract = {The algebraic approaches to graph transformation are based on the concept of gluing of graphs, modelled by pushouts in suitable categories of graphs and graph morphisms. This allows one not only to give an explicit algebraic or set theoretical description of the constructions, but also to use concepts and results from category theory in order to build up a rich theory and to give elegant proofs even in complex situations. In this chapter we start with an overwiev of the basic notions common to the two algebraic approaches, the "double-pushout (DPO) approach" and the "single-pushout (SPO) approach"; next we present the classical theory and some recent development of the double-pushout approach. The next chapter is devoted instead to the single-pushout approach, and it is closed by a comparison between the two approaches. -- This document will appear as a chapter of the "The Handbook of Graph Grammars. Volume I: Foundations", G. Rozenberg (Ed.), World Scientific.},
	booktitle = {Handbook of {Graph} {Gram}- mars and {Computing} by {Graph} {Transformations}},
	publisher = {World Scientific Publishing Co., Inc.},
	author = {Corradini, A. and Montanari, U. and Rossi, F. and Ehrig, H. and Heckel, R. and Loewe, M.},
	year = {1997}
}



@inproceedings{EhrigPrangeT2004,
author="Ehrig, Hartmut
and Prange, Ulrike
and Taentzer, Gabriele",
editor="Ehrig, Hartmut
and Engels, Gregor
and Parisi-Presicce, Francesco
and Rozenberg, Grzegorz",
title="Fundamental Theory for Typed Attributed Graph Transformation",
booktitle="Graph Transformations",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="161--177",
abstract="The concept of typed attributed graph transformation is most significant for modeling and meta modeling in software engineering and visual languages, but up to now there is no adequate theory for this important branch of graph transformation. In this paper we give a new formalization of typed attributed graphs, which allows node and edge attribution. The first main result shows that the corresponding category is isomorphic to the category of algebras over a specific kind of attributed graph structure signature. This allows to prove the second main result showing that the category of typed attributed graphs is an instance of ``adhesive HLR categories''. This new concept combines adhesive categories introduced by Lack and Soboci{\'{n}}ski with the well-known approach of high-level replacement (HLR) systems using a new simplified version of HLR conditions. As a consequence we obtain a rigorous approach to typed attributed graph transformation providing as fundamental results the Local Church-Rosser, Parallelism, Concurrency, Embedding and Extension Theorem and a Local Confluence Theorem known as Critical Pair Lemma in the literature.",
isbn="978-3-540-30203-2",
doi = {10.1007/978-3-540-30203-2_13}
}


@article{PuissantVanDerStraetenM2015,
	title = {Resolving model inconsistencies using automated regression planning},
	volume = {14},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-013-0317-9},
	doi = {10.1007/s10270-013-0317-9},
	abstract = {One of the main challenges in model-driven software engineering is to automate the resolution of design model inconsistencies. We propose to use the artificial intelligence technique of automated planning for the purpose of resolving such inconsistencies through the generation of one or more resolution plans. We implemented Badger, a regression planner in Prolog that generates such plans. We assess its scalability on the resolution of different types of structural inconsistencies in UML models using both generated models and reverse-engineered models of varying sizes, the largest ones containing more than 10,000 model elements. We illustrate the metamodel-independence of our approach by applying it to the resolution of code smells in a Java program. We discuss how the user can adapt the order in which resolution plans are presented by modifying the cost function of the planner algorithm.},
	language = {en},
	number = {1},
	urldate = {2019-11-08},
	journal = {Software \& Systems Modeling},
	author = {Pinna Puissant, Jorge and Van Der Straeten, Ragnhild and Mens, Tom},
	month = feb,
	year = {2015},
	keywords = {Automated planning, Inconsistency resolution, Software modeling, TOOL},
	pages = {461--481}
}



@inproceedings{SilvaMougenotBB2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {Automated} {Inconsistency} {Handling} in {Design} {Models}},
	isbn = {978-3-642-13093-9 978-3-642-13094-6},
	doi = {10.1007/978-3-642-13094-6_28},
	abstract = {The increasing adoption of MDE (Model Driven Engineering) favored the use of large models of different types. It turns out that when the modeled system gets larger, simply computing a list of inconsistencies (as provided by existing techniques for inconsistency handling) gets less and less effective when it comes to actually fixing them. In fact, the inconsistency handling task (i.e. deciding what needs to be done in order to restore consistency) remains largely manual. This work is a step towards its automatization. We propose a method for the generation of repair plans for an inconsistent model. In our approach, the depth of the explored search space is configurable in order to cope with the underlying combinatorial characteristic of this problem and to avoid overwhelming the designer with large plans that can not be fully checked before being applied.},
	language = {en},
	urldate = {2018-07-16},
	booktitle = {Advanced {Information} {Systems} {Engineering}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Silva, Marcos Aurélio Almeida da and Mougenot, Alix and Blanc, Xavier and Bendraou, Reda},
	month = jun,
	year = {2010},
	pages = {348--362}
}


@inproceedings{KleinerDelFabroA2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Model {Search}: {Formalizing} and {Automating} {Constraint} {Solving} in {MDE} {Platforms}},
	isbn = {978-3-642-13595-8},
	shorttitle = {Model {Search}},
	abstract = {Model Driven Engineering (MDE) and constraint programming (CP) have been widely used and combined in different applications. However, existing results are either ad-hoc, not fully integrated or manually executed. In this article, we present a formalization and an approach for automating constraint-based solving in a MDE platform. Our approach generalizes existing work by combining known MDE concepts with CP techniques into a single operation called model search. We present the theoretical basis for model search, as well as an automated process that details the involved operations. We validate our approach by comparing two implemented solutions (one based on Alloy/SAT, the other on OPL/CP), and by executing them over an academic use-case.},
	language = {en},
	booktitle = {ECMFA 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Kleiner, Mathias and Del Fabro, Marcos Didonet and Albert, Patrick},
	editor = {Kühne, Thomas and Selic, Bran and Gervais, Marie-Pierre and Terrier, François},
	year = {2010},
	keywords = {Model Transformation, Software Product Line, Constraint Programming, Model Search, Search Engine},
	pages = {173--188},
	doi = {10.1007/978-3-642-13595-8_15}
}


@inproceedings{MensVanDerStraeten2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Incremental {Resolution} of {Model} {Inconsistencies}},
	isbn = {978-3-540-71998-4},
	abstract = {During model-driven software development, we are inevitably confronted with design models that contain a wide variety of inconsistencies. Interactive and automated support for detecting and resolving these inconsistencies is therefore indispensable. In this paper, we report on an iterative inconsistency resolution process. Our approach relies on the underlying formalism of graph transformation. We exploit the mechanism of critical pair analysis to analyse dependencies and conflicts between inconsistencies and resolutions, to detect resolution cycles and to analyse the completeness of resolutions. The results of this analysis are integrated in the iterative inconsistency resolution process and can help the software engineer to develop and evolve models in presence of inconsistencies.},
	language = {en},
	booktitle = {Recent {Trends} in {Algebraic} {Development} {Techniques}},
	publisher = {Springer Berlin Heidelberg},
	author = {Mens, Tom and Van Der Straeten, Ragnhild},
	editor = {Fiadeiro, José Luiz and Schobbens, Pierre-Yves},
	year = {2007},
	keywords = {Eclipse Modeling Framework, Graph Grammar, Graph Transformation, Type Graph, Dependency Graph},
	pages = {111--126},
	doi = {10.1007/978-3-540-71998-4_7}
}



@inproceedings{XiongHuZSTM2009,
	address = {New York, NY, USA},
	title = {Supporting {Automatic} {Model} {Inconsistency} {Fixing}},
	isbn = {978-1-60558-001-2},
	doi = {10.1145/1595696.1595757},
	abstract = {Modern development environments often involve models with complex consistency relations. Some of the relations can be automatically established through "fixing procedures". When users update some parts of the model and cause inconsistency, a fixing procedure dynamically propagates the update to other parts to fix the inconsistency. Existing fixing procedures are manually implemented, which requires a lot of efforts and the correctness of a fixing procedure is not guaranteed. In this paper we propose a new language, Beanbag, to support the development of fixing procedures. A Beanbag program defines and checks a consistency relation similarly to OCL, but the program can also be executed in a fixing mode, taking user updates on the model and producing new updates to make the model satisfy the consistency relation. In this way Beanbag significantly eases the development of fixing procedures. In addition, a Beanbag program is also guaranteed to be correct with respect to the three correctness properties we define. We evaluate Beanbag over a set of MOF and UML consistency relations and the result shows that Beanbag is useful in practice.},
	urldate = {2018-07-16},
	booktitle = {{ESEC}/{FSE} '09},
	publisher = {ACM},
	author = {Xiong, Yingfei and Hu, Zhenjiang and Zhao, Haiyan and Song, Hui and Takeichi, Masato and Mei, Hong},
	year = {2009},
	keywords = {beanbag, inconsistency fixing, model consistency, ocl},
	pages = {315--324}
}


@inproceedings{VanDerStraetenPuissantM2011,
	title = {Assessing the {Kodkod} {Model} {Finder} for {Resolving} {Model} {Inconsistencies}},
	doi = {10.1007/978-3-642-21470-7_6},
	abstract = {In model-driven software engineering (MDE), software is built through the incremental development, composition and transformation of a variety of models. We are inevitably confronted with design models that contain a wide variety of inconsistencies. Interactive and automated support for detecting and resolving these inconsistencies is indispensable. We evaluate an approach to automate the generation of concrete models in which structural inconsistencies are resolved. We implemented this approach in the model finder Kodkod and assessed its suitability for model inconsistency resolution based on an objective set of criteria.},
	booktitle = {{ECMFA}},
	author = {Straeten, Ragnhild Van Der and Puissant, Jorge Pinna and Mens, Tom},
	year = {2011},
	keywords = {Interactivity, Iterative and incremental development, Model-driven architecture, Model-driven engineering, Sensor, Software engineering}
}



@article{NuseibehEasterbrookR2000,
	title = {Leveraging inconsistency in software development},
	volume = {33},
	issn = {0018-9162},
	doi = {10.1109/2.839317},
	abstract = {Software engineers make use of many descriptions, including analysis models, specifications, designs, program code, user guides, test plans, change requests, style guides, schedules, and process models. But since different developers construct and update these descriptions at various times during development, maintaining consistency among descriptions presents several problems. Descriptions tend to vary considerably. Individual descriptions can be ill-formed or self-contradictory and frequently evolve throughout the life cycle at different rates. Also, checking the consistency of a large, arbitrary set of descriptions is computationally expensive. The authors assert that maintaining consistency at all times is counterproductive. In many cases, it may be desirable to tolerate or even encourage inconsistency to facilitate distributed team-work and prevent premature commitment to design decisions. They advocate using inconsistency to highlight problem areas, using it as a tool to improve the development team's shared understanding, direct the process of requirements elicitation, and assist with verification and validation.},
	number = {4},
	journal = {Computer},
	author = {Nuseibeh, B. and Easterbrook, S. and Russo, A.},
	month = apr,
	year = {2000},
	keywords = {software development, Design engineering, Programming, formal specification, formal verification, Maintenance engineering, Software engineering, requirements elicitation, Libraries, consistency, development team shared understanding, distributed team-work, Educational institutions, inconsistency, software development management, Software testing, Teamwork, validation, verification},
	pages = {24--29},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/4CJDNMR6/839317.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/ISMUJKB2/Nuseibeh et al. - 2000 - Leveraging inconsistency in software development.pdf:application/pdf}
}


@techreport{KangSholomHNP1990,
title={Feature-Oriented Domain Analysis (FODA) Feasibility Study},
author={Kyo Kang and Sholom Cohen and James Hess and William Novak and A. Peterson},
year={1990},
number={CMU/SEI-90-TR-021 },
institution={Software Engineering Institute, Carnegie Mellon University},
address={Pittsburgh, PA},
url={http://resources.sei.cmu.edu/library/asset-view.cfm?AssetID=11231} }



@inproceedings{Pearl1981,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'81},
	title = {Heuristic {Search} {Theory}: {Survey} of {Recent} {Results}},
	shorttitle = {Heuristic {Search} {Theory}},
	abstract = {This paper summarizes recent analytical Investigations of the mathematical properties of heuristics and their Influence on the performance of common search techniques. The results are reported without proofs, together with discussions of motivations and Interpretations. Highlights include the following: relations between the precision of the heuristic estimates and the average complexity of the search, comparisons of the average complexities of A* and BACKTRACKING, procedures for comparing and combining non-admissible heuristic functions, the influence of the weight u{\textgreater} (l-u{\textgreater})g ♦ {\textless}*{\textgreater}h] on the complexity of A*, determination of the branching factors of alpha-beta and SSS*, and the effects of successor ordering on the complexity of alpha-beta and of search depth on the quality of decisions.},
	urldate = {2019-11-14},
	booktitle = {Proceedings of the 7th {International} {Joint} {Conference} on {Artificial} {Intelligence} - {Volume} 1},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Pearl, Judea},
	year = {1981},
	pages = {554--562}
}


@article{CheneyGibbonsMS2015,
	title = {Towards a {Principle} of {Least} {Surprise} for {Bidirectional} {Transformations}},
	volume = {1396},
	abstract = {In software engineering and elsewhere, it is common for different people to work intensively with different, but related, artefacts, e.g. models, documents, or code. They may use bidirectional transformations (bx) to maintain consistency between them. Naturally, they do not want their deliberate decisions disrupted, or their comprehension of their artefact interfered with, by a bx that makes changes to their artefact beyond the strictly necessary. This gives rise to a desire for a principle of Least Change, which has been often alluded to in the field, but seldom addressed head on. In this paper we present examples, briefly survey what has been said about least change in the context of bx, and identify relevant notions from elsewhere that may be applicable. We identify that what is actually needed is a Principle of Least Surprise, to limit a bx to reasonable behaviour. We present candidate formalisations of this, but none is obviously right for all circumstances. We point out areas where further work might be fruitful, and invite discussion.},
	journal = {Proceedings of the 4th International Workshop on Bidirectional Transformations co-located with Software Technologies: Applications and Foundations (STAF 2015)},
	author = {Cheney, James and Gibbons, Jeremy and McKinna, James and Stevens, Perdita},
	year = {2015},
	pages = {66--80}
}


@article{JohnsonRosebrugh2002,
	series = {{CATS}'02, {Computing}: the {Australasian} {Theory} {Symposium}},
	title = {Sketch {Data} {Models}, {Relational} {Schema} and {Data} {Specifications}},
	volume = {61},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066104003056},
	doi = {10.1016/S1571-0661(04)00305-6},
	abstract = {When different mathematical models are used for software analysis and development it is important to understand their relationships. When the models are truly mathematical, and when the aspects of reality that they seek to model are common, it may be possible to express their relationships in precise mathematical terms. This paper studies three mathematical models: The sketch data model, the relational data model, and the data specifications of Piessens and Steegmans, and determines their relationships mathematically and in detail. The constructions presented here answer reasonably long-standing theoretical questions, and offer techniques that promise to be practically useful in integrating data models.},
	urldate = {2019-02-22},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Johnson, Michael and Rosebrugh, Robert},
	month = jan,
	year = {2002},
	keywords = {data model, Category theory, mathematical specification},
	pages = {51--63}
}


@inproceedings{DiskinKadishPJ200,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Universal {Arrow} {Foundations} for {Visual} {Modeling}},
	isbn = {978-3-540-67915-8 978-3-540-44590-6},
	url = {https://link.springer.com/chapter/10.1007/3-540-44590-0_30},
	doi = {10.1007/3-540-44590-0_30},
	abstract = {The goal of the paper is to explicate some common formal logic underlying various notational systems used in visual modeling. The idea is to treat the notational diversity as the diversity of visualizations of the same basic specificational format. It is argued that the task can be well approached in the arrow-diagram logic framework where specifications are directed graphs carrying a structure of diagram predicates and operations.},
	language = {en},
	urldate = {2018-01-03},
	booktitle = {Theory and {Application} of {Diagrams}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Diskin, Zinovy and Kadish, Boris and Piessens, Frank and Johnson, Michael},
	month = sep,
	year = {2000},
	pages = {345--360},
	file = {Snapshot:/Users/past/Zotero/storage/FMTZP92N/3-540-44590-0_30.html:text/html}
}


@article{HofstedeLippeF1996,
	title = {Conceptual {Data} {Modeling} from a {Categorical} {Perspective}},
	volume = {39},
	abstract = {For successful information systems development, conceptual data modeling is essential. Nowadays many techniques for conceptual data modeling exist. In-depth comparisons of concepts of these techniques are very difficult as the mathematical formalizations of these techniques, if they exist at all, are very different. As such there is a need for a unifying formal framework providing a sufficiently high level of abstraction. In this paper the use of category theory for this purpose is addressed. Well-known conceptual data modeling concepts, such as relationship types, generalization, specialization, collection types, and constraint types, such as the total role constraint and the uniqueness constraint, are discussed from a categorical point of view. An important advantage of this framework is its "configurable semantics". Features such as null values, uncertainty, and temporal behavior can be added by selecting appropriate instance categories. The addition of these features usually requir...},
	journal = {The Computer Journal},
	author = {Hofstede, A. H. M. Ter and Lippe, E. and Frederiks, P. J. M.},
	year = {1996}
}


@book{AdamekRosicky1994,
	address = {Cambridge},
	series = {London {Mathematical} {Society} {Lecture} {Note} {Series}},
	title = {Locally {Presentable} and {Accessible} {Categories}},
	isbn = {978-0-521-42261-1},
	url = {https://www.cambridge.org/core/books/locally-presentable-and-accessible-categories/94CB48295B6AF097FC232313A57BDE17},
	abstract = {The concepts of a locally presentable category and an accessible category have turned out to be useful in formulating connections between universal algebra, model theory, logic and computer science. The aim of this book is to provide an exposition of both the theory and the applications of these categories at a level accessible to graduate students. Firstly the properties of l-presentable objects, locally l-presentable categories, and l-accessible categories are discussed in detail, and the equivalence of accessible and sketchable categories is proved. The authors go on to study categories of algebras and prove that Freyd's essentially algebraic categories are precisely the locally presentable categories. In the final chapters they treat some topics in model theory and some set theoretical aspects. For researchers in category theory, algebra, computer science, and model theory, this book will be a necessary purchase.},
	publisher = {Cambridge University Press},
	author = {Adamek, J. and Rosicky, J.},
	year = {1994},
	doi = {10.1017/CBO9780511600579}
}


@article{Makkai1997,
	title = {Generalized sketches as a framework for completeness theorems},
	volume = {115},
	issn = {0022-4049},
	url = {http://www.sciencedirect.com/science/article/pii/S0022404996000072},
	doi = {10.1016/S0022-4049(96)00007-2},
	abstract = {The concept of sketch is generalized. Morphisms of finite (generalized) sketches are used as sketch-entailments. A semantics and a deductive calculus of sketch-entailments are developed. A General Completeness Theorem (GCT) shows that the deductive calculus is adequate for the semantics. In each of a number of categories of sketches, a particular set of sketch-entailments is singled out as a set of axioms used to specify a particular kind of structured category. The specification yields an adequate proof-system to derive sketch-entailments valid in structured categories of the given kind. Classical, Tarski-type semantics is related to the sketch-semantics of the paper. Specific completeness theorems are given in the sketch-based formalism, and they are related to representation theorems of categorical logic, and known completeness theorems of logic.},
	language = {en},
	urldate = {2019-10-31},
	journal = {Journal of Pure and Applied Algebra},
	author = {Makkai, M.},
	month = feb,
	year = {1997},
	pages = {49--79, 179--212, 214--274}
}

@article{BastianiEhresmann1972,
     author = {Bastiani, Andr\'ee and Ehresmann, Charles},
     title = {Categories of sketched structures},
     journal = {Cahiers de Topologie et G\'eom\'etrie Diff\'erentielle Cat\'egoriques},
     publisher = {Dunod \'editeur, publi\'e avec le concours du CNRS},
     volume = {13},
     number = {2},
     year = {1972},
     pages = {104-214},
     zbl = {0263.18009},
     mrnumber = {323856},
     language = {en}
 }


@incollection{DampneyJohnsonM1992,
	address = {New York, NY, USA},
	title = {An {Illustrated} {Mathematical} {Foundation} for {ERA}},
	isbn = {0-19-853684-4},
	url = {http://dl.acm.org/citation.cfm?id=140658.140667},
	booktitle = {The {Unified} {Computation} {Laboratory}},
	publisher = {Oxford University Press, Inc.},
	author = {Dampney, C. N. G. and Johnson, Michael and Monro, G. P.},
	editor = {Rattray, Charles and Clark, Robert G.},
	year = {1992},
	pages = {77--84}
}


@article{PiessensSteegmans1995,
	title = {Categorical data-specifications.},
	volume = {1},
	issn = {1201-561X},
	language = {eng},
	urldate = {2021-07-05},
	journal = {Theory and Applications of Categories},
	author = {Piessens, Frank and Steegmans, Eric},
	year = {1995},
	pages = {156--173},
}



@article{Diskin1997,
	title = {Towards {Algebraic} {Graph}-{Based} {Model} {Theory} for {Computer} {Science}},
	volume = {3},
	journal = {Bulletin of Symbolic Logic},
	author = {Diskin, Z.},
	year = {1997},
	pages = {144--145}
}



@incollection{WolterDiskinK2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Graph {Operations} and {Free} {Graph} {Algebras}},
	isbn = {978-3-319-75395-9 978-3-319-75396-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-75396-6_17},
	language = {en},
	urldate = {2018-07-19},
	booktitle = {Graph {Transformation}, {Specifications}, and {Nets}},
	publisher = {Springer, Cham},
	author = {Wolter, Uwe and Diskin, Zinovy and König, Harald},
	year = {2018},
	doi = {10.1007/978-3-319-75396-6_17},
	pages = {313--331}
}


@article{KoenigWolter2017,
	title = {Van {Kampen} {Colimits} and {Path} {Uniqueness}},
	url = {http://arxiv.org/abs/1710.09784},
	doi = {10.23638/LMCS-14(2:5)2018},
	abstract = {Fibred semantics is the foundation of the model-instance pattern of software engineering. Software models can often be formalized as objects of presheaf topoi, i.e, categories of objects that can be represented as algebras as well as coalgebras, e.g., the category of directed graphs. Multimodeling requires to construct colimits of models, decomposition is given by pullback. Compositionality requires an exact interplay of these operations, i.e., diagrams must enjoy the Van Kampen property. However, checking the validity of the Van Kampen property algorithmically based on its definition is often impossible. In this paper we state a necessary and sufficient yet efficiently checkable condition for the Van Kampen property to hold in presheaf topoi. It is based on a uniqueness property of path-like structures within the defining congruence classes that make up the colimiting cocone of the models. We thus add to the statement "Being Van Kampen is a Universal Property" by Heindel and Soboci{\textbackslash}'\{n\}ski the fact that the Van Kampen property reveals a presheaf-based structural uniqueness feature.},
	urldate = {2019-03-06},
	journal = {arXiv:1710.09784 [math]},
	author = {König, Harald and Wolter, Uwe},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.09784},
	keywords = {Mathematics - Category Theory, 18A15, 18A25},
}


@article{WolterKoenig2015,
	title = {Fibred {Amalgamation}, {Descent} {Data}, and {Van} {Kampen} {Squares} in {Topoi}},
	volume = {23},
	issn = {1572-9095},
	url = {https://doi.org/10.1007/s10485-013-9339-2},
	doi = {10.1007/s10485-013-9339-2},
	abstract = {Reliable semantics for software systems has to follow the semantics-as-instance principal (fibred semantics) rather than the semantics-as-interpretation principal (indexed semantics). While amalgamation of interpretations is simple and nearly always possible, amalgamation of instances is very much involved and not possible in many cases. A condition when two compatible instances (a span of pullbacks) are amalgamable, is presented for presheaves, i.e. functor categories SET 𝒮 . Based on this individual condition we prove further a total condition for amalgamation which simultaneously yields a necessary and sufficient condition for pushouts to be Van Kampen squares. As a necessary and adequate basis to achieve these results we provide a full revision and adaption of the theory of descent data in topoi for applications in diagrammatic specifications including graph transformations. Especially, we characterize Van Kampen squares in arbitrary topoi by pullbacks of categories of descent data.},
	language = {en},
	number = {3},
	urldate = {2019-11-21},
	journal = {Applied Categorical Structures},
	author = {Wolter, Uwe and König, Harald},
	month = jun,
	year = {2015},
	keywords = {03G30, 18B25, 18D30, 18F20, 68Q55, 68Q65, Amalgamation, Descent data, Diagrammatic specification, Fibred semantics, Graph transformation, Van Kampen square},
	pages = {447--486},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/4SM6DHIR/Wolter and König - 2015 - Fibred Amalgamation, Descent Data, and Van Kampen .pdf:application/pdf}
}



@inproceedings{EhrigPfenderS1973,
	title = {Graph-grammars: {An} algebraic approach},
	shorttitle = {Graph-grammars},
	doi = {10.1109/SWAT.1973.11},
	abstract = {The paper presents an algebraic theory of graph-grammars using homomorphisms and pushout-constructions to specify embeddings and direct derivations constructively. We consider the case of arbitrary directed graphs permitting loops and parallel edges. The gluing of two arbitrary labeled graphs (push-out) is defined allowing a strictly symmetric definition of direct derivations and the embedding of derivations into a common frame. A two-dimensional hierarchy of graph-grammars is given including the classical case of Chomsky-grammars and several other graphgrammar constructions as special types. The use of well-known categorical constructions and results allows simplification of the proofs and pregnant formulation of concepts like "parallel composition" and "translation of grammars".},
	booktitle = {14th {Annual} {Symposium} on {Switching} and {Automata} {Theory} (swat 1973)},
	author = {Ehrig, H. and Pfender, M. and Schneider, H. J.},
	month = oct,
	year = {1973},
	keywords = {Labeling, Pattern recognition, Pregnancy, Production},
	pages = {167--180},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/6Y8VBDA7/4569741.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/4FDSIKLA/Ehrig et al. - 1973 - Graph-grammars An algebraic approach.pdf:application/pdf}
}





@incollection{Plump1993,
title = "Hypergraph Rewriting: Critical Pairs and Undecidability of Confluence",
author = "Detlef Plump",
year = "1993",
language = "English",
pages = "201--213",
editor = "Ronan Sleep and Rinus Plasmeijer and {van Eekelen}, Marko",
booktitle = "Term Graph Rewriting",
publisher = "John Wiley",
}



@inproceedings{GaducciHeckel1998,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {An inductive view of graph transformation},
	isbn = {978-3-540-69719-0},
	doi = {10.1007/3-540-64299-4_36},
	abstract = {The dynamic behavior of rule-based systems (like termrewriting systems [24], process algebras [27], and so on) can be traditionally determined in two orthogonal ways. Either operationally, in the sense that a way of embedding a rule into a state is devised, stating explicitly how the result is built: This is the role played by (the application of) a substitution in term rewriting. Or inductively, showing how to build the class of all possible reductions from a set of basic ones: For term rewriting, this is the usual definition of the rewrite relation as the minimal closure of the rewrite rules. As far as graph transformation is concerned, the operational view is by far more popular: In this paper we lay the basis for the orthogonal view. We first provide an inductive description for graphs as arrows of a freely generated dgs-monoidal category. We then apply 2-categorical techniques, already known for term and term graph rewriting [29, 7], recasting in this framework the usual description of graph transformation via double-pushout [13].},
	language = {en},
	booktitle = {Recent {Trends} in {Algebraic} {Development} {Techniques}},
	publisher = {Springer},
	author = {Gadducci, F. and Heckel, R.},
	editor = {Presicce, Francesco Parisi},
	year = {1998},
	keywords = {Derivation Step, Graph Grammar, Graph Production, Graph Transformation, Monoidal Category},
	pages = {223--237},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/MT7DQAGC/Gadducci and Heckel - 1998 - An inductive view of graph transformation.pdf:application/pdf}
}


@inproceedings{BonchiGaducciKSZ2017,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Confluence of {Graph} {Rewriting} with {Interfaces}},
	isbn = {978-3-662-54434-1},
	doi = {10.1007/978-3-662-54434-1_6},
	abstract = {For terminating double-pushout (DPO) graph rewriting systems confluence is, in general, undecidable. We show that confluence is decidable for an extension of DPO rewriting to graphs with interfaces. This variant is important due to it being closely related to rewriting of string diagrams. We show that our result extends, under mild conditions, to decidability of confluence for terminating rewriting systems of string diagrams in symmetric monoidal categories.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer},
	author = {Bonchi, Filippo and Gadducci, Fabio and Kissinger, Aleks and Sobociński, Paweł and Zanasi, Fabio},
	editor = {Yang, Hongseok},
	year = {2017},
	keywords = {Adhesive categories, Confluence, DPO rewriting systems, PROPs, String diagrams},
	pages = {141--169},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/SE3PXDLK/Bonchi et al. - 2017 - Confluence of Graph Rewriting with Interfaces.pdf:application/pdf}
}




@inproceedings{RosebrughWood1992,
	title = {Relational {Databases} and {Indexed} {Categories}},
	abstract = {. A description of relational databases in categorical terminology given here has as intended application the study of database dynamics, in particular we view (i) updates as database objects in a suitable category indexed by a topos; (ii) L-fuzzy databases as database objects in sheaves. Indexed categories are constructed to model the databases on a fixed family of domains and also all databases for a varying family of domains. Further, we show that the process of constructing the relational completion of a relational database is a monad in a 2-category of functors. Introduction  We use the term relation for a subobject of a finite product of objects in a category. Following the relational database literature, we use the term domain  for an object of the ambient category (and warn readers that these are not  the ordered objects which go by the name "domain" elsewhere in theoretical Computer Science.) A relational database, as defined by E. F. Codd [3], is first of all a family of rela...},
	booktitle = {In {Proceedings} of the {International} {Category} {Theory} {Meeting} 1991, {CMS} {Conference} {Proceedings} 13, 391–407, {American} {Mathematical} {Society}},
	publisher = {American Mathematical Society},
	author = {Rosebrugh, Robert and Wood, R. J.},
	year = {1992},
	pages = {391--407},
	file = {Citeseer - Full Text PDF:/Users/past/Zotero/storage/Q9933V5T/Rosebrugh and Wood - 1992 - Relational Databases and Indexed Categories.pdf:application/pdf;Citeseer - Snapshot:/Users/past/Zotero/storage/Q9KQR728/summary.html:text/html}
}


@article{HabelPennemann2009,
	title = {Correctness of high-level transformation systems relative to nested conditions†},
	volume = {19},
	issn = {1469-8072, 0960-1295},
	doi = {10.1017/S0960129508007202},
	abstract = {In this paper we introduce the notions of nested constraints and application conditions, short nested conditions. For a category associated with a graphical representation such as graphs, conditions are a graphical and intuitive, yet precise, formalism that is well suited to describing structural properties. We show that nested graph conditions are expressively equivalent to first-order graph formulas. A part of the proof includes transformations between two satisfiability notions of conditions, namely -satisfiability and -satisfiability. We consider a number of transformations on conditions that can be composed to construct constraint-guaranteeing and constraint-preserving application conditions, weakest preconditions and strongest postconditions. The restriction of rule applications by conditions can be used to correct transformation systems by pruning transitions leading to states violating given constraints. Weakest preconditions and strongest postconditions can be used to verify the correctness of transformation systems with respect to pre- and postconditions.},
	language = {en},
	number = {2},
	urldate = {2019-08-13},
	journal = {Mathematical Structures in Computer Science},
	author = {Habel, Annegret and Pennemann, Karl-Heinz},
	month = apr,
	year = {2009},
	pages = {245--296}
}


@incollection{Selinger2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics}},
	title = {A {Survey} of {Graphical} {Languages} for {Monoidal} {Categories}},
	isbn = {978-3-642-12821-9},
	url = {https://doi.org/10.1007/978-3-642-12821-9_4},
	abstract = {This article is intended as a reference guide to various notions of monoidal categories and their associated string diagrams. It is hoped that this will be useful not just to mathematicians, but also to physicists, computer scientists, and others who use diagrammatic reasoning. We have opted for a somewhat informal treatment of topological notions, and have omitted most proofs. Nevertheless, the exposition is sufficiently detailed to make it clear what is presently known, and to serve as a starting place for more in-depth study. Where possible, we provide pointers to more rigorous treatments in the literature. Where we include results that have only been proved in special cases, we indicate this in the form of caveats.},
	language = {en},
	urldate = {2019-11-26},
	booktitle = {New {Structures} for {Physics}},
	publisher = {Springer},
	author = {Selinger, P.},
	editor = {Coecke, Bob},
	year = {2011},
	doi = {10.1007/978-3-642-12821-9_4},
	keywords = {Graphical Language, Monoidal Category, Monoidal Functor, Reidemeister Move, Symmetric Monoidal Category},
	pages = {289--355}
}

@article{MacLane1965,
	title = {Categorical algebra},
	volume = {71},
	issn = {0002-9904, 1936-881X},
	url = {https://www.ams.org/bull/1965-71-01/S0002-9904-1965-11234-4/},
	doi = {10.1090/S0002-9904-1965-11234-4},
	abstract = {Advancing research. Creating connections.},
	language = {en},
	number = {1},
	urldate = {2019-11-07},
	journal = {Bulletin of the American Mathematical Society},
	author = {MacLane, Saunders},
	year = {1965},
	pages = {40--106},
}

@article{JoyalStreet1991,
	title = {The geometry of tensor calculus},
	volume = {88},
	issn = {0001-8708},
	url = {http://www.sciencedirect.com/science/article/pii/000187089190003P},
	doi = {10.1016/0001-8708(91)90003-P},
	language = {en},
	number = {1},
	urldate = {2019-11-26},
	journal = {Advances in Mathematics},
	author = {Joyal, André and Street, Ross},
	month = jul,
	year = {1991},
	pages = {55--112}
}



@inproceedings{SobocinskiStephens2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Programming} {Language} for {Spatial} {Distribution} of {Net} {Systems}},
	isbn = {978-3-319-07734-5},
	doi = {10.1007/978-3-319-07734-5_9},
	abstract = {Petri nets famously expose concurrency directly in their statespace. Building on the work on the compositional algebra of nets with boundaries, we show how an algebraic decomposition allows one to expose both concurrency and spatial distribution in the statespace.Concretely, we introduce a high-level domain specific language (DSL), PNBml, for the construction of nets in terms of their components. We use PNBml to express several well-known parametric examples.},
	language = {en},
	booktitle = {Application and {Theory} of {Petri} {Nets} and {Concurrency}},
	publisher = {Springer International Publishing},
	author = {Sobociński, Paweł and Stephens, Owen},
	editor = {Ciardo, Gianfranco and Kindler, Ekkart},
	year = {2014},
	keywords = {logical and algebraic calculi, Modelling approaches, net-based semantical, system design using nets},
	pages = {150--169},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/X3IL2AYS/Sobociński and Stephens - 2014 - A Programming Language for Spatial Distribution of.pdf:application/pdf}
}


@inproceedings{CoeckeDuncan2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Interacting {Quantum} {Observables}},
	isbn = {978-3-540-70583-3},
	doi = {10.1007/978-3-540-70583-3_25},
	abstract = {We formalise the constructive content of an essential feature of quantum mechanics: the interaction of complementary quantum observables, and information flow mediated by them. Using a general categorical formulation, we show that pairs of mutually unbiased quantum observables form bialgebra-like structures. We also provide an abstract account on the quantum data encoded in complex phases, and prove a normal form theorem for it. Together these enable us to describe all observables of finite dimensional Hilbert space quantum mechanics. The resulting equations suffice to perform computations with elementary quantum gates, translate between distinct quantum computational models, establish the equivalence of entangled quantum states, and simulate quantum algorithms such as the quantum Fourier transform. All these computations moreover happen within an intuitive diagrammatic calculus.},
	language = {en},
	booktitle = {Automata, {Languages} and {Programming}},
	publisher = {Springer},
	author = {Coecke, Bob and Duncan, Ross},
	editor = {Aceto, Luca and Damgård, Ivan and Goldberg, Leslie Ann and Halldórsson, Magnús M. and Ingólfsdóttir, Anna and Walukiewicz, Igor},
	year = {2008},
	keywords = {Bloch Sphere, Classical Point, Classical Structure, Monoidal Structure, Quantum Observable},
	pages = {298--310},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/494QGQPA/Coecke and Duncan - 2008 - Interacting Quantum Observables.pdf:application/pdf}
}


@article{BaezErbele2015,
	title = {Categories in {Control}},
	volume = {30},
	url = {http://arxiv.org/abs/1405.6881},
	abstract = {Control theory uses "signal-flow diagrams" to describe processes where real-valued functions of time are added, multiplied by scalars, differentiated and integrated, duplicated and deleted. These diagrams can be seen as string diagrams for the symmetric monoidal category FinVect\_k of finite-dimensional vector spaces over the field of rational functions k = R(s), where the variable s acts as differentiation and the monoidal structure is direct sum rather than the usual tensor product of vector spaces. For any field k we give a presentation of FinVect\_k in terms of the generators used in signal flow diagrams. A broader class of signal-flow diagrams also includes "caps" and "cups" to model feedback. We show these diagrams can be seen as string diagrams for the symmetric monoidal category FinRel\_k, where objects are still finite-dimensional vector spaces but the morphisms are linear relations. We also give a presentation for FinRel\_k. The relations say, among other things, that the 1-dimensional vector space k has two special commutative dagger-Frobenius structures, such that the multiplication and unit of either one and the comultiplication and counit of the other fit together to form a bimonoid. This sort of structure, but with tensor product replacing direct sum, is familiar from the "ZX-calculus" obeyed by a finite-dimensional Hilbert space with two mutually unbiased bases.},
	number = {24},
	urldate = {2019-11-26},
	journal = {Theory and Applications of Categories},
	author = {Baez, John C. and Erbele, Jason},
	month = may,
	year = {2015},
	note = {arXiv: 1405.6881},
	keywords = {Mathematics - Category Theory, Mathematics - Quantum Algebra, Quantum Physics},
	pages = {836--881},
	file = {arXiv Fulltext PDF:/Users/past/Zotero/storage/RFXKIHB8/Baez and Erbele - 2015 - Categories in Control.pdf:application/pdf;arXiv.org Snapshot:/Users/past/Zotero/storage/D3FBVN7B/1405.html:text/html}
}


@inproceedings{BonchiGaducciKSZ2018,
	address = {New York, NY, USA},
	series = {{LICS} '18},
	title = {Rewriting with {Frobenius}},
	isbn = {978-1-4503-5583-4},
	url = {http://doi.acm.org/10.1145/3209108.3209137},
	doi = {10.1145/3209108.3209137},
	abstract = {Symmetric monoidal categories have become ubiquitous as a formal environment for the analysis of compound systems in a compositional, resource-sensitive manner using the graphical syntax of string diagrams. Recently, reasoning with string diagrams has been implemented concretely via double-pushout (DPO) hypergraph rewriting. The hypergraph representation has the twin advantages of being convenient for mechanisation and of completely absorbing the structural laws of symmetric monoidal categories, leaving just the domain-specific equations explicit in the rewriting system. In many applications across different disciplines (linguistics, concurrency, quantum computation, control theory,...) the structural component appears to be richer than just the symmetric monoidal structure, as it includes one or more Frobenius algebras. In this work we develop a DPO rewriting formalism which is able to absorb multiple Frobenius structures, thus sensibly simplifying diagrammatic reasoning in the aforementioned applications. As a proof of concept, we use our formalism to describe an algorithm which computes the reduced form of a diagram of the theory of interacting bialgebras using a simple rewrite strategy.},
	urldate = {2019-11-21},
	booktitle = {Proceedings of the 33rd {Annual} {ACM}/{IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	publisher = {ACM},
	author = {Bonchi, Filippo and Gadducci, Fabio and Kissinger, Aleks and Sobocinski, Pawel and Zanasi, Fabio},
	year = {2018},
	note = {event-place: Oxford, United Kingdom},
	keywords = {DPO graph rewriting, Frobenius algebra, PROP, symmetric monoidal category},
	pages = {165--174},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/MM24MSPK/Bonchi et al. - 2018 - Rewriting with Frobenius.pdf:application/pdf}
}



@book{RumbaughJacobsenB2004,
	edition = {2nd},
	title = {Unified {Modeling} {Language} {Reference} {Manual}},
	isbn = {978-0-321-71895-2},
	abstract = {“If you are a serious user of UML, there is no other book quite like this one. I have been involved with the UML specification process for some time, but I still found myself learning things while reading through this book-especially on the changes and new capabilities that have come with UML.” ï ï ï ï ï ï ï ï ï -Ed Seidewitz, Chief Architect, IntelliData Technologies CorporationThe latest version of the Unified Modeling Language-UML 2.0-has increased its capabilities as the standard notation for modeling software-intensive systems. Like most standards documents, however, the official UML specification is difficult to read and navigate. In addition, UML 2.0 is far more complex than previous versions, making a thorough reference book more essential than ever.In this significantly updated and expanded edition of the definitive reference to the standard, James Rumbaugh, Ivar Jacobson, and Grady Booch-the UML's creators-clearly and completely describe UML concepts, including major revisions to sequence diagrams, activity models, state machines, components, internal structure of classes and components, and profiles. Whether you are capturing requirements, developing software architectures, designing implementations, or trying to understand existing systems, this is the book for you.Highlights include: Alphabetical dictionary of articles covering every UML concept Integrated summary of UML concepts by diagram type Two-color diagrams with extensive annotations in blue Thorough coverage of both semantics and notation, separated in each article for easy reference Further explanations of concepts whose meaning or purpose is obscure in the original specifications Discussion sections offering usage advice and additional insight into tricky concepts Notation summary, with references to individual articles A hyperlinked version of the book in Adobe Reader format on CD-ROM, an excellent resource for browsing or searching the text for specific information An enhanced online index available on the book's web site allowing readers to quickly and easily search the entire text for specific topicsThe result is an indispensable resource for anyone who needs to understand the inner workings of the industry standard modeling language.},
	publisher = {Addison-Wesley Professional},
	author = {Rumbaugh, James and Jacobson, Ivar and Booch, Grady},
	year = {2004}
}


@inproceedings{Stevens2001,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On {Associations} in the {Unified} {Modelling} {Language}},
	isbn = {978-3-540-45441-0},
	doi = {10.1007/3-540-45441-1_27},
	abstract = {Associations between classifiers are among the most fundamental of UML concepts. However, there is considerable room for disagreement concerning what an association is, semantically. These have implications for the modeller because they can result in serious misunderstandings of static structure diagrams; similarly, they have implications for tool developers. In this paper we describe and classify the variants which have implicitly or explicitly been described. We discuss the scope for, and difficulties in, understanding these as specialisations of a more general notion and we address the implications for future versions of UML.},
	language = {en},
	booktitle = {{UML} 2001 — {The} {Unified} {Modeling} {Language}. {Modeling} {Languages}, {Concepts}, and {Tools}},
	publisher = {Springer},
	author = {Stevens, Perdita},
	editor = {Gogolla, Martin and Kobryn, Cris},
	year = {2001},
	keywords = {Association Class, Class Diagram, Generalization Arrow, Multiple Link, Turing Machine},
	pages = {361--375}
}


@inproceedings{ShroffFrance1997,
	title = {Towards a formalization of {UML} class structures in {Z}},
	doi = {10.1109/CMPSAC.1997.625087},
	abstract = {There is much interest in developing a firm semantic base for object-oriented modeling concepts. By providing precise characterizations of object-oriented (OO) modeling concepts one gains the ability to build a precise OO model of behavior and structure that can be rigorously analyzed. We present the current results of our ongoing formalization of the Unified Modeling Language (UML). UML is a proposed common OO modeling language, thus it is important that it has a formally defined semantic base. The focus of this paper is the formalization of the primary UML constructs used to build class structures. We use the Z notation to precisely express the meaning of UML class structures.},
	booktitle = {Proceedings {Twenty}-{First} {Annual} {International} {Computer} {Software} and {Applications} {Conference} ({COMPSAC}'97)},
	author = {Shroff, M. and France, R.B.},
	month = aug,
	year = {1997},
	note = {ISSN: 0730-3157},
	keywords = {Computer science, formal specification, Logic, modeling language, Object oriented modeling, object-oriented languages, object-oriented methods, object-oriented modeling, OO model, semantic base, Set theory, specification, specification languages, UML class structures, Unified modeling language, Unified Modeling Language, Z language},
	pages = {646--651}
}


@inproceedings{EvansKent1999,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Core {Meta}-{Modelling} {Semantics} of {UML}: {The} {pUML} {Approach}},
	isbn = {978-3-540-46852-3},
	shorttitle = {Core {Meta}-{Modelling} {Semantics} of {UML}},
	doi = {10.1007/3-540-46852-8_11},
	abstract = {The current UML semantics documentation has made a significant step towards providing a precise description of the UML. However, at present the semantic model it proposes only provides a description of the language’s syntax and well-formedness rules. The meaning of the language, which is mainly described in English, is too informal and unstructured to provide a foundation for developing formal analysis and development techniques. Another problem is the scope of the model, which is both complex and large. This paper describes work currently being undertaken by the precise UML group (pUML), an international group of researchers and practitioners, to address these problems. A formalisation strategy is presented which concentrates on giving a precise denotational semantics to core elements of UML. This is illustrated through the development of precise definitions of two important concepts: generalization and packages. Finally, a viewpoint architecture is proposed as a means of providing improved separation of concerns in the semantics definition.},
	language = {en},
	booktitle = {«{UML}»’99 — {The} {Unified} {Modeling} {Language}},
	publisher = {Springer},
	author = {Evans, Andy and Kent, Stuart},
	editor = {France, Robert and Rumpe, Bernhard},
	year = {1999},
	keywords = {Denotational Semantic, Object Constraint Language, Object Constraint Language Constraint, Object Constraint Language Expression, Package Instance},
	pages = {140--155},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/MIFPXSZN/Evans and Kent - 1999 - Core Meta-Modelling Semantics of UML The pUML App.pdf:application/pdf}
}



@book{EhrigErmelGH2015,
	address = {Berlin Heidelberg},
	series = {Monographs in {Theoretical} {Computer} {Science}. {An} {EATCS} {Series}},
	title = {Graph and {Model} {Transformation}: {General} {Framework} and {Applications}},
	isbn = {978-3-662-47979-7},
	shorttitle = {Graph and {Model} {Transformation}},
	url = {https://www.springer.com/gp/book/9783662479797},
	abstract = {This book is a comprehensive explanation of graph and model transformation. It contains a detailed introduction, including basic results and applications of the algebraic theory of graph transformations, and references to the historical context. Then in the main part the book contains detailed chapters on M-adhesive categories, M-adhesive transformation systems, and multi-amalgamated transformations, and model transformation based on triple graph grammars. In the final part of the book the authors examine application of the techniques in various domains, including chapters on case studies and tool support. The book will be of interest to researchers and practitioners in the areas of theoretical computer science, software engineering, concurrent and distributed systems, and visual modelling.},
	language = {en},
	urldate = {2020-01-16},
	publisher = {Springer-Verlag},
	author = {Ehrig, Hartmut and Ermel, Claudia and Golas, Ulrike and Hermann, Frank},
	year = {2015},
	doi = {10.1007/978-3-662-47980-3},
	file = {Snapshot:/Users/past/Zotero/storage/8SWITFAN/9783662479797.html:text/html}
}



@inproceedings{Heindel2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Hereditary {Pushouts} {Reconsidered}},
	isbn = {978-3-642-15928-2},
	doi = {10.1007/978-3-642-15928-2_17},
	abstract = {The introduction of adhesive categories revived interest in the study of properties of pushouts with respect to pullbacks, which started over thirty years ago in the category of graphs. Adhesive categories provide a single property of pushouts that suffices to derive lemmas that are essential for central theorems of double pushout rewriting such as the local Church-Rosser Theorem.The present paper shows that the same lemmas already hold for pushouts that are hereditary, i.e. those pushouts that remain pushouts when they are embedded into the associated category of partial maps. Hereditary pushouts – a twenty year old concept – induce a generalization of adhesive categories, which will be dubbed partial map adhesive. An application relevant category that does not fit the framework of adhesive categories and its variations in the literature will serve as an illustrating example of a partial map adhesive category.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer},
	author = {Heindel, Tobias},
	editor = {Ehrig, Hartmut and Rensink, Arend and Rozenberg, Grzegorz and Schürr, Andy},
	year = {2010},
	keywords = {Graph Transformation, Simple Graph, Admissible Class, Central Theorem, Graph Functor},
	pages = {250--265}
}


@inproceedings{KosiolFritscheST2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adhesive {Subcategories} of {Functor} {Categories} with {Instantiation} to {Partial} {Triple} {Graphs}},
	isbn = {978-3-030-23611-3},
	abstract = {Synchronization and integration processes of correlated models that are formally based on triple graph grammars often suffer from the fact that elements are unnecessarily deleted and recreated losing information in the process. It has been shown that this undesirable loss of information can be softened by allowing partial correspondence morphisms in triple graphs. We provide a formal framework for this new synchronization process by introducing the category 𝐏𝐓𝐫𝐆PTrG{\textbackslash}mathbf \{PTrG\} of partial triple graphs and proving it to be adhesive. This allows for ordinary double pushout rewriting of partial triple graphs. To exhibit 𝐏𝐓𝐫𝐆PTrG{\textbackslash}mathbf \{PTrG\} as an adhesive category, we present a fundamental construction of subcategories of functor categories and show that these are adhesive HLR if the base category already is. Secondly, we consider an instantiation of this framework by triple graphs to illustrate its practical relevance and to have a concrete example at hand.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {Kosiol, Jens and Fritsche, Lars and Schürr, Andy and Taentzer, Gabriele},
	editor = {Guerra, Esther and Orejas, Fernando},
	year = {2019},
	keywords = {Triple graphs, Adhesiveness, Double pushout rewriting, Functor category},
	pages = {38--54},
	doi = {10.1007/978-3-030-23611-3_3}
}


@misc{SchultzSpivakVW2016,
      title={Algebraic Databases}, 
      author={Patrick Schultz and David I. Spivak and Christina Vasilakopoulou and Ryan Wisnesky},
      year={2016},
      eprint={1602.03501},
      archivePrefix={arXiv},
      primaryClass={math.CT}
}


@incollection{Burmeister1993,
  doi = {10.1007/978-94-017-0697-1_1},
  year = {1993},
  publisher = {Springer Netherlands},
  pages = {1--70},
  author = {Peter Burmeister},
  title = {Partial Algebras {\textemdash} An Introductory Survey},
  booktitle = {Algebras and Orders}
}

@phdthesis{Lawvere1963,
	type = {{PhD} {Thesis}},
	title = {Functorial {Semantics} of {Algebraic} {Theories}},
	url = {http://www.tac.mta.ca/tac/reprints/articles/5/tr5abs.html},
	school = {Columbia University},
	author = {Lawvere, F. William},
	year = {1963}
}


@inproceedings{LellahiSpyratos1991,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards a categorical data model supporting structured objects and inheritance},
	isbn = {978-3-540-47444-9},
	doi = {10.1007/3-540-54141-1_6},
	abstract = {We propose a data model in which the data scheme, the data domain and the database are defined using the concepts of graph, category and diagram, respectively, and in which the limit of a diagram plays an essential role. Our model incorporates important concepts of known database models (such as structured objects and inheritance) and provides new insights into these models.},
	language = {en},
	booktitle = {Next {Generation} {Information} {System} {Technology}},
	publisher = {Springer},
	author = {Lellahi, S. K. and Spyratos, N.},
	editor = {Schmidt, Joachim W. and Stogny, Anatoly A.},
	year = {1991},
	pages = {86--105},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/UGWUXY8A/Lellahi and Spyratos - 1991 - Towards a categorical data model supporting struct.pdf:application/pdf}
}


@inproceedings{DiskinCadish1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Variable sets and functions framework for conceptual modeling: {Integrating} {ER} and {OO} via sketches with dynamic markers},
	isbn = {978-3-540-48527-8},
	shorttitle = {Variable sets and functions framework for conceptual modeling},
	doi = {10.1007/BFb0020535},
	abstract = {In the paper a graph-based specification language for semantic modeling is proposed. It is as handy as conventional graphical languages but, in contrast to them, possesses a precisely formalized semantics based on certain ideas of the mathematical category theory. In particular, it provides mathematically correct semantics for formerly somewhat mythical notions of object identity and weak entity type. Among other benefits of the approach there are provable (!) universality w.r.to simulation of any other formal data specification, flexibility and unification in treating various kinds of associations and relationships, precise semantic basis for the familiar distinguishing between the specialization and generalization ISA-relationships, intrinsic object-orientedness.},
	language = {en},
	booktitle = {{OOER} '95: {Object}-{Oriented} and {Entity}-{Relationship} {Modeling}},
	publisher = {Springer},
	author = {Diskin, Zinovy and Cadish, Boris},
	editor = {Papazoglou, Michael P.},
	year = {1995},
	keywords = {Categorical Logic, Object Identity, Semantic Modeling, Semantic Schema, State Transition Mapping},
	pages = {226--237},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/7QFV3C46/Diskin and Cadish - 1995 - Variable sets and functions framework for conceptu.pdf:application/pdf}
}


@inproceedings{CadishDiskin1996,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Heterogeneous view integration via sketches and equations},
	isbn = {978-3-540-68440-4},
	doi = {10.1007/3-540-61286-6_184},
	abstract = {In the paper a new approach to semantic modeling and view integration is proposed. The underlying data model is graph-based yet completely formalized so that graphical schemas themselves are precise specifications suitable for implementation: the approach is an adaptation of a familiar in the mathematical category theory specification framework based on the so called sketches. On this ground, a procedure of automated view integration is developed. Its distinctive feature consists in specifying correspondence between different views (on the same universe of discourse) by equations that reduces the integration task to a sequence of formal algebraic procedures.},
	language = {en},
	booktitle = {Foundations of {Intelligent} {Systems}},
	publisher = {Springer},
	author = {Cadish, Boris and Diskin, Zinovy},
	editor = {Raś, Zbigniew W. and Michalewicz, Maciek},
	year = {1996},
	keywords = {Graphical Schema, Local Schema, Semantic Modeling, Semantic Schema, View Integration},
	pages = {603--612},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/3BDAM6KV/Cadish and Diskin - 1996 - Heterogeneous view integration via sketches and eq.pdf:application/pdf}
}

@misc{MicroservicesFowler,
author = {Fowler, Martin and Lewis, James},
title = {Microservices: a definition of this new architectural term},
howpublished={\url{https://martinfowler.com/articles/microservices.html}, Last Accessed: 07.02.2020},
urldate = {2020-02-07},
year = {2014},
month = mar
}
@misc{FallaciesDeutsch,
author = {Deutsch, Peter and Gosling, James},
title = {The fallacies of distributed computing},
year = {1997},
howpublished={Communicated via Sun Microsystems Web Blog}
}


@inproceedings{FrancescoMalavoltaL2017,
	title = {Research on {Architecting} {Microservices}: {Trends}, {Focus}, and {Potential} for {Industrial} {Adoption}},
	shorttitle = {Research on {Architecting} {Microservices}},
	doi = {10.1109/ICSA.2017.24},
	abstract = {Microservices are a new trend rising fast from the enterprise world. Even though the design principles around microservices have been identified, it is difficult to have a clear view of existing research solutions for architecting microservices. In this paper we apply the systematic mapping study methodology to identify, classify, and evaluate the current state of the art on architecting microservices from the following three perspectives: publication trends, focus of research, and potential for industrial adoption. More specifically, we systematically define a classification framework for categorizing the research on architecting microservices and we rigorously apply it to the 71 selected studies. We synthesize the obtained data and produce a clear overview of the state of the art. This gives a solid basis to plan for future research and applications of architecting microservices.},
	booktitle = {{ICSA} 2017},
	author = {Francesco, Paolo Di and Malavolta, Ivano and Lago, Patricia},
	month = apr,
	year = {2017},
	keywords = {Architecture, Computer architecture, Data mining, enterprise world, industrial adoption, Market research, microservices, Microservices, Service-oriented architecture, software architecture, Software Architecture, systematic mapping, Systematic Mapping Study, Systematics},
	pages = {21--30},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/4MXQLFES/7930195.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/ZZDSCC8S/Francesco et al. - 2017 - Research on Architecting Microservices Trends, Fo.pdf:application/pdf}
}


@inproceedings{AgarwalLakshmi2019,
	address = {Tokyo, Japan},
	title = {Cost {Aware} {Resource} {Sizing} and {Scaling} of {Microservices}},
	isbn = {978-1-4503-7241-1},
	doi = {10.1145/3361821.3361823},
	abstract = {Microservices are small, independent, loosely coupled components which provide flexibility, agility, and scalability to an application. While these are aimed for scalability, achieving it needs judicious trade-offs between size, number and cost of provisioning. In this architecture, sizing in both homogeneous and heterogeneous resources plays a key role to balance application performance and resource requirement, as workload demand varies. This paper provides insights where the importance of considering workload characterization to decide a homogeneous or heterogeneous scaling strategy for a microservice is discussed. The work exploits the correlation of workload characterization, predicted workload demand and selection of right-sized microservice to minimize resource costs. Size of microservice is referred with respect to the amount of resources allocated to the microservice. This work also evaluates trade-offs between considering the entire predicted workload demand for resource cost optimization against algorithmic computational complexity and designs a heuristic to reduce such complexity. Evaluation of results demonstrate two important outcomes. Firstly, workload characterization helps to choose between homogeneous or heterogeneous sizing for different microservices. And secondly, by considering workload demand prediction beyond the current scheduling interval, allows to make scaling decision in the current cycle keeping in view whether the demand is going to increase or decrease. The paper also details on how to use the insights of application characterization and workload trend for choosing an appropriate scaling strategy.},
	urldate = {2020-02-07},
	booktitle = {{CCIOT} 2019},
	publisher = {ACM},
	author = {Agarwal, Preyashi and Lakshmi, J.},
	month = sep,
	year = {2019},
	keywords = {Container Sizing, Microservices, Resource Optimization, Scalability, Workload Characterization},
	pages = {66--74}
}


@inproceedings{AlshuqayranAliE2016,
	title = {A {Systematic} {Mapping} {Study} in {Microservice} {Architecture}},
	doi = {10.1109/SOCA.2016.15},
	abstract = {The accelerating progress of network speed, reliability and security creates an increasing demand to move software and services from being stored and processed locally on users' machines to being managed by third parties that are accessible through the network. This has created the need to develop new software development methods and software architectural styles that meet these new demands. One such example in software architectural design is the recent emergence of the microservices architecture to address the maintenance and scalability demands of online service providers. As microservice architecture is a new research area, the need for a systematic mapping study is crucial in order to summarise the progress so far and identify the gaps and requirements for future studies. In this paper we present a systematic mapping study of microservices architectures and their implementation. Our study focuses on identifying architectural challenges, the architectural diagrams/views and quality attributes related to microsevice systems.},
	booktitle = {{SOCA} 2016},
	author = {Alshuqayran, Nuha and Ali, Nour and Evans, Roger},
	month = nov,
	year = {2016},
	keywords = {architectural diagrams, architectural views, Business, Computer architecture, Conferences, microservice architecture, microsevice systems, online service providers, quality attributes, Security, service-oriented architecture, Service-oriented architecture, software architectural design, software architectural styles, software development, systematic mapping, Systematics},
	pages = {44--51}
}


@incollection{DragoniGiallorenzoLMMMS2017,
	address = {Cham},
	title = {Microservices: {Yesterday}, {Today}, and {Tomorrow}},
	isbn = {978-3-319-67425-4},
	shorttitle = {Microservices},
	url = {https://doi.org/10.1007/978-3-319-67425-4_12},
	abstract = {Microservices is an architectural style inspired by service-oriented computing that has recently started gaining popularity. Before presenting the current state of the art in the field, this chapter reviews the history of software architecture, the reasons that led to the diffusion of objects and services first, and microservices later. Finally, open problems and future challenges are introduced. This survey primarily addresses newcomers to the discipline, while offering an academic viewpoint on the topic. In addition, we investigate some practical issues and point out a few potential solutions.},
	language = {en},
	urldate = {2020-02-07},
	booktitle = {Present and {Ulterior} {Software} {Engineering}},
	publisher = {Springer International Publishing},
	author = {Dragoni, Nicola and Giallorenzo, Saverio and Lafuente, Alberto Lluch and Mazzara, Manuel and Montesi, Fabrizio and Mustafin, Ruslan and Safina, Larisa},
	editor = {Mazzara, Manuel and Meyer, Bertrand},
	year = {2017},
	doi = {10.1007/978-3-319-67425-4_12},
	pages = {195--216},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/BGI86PT5/Dragoni et al. - 2017 - Microservices Yesterday, Today, and Tomorrow.pdf:application/pdf}
}


@book{TanenbaumSteen2007,
	title = {Distributed {Systems}: {Principles} and {Paradigms}},
	isbn = {978-0-13-239227-3},
	shorttitle = {Distributed {Systems}},
	abstract = {Virtually every computing system today is part of a distributed system. Programmers, developers, and engineers need to understand the underlying principles and paradigms as well as the real-world application of those principles. Now, internationally renowned expert Andrew S. Tanenbaum – with colleague Martin van Steen – presents a complete introduction that identifies the seven key principles of distributed systems, with extensive examples of each.   Adds a completely new chapter on architecture to address the principle of organizing distributed systems. Provides extensive new material on peer-to-peer systems, grid computing and Web services, virtualization, and application-level multicasting. Updates material on clock synchronization, data-centric consistency, object-based distributed systems, and file systems and Web systems coordination.   For all developers, software engineers, and architects who need an in-depth understanding of distributed systems.},
	language = {en},
	publisher = {Pearson Prentice Hall},
	author = {Tanenbaum, Andrew S. and Steen, Maarten van},
	year = {2007},
	keywords = {Computers / Client-Server Computing}
}

@misc{apolloFederation,
howpublished = {\url{https://www.apollographql.com/docs/federation/}, Last Accessed: 07.02.2020},
title = {Apollo Federation overview},
author = {Meteor Development Group Inc.},
year = {2021}
}



@inproceedings{CicchettiDiRuscioEP2011,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{JTL}: {A} {Bidirectional} and {Change} {Propagating} {Transformation} {Language}},
	isbn = {978-3-642-19440-5},
	shorttitle = {{JTL}},
	abstract = {In Model Driven Engineering bidirectional transformations are considered a core ingredient for managing both the consistency and synchronization of two or more related models. However, while non-bijectivity in bidirectional transformations is considered relevant, current languages still lack of a common understanding of its semantic implications hampering their applicability in practice.In this paper, the Janus Transformation Language (JTL) is presented, a bidirectional model transformation language specifically designed to support non-bijective transformations and change propagation. In particular, the language propagates changes occurring in a model to one or more related models according to the specified transformation regardless of the transformation direction. Additionally, whenever manual modifications let a model be non reachable anymore by a transformation, the closest model which approximate the ideal source one is inferred. The language semantics is also presented and its expressivity and applicability are validated against a reference benchmark. JTL is embedded in a framework available on the Eclipse platform which aims to facilitate the use of the approach, especially in the definition of model transformations.},
	language = {en},
	booktitle = {SLE 2011},
	publisher = {Springer Berlin Heidelberg},
	author = {Cicchetti, Antonio and Di Ruscio, Davide and Eramo, Romina and Pierantonio, Alfonso},
	editor = {Malloy, Brian and Staab, Steffen and van den Brand, Mark},
	year = {2011},
	keywords = {Model Transformation, Source Model, State Machine, Target Model, Trace Link},
	pages = {183--202},
	doi = {10.1007/978-3-642-19440-5_11}
}


@book{RusselNorvig2010,
	title = {Artificial {Intelligence}: {A} {Modern} {Approach}},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial {Intelligence}},
	abstract = {Artificial Intelligence: A Modern Approach, 3e offers the most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence. Number one in its field, this textbook is ideal for one or two-semester, undergraduate or graduate-level courses in Artificial Intelligence.   Dr. Peter Norvig, contributing Artificial Intelligence author and Professor Sebastian Thrun, a Pearson author are offering a free online course at Stanford University on artificial intelligence.    According to an article in  The New York Times , the course on artificial intelligence is “one of three being offered experimentally by the Stanford computer science department to extend technology knowledge and skills beyond this elite campus to the entire world.” One of the other two courses, an introduction to database software, is being taught by Pearson author Dr. Jennifer Widom.     Artificial Intelligence: A Modern Approach, 3e is available to purchase as an eText for your Kindle™, NOOK™, and the iPhone®/iPad®.    To learn more about the course on artificial intelligence, visit http://www.ai-class.com. To read the full New York Times article, click here.},
	language = {en},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter},
	year = {2010},
	keywords = {Computers / Intelligence (AI) \& Semantics}
}



@book{GoldBernsteinRuh2005,
	title = {Enterprise {Integration}: {The} {Essential} {Guide} to {Integration} {Solutions}},
	isbn = {978-0-321-22390-6},
	shorttitle = {Enterprise {Integration}},
	abstract = {“The book’s use of real-world case study vignettes really does go to the heart of the subject matter. This stuff is real, it has real applicability to real problems, and, as with most things in life, it shows how it all comes down to real money in the final analysis. This book shows you what your peers are doing to drive costs out of integration projects and to build new applications without re-inventing the entire wheel—just a few new spokes and off you go. This is a good book. Read it.”      —Peter Rhys Jenkins, Complex Systems Architect, Candle Corporation “When you get two long-term, acknowledged experts on integration and interoperability together to lay out the current state of the IT universe you expect an immediate return on investment—and this book delivers. It’s common knowledge that 90\% of total software lifecycle cost is in maintenance and integration, and that needs to drive IT decision-making. With comprehensive coverage of the integration technology landscape, and clear case studies presented at every turn, this book belongs on every IT manager’s, every system architect’s, and every software developer’s bookshelf.”      —Richard Mark Soley, chairman and CEO, Object Management Group “Today’s myriad of integration technologies and alternatives can be daunting. This book presents a framework and process for the evaluation, design, and selection of the appropriate integration technologies to meet your strategic business needs. You will find the templates a particularly useful mechanism to jump-start documentation and drive your decision-making process.”      —Ron Zahavi, CIO, Global Business Transformation, Unisys Global Transformation Team; author of Enterprise Application Integration with CORBA “It is refreshing to read a book that presents a good business approach to the integration challenge facing most business leaders today, while at the same time educating them about the major components of the required technologies and management practices changes required. The narrative, examples, and templates establish a common reference point between the business and the technology organizations. A must-read for senior business leaders challenged with the complexities of business integration, as well as Senior IT Leaders challenged with shrinking budgets and lower tolerances for failures.”      —Chuck Papageorgiou, managing partner, Ideasphere “Integration has, and will continue to be, one of the success indicators of any enterprise project. Failing to understand the nuances of integration is a critical mistake managers cannot afford to make.”      —Marcia Robinson, author of Services Blueprint: Roadmap for Execution “A much-needed book; it ties together the business and technology aspects of information system implementation, emphasizing best practices for really getting things done. I believe that both the technical and business communities will benefit from the in-depth material provided in this book.”      —Dr. Barry Horowitz, professor of systems and information engineering, University of Virginia (former CEO, Mitre Corporation) Integration of applications, information, and business process has become today’s \#1 IT investment priority. Most enterprise integration books simply explain the technology. This one shows exactly how to apply it. It’s a step-by-step roadmap for your entire project—from the earliest exploratory stages through analysis, design, architecture, and implementation. Renowned enterprise integration experts Beth Gold-Bernstein and William Ruh present best practices and case studies that bring their methodology to life. They address every stage from the decision-maker’s and implementer’s point of view—showing how to align business requirements to specific solutions, systematically reduce risk, and maximize ROI throughout the entire lifecycle. Coverage includes:  Supporting strategies, tactics, and business planning: enterprise integration from the business perspective Defining realistic project success indicators and metrics Establishing integration architectures: supporting near-term needs while building reusable infrastructure services for the long-term Adopting metadata architecture and standards Implementing four essential implementation patterns: application, information, composite, and process integration Understanding service integration and implementing service-oriented architectures Providing organizational structure and governance to support effective integration  The authors provide detailed plans and specification templates for application integration projects—both in the book and on the CD-ROM. These projects include identifying business drivers and requirements; establishing strategy; and integrating services, information, process, and applications. Enterprise Integration was written for every member of the integration team: business and IT leaders, strategists, architects, project managers, and technical staff. Regardless of your role, you’ll discover where you fit, what to do, and how to drive maximum business value from your next integration project.},
	language = {en},
	publisher = {Addison-Wesley},
	author = {Gold-Bernstein, Beth and Ruh, William A.},
	year = {2005},
	note = {Google-Books-ID: 0fjFQgAACAAJ},
	keywords = {Business \& Economics / Information Management, Computers / Management Information Systems}
}

@MastersThesis{vonBargen2020,
    author     =     {von Bargen, Ole Christoph},
    title     =     {{Integration of Web Services and their data models with special regard to GraphQL}},
    school     =     {H{\o}gskulen p{\r{a}} Vestlandet},
    address     =     {Bergen, Norway},
    year     =     {2020},
    url = {https://gitlab.com/olevonbargen/graphqlintegrator/-/blob/master/thesis/Integration_of_Web_Services_and_their_data_models_with_special_regard_to_GraphQL.pdf}
 }


@book{Evans2003,
	address = {Boston},
	edition = {First edition},
	title = {Domain-{Driven} {Design}: {Tackling} {Complexity} in the {Heart} of {Software}},
	isbn = {978-0-321-12521-7},
	shorttitle = {Domain-{Driven} {Design}},
	language = {English},
	publisher = {Addison-Wesley Professional},
	author = {Evans, Eric},
	month = aug,
	year = {2003}
}


@article{DeursenKlint2004,
	title = {Domain-{Specific} {Language} {Design} {Requires} {Feature} {Descriptions}},
	volume = {10},
	copyright = {Copyright (c) 2016 CIT. Journal of Computing and Information Technology},
	issn = {1846-3908},
	doi = {10.2498/cit.2002.01.01},
	abstract = {A domain-specific language (DSL) provides a notation tailored towards an application domain and is based on the relevant concepts and features of that domain. As such, a DSL is a means to describe and generate members of a family of programs in the domain. A prerequisite for the design of a DSL is a detailed analysis and structuring of the application domain. Graphical feature diagrams have been proposed to organize the dependencies between such features, and to indicate which ones are common to all family members and which ones vary. In this paper, we study feature diagrams in more details, as well as their relationship to domain-specific languages. We propose the Feature Description Language (FDL), a textual language to describe features. We explore automated manipulation of feature descriptions such as normalization, expansion to disjunctive normal form, variability computation and constraint satisfaction. Feature descriptions can be directly mapped to UML diagrams which in their turn can be used for Java code generation. The value of FDL is assessed via a case study in the use and expressiveness of feature descriptions for the area of documentation generators.},
	language = {en-US},
	number = {1},
	urldate = {2020-02-12},
	journal = {CIT. Journal of Computing and Information Technology},
	author = {Deursen, Arie van and Klint, Paul},
	month = oct,
	year = {2004},
	pages = {1--17},
	file = {Full Text PDF:/Users/past/Zotero/storage/YIQZB9KQ/Deursen and Klint - 2004 - Domain-Specific Language Design Requires Feature D.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/2VRP9MS5/1465.html:text/html}
}



@article{DingelDiskinZ2008,
	title = {Understanding and improving {UML} package merge},
	volume = {7},
	issn = {1619-1374},
	doi = {10.1007/s10270-007-0073-9},
	abstract = {Package merge allows the content of one package to be combined with that of another package. Package merge is used extensively in the UML 2 specification to modularize the definition of the UML 2 meta model and to define the four compliance levels of UML 2. Package merge is a novel construct in UML and currently not well understood. This paper summarizes our work to understand and improve package merge. First, we identify ambiguous and missing rules in the package merge definition and suggest corrections. Then, we formalize package merge and analyze it with respect to some desirable properties. Our analyses employs Alloy, a first-order modelling language with tool support, and concepts from mathematical logic which allow us to develop a general taxonomy of package extension mechanisms. The analyses reveal the unexpected failure of important properties.},
	language = {en},
	number = {4},
	journal = {Software \& Systems Modeling},
	author = {Dingel, J. and Diskin, Z. and Zito, A.},
	month = oct,
	year = {2008},
	keywords = {UML, Metamodeling techniques, Model composition, Semantics formalization},
	pages = {443--467}
}



@inproceedings{KlareGleitze2019,
	title = {Commonalities for {Preserving} {Consistency} of {Multiple} {Models}},
	doi = {10.1109/MODELS-C.2019.00058},
	abstract = {Models are used to describe different properties of a software system. Those models often share information that is represented redundantly and, thus, has to be kept consistent. Defining model transformations between the involved metamodels is a common means to preserve the consistency of their instances. Such transformations specify the relations between instances of metamodels and how to enforce them. However, redundancies are often caused by different models containing representations of the same concept. We propose to make such common, duplicated concepts explicit instead of encoding them in transformations implicitly. We achieve this by defining an additional concept metamodel and the relations between it and the existing metamodels, which we call the Commonalities approach. We describe a language that allows to define both a concept metamodel and its relations to existing metamodels in one place, in order to achieve conciseness comparable to a direct transformation between the metamodels. Additionally, our approach allows hierarchical composition of concept metamodels to keep multiple models consistent. The expected benefits of our approach are an improved understandability of relations between metamodels by making the information about commonalities explicit, reduced errors in comparison to the combination of several transformations to keep multiple models consistent, and improved reusability because metamodels are not related directly, but only through concept metamodels.},
	booktitle = {{MODELS} 2019 Companion},
	author = {Klare, Heiko and Gleitze, Joshua},
	month = sep,
	year = {2019},
	keywords = {commonalities approach, concept metamodel, direct transformation, duplicated concepts, formal specification, model consistency, model transformation, multidirectional transformation, commonalities, model transformations, mproved reusability, preserving consistency, program verification, simulation languages, software reusability, software system},
	pages = {371--378},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/DYS4CSYY/8904619.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/F46X67GS/Klare and Gleitze - 2019 - Commonalities for Preserving Consistency of Multip.pdf:application/pdf}
}



@article{HeXu2014,
	title = {Integration of {Distributed} {Enterprise} {Applications}: {A} {Survey}},
	volume = {10},
	issn = {1941-0050},
	shorttitle = {Integration of {Distributed} {Enterprise} {Applications}},
	doi = {10.1109/TII.2012.2189221},
	abstract = {Many industrial enterprises acquire disparate systems and applications over the years. The need to integrate these different systems and applications is often prominent for satisfying business requirements and needs. In an effort to help researchers in industrial informatics understand the state-of-the-art of the enterprise application integration, we examined the architectures and technologies for integrating distributed enterprise applications, illustrated their strengths and weaknesses, and identified research trends and opportunities in this increasingly important area.},
	number = {1},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {He, Wu and Xu, Li Da},
	month = feb,
	year = {2014},
	keywords = {Business, business communication, business data processing, Computer architecture, distributed enterprise applications, Distributed enterprise applications, enterprise application integration, enterprise service bus, enterprise systems, industrial enterprises, industrial informatics, industrial information integration engineering, Industries, Internet of Things, Internet of things (IoT), IoT, Java, middleware, Protocols, radio frequency identification (RFID), Web services},
	pages = {35--42},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/UPDZJTPL/6165353.html:text/html}
}


@article{DustdarSchreiner2005,
	title = {A survey on web services composition},
	volume = {1},
	issn = {1741-1106},
	url = {https://doi.org/10.1504/IJWGS.2005.007545},
	doi = {10.1504/IJWGS.2005.007545},
	abstract = {Due to the web services' heterogeneous nature, which stems from the definition of several XML-based standards to overcome platform and language dependence, web services have become an emerging and promising technology to design and build complex inter-enterprise business applications out of single web-based software components. To establish the existence of a global component market, in order to enforce extensive software reuse, service composition experienced increasing interest in doing a lot of research effort. This paper discusses the urgent need for service composition, the required technologies to perform service composition. It also presents several different composition strategies, based on some currently existing composition platforms and frameworks, re-presenting first implementations of state-of the-art technologies, and gives an outlook to essential future research work.},
	number = {1},
	urldate = {2020-02-13},
	journal = {International Journal of Web and Grid Services},
	author = {Dustdar, Schahram and Schreiner, Wolfgang},
	month = aug,
	year = {2005},
	keywords = {context, conversation modelling, coordination protocols, quality of service, service composition, service execution, transactions, web services},
	pages = {1--30},
	file = {Submitted Version:/Users/past/Zotero/storage/KTR6A53P/Dustdar and Schreiner - 2005 - A survey on web services composition.pdf:application/pdf}
}



@book{Richards2015,
	address = {1005 Gravenstein Highway North, Sebastopol, CA 95472.},
	edition = {First Edition},
	title = {Microservices vs. {Service}-{Oriented} {Architecture}},
	publisher = {O’Reilly Media, Inc},
	author = {Richards, Mark},
	month = nov,
	year = {2015}
}


@article{CernyDonahooT2018,
	title = {Contextual understanding of microservice architecture: current and future directions},
	volume = {17},
	issn = {1559-6915},
	shorttitle = {Contextual understanding of microservice architecture},
	doi = {10.1145/3183628.3183631},
	abstract = {Current industry trends in enterprise architectures indicate movement from Service-Oriented Architecture (SOA) to Microservices. By understanding the key differences between these two approaches and their features, we can design a more effective Microservice architecture by avoiding SOA pitfalls. To do this, we must know why this shift is happening and how key SOA functionality is addressed by key features of the Microservice-based system. Unfortunately, Microservices do not address all SOA shortcomings. In addition, Microservices introduce new challenges. This work provides a detailed analysis of the differences between these two architectures and their features. Next, we describe both research and industry perspectives on the strengths and weaknesses of both architectural directions. Finally, we perform a systematic mapping study related to Microservice research, identifying interest and challenges in multiple categories from a range of recent research.},
	number = {4},
	urldate = {2020-02-13},
	journal = {ACM SIGAPP Applied Computing Review},
	author = {Cerny, Tomas and Donahoo, Michael J. and Trnka, Michal},
	month = jan,
	year = {2018},
	keywords = {architectures, microservices, self-contained systems, SOA, survey, systematic mapping study},
	pages = {29--45}
}


@book{Josuttis2007,
	title = {{SOA} in {Practice}},
	isbn = {978-0-596-52955-0},
	abstract = {This book demonstrates service-oriented architecture (SOA) as a concrete discipline rather than a hopeful collection of cloud charts. Built upon the author's firsthand experience rolling out a SOA at a major corporation, SOA in Practice explains how SOA can simplify the creation and maintenance of large-scale applications. Whether your project involves a large set of Web Services-based components, or connects legacy applications to modern business processes, this book clarifies how -- and whether -- SOA fits your needs.    SOA has been a vision for years. This book brings it down to earth by describing the real-world problems of implementing and running a SOA in practice. After defining SOA's many facets, examining typical use patterns, and exploring how loose coupling helps build stronger applications, SOA in Practice presents a framework to help you determine when to take advantage of SOA. In this book you will:  Focus squarely on real deployment and technology, not just standards maps Examine business problems to determine which ones fit a SOA approach before plastering a SOA solution on top of them Find clear paths for building solutions without getting trapped in the mire of changing web services details Gain the experience of a systems analyst intimately involved with SOA  "The principles and experiences described in this book played an important role in making SOA at T-Mobile a success story, with more than 10 million service calls per day."    --Dr. Steffen Roehn, Member of the Executive Committee T-Mobile International (CIO)    "Nicolai Josuttis has produced something that is rare in the over-hyped world of SOA; a thoughtful work with deep insights based on hands-on experiences. This book is a significant milestone in promoting practical disciplines for all SOA practitioners."    --John Schmidt, Chairman, Integration Consortium    "The book belongs in the hands of every CIO, IT Director and IT planning manager."    --Dr. Richard Mark Soley, Chairman and CEO, Object Management Group; Executive Director, SOA Consortium},
	language = {en},
	publisher = {"O'Reilly Media, Inc."},
	author = {Josuttis, Nicolai M.},
	year = {2007},
	keywords = {Computers / Enterprise Applications / General, Computers / Networking / General, Computers / Software Development \& Engineering / General, Computers / Systems Architecture / General}
}


@book{DoanHalevyI2012,
	title = {Principles of {Data} {Integration}},
	isbn = {978-0-12-391479-8},
	abstract = {Principles of Data Integration is the first comprehensive textbook of data integration, covering theoretical principles and implementation issues as well as current challenges raised by the semantic web and cloud computing. The book offers a range of data integration solutions enabling you to focus on what is most relevant to the problem at hand. Readers will also learn how to build their own algorithms and implement their own data integration application. Written by three of the most respected experts in the field, this book provides an extensive introduction to the theory and concepts underlying today's data integration techniques, with detailed, instruction for their application using concrete examples throughout to explain the concepts. This text is an ideal resource for database practitioners in industry, including data warehouse engineers, database system designers, data architects/enterprise architects, database researchers, statisticians, and data analysts; students in data analytics and knowledge discovery; and other data professionals working at the R\&D and implementation levels.Offers a range of data integration solutions enabling you to focus on what is most relevant to the problem at handEnables you to build your own algorithms and implement your own data integration applications},
	language = {en},
	publisher = {Elsevier},
	author = {Doan, AnHai and Halevy, Alon and Ives, Zachary},
	month = jun,
	year = {2012},
	keywords = {Computers / Data Processing, Computers / Databases / General}
}


@article{MukhiyaRabbiIRY2019,
	series = {The 10th {International} {Conference} on {Emerging} {Ubiquitous} {Systems} and {Pervasive} {Networks} ({EUSPN}-2019) / {The} 9th {International} {Conference} on {Current} and {Future} {Trends} of {Information} and {Communication} {Technologies} in {Healthcare} ({ICTH}-2019) / {Affiliated} {Workshops}},
	title = {A {GraphQL} approach to {Healthcare} {Information} {Exchange} with {HL7} {FHIR}},
	volume = {160},
	issn = {1877-0509},
	doi = {10.1016/j.procs.2019.11.082},
	abstract = {Interoperability is accepted as a fundamental necessity for the successful realization of Healthcare Information Systems. It can be achieved by utilizing consistent standards defining syntactic and semantic meaning of the information being exchanged. HL7 FHIR is one of such open standards for Health Information Exchange (HIE). While HL7 FHIR supports Representational State Transfer (REST) architecture and Service-oriented Architecture (SOA) for seamless information exchange, it inherits the inflexibility and complexity associated with the RESTful approach. GraphQL is a query language developed by Facebook that provides promising techniques to overcome these issues. In this paper, we exploit the use of GraphQL and HL7 FHIR for HIE; present an algorithm to map HL7 FHIR resources to a GraphQL schema, and created a prototype implementation of the approach and compare it with a RESTful approach. Our experimental results indicate that the combination of GraphQL and HL7 FHIR-based web APIs for HIE is performant, cost-effective, scalable and flexible to meet web and mobile clients requirements.},
	language = {en},
	urldate = {2020-02-07},
	journal = {Procedia Computer Science},
	author = {Mukhiya, Suresh Kumar and Rabbi, Fazle and Ka I Pun, Violet and Rutle, Adrian and Lamo, Yngve},
	month = jan,
	year = {2019},
	keywords = {GraphQL, Health Information Exchange, HL7 FHIR, Interoperability, overfetching, REST API, REST vs GraphQL, underfetching},
	pages = {338--345},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/SKIJWD8E/Mukhiya et al. - 2019 - A GraphQL approach to Healthcare Information Excha.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/J8Y6GPJY/S187705091931782X.html:text/html}
}
@misc{SOAPSpec,
author = "{World Wide Web Consortium (W3C)}",
title = {{Simple Object Access Protocol (SOAP) 1.2}},
url = {https://www.w3.org/TR/soap12/},
year = {2007},
moth = apr
}


@inproceedings{Fielding2000,
	address = {Limerick, Ireland},
	title = {Principled design of the modern {Web} architecture},
	isbn = {978-1-58113-206-9},
	doi = {10.1145/337180.337228},
	abstract = {The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia system. The modern Web architecture emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. In this paper, we introduce the Representational State Transfer (REST) architectural style, developed as an abstract model of the Web architecture to guide our redesign and definition of the Hypertext Transfer Protocol and Uniform Resource Identifiers. We describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. We then compare the abstract model to the currently deployed Web architecture in order to elicit mismatches between the existing protocols and the applications they are intended to support.},
	urldate = {2020-02-04},
	booktitle = {{ICSE} '00},
	publisher = {ACM},
	author = {Fielding, Roy T. and Taylor, Richard N.},
	month = jun,
	year = {2000},
	keywords = {software architectural style, software architecture, WWW},
	pages = {407--416},
}


@incollection{PaigeKolovosRMW2013,
	address = {Berlin, Heidelberg},
	series = {LNCS},
	title = {Model {Management} in the {Wild}},
	isbn = {978-3-642-35992-7},
	abstract = {Model management is the discipline of manipulating models in support of Model-Driven Engineering (MDE) scenarios of interest. Model management may be supported and implemented via different operations – e.g., model transformation, validation, and code generation. We motivate the concepts and processes of model management, present a practical model management framework – Epsilon – and briefly indicate how it has been used to solve significant model management problems ’in the wild’.},
	language = {en},
	urldate = {2020-02-14},
	booktitle = {{GTTSE} 2011},
	publisher = {Springer},
	author = {Paige, Richard F. and Kolovos, Dimitrios S. and Rose, Louis M. and Matragkas, Nikos and Williams, James R.},
	editor = {Lämmel, Ralf and Saraiva, João and Visser, Joost},
	year = {2013},
	doi = {10.1007/978-3-642-35992-7_5},
	keywords = {Model Transformation, Object Constraint Language, Transformation Language, Model Management, Model Migration},
	pages = {197--218},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/5J7Z93IT/Paige et al. - 2013 - Model Management in the Wild.pdf:application/pdf}
}


@inproceedings{DamRederEgyed2014,
	title = {Inconsistency {Resolution} in {Merging} {Versions} of {Architectural} {Models}},
	doi = {10.1109/WICSA.2014.31},
	abstract = {State-of-the-art optimistic model versioning systems, which are critical to enable efficient team-based development of architectural models, are able to detect and help resolve basic conflicts arising during the merging of model versions. However, it is often overlooked that model merging may also cause severe syntactical and semantic inconsistencies. In this paper, we propose an approach to guide the resolution of inconsistencies detected in a merged architectural model. Our approach automatically finds and presents to the software architects all solutions for resolving all inconsistencies arisen during the merging of model versions. For inconsistencies that pre-exist in the model, our approach is able to suggest exactly which model elements should be changed to resolve them. Our approach is built upon a repair generation which can quickly derive resolutions for an inconsistency by examining its static and dynamic structure and forming concrete repair actions from changes in the versions to be merged. An empirical validation on a range of industrial models has demonstrated that our approach is scalable to both large models and large differences between model versions.},
	booktitle = {2014 {IEEE}/{IFIP} {Conference} on {Software} {Architecture}},
	author = {Dam, H. K. and Reder, A. and Egyed, A.},
	month = apr,
	year = {2014},
	keywords = {Software, Unified modeling language, Maintenance engineering, Merging, Computational modeling, Architectural modeling, Concrete, dynamic structure, Graphical user interfaces, inconsistency management, inconsistency resolution, merging versions, model merging, model versioning, optimistic model versioning systems, repair generation, software architecture, static structure, team-based development},
	pages = {153--162},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/TZ2SHYNK/6827113.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/JTELJQRQ/Dam et al. - 2014 - Inconsistency Resolution in Merging Versions of Ar.pdf:application/pdf}
}


@book{Parr2007,
	title = {The {Definitive} {ANTLR} {Reference}: {Building} {Domain}-specific {Languages}},
	isbn = {978-0-9787392-5-6},
	shorttitle = {The {Definitive} {ANTLR} {Reference}},
	abstract = {ANTLR v3 is the most powerful, easy-to-use parser generator built to date, and represents the culmination of more than 15 years of research by Terence Parr. This book is the essential reference guide to using this completely rebuilt version of ANTLR, with its amazing new LL() parsing technology, tree construction facilities, StringTemplate code generation template engine, and sophisticated ANTLRWorks GUI development environment. Learn to use ANTLR directly from the author!ANTLR is a parser generator-a program that generates code to translate a specified input language into a nice, tidy data structure. You might think that parser generators are only used to build compilers. But in fact, programmers usually use parser generators to build translators and interpreters for domain-specific languages such as proprietary data formats, common network protocols, text processing languages, and domain-specific programming languages.Domain-specific languages are important to software development because they represent a more natural, high fidelity, robust, and maintainable means of encoding a problem than simply writing software in a general-purpose language. For example, NASA uses domain-specific command languages for space missions to improve reliability, reduce risk, reduce cost, and increase the speed of development. Even the first Apollo guidance control computer from the 1960s used a domain-specific language that supported vector computations.This book is the definitive guide to using the completely rebuilt ANTLR v3 and describes all features in detail, including the amazing new LL() parsing technology, tree construction facilities, StringTemplate code generation template engine, and sophisticated ANTLRWorks GUI development environment. You'll learn all about ANTLR grammar syntax, resolving grammar ambiguities, parser fault tolerance and error reporting, embedding actions to interpret or translate languages, building intermediate-form trees, extracting information from trees, generating source code, and how to use the ANTLR Java API.},
	language = {en},
	publisher = {Pragmatic Bookshelf},
	author = {Parr, Terence},
	year = {2007},
	note = {Google-Books-ID: 3vE5ngEACAAJ},
	keywords = {Computers / Compilers, Computers / Computer Engineering, Computers / Programming Languages / General}
}


@inproceedings{SchneiderLambersO2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Logic}-{Based} {Incremental} {Approach} to {Graph} {Repair}},
	isbn = {978-3-030-16722-6},
	abstract = {Graph repair, restoring consistency of a graph, plays a prominent role in several areas of computer science and beyond: For example, in model-driven engineering, the abstract syntax of models is usually encoded using graphs. Flexible edit operations temporarily create inconsistent graphs not representing a valid model, thus requiring graph repair. Similarly, in graph databases—managing the storage and manipulation of graph data—updates may cause that a given database does not satisfy some integrity constraints, requiring also graph repair.We present a logic-based incremental approach to graph repair, generating a sound and complete (upon termination) overview of least-changing repairs. In our context, we formalize consistency by so-called graph conditions being equivalent to first-order logic on graphs. We present two kind of repair algorithms: State-based repair restores consistency independent of the graph update history, whereas delta-based (or incremental) repair takes this history explicitly into account. Technically, our algorithms rely on an existing model generation algorithm for graph conditions implemented in AUTOGRAPHAUTOGRAPH{\textbackslash}textsc \{AutoGraph\}. Moreover, the delta-based approach uses the new concept of satisfaction (ST) trees for encoding if and how a graph satisfies a graph condition. We then demonstrate how to manipulate these STsSTs{\textbackslash}mathrm \{STs\} incrementally with respect to a graph update.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer International Publishing},
	author = {Schneider, Sven and Lambers, Leen and Orejas, Fernando},
	editor = {Hähnle, Reiner and van der Aalst, Wil},
	year = {2019},
	pages = {151--167},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/4LKMB2P3/Schneider et al. - 2019 - A Logic-Based Incremental Approach to Graph Repair.pdf:application/pdf}
}


@inproceedings{EramoMarinelliP2014,
	title = {Towards a {Taxonomy} for {Bidirectional} {Transformation}},
	abstract = {In Model Driven Engineering, bidirectional transformations are considered a core ingredient for managing both the consistency and synchronization of two or more related models. However, current languages still lack of a common understanding of their semantic implications hampering their applicability in practice. This paper illustrates a set of relevant properties pertaining to bidirectional model transformations. It is a first step towards a taxonomy that can help developers to decide which bidirectional language or tool is best suited to their task at hand. This study is based on the existing literature and characteristics of existing approaches.},
	booktitle = {{SATToSE}},
	author = {Eramo, Romina and Marinelli, Romeo and Pierantonio, Alfonso},
	year = {2014},
	keywords = {Bidirectional transformation, Model-driven engineering, Model transformation, Taxonomy (general), Transformation language},
	file = {Full Text PDF:/Users/past/Zotero/storage/2MZU5F8C/Eramo et al. - 2014 - Towards a Taxonomy for Bidirectional Transformatio.pdf:application/pdf}
}



@article{CicchettiCicozziP2019,
	title = {Multi-view approaches for software and system modelling: a systematic literature review},
	volume = {18},
	issn = {1619-1374},
	shorttitle = {Multi-view approaches for software and system modelling},
	doi = {10.1007/s10270-018-00713-w},
	abstract = {Over the years, a number of approaches have been proposed on the description of systems and software in terms of multiple views represented by models. This modelling branch, so-called multi-view software and system modelling, praises a differentiated and complex scientific body of knowledge. With this study, we aimed at identifying, classifying, and evaluating existing solutions for multi-view modelling of software and systems. To this end, we conducted a systematic literature review of the existing state of the art related to the topic. More specifically, we selected and analysed 40 research studies among over 8600 entries. We defined a taxonomy for characterising solutions for multi-view modelling and applied it to the selected studies. Lastly, we analysed and discussed the data extracted from the studies. From the analysed data, we made several observations, among which: (i) there is no uniformity nor agreement in the terminology when it comes to multi-view artefact types, (ii) multi-view approaches have not been evaluated in industrial settings and (iii) there is a lack of support for semantic consistency management and the community does not appear to consider this as a priority. The study results provide an exhaustive overview of the state of the art for multi-view software and systems modelling useful for both researchers and practitioners.},
	language = {en},
	number = {6},
	urldate = {2020-02-28},
	journal = {Software and Systems Modeling},
	author = {Cicchetti, Antonio and Ciccozzi, Federico and Pierantonio, Alfonso},
	month = dec,
	year = {2019},
	pages = {3207--3233},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/2PPX4PQ5/Cicchetti et al. - 2019 - Multi-view approaches for software and system mode.pdf:application/pdf}
}


@inproceedings{DiskinMaibaumC2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Intermodeling, {Queries}, and {Kleisli} {Categories}},
	isbn = {978-3-642-28872-2},
	doi = {10.1007/978-3-642-28872-2_12},
	abstract = {Specification and maintenance of relationships between models are vital for MDE. We show that a wide class of such relationships can be specified in a compact and precise manner, if intermodel mappings are allowed to link derived model elements computed by corresponding queries. Composition of such mappings is not straightforward and requires specialized algebraic machinery. We present a formal framework, in which such machinery can be defined generically for a wide class of metamodel definitions. This enables algebraic specification of practical intermodeling scenarios, e.g., model merge.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer},
	author = {Diskin, Zinovy and Maibaum, Tom and Czarnecki, Krzysztof},
	editor = {de Lara, Juan and Zisman, Andrea},
	year = {2012},
	keywords = {Category Theory, Query Language, Query Mechanism, Triple Graph, View Model},
	pages = {163--177},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/ZAZNEZGF/Diskin et al. - 2012 - Intermodeling, Queries, and Kleisli Categories.pdf:application/pdf}
}




@inproceedings{DiskinMaibaumC2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Model} {Management} {Imperative}: {Being} {Graphical} {Is} {Not} {Sufficient}, {You} {Have} to {Be} {Categorical}},
	isbn = {978-3-319-21151-0},
	shorttitle = {A {Model} {Management} {Imperative}},
	doi = {10.1007/978-3-319-21151-0_11},
	abstract = {Graph-based modeling is both common in and fundamental for Model Driven Engineering (MDE). The paper argues that several important model management (MMt) scenarios require an essential extension of graphical models. We show that different versions of model merge and sync, including many-to-many correspondences between models, can be treated in a uniform, compact and well-defined mathematical way if we specify graphical models as directed graphs with associative arrow composition and identity loops, that is, as categories.},
	language = {en},
	booktitle = {Modelling {Foundations} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Diskin, Zinovy and Maibaum, Tom and Czarnecki, Krzysztof},
	editor = {Taentzer, Gabriele and Bordeleau, Francis},
	year = {2015},
	keywords = {Category Theory, Idle Transition, Label Transition System, Model Drive Engineer, Parallel Composition},
	pages = {154--170}
}


@book{SteinbergBudinskyMP2008,
	title = {{EMF}: {Eclipse} {Modeling} {Framework}},
	isbn = {978-0-13-270221-8},
	shorttitle = {{EMF}},
	abstract = {EMF: Eclipse Modeling Framework    Dave Steinberg Frank Budinsky  Marcelo Paternostro Ed Merks   Series Editors: Erich Gamma • Lee Nackman • John Wiegand   The Authoritative Guide to EMF Modeling and Code Generation The Eclipse Modeling Framework enables developers to rapidly construct robust applications based on surprisingly simple models. Now, in this thoroughly revised Second Edition, the project’s developers offer expert guidance, insight, and examples for solving real-world problems with EMF, accelerating development processes, and improving software quality.    This edition contains more than 40\% new material, plus updates throughout to make it even more useful and practical. The authors illuminate the key concepts and techniques of EMF modeling, analyze EMF’s most important framework classes and generator patterns, guide you through choosing optimal designs, and introduce powerful framework customizations and programming techniques. Coverage includes     • Defining models with Java, UML, XML Schema, and Ecore  • NEW: Using extended Ecore modeling to fully unify XML with UML and Java  • Generating high-quality code to implement models and editors  • Understanding and customizing generated code  • Complete documentation of @model Javadoc tags, generator model properties, and resource save and load options  • NEW: Leveraging the latest EMF features, including extended metadata, feature maps, EStore, cross-reference adapters, copiers, and content types  • NEW: Chapters on change recording, validation, and utilizing EMF in stand-alone and Eclipse RCP applications  • NEW: Modeling generics with Ecore and generating Java 5 code   About the Authors   Dave Steinberg is a software developer in IBM Software Group. He has worked with Eclipse and modeling technologies since joining the company, and has been a committer on the EMF project since its debut in 2002.   Frank Budinsky, a senior architect in IBM Software Group, is an original coinventor of EMF and a founding member of the EMF project at Eclipse. He is currently cochair of the Service Data Objects (SDO) specification technical committee at OASIS and lead SDO architect for IBM.   Marcelo Paternostro is a software architect and engineer in IBM Software Group. He is an EMF committer and has been an active contributor to several other Eclipse projects. Before joining IBM, Marcelo managed, designed, and implemented numerous projects using Rational's tools and processes.   Ed Merks is the project lead of EMF and a colead of the top-level Modeling project at Eclipse. He holds a Ph.D. in Computing Science and has many years of in-depth experience in the design and implementation of languages, frameworks, and application development environments. Ed works as a software consultant in partnership with itemis AG.},
	language = {en},
	publisher = {Pearson Education},
	author = {Steinberg, Dave and Budinsky, Frank and Merks, Ed and Paternostro, Marcelo},
	month = dec,
	year = {2008},
	keywords = {Computers / Programming Languages / Java}
}

@inproceedings{LeblebiciAnjorinS2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Developing {eMoflon} with {eMoflon}},
	isbn = {978-3-319-08789-4},
	abstract = {eMoflon is a Model-Driven Engineering (MDE) tool that supports rule-based unidirectional and bidirectional model transformation. eMoflon is not only being used successfully for both industrial case studies and in academic research projects, but is also consequently used to develop itself. This is known as bootstrapping and has become an important test, proof-of-concept, and success story for us. Interestingly, although MDE technologies are inherently self-descriptive and higher-order, very few actively developed MDE tools are bootstrapped. In this paper, we (i) report on the current state and focus of eMoflon, (ii) share our experience with bootstrapping in an MDE context, and (iii) provide a scalability analysis of a core component in eMoflon implemented as both a unidirectional and bidirectional model transformation with eMoflon.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformations}},
	publisher = {Springer International Publishing},
	author = {Leblebici, Erhan and Anjorin, Anthony and Schürr, Andy},
	editor = {Di Ruscio, Davide and Varró, Dániel},
	year = {2014},
	keywords = {MDE, model transformation, bootstrapping, eMoflon},
	pages = {138--145},
	doi = {10.1007/978-3-319-08789-4_10}
}


@inproceedings{Buchmann2019,
	title = {{BXtend} - {A} {Framework} for ({Bidirectional}) {Incremental} {Model} {Transformations}},
	isbn = {978-989-758-283-7},
	urldate = {2019-10-15},
	author = {Buchmann, Thomas},
	month = oct,
	year = {2019},
	pages = {336--345},
	booktitle = {MODELSWARD 2019 Proceedings},
	doi = {10.5220/0006563503360345}
}


@inproceedings{DiskinEramoPC2016,
	title = {Incorporating {Uncertainty} into {Bidirectional} {Model} {Transformations} and their {Delta}-{Lens} {Formalization}},
	url = {http://ceur-ws.org/Vol-1571/paper_9.pdf},
	booktitle = {Proceedings of the 5th {International} {Workshop} on {Bidirectional} {Transformations}, {Bx} 2016, co-located with {The} {European} {Joint} {Conferences} on {Theory} and {Practice} of {Software}, {ETAPS} 2016, {Eindhoven}, {The} {Netherlands}, {April} 8, 2016},
	author = {Diskin, Zinovy and Eramo, Romina and Pierantonio, Alfonso and Czarnecki, Krzysztof},
	year = {2016},
	pages = {15--31}
}


@article{HinkelBurger2019,
	title = {Change {Propagation} and {Bidirectionality} in {Internal} {Transformation} {DSLs}},
	volume = {18},
	issn = {1619-1366},
	doi = {10.1007/s10270-017-0617-6},
	abstract = {Despite good results in several industrial projects, model-driven engineering (MDE) has not been widely adopted in industry. Although MDE has existed for more than a decade now, the lack of tool support is still one of the major problems, according to studies by Staron and Mohaghegi (Staron, in: Model driven engineering languages and systems, Springer, Berlin, 2006; Mohagheghi et al. in Empir Softw Eng 18(1):89---116, 2013). Internal languages offer a solution to this problem for model transformations, which are a key part of MDE. Developers can use existing tools of host languages to create model transformations in a familiar environment. These internal languages, however, typically lack key features such as change propagation or bidirectional transformations. In our opinion, one reason is that existing formalisms for these properties are not well suited for textual languages. In this paper, we present a new formalism describing incremental, bidirectional model synchronizations using synchronization blocks. We prove the ability of this formalism to detect and repair inconsistencies and show its hippocraticness. We use this formalism to create a single internal model transformation language for unidirectional and bidirectional model transformations with optional change propagation. In total, we currently provide 18 operation modes based on a single specification. At the same time, the language may reuse tool support for C\#. We validate the applicability of our language using a synthetic example with a transformation from finite state machines to Petri nets where we achieved speedups of up to multiple orders of magnitude compared to classical batch transformations.},
	number = {1},
	urldate = {2019-10-29},
	journal = {Softw. Syst. Model.},
	author = {Hinkel, Georg and Burger, Erik},
	month = feb,
	year = {2019},
	keywords = {Model-driven engineering, Model synchronization, Bidirectional, Change propagation, Domain-specific language, Incremental},
	pages = {249--278}
}


@inproceedings{RederEgyed2010,
	address = {Antwerp, Belgium},
	series = {{ASE} '10},
	title = {Model/analyzer: a tool for detecting, visualizing and fixing design errors in {UML}},
	isbn = {978-1-4503-0116-9},
	shorttitle = {Model/analyzer},
	doi = {10.1145/1858996.1859069},
	abstract = {Integrated development environments are widely used in industry and support software engineers with instant error feedback about their work. Modeling tools often react to changes at a coarse level of granularity that make reasoning about errors inefficient and late. Furthermore, there is often a lack of appropriate visualizations of model errors and information on how to fix them. This paper presents the Model/Analyzer tool, an eclipse-based plug-in for the IBM Rational Software Modeler (RSM). The tool lets software engineers define arbitrary design rules and provides instant feedback on their validity in context of a model. Design errors are then visualized together with the information on what parts of the model contributed to them and how to fix them. The tool is fully automated and currently supports OCL and Java as languages for defining the design rules; and UML as the modeling language. The main benefit for the software engineer is the tool's incremental nature if providing instant feedback for many kinds of design errors even for large models.},
	urldate = {2020-03-04},
	booktitle = {Proceedings of the {IEEE}/{ACM} international conference on {Automated} software engineering},
	publisher = {Association for Computing Machinery},
	author = {Reder, Alexander and Egyed, Alexander},
	month = sep,
	year = {2010},
	keywords = {consistency checking, ocl, uml},
	pages = {347--348},
	file = {Full Text PDF:/Users/past/Zotero/storage/69I6JKM6/Reder and Egyed - 2010 - Modelanalyzer a tool for detecting, visualizing .pdf:application/pdf}
}



@incollection{DiRuscioEramoP2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Model {Transformations}},
	isbn = {978-3-642-30982-3},
	abstract = {In recent years, Model-Driven Engineering has taken a leading role in advancing a new paradigm shift in software development. Leveraging models to a first-class status is at the core of this methodology. Shifting the focus of software development from coding to modeling permits programs to transform models in order to generate other models which are amenable for a wide range of purposes, including code generation. This paper introduces a classification of model transformation approaches and languages, illustrating the characteristics of the most prominent ones. Moreover, two specific application scenarios are proposed to highlight bidirectionality and higher-order transformations in the change propagation and coupled evolution domains, respectively.},
	language = {en},
	urldate = {2020-02-14},
	booktitle = {{SFM} 2012},
	publisher = {Springer},
	author = {Di Ruscio, Davide and Eramo, Romina and Pierantonio, Alfonso},
	editor = {Bernardo, Marco and Cortellessa, Vittorio and Pierantonio, Alfonso},
	year = {2012},
	doi = {10.1007/978-3-642-30982-3_4},
	keywords = {Graph Transformation, Model Transformation, Object Management Group, Transformation Language, Target Model},
	pages = {91--136},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/H3U2CSWE/Di Ruscio et al. - 2012 - Model Transformations.pdf:application/pdf}
}



@article{PaigeMatragkasR2016,
	title = {Evolving models in {Model}-{Driven} {Engineering}: {State}-of-the-art and future challenges},
	volume = {111},
	issn = {0164-1212},
	shorttitle = {Evolving models in {Model}-{Driven} {Engineering}},
	doi = {10.1016/j.jss.2015.08.047},
	abstract = {The artefacts used in Model-Driven Engineering (MDE) evolve as a matter of course: models are modified and updated as part of the engineering process; metamodels change as a result of domain analysis and standardisation efforts; and the operations applied to models change as engineering requirements change. MDE artefacts are inter-related, and simultaneously constrain each other, making evolution a challenge to manage. We discuss some of the key problems of evolution in MDE, summarise the key state-of-the-art, and look forward to new challenges in research in this area.},
	language = {en},
	urldate = {2020-02-14},
	journal = {Journal of Systems and Software},
	author = {Paige, Richard F. and Matragkas, Nicholas and Rose, Louis M.},
	month = jan,
	year = {2016},
	keywords = {Co-evolution, Evolution, Migration},
	pages = {272--280},
}


@incollection{PottingerBernstein2003,
	address = {San Francisco},
	title = {Merging {Models} {Based} on {Given} {Correspondences}},
	isbn = {978-0-12-722442-8},
	abstract = {This chapter defines the Merge operator for model merging, both generically and for a specific meta-meta-model, Vanilla. It defines and classifies the conflicts that arise in combining two models and describes when conflicts from different classes must be resolved. Resolution strategies for conflicts that must be resolved in Merge, both for Vanilla and in general are presented. The chapter evaluates Merge by showing how Merge in Vanilla can be used to subsume some previous merging algorithms and by testing Merge on two large real-world ontologies. The chapter envisions several future directions. The first involves showing that the Merge result, when applied to models and mappings that are templates for instances, has an appropriate interpretation on instances. This will demonstrate the usefulness of Merge in specific applications such as data integration and view integration.},
	urldate = {2019-02-04},
	booktitle = {Proceedings 2003 {VLDB} {Conference}},
	publisher = {Morgan Kaufmann},
	author = {Pottinger, Rachel A. and Bernstein, Philip A.},
	editor = {Freytag, Johann-Christoph and Lockemann, Peter and Abiteboul, Serge and Carey, Michael and Selinger, Patricia and Heuer, Andreas},
	month = jan,
	year = {2003},
	doi = {10.1016/B978-012722442-8/50081-1},
	pages = {862--873},
	file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/WFJL4LHG/B9780127224428500811.html:text/html}
}



@inproceedings{KlingJouaultWBC2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{MoScript}: {A} {DSL} for {Querying} and {Manipulating} {Model} {Repositories}},
	isbn = {978-3-642-28830-2},
	shorttitle = {{MoScript}},
	doi = {10.1007/978-3-642-28830-2_10},
	abstract = {Growing adoption of Model-Driven Engineering has hugely increased the number of modelling artefacts (models, metamodels, transformations, ...) to be managed. Therefore, development teams require appropriate tools to search and manipulate models stored in model repositories, e.g. to find and reuse models or model fragments from previous projects. Unfortunately, current approaches for model management are either ad-hoc (i.e., tied to specific types of repositories and/or models), do not support complex queries (e.g., based on the model structure and its relationship with other modelling artefacts) or do not allow the manipulation of the resulting models (e.g., inspect, transform). This hinders the probability of efficiently reusing existing models or fragments thereof. In this paper we introduce MoScript, a textual domain-specific language for model management. With MoScript, users can write scripts containing queries (based on model content, structure, relationships, and behaviour derived through on-the-fly simulation) to retrieve models from model repositories, manipulate them (e.g., by running transformations on sets of models), and store them back in the repository. MoScript relies on the megamodeling concept to provide a homogeneous model-based interface to heterogeneous repositories.},
	language = {en},
	booktitle = {Software {Language} {Engineering}},
	publisher = {Springer},
	author = {Kling, Wolfgang and Jouault, Frédéric and Wagelaar, Dennis and Brambilla, Marco and Cabot, Jordi},
	editor = {Sloane, Anthony and Aßmann, Uwe},
	year = {2012},
	keywords = {DSL, Megamodel, Model Management, OCL, Scripting},
	pages = {180--200},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/WDBMG56G/Kling et al. - 2012 - MoScript A DSL for Querying and Manipulating Mode.pdf:application/pdf}
}



@inproceedings{MelnikRahmB2003,
	address = {New York, NY, USA},
	series = {{SIGMOD} '03},
	title = {Rondo: {A} {Programming} {Platform} for {Generic} {Model} {Management}},
	isbn = {978-1-58113-634-0},
	shorttitle = {Rondo},
	url = {http://doi.acm.org/10.1145/872757.872782},
	doi = {10.1145/872757.872782},
	abstract = {Model management aims at reducing the amount of programming needed for the development of metadata-intensive applications. We present a first complete prototype of a generic model management system, in which high-level operators are used to manipulate models and mappings between models. We define the key conceptual structures: models, morphisms, and selectors, and describe their use and implementation. We specify the semantics of the known model-management operators applied to these structures, suggest new ones, and develop new algorithms for implementing the individual operators. We examine the solutions for two model-management tasks that involve manipulations of relational schemas, XML schemas, and SQL views.},
	urldate = {2019-10-08},
	booktitle = {Proceedings of the 2003 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Melnik, Sergey and Rahm, Erhard and Bernstein, Philip A.},
	year = {2003},
	note = {event-place: San Diego, California},
	pages = {193--204},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/Z3TANXZE/Melnik et al. - 2003 - Rondo A Programming Platform for Generic Model Ma.pdf:application/pdf}
}


@inproceedings{MossakowskiTarlecki2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Heterogeneous {Logical} {Environments} for {Distributed} {Specifications}},
	isbn = {978-3-642-03429-9},
	doi = {10.1007/978-3-642-03429-9_18},
	abstract = {We use the theory of institutions to capture the concept of a heterogeneous logical environment as a number of institutions linked by institution morphisms and comorphisms. We discuss heterogeneous specifications built in such environments, with inter-institutional specification morphisms based on both institution morphisms and comorphisms. We distinguish three kinds of heterogeneity: (1) specifications in logical environments with universal logic (2) heterogeneous specifications focused at a particular logic, and (3) heterogeneous specifications distributed over a number of logics.},
	language = {en},
	booktitle = {Recent {Trends} in {Algebraic} {Development} {Techniques}},
	publisher = {Springer},
	author = {Mossakowski, Till and Tarlecki, Andrzej},
	editor = {Corradini, Andrea and Montanari, Ugo},
	year = {2009},
	keywords = {Logical System, Model Functor, Proof Obligation, Relational Link, Signature Category},
	pages = {266--289},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/SSF3JQV2/Mossakowski and Tarlecki - 2009 - Heterogeneous Logical Environments for Distributed.pdf:application/pdf}
}


@inproceedings{AlgaicBernstein2002,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Model} {Theory} for {Generic} {Schema} {Management}},
	isbn = {978-3-540-46093-0},
	doi = {10.1007/3-540-46093-4_14},
	abstract = {The core of a model theory for generic schema management is developed. This theory has two distinctive features: it applies to a variety of categories of schemas, and it applies to transformations of both the schema structure and its integrity constraints. A subtle problem of schema integration is considered in its general form, not bound to any particular category of schemas. The proposed solution, as well as the overall theory, is based entirely on schema morphisms that carry both structural and semantic properties. Duality results that apply to the schema and the data levels are established. These results lead to the main contribution of this paper: a formal schema and data management framework for generic schema management. Implications of this theory are established that apply to integrity problems in schema integration. The theory is illustrated by a particular category of schemas with object-oriented features along with typical database integrity constraints.},
	language = {en},
	booktitle = {Database {Programming} {Languages}},
	publisher = {Springer},
	author = {Alagić, Suad and Bernstein, Philip A.},
	editor = {Ghelli, Giorgio and Grahne, Gösta},
	year = {2002},
	keywords = {Database Schema, Integrity Constraint, Model Theory, Schema Integration, Schema Signature},
	pages = {228--246},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/DGMGCY5H/Alagić and Bernstein - 2002 - A Model Theory for Generic Schema Management.pdf:application/pdf}
}


@article{GoguenBurstall1992,
	title = {Institutions: abstract model theory for specification and programming},
	volume = {39},
	issn = {0004-5411},
	shorttitle = {Institutions},
	url = {https://doi.org/10.1145/147508.147524},
	doi = {10.1145/147508.147524},
	abstract = {There is a population explosion among the logical systems used in computing science. Examples include first-order logic, equational logic, Horn-clause logic, higher-order logic, infinitary logic, dynamic logic, intuitionistic logic, order-sorted logic, and temporal logic; moreover, there is a tendency for each theorem prover to have its own idiosyncratic logical system. The concept of institution is introduced to formalize the informal notion of “logical system.” The major requirement is that there is a satisfaction relation between models and sentences that is consistent under change of notation. Institutions enable abstracting away from syntactic and semantic detail when working on language structure “in-the-large”; for example, we can define language features for building large logical system. This applies to both specification languages and programming languages. Institutions also have applications to such areas as database theory and the semantics of artificial and natural languages. A first main result of this paper says that any institution such that signatures (which define notation) can be glued together, also allows gluing together theories (which are just collections of sentences over a fixed signature). A second main result considers when theory structuring is preserved by institution morphisms. A third main result gives conditions under which it is sound to use a theorem prover for one institution on theories from another. A fourth main result shows how to extend institutions so that their theories may include, in addition to the original sentences, various kinds of constraint that are useful for defining abstract data types, including both “data” and “hierarchy” constraints. Further results show how to define institutions that allow sentences and constraints from two or more institutions. All our general results apply to such “duplex” and “multiplex” institutions.},
	number = {1},
	urldate = {2020-03-05},
	journal = {Journal of the ACM},
	author = {Goguen, Joseph A. and Burstall, Rod M.},
	month = jan,
	year = {1992},
	pages = {95--146},
	file = {Full Text PDF:/Users/past/Zotero/storage/MRTIFCKQ/Goguen and Burstall - 1992 - Institutions abstract model theory for specificat.pdf:application/pdf}
}


@incollection{AntkiewiczCzarnecki2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Design {Space} of {Heterogeneous} {Synchronization}},
	isbn = {978-3-540-88643-3},
	abstract = {This tutorial explores the design space of heterogeneous synchronization, which is concerned with establishing consistency among artifacts that conform to different schemas or are expressed in different languages. Our main application scenario is synchronization of software artifacts, such as code, models, and configuration files. We classify heterogeneous synchronizers according to the cardinality of the relation that they enforce between artifacts, their directionality, their incrementality, and whether they support reconciliation of concurrent updates. We then provide a framework of artifact operators that describes different ways of building heterogeneous synchronizers, such as synchronizers based on artifact or update translation. The design decisions within the framework are described using feature models. We present 16 concrete instances of the framework, discuss tradeoffs among them, and identify sample implementations for some of them. We also explore additional design decisions such as representation of updates, establishing correspondence among model elements, and strategies for selecting a single synchronization result from a set of alternatives. Finally, we discuss related fields including data synchronization, inconsistency management in software engineering, model management, and model transformation.},
	language = {en},
	urldate = {2020-03-05},
	booktitle = {{GTTSE} 2007},
	publisher = {Springer},
	author = {Antkiewicz, Michał and Czarnecki, Krzysztof},
	editor = {Lämmel, Ralf and Visser, Joost and Saraiva, João},
	year = {2008},
	doi = {10.1007/978-3-540-88643-3_1},
	keywords = {Atlas Transformation Language, Design Space, Eclipse Modeling Framework, Model Transformation, Original Target},
	pages = {3--46},
}


@article{BruniMeseguerM2002,
	title = {Symmetric monoidal and cartesian double categories as a semantic framework for tile logic},
	volume = {12},
	issn = {0960-1295},
	url = {https://doi.org/10.1017/S0960129501003462},
	doi = {10.1017/S0960129501003462},
	abstract = {Tile systems offer a general paradigm for modular descriptions of concurrent systems, based on a set of rewriting rules with side-effects. Monoidal double categories are a natural semantic framework for tile systems, because the mathematical structures describing system states and synchronizing actions (called configurations and observations, respectively, in our terminology) are monoidal categories having the same objects (the interfaces of the system). In particular, configurations and observations based on net-process-like and term structures are usually described in terms of symmetric monoidal and cartesian categories, where the auxiliary structures for the rearrangement of interfaces correspond to suitable natural transformations. In this paper we discuss the lifting of these auxiliary structures to double categories. We notice that the internal construction of double categories produces a pathological asymmetric notion of natural transformation, which is fully exploited in one dimension only (for example, for configurations or for observations, but not for both). Following Ehresmann (1963), we overcome this biased definition, introducing the notion of generalized natural transformation between four double functors (rather than two). As a consequence, the concepts of symmetric monoidal and cartesian (with consistently chosen products) double categories arise in a natural way from the corresponding ordinary versions, giving a very good relationship between the auxiliary structures of configurations and observations. Moreover, the Kelly–Mac Lane coherence axioms can be lifted to our setting without effort, thanks to the characterization of two suitable diagonal categories that are always present in a double category. Then, symmetric monoidal and cartesian double categories are shown to offer an adequate semantic setting for process and term tile systems.},
	number = {1},
	urldate = {2020-03-05},
	journal = {Mathematical Structures in Computer Science},
	author = {Bruni, Roberto and Meseguer, José and Montanari, Ugo},
	month = feb,
	year = {2002},
	pages = {53--90}
}


@inproceedings{WirsingKnapp2004,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {View {Consistency} in {Software} {Development}},
	isbn = {978-3-540-24626-8},
	doi = {10.1007/978-3-540-24626-8_24},
	abstract = {An algebraic approach to the view consistency problem in software development is provided. A view is formalised as a sentence of a viewpoint language; a viewpoint is given by a language and its semantics. Views in possibly different viewpoints are compared over a common view for consistency by a heterogenous pull-back construction. This general notion of view consistency is illustrated by several examples from viewpoints used in object-oriented software development.},
	language = {en},
	booktitle = {Radical {Innovations} of {Software} and {Systems} {Engineering} in the {Future}},
	publisher = {Springer},
	author = {Wirsing, Martin and Knapp, Alexander},
	editor = {Wirsing, Martin and Knapp, Alexander and Balsamo, Simonetta},
	year = {2004},
	keywords = {Automatic Teller Machine, Class Diagram, Interaction Diagram, Operation Symbol, Semantic Domain},
	pages = {341--357},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/TP5W5CDI/Wirsing and Knapp - 2004 - View Consistency in Software Development.pdf:application/pdf}
}



@inproceedings{BezivinBouzitounaDGJKKP2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Canonical} {Scheme} for {Model} {Composition}},
	isbn = {978-3-540-35910-4},
	doi = {10.1007/11787044_26},
	abstract = {There is little agreement on terminology in model composition, and even less on key characteristics of a model composition solution. We present three composition frameworks: the Atlas Model Weaver, the Epsilon Merging Language, and the Glue Generator Tool, and from them derive a core set of common definitions. We use this to outline the key requirements of a model composition solution, in terms of language and tool support.},
	language = {en},
	booktitle = {Model {Driven} {Architecture} – {Foundations} and {Applications}},
	publisher = {Springer},
	author = {Bézivin, Jean and Bouzitouna, Salim and Del Fabro, Marcos Didonet and Gervais, Marie-Pierre and Jouault, Fréderic and Kolovos, Dimitrios and Kurtev, Ivan and Paige, Richard F.},
	editor = {Rensink, Arend and Warmer, Jos},
	year = {2006},
	keywords = {Composition Operation, Composition Rule, Match Operation, Model Composition, Model Transformation},
	pages = {346--360},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/B6UXTCRG/Bézivin et al. - 2006 - A Canonical Scheme for Model Composition.pdf:application/pdf}
}



@inproceedings{FiadeiroMaibaum1995,
	address = {New York, NY, USA},
	series = {{SIGSOFT} '95},
	title = {Interconnecting {Formalisms}: {Supporting} {Modularity}, {Reuse} and {Incrementality}},
	isbn = {978-0-89791-716-2},
	shorttitle = {Interconnecting {Formalisms}},
	url = {http://doi.acm.org/10.1145/222124.222141},
	doi = {10.1145/222124.222141},
	urldate = {2019-02-04},
	booktitle = {Proceedings of the 3rd {ACM} {SIGSOFT} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Fiadeiro, José Luiz and Maibaum, Tom},
	year = {1995},
	keywords = {formal methods, compositionality, general systems theory, incremental development, multiperspective specification, reuse},
	pages = {72--80},
	file = {ACM Full Text PDF:/Users/past/Zotero/storage/KGFJ2JYI/Fiadeiro and Maibaum - 1995 - Interconnecting Formalisms Supporting Modularity,.pdf:application/pdf}
}



@inproceedings{JohnsonStevens2018,
	address = {Nice, France},
	series = {Programming'18 {Companion}},
	title = {Confidentiality in the process of (model-driven) software development},
	isbn = {978-1-4503-5513-1},
	doi = {10.1145/3191697.3191714},
	abstract = {Much is now understood about how to develop software that will have good security properties in use. We claim that a topic which needs more attention, in particular from the Bx community, is security, especially confidentiality, in the software development process itself. What is then at issue is not what particular users of the software may be allowed to know, but rather, what particular developers of the software may be allowed to know. How can software development processes guarantee to respect confidentiality without compromising effective development? The question is of general interest across software engineering, but model-driven development (MDD) seems a particularly promising arena in which to address it, because of MDD's focus on separation of concerns. In MDD, different people work with separate models, where (ideally) each model records all and only the information necessary to those who work with it. When necessary, the models are reconciled by bidirectional transformations, which automate a process which would otherwise have to be undertaken manually by the groups of experts meeting and studying both their models in order to bring them back into consistency. In model-driven development confidentiality issues become particularly clear and tractable, and bidirectional transformations have a key technical role. We hope to encourage the community to take up this challenge, and in this paper we begin our own analysis of a selection of the issues, focusing particularly on developing a threat model and some examples of secure restoration of consistency.},
	urldate = {2020-03-05},
	booktitle = {Conference {Companion} of the 2nd {International} {Conference} on {Art}, {Science}, and {Engineering} of {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Johnson, Michael and Stevens, Perdita},
	month = apr,
	year = {2018},
	keywords = {Confidentiality, Cospan, Model-driven software development, Security},
	pages = {1--8},
}


@inproceedings{DemuthTroelsKME2018,
	title = {Experiences on {Traceability} and {Consistency} {Checking} across {Engineering} {Tools} in an {Automation} {Solution} {Company}},
	isbn = {978-3-88579-673-2},
	url = {http://dl.gi.de/handle/20.500.12116/21146},
	abstract = {The engineering of systems is unimaginable without software tools. Engineers use them to capture and analyze engineering problems; specify, implement, test, and maintain engineering solutions, and manage engineering processes. Yet, there is a gap between the capabilities of independently working engineers and the needs of a collaborative engineering team. The existing tool landscape emphasizes the former. Most engineering tools are single-user applications – often of excellent quality but limited in that they support the works of individual engineers and not that of a group of engineers. And herein lies one of the most fundamental problems of software and systems engineering. Engineers know well the engineering knowledge they capture but they often lack awareness of the many implications their work has on other engineers and/or other engineering domains. This is a problem because in today’s engineering projects, companies continuously have to adapt their systems to changing customer or market requirements. This requires a flexible, iterative development process in which different parts of the system under construction are built and updated concurrently. However, concurrent engineering is quite problematic in domains where different engineering domains and different engineering tools come together. In this paper, we discuss experiences with Van Hoecke Automation, a leading company in the areas of production automation and product processing, in maintaining the consistency between electrical models and the corresponding software controller when both are subject to continuous change. The paper discusses how we let engineers describe the relationships between electrical model and software code in form of links and consistency rules; and how through continuous consistency checking our approach then notified those engineers of the erroneous impact of changes in either electrical model or code.},
	language = {en},
	urldate = {2019-10-08},
	booktitle = {Software {Engineering} und {Software} {Management} 2018},
	publisher = {Gesellschaft für Informatik},
	author = {Demuth, Andreas and Kretschmer, Roland and Tröls, Michael and Kanakis, Georgios and Maes, Davy and Egyed, Alexander},
	year = {2018},
	file = {Full Text PDF:/Users/past/Zotero/storage/D9X29K8U/Demuth et al. - 2018 - Experiences on Traceability and Consistency Checki.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/XXELRVUY/21146.html:text/html}
}

@inproceedings{StuenkelKoenigLR2020,
  author    = {Patrick St{\"{u}}nkel and Harald K{\"{o}}nig and Yngve Lamo and Adrian Rutle},
  title     = {Towards Multiple Model Synchronization with Comprehensive Systems},
  booktitle="Fundamental Approaches to Software Engineering",
  year      = {2020},
  month = apr,
  doi = {10.1007/978-3-030-45234-6_17},
  isbn = {978-3-030-45233-9},
  publisher= {Springer, Cham},
  series = {Lecture {Notes} in {Computer} {Science}},
  volume = {12076},
  pages="335--356",
  editor="Wehrheim, Heike and Cabot, Jordi",
}
}


@article{KessentiniSahraouiW2019,
	title = {Automated metamodel/model co-evolution: {A} search-based approach},
	volume = {106},
	issn = {0950-5849},
	shorttitle = {Automated metamodel/model co-evolution},
	doi = {10.1016/j.infsof.2018.09.003},
	abstract = {Context: Metamodels evolve over time to accommodate new features, improve existing designs, and fix errors identified in previous releases. One of the obstacles that may limit the adaptation of new metamodels by developers is the extensive manual changes that have been applied to migrate existing models. Recent studies addressed the problem of automating the metamodel/model co-evolution based on manually defined migration rules. The definition of these rules requires the list of changes at the metamodel level which are difficult to fully identify. Furthermore, different possible alternatives may be available to translate a metamodel change to a model change. Thus, it is hard to generalize these co-evolution rules. Objective: We propose an alternative automated approach for the metamodel/model co-evolution. The proposed approach refines an initial model instantiated from the previous metamodel version to make it as conformant as possible to the new metamodel version by finding the best compromise between three objectives, namely minimizing (i) the non-conformities with new metamodel version, (ii) the changes to existing models, and (iii) the textual and structural dissimilarities between the initial and revised models. Method: We formulated the metamodel/model co-evolution as a multi-objective optimization problem to handle the different conflicting objectives using the Non-dominated Sorting Genetic Algorithm II (NSGA-II) and the Multi-Objective Particle Swarm Optimization (MOPSO). Results: We evaluated our approach on several evolution scenarios extracted from different widely used metamodels. The results confirm the effectiveness of our approach with average manual correctness, precision and recall respectively higher than 91\%, 88\% and 89\% on the different co-evolution scenarios. Conclusion: A comparison with our previous work confirms the out-performance of our multi-objective formulation.},
	language = {en},
	urldate = {2019-11-14},
	journal = {Information and Software Technology},
	author = {Kessentini, Wael and Sahraoui, Houari and Wimmer, Manuel},
	month = feb,
	year = {2019},
	keywords = {Model migration, Coupled evolution, Metamodel/model co-evolution, Search based software engineering},
	pages = {49--67},
	file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/7ZTATTLZ/S0950584918301915.html:text/html}
}


@article{JohnsonRosebrugh2007,
	title = {Fibrations and universal view updatability},
	volume = {388},
	issn = {0304-3975},
	doi = {10.1016/j.tcs.2007.06.004},
	abstract = {Maintainability and modifiability of information system software can be enhanced by the provision of comprehensive support for views, since view support allows application programs to continue to operate unchanged when the underlying information system is modified. Supporting views depend upon a solution to the view update problem. This paper presents a new treatment of view updates for formally specified semantic data models based on the category theoretic sketch data model. The sketch data model has been the basis of a number of successful major information system consultancies. We define view updates by a universal property in models of the formal specification, and explain why this indeed gives a complete and correct treatment of view updatability, including a solution to the view update problem. However, a definition of updatability which is based on models causes some inconvenience in applications, so we prove that in a variety of circumstances updatability is guaranteed independently of the current model. This is done first with a very general criterion, and then for some specific cases relevant to applications. We include some details about the sketch data model, noting that it involves extensions of algebraic data specification techniques.},
	number = {1},
	urldate = {2018-07-19},
	journal = {Theoretical Computer Science},
	author = {Johnson, Michael and Rosebrugh, Robert},
	month = dec,
	year = {2007},
	keywords = {Database, Fibration, Semantic data model, Sketch, View update},
	pages = {109--129},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/BVEFQYTX/Johnson and Rosebrugh - 2007 - Fibrations and universal view updatability.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/QD7G46JY/S0304397507004835.html:text/html}
}


@article{JohnsonRosebrughW2010,
	title = {Algebras and {Update} {Strategies}},
	volume = {16},
	abstract = {The classical (Bancilhon-Spyratos) correspondence between view update translations and views with a constant complement reappears more generally as the correspondence between update strategies and meet complements in the order based setting of S. Hegner. We show that these two theories of database view updatability are linked by the notion of},
	number = {5},
	journal = {j-jucs},
	author = {Johnson, Michael and Rosebrugh, Robert and Wood, Richard},
	month = mar,
	year = {2010},
	pages = {729--748},
	doi = {10.3217/jucs-016-05-0729}
}


@inproceedings{PinnaPuissantVanDerStraetenM2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Badger: {A} {Regression} {Planner} to {Resolve} {Design} {Model} {Inconsistencies}},
	isbn = {978-3-642-31491-9},
	shorttitle = {Badger},
	doi = {10.1007/978-3-642-31491-9_13},
	abstract = {One of the main challenges in model-driven software engineering is to deal with design model inconsistencies. Automated techniques to detect and resolve these inconsistencies are essential. We propose to use the artificial intelligence technique of automated planning for the purpose of resolving software model inconsistencies. We implemented a regression planner in Prolog and validated it on the resolution of different types of structural inconsistencies for generated models of varying sizes. We discuss the scalability results of the approach obtained through several stress-tests and discuss the limitations of our approach.},
	language = {en},
	booktitle = {Modelling {Foundations} and {Applications}},
	publisher = {Springer},
	author = {Pinna Puissant, Jorge and Van Der Straeten, Ragnhild and Mens, Tom},
	editor = {Vallecillo, Antonio and Tolvanen, Juha-Pekka and Kindler, Ekkart and Störrle, Harald and Kolovos, Dimitris},
	year = {2012},
	keywords = {inconsistency resolution, model, automated planning, scalability},
	pages = {146--161},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/CHRJGVX2/Pinna Puissant et al. - 2012 - Badger A Regression Planner to Resolve Design Mod.pdf:application/pdf}
}



@inproceedings{KolovosPaigeP2008,
	address = {Washington, DC, USA},
	series = {{ICST} '08},
	title = {Detecting and {Repairing} {Inconsistencies} {Across} {Heterogeneous} {Models}},
	isbn = {978-0-7695-3127-4},
	url = {https://doi.org/10.1109/ICST.2008.23},
	doi = {10.1109/ICST.2008.23},
	abstract = {With the advent of Domain Specific Languages for Model Engineering, detecting inconsistencies between models is becoming increasingly challenging. Nowadays, it is not uncommon for models participating in the same development process to be captured using different modelling languages and even different modelling technologies. We present a classification of the types of relationships that can arise between models participating in a software development process and outline the types of inconsistencies each relationship can suffer from. From this classification we identify a set of requirements for a generic inconsistency detection and reconciliation mechanism and use a case study to demonstrate how those requirements are implemented in the Epsilon Validation Language (EVL), a task-specific language developed in the context of the Epsilon GMT component.},
	urldate = {2019-10-08},
	booktitle = {Proceedings of the 2008 {International} {Conference} on {Software} {Testing}, {Verification}, and {Validation}},
	publisher = {IEEE Computer Society},
	author = {Kolovos, Dimitrios and Paige, Richard and Polack, Fiona},
	year = {2008},
	keywords = {Inconsistency Management, Model Consistency, Model Driven Development},
	pages = {356--364}
}


@inproceedings{HidakaHuIKN2011,
	title = {{GRoundTram}: {An} integrated framework for developing well-behaved bidirectional model transformations},
	shorttitle = {{GRoundTram}},
	doi = {10.1109/ASE.2011.6100104},
	abstract = {Bidirectional model transformation is useful for maintaining consistency between two models, and has many potential applications in software development including model synchronization, round-trip engineering, and software evolution. Despite these attractive uses, the lack of a practical tool support for systematic development of well-behaved and efficient bidirectional model transformation prevents it from being widely used. In this paper, we solve this problem by proposing an integrated framework called GRoundTram, which is carefully designed and implemented for compositional development of well-behaved and efficient bidirectional model transformations. GRoundTram is built upon a well-founded bidirectional framework, and is equipped with a user-friendly language for coding bidirectional model transformation, a new tool for validating both models and bidirectional model transformations, an optimization mechanism for improving efficiency, and a powerful debugging environment for testing bidirectional behavior. GRoundTram has been used by people of other groups and their results show its usefulness in practice.},
	booktitle = {2011 26th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE} 2011)},
	author = {Hidaka, S. and Hu, Z. and Inaba, K. and Kato, H. and Nakano, K.},
	month = nov,
	year = {2011},
	keywords = {software development, Unified modeling language, software evolution, Testing, Programming, Software engineering, software maintenance, Computational modeling, bidirectional model transformation coding, consistency maintainance, Debugging, GRoundTram, model synchronization, optimisation, optimization mechanism, round trip engineering, US Department of Transportation, user friendly language, well behaved bidirectional model transformations},
	pages = {480--483},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/XVKS2ZNP/6100104.html:text/html;Submitted Version:/Users/past/Zotero/storage/S76JIYJ4/Hidaka et al. - 2011 - GRoundTram An integrated framework for developing.pdf:application/pdf}
}


@incollection{GogollaHamannHKF2014,
	address = {Bonn},
	title = {From {Application} {Models} to {Filmstrip} {Models}: {An} {Approach} to {Automatic} {Validation} of {Model} {Dynamics}},
	isbn = {978-3-88579-619-0},
	url = {http://dl.gi.de/handle/20.500.12116/20945},
	abstract = {Efficient model validation and verification techniques are strong in the analysis of systems describing static structures, for example, UML class diagrams and OCL invariants. However, general UML and OCL models can involve dynamic aspects in form of OCL preand postconditions for operations. This paper describes the automatic transformation of a UML and OCL model with invariants and preand postconditions into an equivalent model with only invariants. We call the first model (with preand postconditions) the application model and the second model (with invariants only) the filmstrip model, because a sequence of system states in the application model becomes a single system state in the filmstrip model. This single system state can be thought of as being a filmstrip presenting snapshots from the application model with different logical time stamps. Preand postconditions from the application model become invariants in the filmstrip model. Providing a proper context, the text of the preand postconditions can be used in the filmstrip model nearly unchanged. The filmstrip model can be employed for automatically constructing dynamic test scenarios and for checking temporal properties.},
	language = {en},
	urldate = {2020-03-20},
	booktitle = {Modellierung},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Gogolla, Martin and Hamann, Lars and Hilken, Frank and Kuhlmann, Mirco and France, Robert},
	year = {2014},
	note = {Accepted: 2019-03-19T14:06:56Z
ISSN: 1617-5468},
	pages = {273--288},
	file = {Full Text PDF:/Users/past/Zotero/storage/ZYG64WNH/Gogolla et al. - 2014 - From Application Models to Filmstrip Models An Ap.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/WU9LK233/20945.html:text/html}
}





@article{Stevens2020,
	title = {Connecting software build with maintaining consistency between models: towards sound, optimal, and flexible building from megamodels},
	issn = {1619-1374},
	shorttitle = {Connecting software build with maintaining consistency between models},
	doi = {10.1007/s10270-020-00788-4},
	abstract = {Software build systems tackle the problem of building software from sources in a way which is sound (when a build completes successfully, the relations between the generated and source files are as specified) and optimal (only genuinely required rebuilding steps are done). In this paper, we explain and exploit the connection between software build and the megamodel consistency problem. The model-driven development of systems involves multiple models, metamodels and transformations. Transformations—which may be bidirectional—specify, and provide means to enforce, desired “consistency” relationships between models. We can describe the whole configuration using a megamodel. As development proceeds, and various models are modified, we need to be able to restore consistency in the megamodel, so that the consequences of decisions first recorded in one model are appropriately reflected in the others. At the same time, we need to minimise the amount of recomputation needed; in particular, we would like to avoid reapplying a transformation when no relevant changes have occurred in the models it relates. The megamodel consistency problem requires flexibility beyond what is found in conventional software build, because different results are obtained depending on which models are allowed to be modified and on the order and direction of transformation application. In this paper, we propose using an orientation model to make important choices explicit. We show how to extend the formalised build system pluto to provide a means of restoring consistency in a megamodel, that is, in appropriate senses, flexible, sound and optimal.},
	language = {en},
	urldate = {2020-03-20},
	journal = {Software and Systems Modeling},
	author = {Stevens, Perdita},
	month = mar,
	year = {2020},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/PQGC4VMQ/Stevens - 2020 - Connecting software build with maintaining consist.pdf:application/pdf}
}


@incollection{ShahKerzhnerSP2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multi-view {Modeling} to {Support} {Embedded} {Systems} {Engineering} in {SysML}},
	isbn = {978-3-642-17322-6},
	url = {https://doi.org/10.1007/978-3-642-17322-6_25},
	abstract = {Embedded systems engineering problems often involve many domains, each with their own experts and tools. To help these experts with analysis and decision making in their domain, it is desirable to present them with a view of the system that is tailored to their particular task. In this paper, a model integration framework is demonstrated to address issues associated with multi-view modeling. The Systems Modeling Language (OMG SysMLTM) is used as a general language to represent a common model for the system as well as the dependencies between the different domain-specific tools and languages. To maintain consistency between these domain-specific views, model transformations are defined that map the interdependent constructs to and from a common SysML model. The approach is illustrated by means of a mechatronic design problem involving views in multiple domain-specific tools, namely EPLAN FluidTM (to create production ready layouts) and Modelica® (for dynamic system analysis).},
	language = {en},
	urldate = {2020-03-20},
	booktitle = {Graph {Transformations} and {Model}-{Driven} {Engineering}: {Essays} {Dedicated} to {Manfred} {Nagl} on the {Occasion} of his 65th {Birthday}},
	publisher = {Springer},
	author = {Shah, Aditya A. and Kerzhner, Aleksandr A. and Schaefer, Dirk and Paredis, Christiaan J. J.},
	editor = {Engels, Gregor and Lewerentz, Claus and Schäfer, Wilhelm and Schürr, Andy and Westfechtel, Bernhard},
	year = {2010},
	doi = {10.1007/978-3-642-17322-6_25},
	keywords = {Common Model, Graph Transformation, Meta Object Facility, Model Transformation, Multiple View},
	pages = {580--601}
}



@article{AwadidNurcan2019,
	title = {Consistency requirements in business process modeling: a thorough overview},
	volume = {18},
	issn = {1619-1374},
	shorttitle = {Consistency requirements in business process modeling},
	url = {https://doi.org/10.1007/s10270-017-0629-2},
	doi = {10.1007/s10270-017-0629-2},
	abstract = {The field of business process modeling has been beset by inter-model consistency problems which are mainly due to the existence of multiple variants of the same business process, for instance when models have been produced by different actors, or through the time by a same (or different) actor(s), as well as the possibility of its modeling from discrete and complementary perspectives (using different lenses). Accordingly, our overall aim in this paper is to provide a thorough overview of consistency requirements in business process modeling, which is strongly needed not only for the sake of a comprehensive investigation of this challenging subject, but also for the sake of empowering significant contributions to it. In order to do so, we opted for a systematic literature review of consistency among business process models as starting point and basis to attain the intended overview and to guide our contributions in this field.},
	language = {en},
	number = {2},
	urldate = {2020-03-20},
	journal = {Software \& Systems Modeling},
	author = {Awadid, Afef and Nurcan, Selmin},
	month = apr,
	year = {2019},
	pages = {1097--1115}
}


@article{BruneliereBurgerCW2019,
	title = {A feature-based survey of model view approaches},
	volume = {18},
	issn = {1619-1374},
	doi = {10.1007/s10270-017-0622-9},
	abstract = {When dealing with complex systems, information is very often fragmented across many different models expressed within a variety of (modeling) languages. To provide the relevant information in an appropriate way to different kinds of stakeholders, (parts of) such models have to be combined and potentially revamped by focusing on concerns of particular interest for them. Thus, mechanisms to define and compute views over models are highly needed. Several approaches have already been proposed to provide (semi)automated support for dealing with such model views. This paper provides a detailed overview of the current state of the art in this area. To achieve this, we relied on our own experiences of designing and applying such solutions in order to conduct a literature review on this topic. As a result, we discuss the main capabilities of existing approaches and propose a corresponding research agenda. We notably contribute a feature model describing what we believe to be the most important characteristics of the support for views on models. We expect this work to be helpful to both current and potential future users and developers of model view techniques, as well as to any person generally interested in model-based software and systems engineering.},
	language = {en},
	number = {3},
	urldate = {2020-03-20},
	journal = {Software \& Systems Modeling},
	author = {Bruneliere, Hugo and Burger, Erik and Cabot, Jordi and Wimmer, Manuel},
	month = jun,
	year = {2019},
	pages = {1931--1952},
}


@incollection{Dijkstra1982SoC,
	address = {New York, NY},
	series = {Texts and {Monographs} in {Computer} {Science}},
	title = {On the {Role} of {Scientific} {Thought}},
	isbn = {978-1-4612-5695-3},
	url = {https://doi.org/10.1007/978-1-4612-5695-3_12},
	abstract = {Essentially, this essay contains nothing new; on the contrary, its subject matter is so old that sometimes it seems forgotten. It is written in an effort to undo some of the more common misunderstandings that I encounter (nearly daily) in my professional world of computing scientists, programmers, computer users and computer designers, and even colleagues engaged in educational politics. The decision to write this essay now was taken because I suddenly realized that my confrontation with this same pattern of misunderstanding was becoming a regular occurrence.},
	language = {en},
	urldate = {2020-03-20},
	booktitle = {Selected {Writings} on {Computing}: {A} personal {Perspective}},
	publisher = {Springer},
	author = {Dijkstra, Edsger W.},
	editor = {Dijkstra, Edsger W.},
	year = {1982},
	doi = {10.1007/978-1-4612-5695-3_12},
	keywords = {Computing Scientist, Gramming Language, Programming Language, Scientific Discipline, Scientific Thought},
	pages = {60--66}
}



@article{DiskinKoenigL2019,
	title = {Multiple model synchronization with multiary delta lenses with amendment {andK}-{Putput}},
	volume = {31},
	issn = {1433-299X},
	doi = {10.1007/s00165-019-00493-0},
	abstract = {Multiple (more than 2) model synchronization is ubiquitous and important for MDE, but its theoretical underpinning gained much less attention than the binary case. Specifically, the latter was extensively studied by the bx community in the framework of algebraic models for update propagation called lenses. We make a step to restore the balance and propose a notion of multiary delta lens. Besides multiarity, our lenses feature reflective updates, when consistency restoration requires some amendment of the update that violated consistency, and a reasonable Put Put law that requires compatibility of update propagation with update composition for a precisely specified restricted class of composable update pairs. We emphasize the importance of various ways of lens composition for practical applications of the framework, and prove several composition results.},
	language = {en},
	number = {5},
	urldate = {2020-03-23},
	journal = {Formal Aspects of Computing},
	author = {Diskin, Zinovy and König, Harald and Lawford, Mark},
	month = nov,
	year = {2019},
	pages = {611--640}
}



@inproceedings{LeblebiciAnjorinFVS2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Leveraging {Incremental} {Pattern} {Matching} {Techniques} for {Model} {Synchronisation}},
	isbn = {978-3-319-61470-0},
	abstract = {Triple Graph Grammars (TGGs) are a declarative, rule-based approach to model synchronisation with numerous implementations. TGG-based approaches derive typically a set of operational graph transformations from direction-agnostic TGG rules to realise model synchronisation. In addition to these derived graph transformations, however, further runtime analyses are required to calculate the consequences of model changes in a synchronisation run. This part of TGG-based synchronisation is currently manually implemented, which not only increases implementation and tool maintenance effort, but also requires tool or at least approach-specific proofs for correctness. In this paper, therefore, we discuss how incremental graph pattern matchers can be leveraged to simplify the runtime steps of TGG-based synchronisation. We propose to outsource the task of calculating the consequences of model changes to an underlying incremental pattern matcher. As a result, a TGG-based synchroniser is reduced to a component reacting solely to appearing and disappearing matches. This abstracts high-level synchronisation goals from low-level details of handling model changes, providing a viable and unifying foundation for a new generation of TGG tools.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {Leblebici, Erhan and Anjorin, Anthony and Fritsche, Lars and Varró, Gergely and Schürr, Andy},
	editor = {de Lara, Juan and Plump, Detlef},
	year = {2017},
	pages = {179--195},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/T62865RL/Leblebici et al. - 2017 - Leveraging Incremental Pattern Matching Techniques.pdf:application/pdf}
}



@inproceedings{WeidmannAnjorinLS2019,
	address = {Athens, Greece},
	series = {{SLE} 2019},
	title = {Consistency management via a combination of triple graph grammars and linear programming},
	isbn = {978-1-4503-6981-7},
	doi = {10.1145/3357766.3359544},
	abstract = {Consistency management is an important task in the context of Domain-Specific Language (DSL) development. It involves operations such as program (model) transformation, synchronisation, integration, and consistency checking, which are all tasks required to enable concurrent engineering using multiple DSLs. Even though consistency management is a well-researched topic, existing approaches either implement a fixed strategy for each consistency management operation, or do not scale for large models. This has been criticised in the literature, as practical applications require not only reasonable scalability with model size, but also unite multiple consistency management tasks within one tool. To raise the adaptability of such a tool to an appropriate level, a uniform way of performing these tasks is a desirable goal. In this paper, we propose an approach to consistency management that leverages a synergetic combination of Triple Graph Grammars and Integer Linear Programming. By modelling consistency management as an optimisation problem with a configurable objective function, we are able to uniformly address a wide range of consistency management operations. We show that our approach scales acceptably in practice, while still guaranteeing that a consistent solution is found if and only if one exists.},
	urldate = {2020-03-23},
	booktitle = {Proceedings of the 12th {ACM} {SIGPLAN} {International} {Conference} on {Software} {Language} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Weidmann, Nils and Anjorin, Anthony and Leblebici, Erhan and Schürr, Andy},
	month = oct,
	year = {2019},
	keywords = {Consistency Checking, Integer Linear Programming, Model Transformation, Triple Graph Grammars},
	pages = {29--41}
}


@article{ErmelHermannGB2012,
	title = {Visual {Modeling} and {Analysis} of {EMF} {Model} {Transformations} {Based} on {Triple} {Graph} {Grammars}},
	volume = {54},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/771},
	doi = {10.14279/tuj.eceasst.54.771},
	abstract = {The tool HENSHIN is an Eclipse plug-in supporting visual modeling and execution of rule-based EMF model transformations. This paper describes the recent extensions of HENSHIN by a visual editor for triple graph grammars (TGGs).The visual editor (called HENSHINTGG) supports a compact visualization of triple rules in an integrated editor panel. Internally, triple graph rules are represented as HENSHIN rules and can be simulated using the HENSHIN EMF model transformation engine. Our extension supports the automatic generation of forward translation rules for transforming source into target models. A converter from HENSHIN TGG rules to the graph transformation analysis tool AGG allows a systematic check for conflicts of forward translation rules in AGG based on critical pair analysis.},
	language = {en},
	number = {0},
	urldate = {2020-03-23},
	journal = {Electronic Communications of the EASST},
	author = {Ermel, Claudia and Hermann, Frank and Gall, Jürgen and Binanzer, Daniel},
	month = dec,
	year = {2012},
	note = {Number: 0},
	file = {Full Text PDF:/Users/past/Zotero/storage/DHZF66IW/Ermel et al. - 2012 - Visual Modeling and Analysis of EMF Model Transfor.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/63YS6S7U/771.html:text/html}
}


@inproceedings{WeidmannAnjorinFVSL2019,
	series = {{CEUR} {Workshop} {Proceedings}},
	title = {Incremental {Bidirectional} {Model} {Transformation} with {eMoflon}: : {IBeX}},
	volume = {2355},
	shorttitle = {Incremental {Bidirectional} {Model} {Transformation} with {eMoflon}},
	url = {http://ceur-ws.org/Vol-2355/paper4.pdf},
	urldate = {2020-03-23},
	booktitle = {Proceedings of the 8th {International} {Workshop} on {Bidirectional} {Transformations} co-located with the {Philadelphia} {Logic} {Week}, {Bx}@{PLW} 2019, {Philadelphia}, {PA}, {USA}, {June} 4, 2019},
	publisher = {CEUR-WS.org},
	author = {Weidmann, Nils and Anjorin, Anthony and Fritsche, Lars and Varró, Gergely and Schürr, Andy and Leblebici, Erhan},
	editor = {Cheney, James and Ko, Hsiang-Shang},
	year = {2019},
	pages = {45--55}
}


@inproceedings{EramoPierantonioR2014,
	address = {Hyderabad, India},
	series = {{MiSE} 2014},
	title = {Uncertainty in bidirectional transformations},
	isbn = {978-1-4503-2849-4},
	url = {https://doi.org/10.1145/2593770.2593772},
	doi = {10.1145/2593770.2593772},
	abstract = {In Model-Driven Engineering, models are primary artifact manipulated by means of automated transformations. Recently, a notion of uncertainty has been introduced in models permitting modelers to postpone design decisions in case of lack of information. Interestingly, other forms of model uncertainty are induced by bidirectional transformations. In fact, in certain situations more than one admissible solution is in principle possible, despite most of the current languages generate only one model at time, possibly not the desired one. In this paper, the uncertainty due to the solution multiplicity in bidirectional transformations is discussed. In particular, we propose to represent the models in the solution space as concretizations of an uncertain model because there are cases where the responsibility of identifying the solution must be left to the modeler. The problem is illustrated by a round-tripping scenario realized with the JTL transformation language.},
	urldate = {2020-03-04},
	booktitle = {Proceedings of the 6th {International} {Workshop} on {Modeling} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Eramo, Romina and Pierantonio, Alfonso and Rosa, Gianni},
	month = jun,
	year = {2014},
	keywords = {MDE, Uncertainty, Bidirectional Model Transformation, JTL},
	pages = {37--42},
	file = {Full Text PDF:/Users/past/Zotero/storage/7QSAYK95/Eramo et al. - 2014 - Uncertainty in bidirectional transformations.pdf:application/pdf}
}


@inproceedings{EramoPierantonioR2015,
	address = {Pittsburgh, PA, USA},
	title = {Managing uncertainty in bidirectional model transformations},
	isbn = {978-1-4503-3686-4},
	doi = {10.1145/2814251.2814259},
	abstract = {In Model-Driven Engineering bidirectionality in transformations is regarded as a key mechanism. Recent approaches to non-deterministic transformations have been proposed for dealing with non-bijectivity. Among them, the JTL language is based on a relational model transformation engine which restores consistency by returning all admissible models. This can be regarded as an uncertainty reducing process: the unknown uncertainty at design-time is translated into known uncertainty at run-time by generating multiple choices. Unfortunately, little changes in a model usually correspond to a combinatorial explosion of the solution space. In this paper, we propose to represent the multiple solutions in a intensional manner by adopting a model for uncertainty. The technique is applied to JTL demonstrating the advantages of the proposal.},
	urldate = {2020-03-04},
	booktitle = {{SLE} 2015},
	publisher = {Association for Computing Machinery},
	author = {Eramo, Romina and Pierantonio, Alfonso and Rosa, Gianni},
	month = oct,
	year = {2015},
	keywords = {Model-Driven Engineering, Bidirectional Model Transformations, Uncertainty},
	pages = {49--58},
}


@article{Westfechtel2018,
	title = {Case-based exploration of bidirectional transformations in {QVT} {Relations}},
	volume = {17},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-016-0527-z},
	doi = {10.1007/s10270-016-0527-z},
	abstract = {QVT Relations (QVT-R), a standard issued by the Object Management Group, is a language for the declarative specification of model transformations. This paper focuses on a particularly interesting feature of QVT-R: the declarative specification of bidirectional transformations. Rather than writing two unidirectional transformations separately, a transformation developer may provide a single relational specification which may be executed in both directions. This approach saves specification effort and ensures the consistency of forward and backward transformations. This paper explores QVT-R’s support for bidirectional model transformations through a spectrum of transformation cases. The transformation cases vary with respect to several factors such as the size of the transformation definition or the relationships between the metamodels for source and target models. The cases are solved in QVT-R, but may be applied to other bidirectional transformation languages, as well; thus, they may be used as a benchmark for comparing bidirectional transformation languages. In our work, we focus on the following research questions: functionality of bidirectional transformations in terms of relations between source and target models, solvability (which problems may be solved by a single relational specification of a bidirectional transformation), variability (does a bidirectional transformation contain varying elements, i.e., elements being specific to one direction), comprehensibility (referring to the ease of understanding and constructing QVT-R transformations), and the semantic soundness of bidirectional transformations written in QVT-R.},
	language = {en},
	number = {3},
	urldate = {2019-10-29},
	journal = {Software \& Systems Modeling},
	author = {Westfechtel, Bernhard},
	month = jul,
	year = {2018},
	keywords = {Bidirectional model transformations, Model-driven software engineering, QVT Relations},
	pages = {989--1029},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/JM79L2IR/Westfechtel - 2018 - Case-based exploration of bidirectional transforma.pdf:application/pdf}
}


@book{NorbisrathZuendorfAJ2013,
	address = {s.l.},
	edition = {1 edition},
	title = {Story {Driven} {Modeling}},
	isbn = {978-1-4839-4925-3},
	abstract = {If you would ask us, whether this is just another book about modeling, we would probably feel inclined to say: yes and no. Yes, it is a lot about modeling, but no, it is also about programming, methodological software design, and rapid prototyping via methods from model driven engineering. It will also be one of the first complete references and teaching guides for Story Driven Modeling. Story Driven Modeling is an agile software development method using objects and scenarios and special modeling steps to facilitate system analysis and design. Most parts of this book can be done with pencil and paper and with standard UML tools and standard software development environments. However, some steps are best supported by the rapid prototyping tool Fujaba or the Story Driven Modeling library SDMLib. The title of this book does not include Object Oriented Modeling on purpose. Object Orientation, Object Oriented Design, Object Oriented Analysis, and other object oriented methods all refer somehow to class diagrams and inheritance. Instead of this, we will actively use objects for modeling, analysis, and design. We will learn to think in objects. This book is foremost planned to be a textbook for software modeling courses. It offers a very interactive and agile approach to modern software design. In this book, we introduce the Objects First principle which is the foundation of the Story Driven Modeling development method. This is not to be mistaken with an object oriented development method. You will see that the Object First method slightly differs from traditional object oriented methods. With this book, we address a majority of readers dealing with or wanting to learn software development. This includes teachers and students for introduction to Object Orientation, Systems Modeling, Object Oriented Design, or Model Driven Engineering. This book should also be insightful for people interested in modeling and program design and beginning programmers. We expect from the reader some very basic programming skills, preferable in Java, though most of the presented concepts in this book can be also applied in any other object oriented language. However, all the examples presented in this book focus on Java as the example language.},
	language = {English},
	publisher = {CreateSpace Independent Publishing Platform},
	author = {Norbisrath, Ulrich and Zündorf, Albert and Jubeh, Ruben},
	month = apr,
	year = {2013}
}


@inproceedings{BascianiRoccoRSIP2014,
	series = {{CEUR} {Workshop} {Proceedings}},
	title = {{MDEForge}: an {Extensible} {Web}-{Based} {Modeling} {Platform}},
	volume = {1242},
	shorttitle = {{MDEForge}},
	url = {http://ceur-ws.org/Vol-1242/paper10.pdf},
	urldate = {2020-03-24},
	booktitle = {{CloudMDE}@{MoDELS} 2014},
	publisher = {CEUR-WS.org},
	author = {Basciani, Francesco and Rocco, Juri Di and Ruscio, Davide Di and Salle, Amleto Di and Iovino, Ludovico and Pierantonio, Alfonso},
	editor = {Paige, Richard F. and Cabot, Jordi and Brambilla, Marco and Rose, Louis M. and Hill, James H.},
	year = {2014},
	pages = {66--75}
}


@inproceedings{Hinkel2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{NMF}: {A} {Multi}-platform {Modeling} {Framework}},
	isbn = {978-3-319-93317-7},
	shorttitle = {{NMF}},
	doi = {10.1007/978-3-319-93317-7_10},
	abstract = {For its promises in terms of increased productivity, Model-driven engineering (MDE) is getting applied increasingly often in both industry and academia. However, most tools currently available are based on the Eclipse Modeling Framework (EMF) and hence based on the Java platform whereas tool support for other platforms is limited. This leads to a language and tool adoption problem for developers of other platforms such as .NET. As a result, few projects on the .NET platform adopt MDE. In this paper, we present the .NET Modeling Framework (NMF), a tool set for model repositories, model-based incrementalization, model transformation, model synchronization and code generation that is now available for a multitude of different operating systems, including Windows, Linux, Android, iOS and Mac. The framework makes intensive use of the C\# language as host language for model transformation and synchronization languages, whereas the model repository serialization is compatible with EMF. This solves the language adoption problem for C\# programmers and creates a bridge to the EMF platform.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformation}},
	publisher = {Springer International Publishing},
	author = {Hinkel, Georg},
	editor = {Rensink, Arend and Sánchez Cuadrado, Jesús},
	year = {2018},
	pages = {184--194}
}


@article{HinkelGoldschmidtBR2019,
	title = {Using internal domain-specific languages to inherit tool support and modularity for model transformations},
	volume = {18},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-017-0578-9},
	doi = {10.1007/s10270-017-0578-9},
	abstract = {Model-driven engineering (MDE) has proved to be a useful approach to cope with today’s ever-growing complexity in the development of software systems; nevertheless, it is not widely applied in industry. As suggested by multiple studies, tool support is a major factor for this lack of adoption. In particular, the development of model transformations lacks good tool support. Additionally, modularization techniques are inevitable for the development of larger model transformations to keep them maintainable. Existing tools for MDE, in particular model transformation approaches, are often developed by small teams and cannot keep up with advanced tool support for mainstream general-purpose programming languages, such as IntelliJ or Visual Studio. Internal DSLs are a promising solution to these problems. In this paper, we investigate the impact of design decisions of an internal DSL to the reuse of tool support and modularization concepts from the host language. We validate our findings in terms of understandability, applicability, tool support, and extensibility using three case studies from academia, a model-driven engineering platform, and the industrial automation domain where we apply an implementation of an internal model transformation language on the .NET platform. The results confirm the value of inherited modularity and tool support while conciseness and understandability are still competitive.},
	language = {en},
	number = {1},
	urldate = {2020-03-24},
	journal = {Software \& Systems Modeling},
	author = {Hinkel, Georg and Goldschmidt, Thomas and Burger, Erik and Reussner, Ralf},
	month = feb,
	year = {2019},
	pages = {129--155}
}


@inproceedings{BuchmannGreiner2016,
	title = {Handcrafting a {Triple} {Graph} {Transformation} {System} to {Realize} {Round}-trip {Engineering} {Between} {UML} {Class} {Models} and {Java} {Source} {Code}},
	doi = {10.5220/0005957100270038},
	abstract = {Model transformations are a mandatory requirement for model-driven development, a software engineering discipline, which has become more and more popular during the last decade. Over the years, the concept of unidirectional model transformations and corresponding tool support reached maturity since these kind of transformations are widely used in model-driven engineering, mainly for forward engineering and code generation. In incremental and iterative software engineering processes, forward engineering may be too restrictive since it resembles waterfall-like processes. Thus, bidirectional transformations are required, which aim to provide support for (incrementally) transforming one or more source model to one or more target model and vice versa from only one transformation description. However, they seem to be rarely used in modeldriven software development as adequate tool support is missing. On the other hand, programming languages nowadays provide support for higher-level features like closures or lambda expressions which allow to describe transformation patterns in a declarative way. In this paper, we present an approach for round-trip engineering between UML class models and Java source code, which is realized with a triple graph transformation system written in the Xtend programming language.},
	booktitle = {{ICSOFT}-{PT}},
	author = {Buchmann, Thomas and Greiner, Sandra},
	year = {2016}
}


@inproceedings{EramoPierantonioT2018,
	address = {Nice, France},
	series = {Programming'18 {Companion}},
	title = {Enhancing the {JTL} tool for bidirectional transformations},
	isbn = {978-1-4503-5513-1},
	url = {https://doi.org/10.1145/3191697.3191720},
	doi = {10.1145/3191697.3191720},
	abstract = {In Model-Driven Engineering, the potential advantages of using bidirectional transformations in various scenarios are largely recognized; as for instance, assuring the overall consistency of a set of interrelated models which requires the capability of propagating changes back and forth the transformation chain. Among the existing approaches, JTL (Janus Transformation Language) is a constraint-based bidirectional transformation language specifically tailored to support change propagation and non-deterministic transformations. In fact, its relational and constraint-based semantics allows to restore consistency by returning all admissible models. This paper introduces the new implementation of the language and presents the tools and its features by means of a running example.},
	urldate = {2020-03-04},
	booktitle = {Conference {Companion} of the 2nd {International} {Conference} on {Art}, {Science}, and {Engineering} of {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Eramo, Romina and Pierantonio, Alfonso and Tucci, Michele},
	month = apr,
	year = {2018},
	keywords = {MDE, Bidirectional model transformation, JTL},
	pages = {36--41},
	file = {Full Text PDF:/Users/past/Zotero/storage/P7KW5US4/Eramo et al. - 2018 - Enhancing the JTL tool for bidirectional transform.pdf:application/pdf}
}


@article{LambersHildebrandtGO2012,
	title = {Attribute {Handling} for {Bidirectional} {Model} {Transformations}: {The} {Triple} {Graph} {Grammar} {Case}},
	volume = {49},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	shorttitle = {Attribute {Handling} for {Bidirectional} {Model} {Transformations}},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/706},
	doi = {10.14279/tuj.eceasst.49.706},
	abstract = {When describing bidirectional model transformations in a declarative (relational) way, the relation between structures in source and target models is specified. But not only structural correspondences between source and target models need to be described. Another important aspect is the specification of the relation between attribute values of elements in source and target models. However, most existing approaches either do not allow such a relational kind of specification for attributes or allow it only in a restricted way.We consider the challenge of bridging the gap between a flexible declarative attribute specification and its operationalization for the triple graph grammar (TGG) specification technique as an important representative for describing bidirectional model transformations in a relational way. First, we present a formal way to specify attributes in TGG rules in a purely declarative (relational) way. Then, we give an overview of characteristic barriers that bidirectional model transformation tool developers are confronted with when operationalizing relational attribute constraints for different TGG application scenarios. Moreover, we present pragmatic solutions to overcome the operationalization barriers for different TGG application scenarios in our own TGG implementation.},
	language = {en},
	number = {0},
	urldate = {2019-09-30},
	journal = {Electronic Communications of the EASST},
	author = {Lambers, Leen and Hildebrandt, Stephan and Giese, Holger and Orejas, Fernando},
	month = jul,
	year = {2012},
	file = {Full Text PDF:/Users/past/Zotero/storage/K99YENGI/Lambers et al. - 2012 - Attribute Handling for Bidirectional Model Transfo.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/W66GN3EZ/706.html:text/html}
}


@inproceedings{SchurrWinterZ1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Graph grammar engineering with {PROGRES}},
	isbn = {978-3-540-45552-3},
	doi = {10.1007/3-540-60406-5_17},
	abstract = {Graph-like data structures and rule-based systems play an important role within many branches of computer science. Nevertheless, their symbiosis in the form of graph rewriting systems or graph grammars are not yet popular among software engineers. This is a consequence of the fact that graph grammar tools were not available until recently and of the lack of knowledge about how to use graph grammars for software development purposes. “Graph grammar engineering” is a first attempt to establish a new graph and rule centered methodology for the development of information system components. Having its roots in the late 80's it gradually evolved from a “paper and pencil” specification formalism to a tool-assisted specification and rapid prototyping approach.},
	language = {en},
	booktitle = {Software {Engineering} — {ESEC} '95},
	publisher = {Springer},
	author = {Schürr, Andy and Winter, Andreas J. and Zündorf, Albert},
	editor = {Schäfer, Wilhelm and Botella, Pere},
	year = {1995},
	keywords = {Graph Grammar, Graph Pattern, Graph Schema, Graph Transformation, Node Class},
	pages = {219--234}
}


@inproceedings{NickelNiereZ2000,
	address = {Limerick, Ireland},
	title = {Tool demonstration: {The} {FUJABA} environment},
	booktitle = {Proc. of the 22nd {International} {Conference} on {Software} {Engineering} ({ICSE}), {Limerick}, {Ireland}},
	publisher = {ACM Press},
	author = {Nickel, Ulrich and Niere, Jörg and Zündorf, Albert},
	year = {2000},
	pages = {742--745}
}


@inproceedings{XiongLiuHZTM2007,
	address = {Atlanta, Georgia, USA},
	series = {{ASE} '07},
	title = {Towards automatic model synchronization from model transformations},
	isbn = {978-1-59593-882-4},
	url = {https://doi.org/10.1145/1321631.1321657},
	doi = {10.1145/1321631.1321657},
	abstract = {The metamodel techniques and model transformation techniques provide a standard way to represent and transform data, especially the software artifacts in software development. However, after a transformation is applied, the source model and the target model usually co-exist and evolve independently. How to propagate modifications across models in different formats still remains as an open problem. In this paper we propose an automatic approach to synchronizing models that are related by model transformations. Given a unidirectional transformation between metamodels, we can automatically synchronize models in the metamodels by propagating modifications across the models. We have implemented a model synchronization system supporting the Atlas Transformation Language (ATL) and have successfully tested our implementation on several ATL transformation examples in the ATL web site.},
	urldate = {2020-03-14},
	booktitle = {Proceedings of the twenty-second {IEEE}/{ACM} international conference on {Automated} software engineering},
	publisher = {Association for Computing Machinery},
	author = {Xiong, Yingfei and Liu, Dongxi and Hu, Zhenjiang and Zhao, Haiyan and Takeichi, Masato and Mei, Hong},
	month = nov,
	year = {2007},
	keywords = {ATL, model transformation, MDA, model synchronization},
	pages = {164--173},
	file = {Full Text PDF:/Users/past/Zotero/storage/2MIXKKGU/Xiong et al. - 2007 - Towards automatic model synchronization from model.pdf:application/pdf}
}


@inproceedings{EgyedLetierF2008,
	title = {Generating and {Evaluating} {Choices} for {Fixing} {Inconsistencies} in {UML} {Design} {Models}},
	doi = {10.1109/ASE.2008.20},
	abstract = {Our objective is to provide automated support for assisting designers in fixing inconsistencies in UML models. We have previously developed techniques for efficiently detecting inconsistencies in such models and identifying where changes need to occur in order to fix problems detected by these means. This paper extends previous work by describing a technique for automatically generating a set of concrete changes for fixing inconsistencies and providing information about the impact of each change on all consistency rules. The approach is integrated with the design tool IBM Rational Rose . We demonstrate the computational scalability and usability of the approach through the empirical evaluation of 39 UML models of sizes up to 120,000 elements.},
	booktitle = {2008 23rd {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	author = {Egyed, A. and Letier, E. and Finkelstein, A.},
	month = sep,
	year = {2008},
	keywords = {Unified modeling language, Unified Modeling Language, Computational modeling, computational scalability, Generators, IBM Rational Rose, Manuals, Receivers, Servers, UML design model, Writing},
	pages = {99--108},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/77QYC8C2/4639313.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/N6JZ7N3J/Egyed et al. - 2008 - Generating and Evaluating Choices for Fixing Incon.pdf:application/pdf}
}


@article{EasterbrookNuseibeh1996,
	title = {Using {ViewPoints} for inconsistency management},
	volume = {11},
	issn = {0268-6961},
	doi = {10.1049/sej.1996.0004},
	abstract = {Large-scale software development is an evolutionary process. In an evolving specification, multiple development participants often hold multiple inconsistent views on the system being developed, and considerable effort is spent handling recurrent inconsistencies. Detecting and resolving inconsistencies is only part of the problem; a resolved inconsistency might not stay resolved as a specification evolves. Frameworks in which inconsistency is tolerated help by allowing resolution to be delayed. However, the evolution of a specification may affect both resolved and unresolved inconsistencies. A framework is presented and elaborated in which software development knowledge is partitioned into multiple views called ViewPoints. Inconsistencies between ViewPoints are managed by explicitly representing relationships between them, and recording both resolved and unresolved inconsistencies. It is assumed that ViewPoints will often be inconsistent, and so a complete work record is kept, detailing any inconsistencies that have been detected and what actions, if any, have been taken to resolve them. The work record is then used to reason about the effects of subsequent changes to ViewPoints, without constraining the development process. The paper demonstrates how inconsistency management is used as a tool for requirements elicitation and how ViewPoints provide a vehicle for achieving this. Inconsistency is used as a stimulus for eliciting missing information and capturing user-defined relationships that arise between elements of an evolving specification.},
	number = {1},
	journal = {Software Engineering Journal},
	author = {Easterbrook, S. and Nuseibeh, B.},
	month = jan,
	year = {1996},
	keywords = {formal specification, software engineering, Software engineering, requirements elicitation, inconsistency management, configuration management, evolutionary process, evolving specification, explicitly represented relationships, large-scale software development, missing information, multiple development participants, multiple inconsistent views, recurrent inconsistencies, resolved inconsistencies, software development knowledge partitioning, Software requirements and specifications, unresolved inconsistencies, user-defined relationships, ViewPoints, work record, MOTIVATION},
	pages = {31--43},
	file = {Full Text:/Users/past/Zotero/storage/EUD27D2K/Easterbrrok and Nuseibeh - 1996 - Using ViewPoints for inconsistency management.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/past/Zotero/storage/3LFI6ZPZ/487321.html:text/html}
}


@article{BoronatMeseguer2010,
	title = {An algebraic semantics for {MOF}},
	volume = {22},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-009-0140-9},
	doi = {10.1007/s00165-009-0140-9},
	abstract = {In model-driven development, software artifacts are represented as models in order to improve productivity, quality, and cost effectiveness. In this area, the meta-object facility (MOF) standard plays a crucial role as a generic framework within which a wide range of modeling languages can be defined. The MOF standard aims at offering a good basis for model-driven development, providing some of the building concepts that are needed: what is a model, what is a metamodel, what is reflection in the MOF framework, and so on. However, most of these concepts are not yet fully formally defined in the current MOF standard. In this paper we define a reflective, algebraic, executable framework for precise metamodeling based on membership equational logic (mel) that supports the MOF standard. Our framework provides a formal semantics of the following notions: metamodel, model, and conformance of a model to its metamodel. Furthermore, by using the Maude language, which directly supports mel specifications, this formal semantics is executable. This executable semantics has been integrated within the Eclipse modeling framework as a plugin tool called MOMENT2. In this way, formal analyses, such as semantic consistency checks, model checking of invariants and LTL model checking, become available within Eclipse to provide formal support for model-driven development processes.},
	language = {en},
	number = {3},
	urldate = {2020-03-26},
	journal = {Formal Aspects of Computing},
	author = {Boronat, Artur and Meseguer, José},
	month = may,
	year = {2010},
	pages = {269--296},
	file = {Submitted Version:/Users/past/Zotero/storage/B7KCT8G7/Boronat and Meseguer - 2010 - An algebraic semantics for MOF.pdf:application/pdf}
}



@article{BergmannRathVV2012,
	title = {Change-driven model transformations},
	volume = {11},
	issn = {1619-1374},
	doi = {10.1007/s10270-011-0197-9},
	abstract = {In this paper, we investigate change-driven model transformations, a novel class of transformations, which are directly triggered by complex model changes carried out by arbitrary transactions on the model (e.g. editing operation, transformation, etc). After a classification of relevant change scenarios, we identify challenges for change-driven transformations. As the main technical contribution of the current paper, we define an expressive, high-level language for specifying change-driven transformations as an extension of graph patterns and graph transformation rules. This language generalizes previous results on live model transformations by offering trigger events for arbitrarily complex model changes, and dedicated reactions for specific kinds of changes, making this way the concept of change to be a first-class citizen of the transformation language. We discuss how the underlying transformation engine needs to be adapted in order to use the same language uniformly for different change scenarios. The technicalities of our approach will be discussed on a (1) model synchronization case study with non-materialized target models and (2) a case study on detecting the violation of evolutionary (temporal) constraints in the security requirements engineering domain.},
	language = {en},
	number = {3},
	urldate = {2020-03-14},
	journal = {Software \& Systems Modeling},
	author = {Bergmann, Gábor and Ráth, István and Varró, Gergely and Varró, Dániel},
	month = jul,
	year = {2012},
	pages = {431--461},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/3C7C7ZHD/Bergmann et al. - 2012 - Change-driven model transformations.pdf:application/pdf}
}



@inproceedings{EngelsHausmannHS2000,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dynamic {Meta} {Modeling}: {A} {Graphical} {Approach} to the {Operational} {Semantics} of {Behavioral} {Diagrams} in {UML}},
	isbn = {978-3-540-40011-0},
	shorttitle = {Dynamic {Meta} {Modeling}},
	doi = {10.1007/3-540-40011-7_23},
	abstract = {In this paper, dynamic meta modeling is proposed as a new approach to the operational semantics of behavioral UML diagrams. The dynamic meta model extends the well-known static meta model by a speci.cation of the system’s dynamics by means of collaboration diagrams. In this way, it is possible to de.ne the behavior of UML diagrams within UML.The conceptual idea is inherited from Plotkin’s structured operational semantics (SOS) paradigm, a style of semantics speci.cation for concurrent programming languages and process calculi: Collaboration diagrams are used as deduction rules to specify a goal-oriented interpreter for the language. The approach is exemplified using a fragment of UML statechart and object diagrams.Formally, collaboration diagrams are interpreted as graph transformation rules. In this way, dynamic UML semantics can be both mathematically rigorous so as to enable formal specifications and proofs and, due to the use of UML notation, understandable without prior knowledge of heavy mathematic machinery. Thus, it can be used as a reference by tool developers, teachers, and advanced users.},
	language = {en},
	booktitle = {{UML} 2000 — {The} {Unified} {Modeling} {Language}},
	publisher = {Springer},
	author = {Engels, Gregor and Hausmann, Jan Hendrik and Heckel, Reiko and Sauer, Stefan},
	editor = {Evans, Andy and Kent, Stuart and Selic, Bran},
	year = {2000},
	keywords = {graph transformation, precise behavioral semantics, statechart diagrams, UML meta model},
	pages = {323--337}
}


@inproceedings{SalayMylopoulosE2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Using {Macromodels} to {Manage} {Collections} of {Related} {Models}},
	isbn = {978-3-642-02144-2},
	abstract = {The creation and manipulation of multiple related models is common in software development, however there are few tools that help to manage such collections of models. We propose a framework in which different types of model relationships – such as submodelOfand refinementOf – can be formally defined and used with a new type of model, called a macromodel, to express the required relationships between models at a high-level of abstraction. Macromodels can be used to support the development, comprehension, consistency management and evolution of sets of related models. We illustrate the framework with a detailed example from the telecommunications industry and describe a prototype implementation.},
	language = {en},
	booktitle = {Advanced {Information} {Systems} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Salay, Rick and Mylopoulos, John and Easterbrook, Steve},
	editor = {van Eck, Pascal and Gordijn, Jaap and Wieringa, Roel},
	year = {2009},
	keywords = {Modeling, Metamodeling, Macromodeling, Mappings, Relationships},
	pages = {141--155},
	doi = {10.1007/978-3-642-02144-2_15}
}



@inproceedings{CicchettiDiRuscioP2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Managing {Dependent} {Changes} in {Coupled} {Evolution}},
	isbn = {978-3-642-02408-5},
	doi = {10.1007/978-3-642-02408-5_4},
	abstract = {In Model-Driven Engineering models and metamodels are not preserved from the evolutionary pressure which inevitably affects almost any artefacts. Moreover, the coupling between models and metamodels implies that when a metamodel undergoes a modification, the conforming models require to be accordingly co-adapted. One of the main obstacles to the complete automation of the adaptation process is represented by the dependencies which occur among the different kinds of modifications. The paper illustrates a dependency analysis, classifies such dependencies, and proposes a metamodeling language driven resolution which is independent from the evolving metamodel and its underlying semantics. The resolution enables a decomposition and consequent scheduling of the adaptation steps allowing the full automation of the process.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformations}},
	publisher = {Springer},
	author = {Cicchetti, Antonio and Di Ruscio, Davide and Pierantonio, Alfonso},
	editor = {Paige, Richard F.},
	year = {2009},
	keywords = {Model Transformation, Couple Evolution, Dependent Change, Model Drive Engineer, Parallel Dependence},
	pages = {35--51},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/EMLTWFYR/Cicchetti et al. - 2009 - Managing Dependent Changes in Coupled Evolution.pdf:application/pdf}
}


@article{SaitoShapiro2005,
	title = {Optimistic replication},
	volume = {37},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/1057977.1057980},
	doi = {10.1145/1057977.1057980},
	abstract = {Data replication is a key technology in distributed systems that enables higher availability and performance. This article surveys optimistic replication algorithms. They allow replica contents to diverge in the short term to support concurrent work practices and tolerate failures in low-quality communication links. The importance of such techniques is increasing as collaboration through wide-area and mobile networks becomes popular.Optimistic replication deploys algorithms not seen in traditional “pessimistic” systems. Instead of synchronous replica coordination, an optimistic algorithm propagates changes in the background, discovers conflicts after they happen, and reaches agreement on the final contents incrementally.We explore the solution space for optimistic replication algorithms. This article identifies key challenges facing optimistic replication systems---ordering operations, detecting and resolving conflicts, propagating changes efficiently, and bounding replica divergence---and provides a comprehensive survey of techniques developed for addressing these challenges.},
	number = {1},
	urldate = {2020-03-05},
	journal = {ACM Computing Surveys},
	author = {Saito, Yasushi and Shapiro, Marc},
	month = mar,
	year = {2005},
	keywords = {disconnected operation, distributed systems, large scale systems, optimistic techniques, Replication},
	pages = {42--81},
	file = {Full Text PDF:/Users/past/Zotero/storage/IL85WHVX/Saito and Shapiro - 2005 - Optimistic replication.pdf:application/pdf}
}


@article{XiongSongHT2013,
	title = {Synchronizing concurrent model updates based on bidirectional transformation},
	volume = {12},
	issn = {1619-1374},
	doi = {10.1007/s10270-010-0187-3},
	abstract = {Model-driven software development often involves several related models. When models are updated, the updates need to be propagated across all models to make them consistent. A bidirectional model transformation keeps two models consistent by updating one model in accordance with the other. However, it does not work when the two models are modified at the same time. In this paper we first examine the requirements for synchronizing concurrent updates. We view a synchronizer for concurrent updates as a function taking the two original models and the two updated models as input, and producing two new models where the updates are synchronized. We argue that the synchronizer should satisfy three properties that we define to ensure a reasonable synchronization behavior. We then propose a new algorithm to wrap any bidirectional transformation into a synchronizer with the help of model difference approaches. We show that synchronizers produced by our algorithm are ensured to satisfy the three properties if the bidirectional transformation satisfies the correctness property and the hippocraticness property. We also show that the history ignorance property contributes to the symmetry of our algorithm. An implementation of our algorithm shows that it worked well in a practical runtime management framework.},
	language = {en},
	number = {1},
	urldate = {2019-08-21},
	journal = {Software \& Systems Modeling},
	author = {Xiong, Yingfei and Song, Hui and Hu, Zhenjiang and Takeichi, Masato},
	month = feb,
	year = {2013},
	keywords = {Bidirectional transformation, Model synchronization, Concurrent updates, Model difference, Model integration},
	pages = {89--104}
}


@book{ArenasBarceloLM2014,
	address = {Cambridge},
	title = {Foundations of {Data} {Exchange}},
	isbn = {978-1-107-01616-3},
	abstract = {The problem of exchanging data between different databases with different schemas is an area of immense importance. Consequently data exchange has been one of the most active research topics in databases over the past decade. Foundational questions related to data exchange largely revolve around three key problems: how to build target solutions; how to answer queries over target solutions; and how to manipulate schema mappings themselves? The last question is also known under the name 'metadata management', since mappings represent metadata, rather than data in the database. In this book the authors summarize the key developments of a decade of research. Part I introduces the problem of data exchange via examples, both relational and XML; Part II deals with exchanging relational data; Part III focuses on exchanging XML data; and Part IV covers metadata management.},
	publisher = {Cambridge University Press},
	author = {Arenas, Marcelo and Barceló, Pablo and Libkin, Leonid and Murlak, Filip},
	year = {2014},
	doi = {10.1017/CBO9781139060158}
}



@article{KlareSymaBR2019,
	title = {A {Categorization} of {Interoperability} {Issues} in {Networks} of {Transformations}},
	volume = {18},
	doi = {10.5381/jot.2019.18.3.a4.},
	abstract = {Bidirectional transformations (BX) are a common approach for keeping two types of models consistent, but consistency preservation between more than two types of models is not researched well. One solution is the composition of BX to networks of transformations. Nevertheless, such networks are prone to failures due to interoperability issues between the individual BX, which are independently developed by various experts. We therefore systematically identify and categorize such issues. First, we structure the process of consistency specification into different conceptual levels. Then we develop a catalog of potential mistakes, which we derive from those levels, and consequential failure types. Finally, we discuss strategies to avoid mistakes at the different levels. This catalog is beneficial for transformation developers and transformation language developers. It improves awareness in developers of potential mistakes and consequential failures, enables the development of techniques to avoid specific mistakes by construction, and eases the identification of reasons for failures.},
	number = {3},
	journal = {Journal of Object Technology},
	author = {Klare, Heiko and Syma, Torsten and Burger, Erik and Reussner, Ralf},
	year = {2019},
	pages = {1--20}
}



@book{HuthRyan2004,
	address = {Cambridge},
	edition = {2},
	title = {Logic in {Computer} {Science}: {Modelling} and {Reasoning} about {Systems}},
	isbn = {978-0-521-54310-1},
	abstract = {Recent years have seen the development of powerful tools for verifying hardware and software systems, as companies worldwide realise the need for improved means of validating their products. There is increasing demand for training in basic methods in formal reasoning so that students can gain proficiency in logic-based verification methods. The second edition of this successful textbook addresses both those requirements, by continuing to provide a clear introduction to formal reasoning which is both relevant to the needs of modern computer science and rigorous enough for practical application. Improvements to the first edition have been made throughout, with extra and expanded sections on SAT solvers, existential/universal second-order logic, micro-models, programming by contract and total correctness. The coverage of model-checking has been substantially updated. Further exercises have been added. Internet support for the book includes worked solutions for all exercises for teachers, and model solutions to some exercises for students.},
	publisher = {Cambridge University Press},
	author = {Huth, Michael and Ryan, Mark},
	year = {2004},
	doi = {10.1017/CBO9780511810275}
}



@book{JacobsonLawsonNMG2019,
	title = {The {Essentials} of {Modern} {Software} {Engineering}: {Free} the {Practices} from the {Method} {Prisons}!},
	isbn = {978-1-947487-27-7},
	shorttitle = {The {Essentials} of {Modern} {Software} {Engineering}},
	abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods. This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons. The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering. Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
	publisher = {Association for Computing Machinery and Morgan \& Claypool},
	author = {Jacobson, Ivar and Lawson, Harold "Bud" and Ng, Pan-Wei and McMahon, Paul E. and Goedicke, Michael},
	year = {2019}
}



@techreport{NaurRandell1968,
	address = {Brussels},
	title = {Software {Engineering}: {Report} of a conference sponsored by the {NATO} {Science} {Committee}, {Garmisch}, {Germany}, 7-11 {Oct}. 1968},
	shorttitle = {Software {Engineering}},
	institution = {Scientific Affairs Division, NATO},
	author = {Naur, Peter and Randell, Brian},
	year = {1969},
	pages = {136}
}




@article{LoregianRiehl2019,
	title = {Categorical notions of fibration},
	issn = {0723-0869},
	url = {http://www.sciencedirect.com/science/article/pii/S0723086918300872},
	doi = {10.1016/j.exmath.2019.02.004},
	abstract = {Fibrations over a category B, introduced to category theory by Grothendieck, encode pseudo-functors Bop⇝Cat, while the special case of discrete fibrations encodes presheaves Bop→Set. A two-sided discrete variation encodes functors Bop×A→Set, which are also known as profunctors from A to B. By work of Street, all of these fibration notions can be defined internally to an arbitrary 2-category or bicategory. While the two-sided discrete fibrations model profunctors internally to Cat, unexpectedly, the dual two-sided codiscrete cofibrations are necessary to model V-profunctors internally to V-Cat.},
	language = {en},
	urldate = {2020-04-30},
	journal = {Expositiones Mathematicae},
	author = {Loregian, Fosco and Riehl, Emily},
	month = jun,
	year = {2019},
	keywords = {Grothendieck fibration, Profunctor, Two-sided fibration}
}


@article{Grothendieck2004,
	title = {Rev\^{e}tements \'{e}tales et groupe fondamental ({SGA} 1)},
	url = {http://arxiv.org/abs/math/0206203},
	abstract = {Le texte pr{\textbackslash}'esente les fondements d'une th{\textbackslash}'eorie du groupe fondamental en G{\textbackslash}'eom{\textbackslash}'etrie Alg{\textbackslash}'ebrique, dans le point de vue ``kroneckerien'' permettant de traiter sur le m{\textbackslash}{\textasciicircum}eme pied le cas d'une vari{\textbackslash}'et{\textbackslash}'e alg{\textbackslash}'ebrique au sens habituel, et celui d'un anneau des entiers d'un corps de nombres, par exemple. The text presents the foundations of a theory of the fundamental group in Algebraic Geometry from the Kronecker point of view, allowing one to treat on an equal footing the case of an algebraic variety in the usual sense, and that of the ring of integers in a number field, for instance.},
	urldate = {2020-04-30},
	journal = {arXiv:math/0206203},
	author = {Grothendieck, Alexander and Raynaud, Michele},
	month = jan,
	year = {1971},
	note = {arXiv: math/0206203},
	keywords = {14 (primary), 11G (secondary), Mathematics - Algebraic Geometry, Mathematics - Category Theory, Mathematics - Number Theory},
	file = {arXiv Fulltext PDF:/Users/past/Zotero/storage/ME6QE7A2/Grothendieck and Raynaud - 2004 - Rev^etements 'etales et groupe fondamental (SGA .pdf:application/pdf;arXiv.org Snapshot:/Users/past/Zotero/storage/N3PRSA2F/0206203.html:text/html}
}


@inproceedings{Gray1966,
	address = {Berlin, Heidelberg},
	title = {Fibred and {Cofibred} {Categories}},
	isbn = {978-3-642-99902-4},
	doi = {10.1007/978-3-642-99902-4_2},
	abstract = {Fibred categories were introduced by Gkothendieck in [SGA] and [BB190]. As far as I know these are the only easily available references to the subject. Through sheer luck, during the final preparation of this paper I obtained a copy of handwritten notes [BN] of a seminar given by Chevalley at Berkeley in 1962 which treated these questions from a slightly different point of view. We discuss the “Chevalley condition” in 3.11.},
	language = {en},
	booktitle = {Proceedings of the {Conference} on {Categorical} {Algebra}},
	publisher = {Springer},
	author = {Gray, John W.},
	editor = {Eilenberg, S. and Harrison, D. K. and MacLane, S. and Röhrl, H.},
	year = {1966},
	keywords = {Forgetful Functor, Left Adjoint, Left Ideal, Left Limit, Natural Transformation},
	pages = {21--83}
}



@inproceedings{AtkinsonTunjicM2015,
	title = {Fundamental {Realization} {Strategies} for {Multi}-view {Specification} {Environments}},
	doi = {10.1109/EDOC.2015.17},
	abstract = {All Enterprise Architecture Modeling (EAM) approaches revolve around the use of multiple, inter-related views to describe the properties of a system and its surrounding environment - that is, they are multi-view specification (MVS) approaches. However, there is still little consensus on how such modeling environments should be realized and on the pros and cons of the different fundamental design choices involved in building them. In this paper we identify the different design choices put forward in the literature, evaluate their mutual compatibility, and discuss the extent to which they scale up to large enterprise systems. Finally we present some additional choices and outline some of the key features that future multi-view modeling environments should ideally support.},
	booktitle = {2015 {IEEE} 19th {International} {Enterprise} {Distributed} {Object} {Computing} {Conference}},
	author = {Atkinson, Colin and Tunjic, Christian and Möller, Torben},
	month = sep,
	year = {2015},
	note = {ISSN: 1541-7719},
	keywords = {business data processing, Computer architecture, Context, design choices, EAM, enterprise architecture modeling, large enterprise systems, model-driven development, modeling environments, multi-view specification, multiple-interrelated views, multiview specification environments, mutual compatibility, MVS, Pragmatics, realization strategies, Redundancy, Reliability engineering, software architecture, Standards, viewpoints, views},
	pages = {40--49},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/GJMSMVHV/7321154.html:text/html}
}


@inproceedings{Kent2002,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Model {Driven} {Engineering}},
	isbn = {978-3-540-47884-3},
	doi = {10.1007/3-540-47884-1_16},
	abstract = {The Object Management Group’s (OMG) Model Driven Architecture (MDA) strategy envisages a world where models play a more direct role in software production, being amenable to manipulation and transformation by machine. Model Driven Engineering (MDE) is wider in scope than MDA. MDE combines process and analysis with architecture. This article sets out a framework for model driven engineering, which can be used as a point of reference for activity in this area. It proposes an organisation of the modelling ‘space’ and how to locate models in that space. It discusses different kinds of mappings between models. It explains why process and architecture are tightly connected. It discusses the importance and nature of tools. It identifies the need for defining families of languages and transformations, and for developing techniques for generating/configuring tools from such definitions. It concludes with a call to align metamodelling with formal language engineering techniques.},
	language = {en},
	booktitle = {Integrated {Formal} {Methods}},
	publisher = {Springer},
	author = {Kent, Stuart},
	editor = {Butler, Michael and Petre, Luigia and Sere, Kaisa},
	year = {2002},
	keywords = {Abstract Syntax, Object Management Group, Model Drive Architecture, Meta Object Facility, Model Drive Engineering},
	pages = {286--298},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/MUWV3TBK/Kent - 2002 - Model Driven Engineering.pdf:application/pdf}
}


@article{FinkelsteinKramerNFG1992,
	title = {Viewpoints: a framework for integrating multiple perspectives in system development},
	volume = {02},
	issn = {0218-1940},
	shorttitle = {Viewpoints},
	doi = {10.1142/S0218194092000038},
	abstract = {This paper outlines a framework which supports the use of multiple perspectives in system development, and provides a means for developing and applying systems design methods. The framework uses "viewpoints" to partition the system specification, the development method and the formal representations used to express the system specifications. This VOSE (viewpoint-oriented systems engineering) framework can be used to support the design of heterogeneous and composite systems. We illustrate the use of the framework with a small example drawn from composite system development and give an account of prototype automated tools based on the framework.},
	number = {01},
	urldate = {2020-03-14},
	journal = {International Journal of Software Engineering and Knowledge Engineering},
	author = {Finkelstein, A. and Kramer, J. and Nuseibeh, B. and Finkelstein, L. and Goedicke, M.},
	month = mar,
	year = {1992},
	note = {Publisher: World Scientific Publishing Co.},
	pages = {31--57},
}




@incollection{GoldschmidtBeckerB2012,
	title = {Towards a tool-oriented taxonomy of view-based modelling},
	isbn = {978-3-88579-295-6},
	url = {http://dl.gi.de/handle/20.500.12116/18148},
	abstract = {The separation of view and model is one of the key concepts of Model- Driven Engineering (MDE). Having different views on a central model helps modellers to focus on specific aspects. Approaches for the creation of Domain-Specific Modelling Languages (DSML) allow language engineers to define languages tailored for specific problems. To be able to build DSMLs that also benefit from view-based modelling a common understanding of the properties of both paradigms is required. However, research has not yet considered the combination of both paradigms, namely view-based domain specific modelling to a larger extent. Especially, a comprehensive analysis of a view's properties (e.g., partial, overlapping, editable, persistent, etc.) has not been conducted. Thus, it is also still unclear to which extent view-based modelling is understood by current DSML approaches and what a common understanding if this paradigm is. In this paper, we explore view-based modelling in a tool-oriented way. Furthermore, we analyse the properties of the view-based domain-specific modelling concept and provide a feature-based classification of these properties.},
	language = {en},
	urldate = {2020-05-11},
	booktitle = {Modellierung 2012},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Goldschmidt, Thomas and Becker, Steffen and Burger, Erik},
	editor = {Sinz, Elmar and Schürr, Andy},
	year = {2012},
	note = {Accepted: 2018-11-14T09:41:29Z
ISSN: 1617-5468},
	pages = {59--74},
	file = {Full Text PDF:/Users/past/Zotero/storage/TKCEU42Z/Goldschmidt et al. - 2012 - Towards a tool-oriented taxonomy of view-based mod.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/QPX7MWWY/18148\;jsessionid=A0B966372ED7E9B064FACF721A796AE1.html:text/html}
}


@inproceedings{deLaraGuerraKH2018,
	address = {Boston, MA, USA},
	title = {Facet-oriented modelling: open objects for model-driven engineering},
	isbn = {978-1-4503-6029-6},
	shorttitle = {Facet-oriented modelling},
	doi = {10.1145/3276604.3276610},
	abstract = {Model-driven engineering (MDE) promotes models as the principal assets in software projects. Models are built using a modelling language whose syntax is defined by a metamodel. Hence, objects in models are typed by a metamodel class, and this typing relation is static as it is established at creation time and cannot be changed later. This way, objects in MDE are closed and fixed with respect to the type they conform to, the slots/properties they have, and the constraints they should obey. This hampers the reuse of model-related artefacts like model transformations, as well as the opportunistic or dynamic combination of metamodels. To alleviate this rigidity, we propose making model objects open so that they can acquire or drop so-called facets, each one contributing a type, slots and constraints to the object. Facets are defined by regular metamodels, hence being a lightweight extension of standard metamodelling. Facet metamodels may declare usage interfaces, and it is possible to specify laws that govern how facets are to be assigned to the instances of a metamodel. In this paper, we describe our proposal, report on an implementation, and illustrate scenarios where facets have advantages over other techniques.},
	booktitle = {SLE 2018},
	publisher = {Association for Computing Machinery},
	author = {de Lara, Juan and Guerra, Esther and Kienzle, Jörg and Hattab, Yanis},
	month = oct,
	year = {2018},
	keywords = {Flexible Modelling, MetaDepth, Metamodelling, Model-Driven Engineering, Reuse, Role-Based Modelling},
	pages = {147--159},
}



@inproceedings{MaciasGuerraL2017,
	address = {Cham},
	series = {LNCS},
	title = {Towards {Rearchitecting} {Meta}-{Models} into {Multi}-level {Models}},
	isbn = {978-3-319-69904-2},
	doi = {10.1007/978-3-319-69904-2_5},
	abstract = {Meta-models play a pivotal role in Model-Driven Engineering, as they are used to define the structure of instance models one level below. However, in some scenarios, organizing meta-models and their instances in multi-level models spanning more than two levels yields simpler solutions. This fact has triggered the proposal of different multi-level modelling tools and approaches, although each one of them supports small variations of the multi-level concepts.In order to benefit from multi-level technology, existing meta-models and their instances could be migrated manually, but this is error prone, costly, and requires expertise for choosing the most appropriate tool and approach. Hence, we propose an automated migration process. This way, starting from a meta-model annotated with multi-level “smells”, our approach creates a neutral multi-level representation, and recommends the most appropriate tool according to the required multi-level features. We present an initial prototype, and a preliminary evaluation on the basis of meta-models developed by third parties.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Macías, Fernando and Guerra, Esther and de Lara, Juan},
	editor = {Mayr, Heinrich C. and Guizzardi, Giancarlo and Ma, Hui and Pastor, Oscar},
	year = {2017},
	pages = {59--68}
}


@inproceedings{AtkinsonKuehne2001,
	address = {Berlin, Heidelberg},
	series = {LNCS},
	title = {The {Essence} of {Multilevel} {Metamodeling}},
	isbn = {978-3-540-45441-0},
	doi = {10.1007/3-540-45441-1_3},
	abstract = {As the UMLattempts to make the transition from a single, albeit extensible, language to a framework for a family of languages, the nature and form of the underlying meta-modeling architecture will assume growing importance. It is generally recognized that without a simple, clean and intuitive theory of how metamodel levels are created and related to one another, the UML2.0 vision of a coherent family of languages with a common core set of concepts will remain elusive. However, no entirely satisfactory metamodeling approach has yet been found. Current (meta-)modeling theories used or proposed for the UML all have at least one fundamental problem that makes them unsuitable in their present form. In this paper we bring these problems into focus, and present some fundamental principles for overcoming them. We believe that these principles need to be embodied within the metamodeling framework ultimately adopted for the UML2.0 standard.},
	language = {en},
	booktitle = {{UML} 2001},
	publisher = {Springer},
	author = {Atkinson, Colin and Kühne, Thomas},
	editor = {Gogolla, Martin and Kobryn, Cris},
	year = {2001},
	pages = {19--33},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/V9ZHJ28Z/Atkinson and Kühne - 2001 - The Essence of Multilevel Metamodeling.pdf:application/pdf}
}


@article{MaciasWolterRDR2019,
	title = {Multilevel coupled model transformations for precise and reusable definition of model behaviour},
	volume = {106},
	issn = {2352-2208},
	doi = {10.1016/j.jlamp.2018.12.005},
	abstract = {The use of Domain-Specific Languages (DSLs) is a promising field for the development of tools tailored to specific problem spaces, effectively diminishing the complexity of hand-made software. With the goal of making models as precise, simple and reusable as possible, we augment DSLs with concepts from multilevel modelling, where the number of abstraction levels are not limited. This is particularly useful for DSL definitions with behaviour, whose concepts inherently belong to different levels of abstraction. Here, models can represent the state of the modelled system and evolve using model transformations. These transformations can benefit from a multilevel setting, becoming a precise and reusable definition of the semantics for behavioural modelling languages. We present in this paper the concept of Multilevel Coupled Model Transformations, together with examples, formal definitions and tools to assess their conceptual soundness and practical value.},
	language = {en},
	urldate = {2020-05-21},
	journal = {Journal of Logical and Algebraic Methods in Programming},
	author = {Macías, Fernando and Wolter, Uwe and Rutle, Adrian and Durán, Francisco and Rodriguez-Echeverria, Roberto},
	month = aug,
	year = {2019},
	keywords = {Behavioural modelling, Graph transformation, Model-driven engineering, Multilevel coupled model transformation, Multilevel modelling},
	pages = {167--195},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/F4U4IIJE/Macías et al. - 2019 - Multilevel coupled model transformations for preci.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/8UXYX8MD/S2352220817300585.html:text/html}
}


@inproceedings{KuehnBoehmeGA2015,
	address = {Pittsburgh, PA, USA},
	title = {A combined formal model for relational context-dependent roles},
	isbn = {978-1-4503-3686-4},
	url = {https://doi.org/10.1145/2814251.2814255},
	doi = {10.1145/2814251.2814255},
	abstract = {Role-based modeling has been investigated for over 35 years as a promising paradigm to model complex, dynamic systems. Although current software systems are characterized by increasing complexity and context-dependence, all this research had almost no influence on current software development practice, still being discussed in recent literature. One reason for this is the lack of a coherent, comprehensive, readily applicable notion of roles. Researchers focused either on relational roles or context-dependent roles rather then combining both natures. Currently, there is no role-based modeling language sufficiently incorporating both the relational and context-dependent nature of roles together with the various proposed constraints. Hence, this paper formalizes a full-fledged role-based modeling language supporting both natures. To show its sufficiency and adequacy, a real world example is employed.},
	urldate = {2020-04-28},
	booktitle = {{SLE} 2015},
	publisher = {Association for Computing Machinery},
	author = {Kühn, Thomas and Böhme, Stephan and Götz, Sebastian and Aßmann, Uwe},
	month = oct,
	year = {2015},
	keywords = {Role-based Modeling},
	pages = {113--124},
	file = {Full Text PDF:/Users/past/Zotero/storage/852IIMSM/Kühn et al. - 2015 - A combined formal model for relational context-dep.pdf:application/pdf}
}


@inproceedings{BennaniEbersoldHCN2019,
	title = {A {Collaborative} {Decision} {Approach} for {Alignment} of {Heterogeneous} {Models}},
	doi = {10.1109/WETICE.2019.00032},
	abstract = {Design of complex systems goes through a multiview paradigm in which separate teams, from different business viewpoints, build partial models describing the system. As they are expressed in different languages, these partial models are called heterogeneous models. To maintain the global system's consistency, we propose a collaborative approach that combines Group Decision Making (GDM) and Model-Based Engineering. This paper presents a metamodel for collaborative decision elaboration via a set of decision policies which are instances of GDM patterns. Our approach is illustrated with a hospital Emergency Department case study and is supported by a tool allowing models alignment through GDM based processes.},
	booktitle = {2019 {IEEE} 28th {International} {Conference} on {Enabling} {Technologies}: {Infrastructure} for {Collaborative} {Enterprises} ({WETICE})},
	author = {Bennani, Saloua and Ebersold, Sophie and El Hamlaoui, Mahmoud and Coulette, Bernard and Nassar, Mahmoud},
	month = jun,
	year = {2019},
	note = {ISSN: 2641-8169},
	keywords = {Proposals, model matching, groupware, business viewpoints, collaboration, Collaboration, collaborative decision elaboration, complex systems, Complex systems, decision making, Decision making, decision policies, emergency services, GDM based processes, global system, group decision support systems, group decision-making, heterogeneous models, hospital emergency department, hospitals, Hospitals, model alignment, model-based engineering, multiview paradigm, partial models, pattern, separate teams, Stakeholders, Tools},
	pages = {112--117}
}




@inproceedings{ElHamlaouiBennani2018,
	address = {Funchal, Madeira, Portugal},
	series = {{ENASE} 2018},
	title = {A {MDE} {Approach} for {Heterogeneous} {Models} {Consistency}},
	isbn = {978-989-758-300-1},
	url = {https://doi.org/10.5220/0006774101800191},
	doi = {10.5220/0006774101800191},
	abstract = {To design a complex system, we often proceed via separation of viewpoints. Each viewpoint is described by a model that represents a domain expertise. Those partial models are generally heterogeneous (i.e conform to different metamodels) and thus performed by different designers. We proposed a matching process that links partial models through a virtual global model in order to create a complete view of the system. As models evolve, we should consider the impact of changing an element involved in a correspondence on other models to keep the coherence of the global view. So, we have defined a process that automatically identify changes, classify them and treat their potential repercussions on elements of other partial models in order to maintain the global model consistency.},
	urldate = {2020-06-29},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Evaluation} of {Novel} {Approaches} to {Software} {Engineering}},
	publisher = {SCITEPRESS - Science and Technology Publications, Lda},
	author = {El Hamlaoui, Mahmoud and Bennani, Saloua and Nassar, Mahmoud and Ebersold, Sophie and Coulette, Bernard},
	month = mar,
	year = {2018},
	keywords = {Consistency, Correspondences, Heterogeneous Models, Impacts., Matching, Metamodel, Process},
	pages = {180--191}
}



@inproceedings{KehrerTaentzerRK2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Automatically {Deriving} the {Specification} of {Model} {Editing} {Operations} from {Meta}-{Models}},
	isbn = {978-3-319-42064-6},
	doi = {10.1007/978-3-319-42064-6_12},
	abstract = {To optimally support continuous model evolution in model-based software development, adequate tool support for model version management is needed. Instead of reporting model differences to the developer line-by-line or element-wise, their grouping into semantically associated change sets helps in understanding model differences. Edit operations are the concept of choice to group such change sets. Considering visual models in particular, edit operations preserve a basic form of consistency such that changed models can still be viewed in a standard editor. Using edit operations for the version management of domain-specific models requires tool developers to specify all necessary edit operations in order to produce or replicate every possible change on a model. However, edit operations can be numerous and their manual specification is therefore tedious and error-prone. In this paper, we present a precise approach to specify a complete set of consistency-preserving edit operations for a given modeling language. The approach is supported by a generator and has been evaluated in four case studies covering several visual modeling languages and standard editors.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformations}},
	publisher = {Springer International Publishing},
	author = {Kehrer, Timo and Taentzer, Gabriele and Rindt, Michaela and Kelter, Udo},
	editor = {Van Gorp, Pieter and Engels, Gregor},
	year = {2016},
	keywords = {Meta-model, Model consistency, Model-driven engineering, Modelediting},
	pages = {173--188},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/86GA4LNV/Kehrer et al. - 2016 - Automatically Deriving the Specification of Model .pdf:application/pdf}
}


@inproceedings{NassarRadkeA2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Rule-{Based} {Repair} of {EMF} {Models}: {An} {Automated} {Interactive} {Approach}},
	isbn = {978-3-319-61473-1},
	shorttitle = {Rule-{Based} {Repair} of {EMF} {Models}},
	abstract = {Managing and resolving inconsistencies in models is crucial in model-driven engineering (MDE). In this paper we consider models that are based on the Eclipse Modeling Framework (EMF). We propose a rule-based approach to support the modeler in automatically trimming and completing EMF models and thereby resolving their cardinality violations. Although being under repair, the model may be viewed and changed interactively during this repair process. The approach and the developed tool support are based on EMF and the model transformation language Henshin.},
	language = {en},
	booktitle = {Theory and {Practice} of {Model} {Transformation}},
	publisher = {Springer International Publishing},
	author = {Nassar, Nebras and Radke, Hendrik and Arendt, Thorsten},
	editor = {Guerra, Esther and van den Brand, Mark},
	year = {2017},
	keywords = {Model repair, Model driven engineering, Model transformation, Eclipse Modeling Framework (EMF), \#INTERESTING},
	pages = {171--181},
	doi = {10.1007/978-3-319-61473-1_12}
}



@inproceedings{NassarKosiolAT2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{OCL2AC}: {Automatic} {Translation} of {OCL} {Constraints} to {Graph} {Constraints} and {Application} {Conditions} for {Transformation} {Rules}},
	isbn = {978-3-319-92991-0},
	shorttitle = {{OCL2AC}},
	doi = {10.1007/978-3-319-92991-0_11},
	abstract = {Based on an existing theory, we present a tool OCL2AC which is able to adapt a given rule-based model transformation such that resulting models guarantee a given constraint set. OCL2AC has two main functionalities: First, OCL constraints are translated into semantically equivalent graph constraints. Secondly, graph constraints can further be integrated as application conditions into transformation rules. The resulting rule is applicable only if its application does not violate the original constraints. OCL2AC is implemented as Eclipse plug-in and enhances Henshin transformation rules.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {Nassar, Nebras and Kosiol, Jens and Arendt, Thorsten and Taentzer, Gabriele},
	editor = {Lambers, Leen and Weber, Jens},
	year = {2018},
	keywords = {Model transformation, OCL, Henshin, Nested graph constraints},
	pages = {171--177},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/8VCXZARL/Nassar et al. - 2018 - OCL2AC Automatic Translation of OCL Constraints t.pdf:application/pdf}
}



@inproceedings{CicchettiCicozzi2013,
	title = {Towards a {Novel} {Model} {Versioning} {Approach} {Based} on the {Separation} {Between} {Linguistic} and {Ontological} {Aspects}},
	abstract = {With the increasing adoption of Model-Driven Engineering (MDE) the support of distributed development and hence model versioning has become a necessity. MDE research investigations targeting (meta-)model versioning, conflict management, and model co-evolution have progressively recognized the importance of tackling the problem at higher abstraction level and a number of solving techniques have been proposed. However, in general existing mechanisms hit the wall of semantics, i.e. when not only syntax is involved in the manipulations the chances for providing precision and automation are remarkably reduced. In this paper we illustrate a novel version management proposal that leverages on the separation between linguistic and ontological aspects involved in a (meta-)modelling activity. In particular, we revisit the main versioning tasks in terms of the mentioned separation. The aim is to maximize the amount of versioning problems that can be automatically addressed while leaving the ones intertwined with domain-specific semantics to be solved separately, possibly by means of semi-automatic techniques and additional precision.},
	booktitle = {{ME}@{MoDELS}},
	author = {Cicchetti, Antonio and Ciccozzi, Federico},
	year = {2013},
	file = {Full Text PDF:/Users/past/Zotero/storage/MWKFR82X/Cicchetti and Ciccozzi - 2013 - Towards a Novel Model Versioning Approach Based on.pdf:application/pdf}
}


@inproceedings{GuychardGuerinKBD013,
	title = {Conceptual interoperability through {Models} {Federation}},
	url = {https://hal.archives-ouvertes.fr/hal-00905036},
	abstract = {Successful architecting of complex systems requires reconciling heterogeneous viewpoints expressed by the stakeholders involved in the development process, including domain and technical experts, users and managers. Most of the time, each concern is analyzed by experts using well-fitted specific tools to produce their point of view on a solution. This results in a set of models with various technical spaces, formalisms and paradigms. Ensuring global consistency, maintaining traceability and building cross- concerns views in that context is challenging. In order to address this issues, we initiated the development of a tooling that provides support for building conceptual views expanding upon existing models and tools. It has been applied to uses cases such as: model composition across tech- nical spaces, heterogeneous (meta)models alignment and keeping models in sync. In this paper, we introduce the models federation approach to conceptual interoperability that drives the development of our innovative modeling engine.},
	language = {en},
	urldate = {2020-06-29},
	author = {Guychard, Christophe and Guerin, Sylvain and Koudri, Ali and Beugnard, Antoine and Dagnat, Fabien},
	month = oct,
	year = {2013},
	file = {Snapshot:/Users/past/Zotero/storage/YF4TFXPK/hal-00905036.html:text/html}
}



@article{HemelKatsGV2010,
	title = {Code generation by model transformation: a case study in transformation modularity},
	volume = {9},
	issn = {1619-1374},
	shorttitle = {Code generation by model transformation},
	url = {https://doi.org/10.1007/s10270-009-0136-1},
	doi = {10.1007/s10270-009-0136-1},
	abstract = {The realization of model-driven software development requires effective techniques for implementing code generators for domain-specific languages. This paper identifies techniques for improving separation of concerns in the implementation of generators. The core technique is code generation by model transformation, that is, the generation of a structured representation (model) of the target program instead of plain text. This approach enables the transformation of code after generation, which in turn enables the extension of the target language with features that allow better modularity in code generation rules. The technique can also be applied to ‘internal code generation’ for the translation of high-level extensions of a DSL to lower-level constructs within the same DSL using model-to-model transformations. This paper refines our earlier description of code generation by model transformation with an improved architecture for the composition of model-to-model normalization rules, solving the problem of combining type analysis and transformation. Instead of coarse-grained stages that alternate between normalization and type analysis, we have developed a new style of type analysis that can be integrated with normalizing transformations in a fine-grained manner. The normalization strategy has a simple extension interface and integrates non-local, context-sensitive transformation rules. We have applied the techniques in a realistic case study of domain-specific language engineering, i.e. the code generator for WebDSL, using Stratego, a high-level transformation language that integrates model-to-model, model-to-code, and code-to-code transformations.},
	language = {en},
	number = {3},
	urldate = {2020-06-29},
	journal = {Software \& Systems Modeling},
	author = {Hemel, Zef and Kats, Lennart C. L. and Groenewegen, Danny M. and Visser, Eelco},
	month = jun,
	year = {2010},
	pages = {375--402},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/6EKPEZ26/Hemel et al. - 2010 - Code generation by model transformation a case st.pdf:application/pdf}
}


@inproceedings{Wachsmuth2007,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Metamodel {Adaptation} and {Model} {Co}-adaptation},
	isbn = {978-3-540-73589-2},
	doi = {10.1007/978-3-540-73589-2_28},
	abstract = {Like other software artefacts, metamodels evolve over time. We propose a transformational approach to assist metamodel evolution by stepwise adaptation. In the first part of the paper, we adopt ideas from grammar engineering to define several semantics- and instance-preservation properties in terms of metamodel relations. This part is not restricted to any metamodel formalism. In the second part, we present a library of QVT Relations for the stepwise adaptation of MOF compliant metamodels. Transformations from this library separate preservation properties. We distinguish three kinds of adaptation according to these properties; namely refactoring, construction, and destruction. Co-adaptation of models is discussed with respect to instance-preservation. In most cases, co-adaptation is achieved automatically. Finally, we point out applications in the areas of metamodel design, implementation, refinement, maintenance, and recovery.},
	language = {en},
	booktitle = {{ECOOP} 2007 – {Object}-{Oriented} {Programming}},
	publisher = {Springer},
	author = {Wachsmuth, Guido},
	editor = {Ernst, Erik},
	year = {2007},
	keywords = {Eclipse Modeling Framework, Input Metamodel, Meta Object Facility, Preservation Property, Target Metamodel},
	pages = {600--624},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/UBMIRPPF/Wachsmuth - 2007 - Metamodel Adaptation and Model Co-adaptation.pdf:application/pdf}
}



@article{MensTaentzerR2007,
	title = {Analysing refactoring dependencies using graph transformation},
	volume = {6},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-006-0044-6},
	doi = {10.1007/s10270-006-0044-6},
	abstract = {Refactoring is a widely accepted technique to improve the structure of object-oriented software. Nevertheless, existing tool support remains restricted to automatically applying refactoring transformations. Deciding what to refactor and which refactoring to apply still remains a difficult manual process, due to the many dependencies and interrelationships between relevant refactorings. In this paper, we represent refactorings as graph transformations, and we propose the technique of critical pair analysis to detect the implicit dependencies between refactorings. The results of this analysis can help the developer to make an informed decision of which refactoring is most suitable in a given context and why. We report on several experiments we carried out in the AGG graph transformation tool to support our claims.},
	language = {en},
	number = {3},
	urldate = {2020-06-29},
	journal = {Software \& Systems Modeling},
	author = {Mens, Tom and Taentzer, Gabriele and Runge, Olga},
	month = sep,
	year = {2007},
	pages = {269--285},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/BWKRPRBK/Mens et al. - 2007 - Analysing refactoring dependencies using graph tra.pdf:application/pdf}
}

@misc{ISO42010,
 title = {ISO/IEC/IEEE 42010:2011 - Systems and software engineering — Architecture description},
 author = {{ISO/IEC JTC 1/SC 7 Software and systems engineering}},
 howpublished = {\url{https://www.iso.org/standard/50508.html}},
 year = {2011},
 month = dec
}



@article{RoseKolovosPPP2014,
	title = {Epsilon {Flock}: a model migration language},
	volume = {13},
	issn = {1619-1374},
	shorttitle = {Epsilon {Flock}},
	url = {https://doi.org/10.1007/s10270-012-0296-2},
	doi = {10.1007/s10270-012-0296-2},
	abstract = {Model-driven engineering introduces additional challenges for controlling and managing software evolution. Today, tools exist for generating model editors and for managing models with transformation, validation, merging and weaving. There is limited support, however, for model migration—a development activity in which instance models are updated in response to metamodel evolution. In this paper, we propose conservative copy—a style of model transformation that we believe is well-suited to model migration—and Epsilon Flock—a compact model-to-model transformation language tailored for model migration. The proposed structures are evaluated by comparing the conciseness of model migration strategies written in different styles of transformation language, using several examples of evolution taken from UML and the graphical modelling framework.},
	language = {en},
	number = {2},
	urldate = {2020-02-14},
	journal = {Software \& Systems Modeling},
	author = {Rose, Louis M. and Kolovos, Dimitrios S. and Paige, Richard F. and Polack, Fiona A. C. and Poulding, Simon},
	month = may,
	year = {2014},
	pages = {735--755},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/ER3YA7XB/Rose et al. - 2014 - Epsilon Flock a model migration language.pdf:application/pdf}
}


@inproceedings{CicchettiCicozziL2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Supporting {Incremental} {Synchronization} in {Hybrid} {Multi}-view {Modelling}},
	isbn = {978-3-642-29645-1},
	doi = {10.1007/978-3-642-29645-1_11},
	abstract = {Multi-view modelling is a widely accepted technique to reduce the complexity in the development of modern software systems. It allows developers to focus on a narrowed portion of the specification dealing with a selected aspect of the problem. However, multi-view modelling support discloses a number of issues mainly due to consistency management, expressiveness, and customization needs. A possible solution to alleviate those problems is to adopt a hybrid solution for multi-view modelling based on an arbitrary number of custom views defined on top of an underlying modelling language. In this way it is possible to benefit from the consistency by-construction granted by well-formed views while at the same time providing malleable perspectives through which the system under development can be specified. In this respect, this paper presents an approach for supporting synchronization mechanism based on model differences in hybrid multi-view modelling. Model differences allow to focus only on the manipulations operated by the user in a particular view, and to propagate them to the other views in a incremental way thus reducing the overhead of a complete recomputation of modified models.},
	language = {en},
	booktitle = {Models in {Software} {Engineering}},
	publisher = {Springer},
	author = {Cicchetti, Antonio and Ciccozzi, Federico and Leveque, Thomas},
	editor = {Kienzle, Jörg},
	year = {2012},
	keywords = {model-driven engineering, model synchronization, higher-order model transformation, Multi-view modelling, separation of concerns},
	pages = {89--103},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/3MMK25TK/Cicchetti et al. - 2012 - Supporting Incremental Synchronization in Hybrid M.pdf:application/pdf}
}



@article{Bezivin2005,
	title = {On the unification power of models},
	volume = {4},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-005-0079-0},
	doi = {10.1007/s10270-005-0079-0},
	abstract = {In November 2000, the OMG made public the MDA™initiative, a particular variant of a new global trend called MDE (Model Driven Engineering). The basic ideas of MDA are germane to many other approaches such as generative programming, domain specific languages, model-integrated computing, generic model management, software factories, etc. MDA may be defined as the realization of MDE principles around a set of OMG standards like MOF, XMI, OCL, UML, CWM, SPEM, etc. MDE is presently making several promises about the potential benefits that could be reaped from a move from code-centric to model-based practices. When we observe these claims, we may wonder when they may be satisfied: on the short, medium or long term or even never perhaps for some of them. This paper tries to propose a vision of the development of MDE based on some lessons learnt in the past 30 years in the development of object technology. The main message is that a basic principle (“Everything is an object”) was most helpful in driving the technology in the direction of simplicity, generality and power of integration. Similarly in MDE, the basic principle that “Everything is a model” has many interesting properties, among others the capacity to generate a realistic research agenda. We postulate here that two core relations (representation and conformance) are associated to this principle, as inheritance and instantiation were associated to the object unification principle in the class-based languages of the 80’s. We suggest that this may be most useful in understanding many questions about MDE in general and the MDA approach in particular. We provide some illustrative examples. The personal position taken in this paper would be useful if it could generate a critical debate on the research directions in MDE.},
	language = {en},
	number = {2},
	urldate = {2020-06-29},
	journal = {Software \& Systems Modeling},
	author = {Bézivin, Jean},
	month = may,
	year = {2005},
	pages = {171--188},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/7PZ9IPMU/Bézivin - 2005 - On the unification power of models.pdf:application/pdf}
}


@article{Selic2003,
	title = {The pragmatics of model-driven development},
	volume = {20},
	issn = {1937-4194},
	doi = {10.1109/MS.2003.1231146},
	abstract = {The potential benefits of using models are significantly greater in software than in other engineering disciplines because of the potential for a seamless link between models and the systems they represent. Unfortunately, models have rarely produced anticipated benefits. The key lies in resolving pragmatic issues related to the artifacts and culture of the previous generation of software technologies.},
	number = {5},
	journal = {IEEE Software},
	author = {Selic, B.},
	month = sep,
	year = {2003},
	keywords = {software development, Automotive engineering, Productivity, software engineering, Object oriented modeling, Software systems, Programming profession, Bridges, modelling, artifacts, Automobiles, Computer languages, culture, industrial experience, model-driven development methods, Object oriented programming, pragmatic issues, software standards, Systems engineering and theory},
	pages = {19--25}
}



@article{Bezivin2004,
	title = {In search of a {Basic} {Principle} for {Model}-{Driven} {Engineering}},
	volume = {5},
	url = {https://hal.archives-ouvertes.fr/hal-00442702},
	abstract = {no abstract},
	number = {2},
	urldate = {2020-08-11},
	journal = {Novatica – Special Issue on UML (Unified Modeling Language)},
	author = {Bézivin, Jean},
	year = {2004},
	pages = {21--24}
}


@inproceedings{VermolenVisser2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Heterogeneous {Coupled} {Evolution} of {Software} {Languages}},
	isbn = {978-3-540-87875-9},
	doi = {10.1007/978-3-540-87875-9_44},
	abstract = {As most software artifacts, meta-models can evolve. Their evolution requires conforming models to co-evolve along with them. Coupled evolution supports this. Its applicability is not limited to the modeling domain. Other domains are for example evolving grammars or database schemas. Existing approaches to coupled evolution focus on a single, homogeneous domain. They solve the co-evolution problems locally and repeatedly. In this paper we present a systematic, heterogeneous approach to coupled evolution. It provides an automatically derived domain specific transformation language; a means of executing transformations at the top level; a derivation of the coupled bottom level transformation; and it allows for generic abstractions from elementary transformations. The feasibility of the architecture is evaluated by applying it to data model evolution.},
	language = {en},
	booktitle = {Model {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer},
	author = {Vermolen, Sander and Visser, Eelco},
	editor = {Czarnecki, Krzysztof and Ober, Ileana and Bruel, Jean-Michel and Uhl, Axel and Völter, Markus},
	year = {2008},
	keywords = {Object Management Group, Data Model, Data Transformation, Elementary Transformation, Local Transformation},
	pages = {630--644}
}


@article{BarrigaRutleH2020,
  author = {Barriga, Angela and Rutle, Adrian and Heldal, Rogardt},
  title = {Improving Model Repair through Experience Sharing},
  journal = {Journal of Object Technology},
  volume = {19},
  number = {2},
  issn = {1660-1769},
  year = {2020},
  month = jul,
  editor = {Paige, Richard and Vallecillo, Antonio},
  note = {The 16th European Conference on Modelling Foundations and Applications (ECMFA 2020)},
  pages = {13:1-21},
  doi = {10.5381/jot.2020.19.2.a13},
}



@article{IovinoBarrigaRH2020,
  author = {Ludovico, Iovino and Barriga, Angela and Rutle, Adrian and Heldal, Rogardt},
  title = {Model Repair with Quality-Based Reinforcement Learning},
  journal = {Journal of Object Technology},
  volume = {19},
  number = {2},
  issn = {1660-1769},
  year = {2020},
  month = jul,
  editor = {Paige, Richard and Vallecillo, Antonio},
  note = {The 16th European Conference on Modelling Foundations and Applications (ECMFA 2020)},
  pages = {17:1-21},
  doi = {10.5381/jot.2020.19.2.a17},
}


@article{YohannisRodriguezPK2019,
	title = {Towards {Efficient} {Comparison} of {Change}-{Based} {Models}},
	volume = {18},
	issn = {1660-1769},
	doi = {10.5381/jot.2019.18.2.a7},
	number = {2},
	journal = {Journal of Object Technology},
	author = {Yohannis, Alfa and Rodriguez, Rodriguez Hoyos and Polack, Fiona and Kolovos, Dimitris},
	editor = {Combemale, Benoit and Shaukat, Ali},
	month = jul,
	year = {2019},
	pages = {7:1--21}
}



@inproceedings{NarayananLevendovszkyBK2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Automatic {Domain} {Model} {Migration} to {Manage} {Metamodel} {Evolution}},
	isbn = {978-3-642-04425-0},
	doi = {10.1007/978-3-642-04425-0_57},
	abstract = {Metamodel evolution is a significant problem in domain specific software development for several reasons. Domain-specific modeling languages (DSMLs) are likely to evolve much more frequently than programming languages and commonly used software formalisms, often resulting in a large number of valuable instance models that are no longer compliant with the metamodel. In this paper, we present the Model Change Language (MCL), aimed at satisfying these requirements.},
	language = {en},
	booktitle = {Model {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer},
	author = {Narayanan, Anantha and Levendovszky, Tihamer and Balasubramanian, Daniel and Karsai, Gabor},
	editor = {Schürr, Andy and Selic, Bran},
	year = {2009},
	keywords = {Model Migration, Containment Hierarchy, Domain Designer, Enterprise Distribute Object Computing, Migration Rule},
	pages = {706--711},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/454K8LKM/Narayanan et al. - 2009 - Automatic Domain Model Migration to Manage Metamod.pdf:application/pdf}
}


@book{Cohn1965,
	edition = {1st edition},
	title = {Universal {Algebra}},
	isbn = {978-0-06-356115-1},
	language = {English},
	publisher = {Harper \& Row},
	author = {Cohn, P. M.},
	year = {1965}
}



@book{AmblerSadalage2006,
	title = {Refactoring {Databases}: {Evolutionary} {Database} {Design} (paperback)},
	isbn = {978-0-321-63017-9},
	shorttitle = {Refactoring {Databases}},
	abstract = {Refactoring has proven its value in a wide range of development projects–helping software professionals improve system designs, maintainability, extensibility, and performance. Now, for the first time, leading agile methodologist Scott Ambler and renowned consultant Pramodkumar Sadalage introduce powerful refactoring techniques specifically designed for database systems.   Ambler and Sadalage demonstrate how small changes to table structures, data, stored procedures, and triggers can significantly enhance virtually any database design–without changing semantics. You’ll learn how to evolve database schemas in step with source code–and become far more effective in projects relying on iterative, agile methodologies.   This comprehensive guide and reference helps you overcome the practical obstacles to refactoring real-world databases by covering every fundamental concept underlying database refactoring. Using start-to-finish examples, the authors walk you through refactoring simple standalone database applications as well as sophisticated multi-application scenarios. You’ll master every task involved in refactoring database schemas, and discover best practices for deploying refactorings in even the most complex production environments.    The second half of this book systematically covers five major categories of database refactorings. You’ll learn how to use refactoring to enhance database structure, data quality, and referential integrity; and how to refactor both architectures and methods. This book provides an extensive set of examples built with Oracle and Java and easily adaptable for other languages, such as C\#, C++, or VB.NET, and other databases, such as DB2, SQL Server, MySQL, and Sybase.   Using this book’s techniques and examples, you can reduce waste, rework, risk, and cost–and build database systems capable of evolving smoothly, far into the future.},
	language = {en},
	publisher = {Pearson Education},
	author = {Ambler, Scott W. and Sadalage, Pramod J.},
	month = mar,
	year = {2006},
	keywords = {Computers / Software Development \& Engineering / General, Computers / Databases / General}
}


@inproceedings{GomesBarrocaA2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Classification of {Model} {Transformation} {Tools}: {Pattern} {Matching} {Techniques}},
	isbn = {978-3-319-11652-5 978-3-319-11653-2},
	shorttitle = {Classification of {Model} {Transformation} {Tools}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-11653-2_38},
	doi = {10.1007/978-3-319-11653-2_38},
	abstract = {While comparing different model transformation languages (MTLs), it is common to refer to their syntactic and semantic features and overlook their supporting tools’ performance. Performance is one of the aspects that can hamper the application of MDD to industrial scenarios. An highly declarative MTL might simply not scale well when using large models due to its supporting implementation. In this paper, we focus on the several pattern matching techniques (including optimization techniques) employed in the most popular transformation tools, and discuss their effectiveness w.r.t. the expressive power of the languages used. Because pattern matching is the most costly operation in a transformation execution, we present a classification of the existing model transformation tools according to the pattern matching optimization techniques they implement. Our classification complements existing ones that are more focused at syntactic and semantic features of the languages supported by those tools.},
	language = {en},
	urldate = {2018-01-04},
	booktitle = {Model-{Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer, Cham},
	author = {Gomes, Cláudio and Barroca, Bruno and Amaral, Vasco},
	month = sep,
	year = {2014},
	pages = {619--635},
	file = {Snapshot:/Users/past/Zotero/storage/W77L6925/10.html:text/html}
}


@inproceedings{KessentiniWimmerS2018,
	address = {New York, NY, USA},
	series = {{MODELS} '18},
	title = {Integrating the {Designer} in-the-loop for {Metamodel}/{Model} {Co}-{Evolution} via {Interactive} {Computational} {Search}},
	isbn = {978-1-4503-4949-9},
	url = {https://doi.org/10.1145/3239372.3239375},
	doi = {10.1145/3239372.3239375},
	abstract = {Metamodels evolve even more frequently than programming languages. This evolution process may result in a large number of instance models that are no longer conforming to the revised meta-model. On the one hand, the manual adaptation of models after the metamodels' evolution can be tedious, error-prone, and time-consuming. On the other hand, the automated co-evolution of metamodels/models is challenging especially when new semantics is introduced to the metamodels. In this paper, we propose an interactive multi-objective approach that dynamically adapts and interactively suggests edit operations to developers and takes their feedback into consideration. Our approach uses NSGA-II to find a set of good edit operation sequences that minimizes the number of conformance errors, maximizes the similarity with the initial model (reduce the loss of information) and minimizes the number of proposed edit operations. The designer can approve, modify, or reject each of the recommended edit operations, and this feedback is then used to update the proposed rankings of recommended edit operations. We evaluated our approach on a set of metamodel/model coevolution case studies and compared it to fully automated coevolution techniques.},
	urldate = {2020-08-19},
	booktitle = {Proceedings of the 21th {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Kessentini, Wael and Wimmer, Manuel and Sahraoui, Houari},
	month = oct,
	year = {2018},
	keywords = {Coupled Evolution, Interactive Optimization, Metamodel/Model Co-Evolution, Search Based Software Engineering},
	pages = {101--111}
}



@inproceedings{FinkelsteinGabbayHLN1993,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Inconsistency handling in multi-perspective specifications},
	isbn = {978-3-540-47972-7},
	doi = {10.1007/3-540-57209-0_7},
	abstract = {The development of most large and complex systems necessarily involves many people — each with their own perspectives on the system defined by their knowledge, responsibilities, and commitments. To address this we have advocated distributed development of specifications from multiple perspectives. However, this leads to problems of identifying and handling inconsistencies between such perspectives. Maintaining absolute consistency is not always possible. Often this is not even desirable since this can unnecessarily constrain the development process, and can lead to the loss of important information. Indeed since the real-world forces us to work with inconsistencies, we should formalise some of the usually informal or extra-logical ways of responding to them. This is not necessarily done by eradicating inconsistencies but rather by supplying logical rules specifying how we should act on them. To achieve this, we combine two lines of existing research: the Viewpoints framework for perspective development, interaction and organisation, and a logic-based approach to inconsistency handling. This paper presents our technique for inconsistency handling in the Viewpoints framework by using simple examples.},
	language = {en},
	booktitle = {Software {Engineering} — {ESEC} '93},
	publisher = {Springer},
	author = {Finkelstein, A. and Gabbay, D. and Hunter, A. and Kramer, J. and Nuseibeh, B.},
	editor = {Sommerville, Ian and Paul, Manfred},
	year = {1993},
	keywords = {Temporal Logic, Action Table, Classical Logic, Common Data Model, Paraconsistent Logic},
	pages = {84--99},
}


@inproceedings{FinkelsteinSpanoudakisT1996,
	address = {New York, NY, USA},
	series = {{ISAW} '96},
	title = {Managing {Interference}},
	isbn = {978-0-89791-867-1},
	url = {http://doi.acm.org/10.1145/243327.243646},
	doi = {10.1145/243327.243646},
	urldate = {2019-03-07},
	booktitle = {Joint {Proceedings} of the {Second} {International} {Software} {Architecture} {Workshop} ({ISAW}-2) and {International} {Workshop} on {Multiple} {Perspectives} in {Software} {Development} ({Viewpoints} '96) on {SIGSOFT} '96 {Workshops}},
	publisher = {ACM},
	author = {Finkelstein, Anthony and Spanoudakis, George and Till, David},
	year = {1996},
	pages = {172--174},
}


@article{Easterbrook1991,
	title = {Handling conflict between domain descriptions with computer-supported negotiation},
	volume = {3},
	issn = {1042-8143},
	url = {http://www.sciencedirect.com/science/article/pii/104281439190007A},
	doi = {10.1016/1042-8143(91)90007-A},
	abstract = {Conflict is an inevitable part of both knowledge elicitation and system design. People will disagree over how to interpret features of the application domain, what the requirements for a new system are, and how to meet those requirements. Conventional systems analysis techniques avoid such conflicts, making any resolution untraceable and adding to the communication problems. This paper surveys a number of fields which have addressed the problems of conflict resolution. A model of computer-supported negotiation is presented which can be used to address conflicts in systems analysis directly. The model begins with an exploratory phase, in which the conflict is broken down into its components, eliciting the issues which underlie disagreements and criteria to measure their satisfaction. A set of options for possible resolutions are generated using design techniques. Finally, these options are compared to the original issues, and evaluated according to the criteria associated with the issues. The model emphasizes communication, and encourages investigation of other viewpoints. The model has been used to develop a system called Synoptic, which provides a set of tools to support the exploration of conflicts.},
	language = {en},
	number = {3},
	urldate = {2020-03-14},
	journal = {Knowledge Acquisition},
	author = {Easterbrook, Steve},
	month = sep,
	year = {1991},
	pages = {255--289},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/FR5ESZZN/Easterbrook - 1991 - Handling conflict between domain descriptions with.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/8UY333UR/104281439190007A.html:text/html}
}



@inproceedings{GoedickeMeyerT1999,
	title = {{ViewPoint}-oriented software development by distributed graph transformation: towards a basis for living with inconsistencies},
	shorttitle = {{ViewPoint}-oriented software development by distributed graph transformation},
	doi = {10.1109/ISRE.1999.777989},
	abstract = {Software development is a staged and evolutionary process. Multiple stakeholders with different needs and views collaborate to build a system from interoperating and heterogeneous development artifacts. In such a setting, one has to cope with requirements changing dynamically during the entire lifetime of the system. Within this changing world living with inconsistencies is natural. Tool support is needed to tolerate inconsistencies and help developers to use them to drive the development process forward. In this contribution we consider the application of distributed graph transformation to the problem of formalizing the integration of multiple perspectives in software development called ViewPoints. Our work concentrates on requirements engineering. We demonstrate how inconsistency management can be used as a tool for requirements analysis by presenting a sample integration of architecture design and performance evaluation views.},
	booktitle = {Proceedings {IEEE} {International} {Symposium} on {Requirements} {Engineering} ({Cat}. {No}.{PR00188})},
	author = {Goedicke, M. and Meyer, T. and Taentzer, G.},
	month = jun,
	year = {1999},
	note = {ISSN: null},
	keywords = {software development, Programming, requirements engineering, systems analysis, requirements analysis, Software systems, inconsistency management, software architecture, graph theory, Costs, Animation, Collaborative work, Delay, distributed graph transformation, Electrical capacitance tomography, Forward contracts, Organizing, performance evaluation, requirements change, software architecture design, software performance evaluation, Spirals, tool support, ViewPoint},
	pages = {92--99},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/FTDZE8KC/777989.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/HGRYJDPK/Goedicke et al. - 1999 - ViewPoint-oriented software development by distrib.pdf:application/pdf}
}


@inproceedings{FabroBezevinJV2005,
	title = {Applying {Generic} {Model} {Management} to {Data} {Mapping}},
	url = {/paper/Applying-Generic-Model-Management-to-Data-Mapping-Fabro-B%C3%A9zivin/503d665eb6c99f9f7200712365f47edb362d7ecc},
	abstract = {Mapping between heterogeneous data is a central problem in many dataintensive applications. In particular, using one mapping language causes serious limitations and makes mapping management difficult. In this paper, we propose a solution that can better control the trade-off between genericity, expressiveness and efficiency of mappings. Our solution considers mappings as models and exploits specific mapping engines. We define model weaving as a generic way to establish element correspondences. Weaving models may then be used by a model transformation language to translate source model(s) into target model(s). To validate our solution, we implemented a mapping prototype, called AMW, and used it for experimenting with significant application scenarios.},
	language = {en},
	urldate = {2020-10-26},
	booktitle = {{BDA} 2005},
	author = {Fabro, M. D. D. and Bézivin, J. and Jouault, F. and Valduriez, P.},
	year = {2005},
}


@inproceedings{BezevinBouzitounaDDGJKKP2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Canonical} {Scheme} for {Model} {Composition}},
	isbn = {978-3-540-35910-4},
	abstract = {There is little agreement on terminology in model composition, and even less on key characteristics of a model composition solution. We present three composition frameworks: the Atlas Model Weaver, the Epsilon Merging Language, and the Glue Generator Tool, and from them derive a core set of common definitions. We use this to outline the key requirements of a model composition solution, in terms of language and tool support.},
	language = {en},
	booktitle = {Model {Driven} {Architecture} – {Foundations} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bézivin, Jean and Bouzitouna, Salim and Del Fabro, Marcos Didonet and Gervais, Marie-Pierre and Jouault, Fréderic and Kolovos, Dimitrios and Kurtev, Ivan and Paige, Richard F.},
	editor = {Rensink, Arend and Warmer, Jos},
	year = {2006},
	keywords = {Model Transformation, Composition Operation, Composition Rule, Match Operation, Model Composition},
	pages = {346--360},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/Q9XQHSQQ/Bézivin et al. - 2006 - A Canonical Scheme for Model Composition.pdf:application/pdf}
}



@inproceedings{DrivalosKolovosPF2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Engineering a {DSL} for {Software} {Traceability}},
	isbn = {978-3-642-00434-6},
	doi = {10.1007/978-3-642-00434-6_10},
	abstract = {The software artefacts at different levels of abstraction and at different stages of the development process are closely inter-related. For developers to stay in control of the development process, traceability information must be maintained. In this paper, we present the engineering of the Traceability Metamodelling Language (TML), a metamodelling language dedicated to defining traceability metamodels. We present the abstract syntax of the language and its semantics, which are defined using a translational approach. Finally, we provide a case study that demonstrates the construction of a traceability metamodel that captures traceability information between two metamodels using TML.},
	language = {en},
	booktitle = {Software {Language} {Engineering}},
	publisher = {Springer},
	author = {Drivalos, Nikolaos and Kolovos, Dimitrios S. and Paige, Richard F. and Fernandes, Kiran J.},
	editor = {Gašević, Dragan and Lämmel, Ralf and Van Wyk, Eric},
	year = {2009},
	pages = {151--167},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/UD3BMR8D/Drivalos et al. - 2009 - Engineering a DSL for Software Traceability.pdf:application/pdf}
}

@techreport{StephensonMulvilleBDNLS1999,
	author = {Stephenson, Arthur G. and Mulville, Daniel R. and Bauer, Frank H. and Dukeman, Greg A. and Norvig, Peter and LaPiana, Lia S. and Sackheim, Robert},
	institution = {NASA, Washington D.C.},
	url = {https://llis.nasa.gov/llis_lib/pdf/1009464main1_0641-mr.pdf},
	title = {Mars Climate Orbiter Mishap Investigation Board Phase I Report},
	year = {1999}
}



@inproceedings{DidonetDelFabroBezivinJBG2005,
	address = {France},
	title = {{AMW}: a generic model weaver},
	shorttitle = {{AMW}},
	url = {https://hal.archives-ouvertes.fr/hal-00448112},
	abstract = {no abstract},
	urldate = {2020-10-27},
	booktitle = {1 ere {Journées} sur l'{Ingénierie} {Dirigée} par les {Modèles} ({IDM05})},
	author = {Didonet Del Fabro, Marcos and Bézivin, Jean and Jouault, Frédéric and Breton, Erwann and Gueltas, Guillaume},
	year = {2005},
	pages = {105--114},
	file = {HAL Snapshot:/Users/past/Zotero/storage/VWYJ8MF2/hal-00448112.html:text/html}
}


@article{TorresVanDenBrandS2020,
	title = {A systematic literature review of cross-domain model consistency checking by model management tools},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-020-00834-1},
	doi = {10.1007/s10270-020-00834-1},
	abstract = {Objective The goal of this study is to identify gaps and challenges related to cross-domain model management focusing on consistency checking. Method We conducted a systematic literature review. We used the keyword-based search on Google Scholar, and we identified 618 potentially relevant studies; after applying inclusion and exclusion criteria, 96 papers were selected for further analysis. Results The main findings/contributions are: (i) a list of available tools used to support model management; (ii) 40\% of the tools can provide consistency checking on models of different domains and 25\% on models of the same domain, and 35\% do not provide any consistency checking; (iii) available strategies to keep the consistency between models of different domains are not mature enough; (iv) most of the tools that provide consistency checking on models of different domains can only capture up to two inconsistency types; (v) the main challenges associated with tools that manage models on different domains are related to interoperability between tools and the consistency maintenance. Conclusion The results presented in this study can be used to guide new research on maintaining the consistency between models of different domains. Example of further research is to investigate how to capture the Behavioral and Refinement inconsistency types. This study also indicates that the tools should be improved in order to address, for example, more kinds of consistency check.},
	language = {en},
	urldate = {2020-10-26},
	journal = {Software and Systems Modeling},
	author = {Torres, Weslley and van den Brand, Mark G. J. and Serebrenik, Alexander},
	month = oct,
	year = {2020},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/3Y2BQIUQ/Torres et al. - 2020 - A systematic literature review of cross-domain mod.pdf:application/pdf}
}


@inproceedings{UsmanNadeemKC2008,
	address = {USA},
	series = {{ASEA} '08},
	title = {A {Survey} of {Consistency} {Checking} {Techniques} for {UML} {Models}},
	isbn = {978-0-7695-3432-9},
	url = {https://doi.org/10.1109/ASEA.2008.40},
	doi = {10.1109/ASEA.2008.40},
	abstract = {UML is the de-facto industry standard to design object-oriented software. UML provides a set of diagrams to model every aspect of an object-oriented application design in sufficient detail, but lacks any mechanism to rigorously check consistency between the models. Today, most of the effort is applied on creating accurate and consistent UML models rather than implementing the design. Automatic code generation from UML models has emerged as a promising area in recent years. The accuracy of generated code in some ways depends on UML models consistency. In this paper, we present a survey of UML consistency checking techniques. To analyze existing techniques, we identify some analysis parameters and construct an analysis table. The analysis table helps us to evaluate existing consistency checking techniques. We conclude that most of the approaches validates intra and inter level consistencies between UML models by using monitoring strategy. UML class, sequence, and statechart diagrams are used in most of the existing consistency checking techniques.},
	urldate = {2020-10-26},
	booktitle = {Proceedings of the 2008 {Advanced} {Software} {Engineering} and {Its} {Applications}},
	publisher = {IEEE Computer Society},
	author = {Usman, Muhammad and Nadeem, Aamer and Kim, Tai-hoon and Cho, Eun-suk},
	month = dec,
	year = {2008},
	keywords = {UML, Consistency checking},
	pages = {57--62},
	file = {Usman et al. - 2008 - A Survey of Consistency Checking Techniques for UM.pdf:/Users/past/Zotero/storage/2R64U74L/Usman et al. - 2008 - A Survey of Consistency Checking Techniques for UM.pdf:application/pdf}
}



@article{NuseibehEasterbrookR2001,
	title = {Making inconsistency respectable in software development},
	volume = {58},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S016412120100036X},
	doi = {10.1016/S0164-1212(01)00036-X},
	abstract = {The development of software systems inevitably involves the detection and handling of inconsistencies. These inconsistencies can arise in system requirements, design specifications and, quite often, in the descriptions that form the final implemented software product. A large proportion of software engineering research has been devoted to consistency maintenance, or geared towards eradicating inconsistencies as soon as they are detected. Software practitioners, on the other hand, live with inconsistency as a matter of course. Depending on the nature of an inconsistency, its causes and its impact, they sometimes choose to tolerate its presence, rather than resolve it immediately, if at all. This paper argues for “making inconsistency respectable” [A phrase first used by D. Gabbay and A. Hunter (in: Proceedings of Fundamentals of Artificial Intelligence Research'91, Springer, Berlin, p. 19; in: Symbolic and Quantitative Approaches to Reasoning and Uncertainty, Lecture Notes in Computer Science, Springer, Berlin, 1992, p. 129) to describe the same sentiments that motivated our work.] – sometimes avoided or ignored, but more often used as a focus for learning and as a trigger for further (constructive) development actions. The paper presents a characterization of inconsistency in software development and a framework for managing it in this context. It draws upon practical experiences of dealing with inconsistency in large-scale software development projects and relates some lessons learned from these experiences.},
	language = {en},
	number = {2},
	urldate = {2020-02-14},
	journal = {Journal of Systems and Software},
	author = {Nuseibeh, Bashar and Easterbrook, Steve and Russo, Alessandra},
	month = sep,
	year = {2001},
	keywords = {Inconsistency management, Conflict, Inconsistency handling, Requirements engineering, Software specification},
	pages = {171--180},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/N978L82T/Nuseibeh et al. - 2001 - Making inconsistency respectable in software devel.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/ELWU6324/S016412120100036X.html:text/html}
}


@inproceedings{KolovosPaigeP2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Merging {Models} with the {Epsilon} {Merging} {Language} ({EML})},
	isbn = {978-3-540-45773-2},
	doi = {10.1007/11880240_16},
	abstract = {In the context of Model Engineering, work has focused on operations such as model validation and model transformation. By contrast, other model management operations of significant importance remain underdeveloped. One of the least elaborated operations is model merging. In this paper we discuss the special requirements of model merging and introduce the Epsilon Merging Language (EML), a rule-based language, with tool support, for merging models of diverse metamodels and technologies. Moreover, we identify special cases of model merging that are of particular interest and provide a working example through which we demonstrate the practicality and usefulness of the proposed language.},
	language = {en},
	booktitle = {Model {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {Springer},
	author = {Kolovos, Dimitrios S. and Paige, Richard F. and Polack, Fiona A. C.},
	editor = {Nierstrasz, Oscar and Whittle, Jon and Harel, David and Reggio, Gianna},
	year = {2006},
	keywords = {Model Transformation, Abstract Syntax, Object Constraint Language, Object Management Group, Target Model},
	pages = {215--229},
	file = {Kolovos et al. - 2006 - Merging Models with the Epsilon Merging Language (.pdf:/Users/past/Zotero/storage/8J44TYV5/Kolovos et al. - 2006 - Merging Models with the Epsilon Merging Language (.pdf:application/pdf}
}


@article{Raoult1984,
	title = {On graph rewritings},
	volume = {32},
	issn = {0304-3975},
	doi = {10.1016/0304-3975(84)90021-5},
	abstract = {The purpose of the present paper is twofold: Firstly, show that it is possible to rewrite graphs in a way equivalent to, and in fact slightly more powerful than that of Ehrig, Pfender and Schneider (1973), which has, since then, been developed mainly by the Berlin school. Our method consists in using a single push-out of partial morphisms and is described in Section 3. Section 1 is devoted to the elementary definitions concerning graphs and related terms. Section 2 contains the set-theoretic prerequisites for the sequel but the proofs have been moved into an appendix, for easier reading. Secondly, we indicate in Section 4 why this method is not really fit for rewriting graphs that represent collapsed terms (i.e., sharing common subterms) and we introduce pushouts of total functions, which are not morphisms everywhere on their domain. This method is connected to the classical rewriting of the corresponding terms. The adequacy of these new rewriting rules is then tested to prove a local confluence criterion a la Knuth-Bendix (1970) in Section 5, the proof of which turns out to be very short.},
	language = {en},
	number = {1},
	urldate = {2020-11-07},
	journal = {Theoretical Computer Science},
	author = {Raoult, Jean Claude},
	month = jan,
	year = {1984},
	pages = {1--24}
}



@article{EhrigLowe1993,
	title = {Categorical principles, techniques and results for high-level-replacement systems in computer science},
	volume = {1},
	issn = {1572-9095},
	doi = {10.1007/BF00872984},
	abstract = {The aim of this paper is to give an introduction how to use categorical methods in a specific field of computer science: The field of high-level-replacement systems has its roots in the well-established theories of formal languages, term rewriting, Petri nets, and graph grammars playing a fundamental role in computer science. More precisely, it is a generalization of the algebraic approach to graph grammars which is based on gluing constructions for graphs defined as pushouts in the category of graphs. The categorical theory of high-level-replacement systems is suitable for the dynamic handling of a large variety of high-level structures in computer science including different kinds of graphs and algebraic specifications. In this paper we discuss the basic principles and techniques from category theory applied in the field of high-level-replacement systems and present some basic results together with the corresponding categorical proof techniques.},
	language = {en},
	number = {1},
	urldate = {2020-11-07},
	journal = {Applied Categorical Structures},
	author = {Ehrig, Hartmut and Löwe, Michael},
	month = mar,
	year = {1993},
	pages = {21--50}
}


@inproceedings{EhrigHabelKP1991a,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {From graph grammars to high level replacement systems},
	isbn = {978-3-540-38395-6},
	doi = {10.1007/BFb0017395},
	abstract = {The algebraic approach to graph grammars — well-known in the literature for several types of graphs and structures — is extended to include several new types of replacement systems, especially the replacement of algebraic specifications which were recently introduced for a rule-based approach to modular system design.This leads to the new concept of high level replacement systems which is formulated in an axiomatic algebraic framework based on categories and double-pushouts. In this paper only basic notions like productions, derivations, parallel and sequential independence are introduced for high-level replacement systems leading to Church-Rosser and Parallelism Theorems previously shown in the literature for special cases only.},
	language = {en},
	booktitle = {Graph {Grammars} and {Their} {Application} to {Computer} {Science}},
	publisher = {Springer},
	author = {Ehrig, Hartmut and Habel, Annegret and Kreowski, Hans-Jörg and Parisi-Presicce, Francesco},
	editor = {Ehrig, Hartmut and Kreowski, Hans-Jörg and Rozenberg, Grzegorz},
	year = {1991},
	keywords = {category theory, Church-Rosser Theorem, graph grammars, high level replacement systems, independent derivations, parallelism theorem},
	pages = {269--291},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/6UCGPJHW/Ehrig et al. - 1991 - From graph grammars to high level replacement syst.pdf:application/pdf}
}



@article{HabelMuellerP2001,
	title = {Double-pushout graph transformation revisited},
	volume = {11},
	issn = {0960-1295},
	url = {https://doi.org/10.1017/S0960129501003425},
	doi = {10.1017/S0960129501003425},
	abstract = {In this paper we investigate and compare four variants of the double-pushout approach to graph transformation. As well as the traditional approach with arbitrary matching and injective right-hand morphisms, we consider three variations by employing injective matching and/or arbitrary right-hand morphisms in rules. We show that injective matching provides additional expressiveness in two respects: for generating graph languages by grammars without non-terminals and for computing graph functions by convergent graph transformation systems. Then we clarify for each of the three variations whether the well-known commutativity, parallelism and concurrency theorems are still valid and – where this is not the case – give modified results. In particular, for the most general approach with injective matching and arbitrary right-hand morphisms, we establish sequential and parallel commutativity by appropriately strengthening sequential and parallel independence.},
	number = {5},
	urldate = {2020-11-07},
	journal = {Mathematical Structures in Computer Science},
	author = {Habel, Annegret and Müller, Jürgen and Plump, Detlef},
	month = oct,
	year = {2001},
	pages = {637--688},
	file = {Submitted Version:/Users/past/Zotero/storage/GXUPKM4J/Habel et al. - 2001 - Double-pushout graph transformation revisited.pdf:application/pdf}
}


@inproceedings{Kennaway1991,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Graph rewriting in some categories of partial morphisms},
	isbn = {978-3-540-38395-6},
	abstract = {We present a definition of term graph rewriting as the taking of a pushout in a category of partial morphisms, adapting the rather ad hoc definitions we gave in [Ken87] so as to use a standard category-theoretic concept of partial morphism. This single-pushout construction is shown to coincide with the well-known double-pushout description of graph rewriting whenever the latter is defined. In general, the conditions for the single pushout to exist are weaker than those required for the double pushout. In some categories of graphs, no conditions at all are necessary.},
	language = {en},
	booktitle = {Graph {Grammars} and {Their} {Application} to {Computer} {Science}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kennaway, Richard},
	editor = {Ehrig, Hartmut and Kreowski, Hans-Jörg and Rozenberg, Grzegorz},
	year = {1991},
	keywords = {graph rewriting, category, double pushout, hypergraph, jungle, partial morphism, single pushout, term graph},
	pages = {490--504},
	doi = {10.1007/BFb0017408}
}


@incollection{EhrigPrange2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Weak {Adhesive} {High}-{Level} {Replacement} {Categories} and {Systems}: {A} {Unifying} {Framework} for {Graph} and {Petri} {Net} {Transformations}},
	isbn = {978-3-540-35464-2},
	shorttitle = {Weak {Adhesive} {High}-{Level} {Replacement} {Categories} and {Systems}},
	abstract = {Adhesive high-level replacement (HLR) systems have been recently introduced as a new categorical framework for graph tranformation in the double pushout (DPO) approach. They combine the well-known concept of HLR systems with the concept of adhesive categories introduced by Lack and Sobociński.While graphs, typed graphs, attributed graphs and several other variants of graphs together with corresponding morphisms are adhesive HLR categories, such that the categorical framework of adhesive HLR systems can be applied, this has been claimed also for Petri nets. In this paper we show that this claim is wrong for place/transition nets and algebraic high-level nets, although several results of the theory for adhesive HLR systems are known to be true for the corresponding Petri net transformation systems.In fact, we are able to define a weaker version of adhesive HLR categories, called weak adhesive HLR categories, which is still sufficient to show all the results known for adhesive HLR systems. This concept includes not only all kinds of graphs mentioned above, but also place/transition nets, algebraic high-level nets and several other kinds of Petri nets. For this reason weak adhesive HLR systems can be seen as a unifying framework for graph and Petri net transformations.},
	language = {en},
	urldate = {2020-11-07},
	booktitle = {Algebra, {Meaning}, and {Computation}: {Essays} dedicated to {Joseph} {A}. {Goguen} on the {Occasion} of {His} 65th {Birthday}},
	publisher = {Springer},
	author = {Ehrig, Hartmut and Prange, Ulrike},
	editor = {Futatsugi, Kokichi and Jouannaud, Jean-Pierre and Meseguer, José},
	year = {2006},
	doi = {10.1007/11780274_13},
	keywords = {Categorical Framework, Graph Grammar, Graph Transformation, Injective Morphism, Unify Framework},
	pages = {235--251}
}



@inproceedings{HeindelSobocinsky2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Van {Kampen} {Colimits} as {Bicolimits} in {Span}},
	isbn = {978-3-642-03741-2},
	doi = {10.1007/978-3-642-03741-2_23},
	abstract = {The exactness properties of coproducts in extensive categories and pushouts along monos in adhesive categories have found various applications in theoretical computer science, e.g. in program semantics, data type theory and rewriting. We show that these properties can be understood as a single universal property in the associated bicategory of spans. To this end, we first provide a general notion of Van Kampen cocone that specialises to the above colimits. The main result states that Van Kampen cocones can be characterised as exactly those diagrams in ℂ that induce bicolimit diagrams in the bicategory of spans 𝑝𝑎𝑛ℂSpanC{\textbackslash}mathcal\{S\}pan\_\{{\textbackslash}mathbb\{C\}\}, provided that ℂ has pullbacks and enough colimits.},
	language = {en},
	booktitle = {Algebra and {Coalgebra} in {Computer} {Science}},
	publisher = {Springer},
	author = {Heindel, Tobias and Sobociński, Paweł},
	editor = {Kurz, Alexander and Lenisa, Marina and Tarlecki, Andrzej},
	year = {2009},
	keywords = {Extensive Category, Graph Grammar, Natural Transformation, Theoretical Computer Science, Universal Property},
	pages = {335--349},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/GYQC8WAG/Heindel and Sobociński - 2009 - Van Kampen Colimits as Bicolimits in Span.pdf:application/pdf}
}


@article{BurmesterGieseNTWWWZ2004,
	title = {Tool integration at the meta-model level: the {Fujaba} approach},
	volume = {6},
	issn = {1433-2787},
	shorttitle = {Tool integration at the meta-model level},
	url = {https://doi.org/10.1007/s10009-004-0155-8},
	doi = {10.1007/s10009-004-0155-8},
	abstract = {Today’s development processes employ a variety of notations and tools, e.g., the Unified Modeling Language UML, the Standard Description Language SDL, requirements databases, design tools, code generators, model checkers, etc. For better process support, the employed tools may be organized within a tool suite or integration platform, e.g., Rational Rose or Eclipse. While these tool-integration platforms usually provide GUI adaption mechanisms and functional adaption via application programming interfaces, they frequently do not provide appropriate means for data integration at the meta-model level. Thus, overlapping and redundant data from different “integrated” tools may easily become inconsistent and unusable. We propose two design patterns that provide a flexible basis for the integration of different tool data at the meta-model level. To achieve consistency between meta-models, we describe rule-based mechanisms providing generic solutions for managing overlapping and redundant data. The proposed mechanisms are widely used within the Fujaba Tool Suite. We report about our implementation and application experiences  .},
	language = {en},
	number = {3},
	urldate = {2020-11-09},
	journal = {International Journal on Software Tools for Technology Transfer},
	author = {Burmester, Sven and Giese, Holger and Niere, Jörg and Tichy, Matthias and Wadsack, Jörg P. and Wagner, Robert and Wendehals, Lothar and Zündorf, Albert},
	month = aug,
	year = {2004},
	pages = {203--218},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/QSAL4N67/Burmester et al. - 2004 - Tool integration at the meta-model level the Fuja.pdf:application/pdf}
}



@inproceedings{GieseHildebrandtL2010,
	title = {Toward {Bridging} the {Gap} between {Formal} {Semantics} and {Implementation} of {Triple} {Graph} {Grammars}},
	doi = {10.1109/MoDeVVa.2010.14},
	abstract = {The correctness of model transformations is a crucial element for the model-driven engineering of high quality software. A prerequisite to verify model transformations at the level of the model transformation specification is that an unambiguous formal semantics exists and that the employed implementation of the model transformation language adheres to this semantics. However, for existing relational model transformation approaches it is usually not really clear under which constraints particular implementations are really conform to the formal semantics. In this paper, we will bridge this gap for the formal semantics of triple graph grammars (TGG) and an existing efficient implementation. Whereas the formal semantics assumes backtracking and ignores non-determinism, practical implementations do not support backtracking, require rule sets that ensure determinism, and include further optimizations. Therefore, we capture how the considered TGG implementation realizes the transformation by means of operational rules, define required criteria, and show conformance to the formal semantics if these criteria are fulfilled. We further outline how static analysis can be employed to guarantee these criteria.},
	booktitle = {and {Validation} 2010 {Workshop} on {Model}-{Driven} {Engineering}, {Verification}},
	author = {Giese, Holger and Hildebrandt, Stephan and Lambers, Leen},
	month = oct,
	year = {2010},
	note = {ISSN: null},
	keywords = {formal specification, software engineering, model-driven engineering, Runtime, Computational modeling, Semantics, triple graph grammars, Model Transformation, static analysis, Triple Graph Grammar, backtracking, Encoding, formal semantics, Formal Semantics, Grammar, graph grammars, model transformation correctness, model transformation language, model transformation specification, Optimization, Transforms},
	pages = {19--24},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/EE9GIIUZ/5772246.html:text/html;Submitted Version:/Users/past/Zotero/storage/S73M9ABL/Giese et al. - 2010 - Toward Bridging the Gap between Formal Semantics a.pdf:application/pdf}
}


@inproceedings{LackSobocinsky2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Toposes {Are} {Adhesive}},
	isbn = {978-3-540-38872-2},
	abstract = {Adhesive categories have recently been proposed as a categorical foundation for facets of the theory of graph transformation, and have also been used to study techniques from process algebra for reasoning about concurrency. Here we continue our study of adhesive categories by showing that toposes are adhesive. The proof relies on exploiting the relationship between adhesive categories, Brown and Janelidze’s work on generalised van Kampen theorems as well as Grothendieck’s theory of descent.},
	language = {en},
	booktitle = {Graph {Transformations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lack, Stephen and Sobociński, Paweł},
	editor = {Corradini, Andrea and Ehrig, Hartmut and Montanari, Ugo and Ribeiro, Leila and Rozenberg, Grzegorz},
	year = {2006},
	keywords = {Graph Transformation, Comparison Functor, Extensive Category, Process Algebra, Pullback Diagram},
	pages = {184--198},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/6LV3HD32/Lack and Sobociński - 2006 - Toposes Are Adhesive.pdf:application/pdf}
}


@inproceedings{deLaraVangeluwe2002,
  title={AToM 3: A Tool for Multi-formalism and Meta-modelling},
  author={De Lara, Juan and Vangheluwe, Hans},
  booktitle={International Conference on Fundamental Approaches to Software Engineering},
  pages={174--188},
  year={2002},
  organization={Springer}
}


@article{CarboniLackW1993,
	title = {Introduction to extensive and distributive categories},
	volume = {84},
	issn = {0022-4049},
	url = {http://www.sciencedirect.com/science/article/pii/002240499390035R},
	doi = {10.1016/0022-4049(93)90035-R},
	abstract = {In recent years, there has been considerable discussion as to the appropriate definition of distributive categories. Three definitions which have had some support are: (1) A category with finite sums and products such that the canonical map δ:A×B+ A×C→A×(B+C) is an isomorphism (Walters). (2) A category with finite sums and products such that the canonical functor +:A/A× A/B→A/(A+B) is an equivalence (Monro). (3) A category with finite sums and finite limits such that the canonical functor + of (2) is an equivalence (Lawvere and Schanuel). There has been some confusion as to which of these was the natural notion to consider. This resulted from the fact that there are actually two elementary notions being combined in the above three definitions. The first, to which we give the name distributivity, is exactly that of (1). The second notion, which we shall call extensivity, is that of a category with finite sums for which the canonical functor + of definitions (2) and (3) is an equivalence. Extensivity, although it implies the existence of certain pullbacks, is essentially a property of having well-behaved sums. It is the existence of these pullbacks which has caused the confusion. The connections between definition (1) and definitions (2) and (3) are that any extensive category with products is distributive in the first sense, and that any category satisfying (3) satisfies (1) locally. The purpose of this paper is to present some basic facts about extensive and distributive categories, and to discuss the relationships between the two notions.},
	number = {2},
	urldate = {2019-10-17},
	journal = {Journal of Pure and Applied Algebra},
	author = {Carboni, Aurelio and Lack, Stephen and Walters, R. F. C.},
	month = feb,
	year = {1993},
	pages = {145--158},
	file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/RD4XFWFK/Carboni et al. - 1993 - Introduction to extensive and distributive categor.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/ZYLEZNL7/002240499390035R.html:text/html}
}


@book{Walters1992,
	address = {New York, NY, USA},
	title = {Categories and {Computer} {Science}},
	isbn = {978-0-521-42226-0},
	publisher = {Cambridge University Press},
	author = {Walters, R. F. C.},
	year = {1992}
}

@inproceedings{NassarKosiolR2017,
  title={Rule-Based Repair of EMF Models : Formalization and Correctness Proof},
  author={Jens Kosiol and Hendrik Radke},
  year={2017},
  booktitle = {GCM {2017}},
}


@article{HeckelWagner1995,
	series = {{SEGRAGRA} 1995, {Joint} {COMPUGRAPH}/{SEMAGRAPH} {Workshop} on {Graph} {Rewriting} and {Computation}},
	title = {Ensuring {Consistency} of {Conditional} {Graph} {Grammars} - {A} {Constructive} {Approach} -},
	volume = {2},
	issn = {1571-0661},
	doi = {10.1016/S1571-0661(05)80188-4},
	abstract = {Consistency conditions describe basic properties of graphs as e.g. the existence or uniqueness of certain elements. A graph grammar is consistent if the start graph satisfies the consistency condition and the rules preserve this property. We propose a general construction that transforms global consistency conditions into preconditions for individual rules. A so-constructed rule is applicable to a consistent graph if and only if the derived graph is consistent, too. The relevance of this result is motivated by an example specification of a safety-critical system that is, a roundabout.},
	language = {en},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Heckel, Reiko and Wagner, Annika},
	month = jan,
	year = {1995},
	pages = {118--126}
}



@article{SchneiderLambersO2018,
	title = {Automated reasoning for attributed graph properties},
	volume = {20},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-018-0496-3},
	doi = {10.1007/s10009-018-0496-3},
	abstract = {Graphs are ubiquitous in computer science. Moreover, in various application fields, graphs are equipped with attributes to express additional information such as names of entities or weights of relationships. Due to the pervasiveness of attributed graphs, it is highly important to have the means to express properties on attributed graphs to strengthen modeling capabilities and to enable analysis. Firstly, we introduce a new logic of attributed graph properties, where the graph part and attribution part are neatly separated. The graph part is equivalent to first-order logic on graphs as introduced by Courcelle. It employs graph morphisms to allow the specification of complex graph patterns. The attribution part is added to this graph part by reverting to the symbolic approach to graph attribution, where attributes are represented symbolically by variables whose possible values are specified by a set of constraints making use of algebraic specifications. Secondly, we extend our refutationally complete tableau-based reasoning method as well as our symbolic model generation approach for graph properties to attributed graph properties. Due to the new logic mentioned above, neatly separating the graph and attribution parts, and the categorical constructions employed only on a more abstract level, we can leave the graph part of the algorithms seemingly unchanged. For the integration of the attribution part into the algorithms, we use an oracle, allowing for flexible adoption of different available SMT solvers in the actual implementation. Finally, our automated reasoning approach for attributed graph properties is implemented in the tool AutoGraph integrating in particular the SMT solver Z3 for the attribute part of the properties. We motivate and illustrate our work with a particular application scenario on graph database query validation.},
	language = {en},
	number = {6},
	urldate = {2019-09-18},
	journal = {International Journal on Software Tools for Technology Transfer},
	author = {Schneider, Sven and Lambers, Leen and Orejas, Fernando},
	month = nov,
	year = {2018},
	keywords = {Attributed graphs, Graph queries, Model generation, Nested graph conditions, Tableau method},
	pages = {705--737},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/LSXSL5KG/Schneider et al. - 2018 - Automated reasoning for attributed graph propertie.pdf:application/pdf}
}



@article{Plump1998,
	title = {Termination of {Graph} {Rewriting} is {Undecidable}},
	volume = {33},
	issn = {0169-2968},
	url = {http://dl.acm.org/citation.cfm?id=294994.294998},
	number = {2},
	urldate = {2018-11-09},
	journal = {Fundam. Inf.},
	author = {Plump, Detlef},
	month = feb,
	year = {1998},
	keywords = {graph rewriting, post correspondence problem, termination},
	pages = {201--209}
}


@inproceedings{OhrndorfPietschKK2018,
	address = {New York, NY, USA},
	series = {{ICSE} '18},
	title = {{ReVision}: a tool for history-based model repair recommendations},
	isbn = {978-1-4503-5663-3},
	shorttitle = {{ReVision}},
	url = {https://doi.org/10.1145/3183440.3183498},
	doi = {10.1145/3183440.3183498},
	abstract = {Models in Model-Driven Engineering are heavily edited in all stages of software development and can become temporarily inconsistent. In general, there are many alternatives to fix an inconsistency, the actual choice is left to the discretion of the developer. Model repair tools should support developers by proposing a short list of repair alternatives. Such recommendations will be only accepted in practice if the generated proposals are plausible and understandable. Current approaches, which mostly focus on fully automatic, non-interactive model repairs, fail in meeting these requirements. This paper proposes a new approach to generate repair proposals for inconsistencies that were introduced by incomplete editing processes which can be located in the version history of a model. Such an incomplete editing process is extended to a full execution of a consistency-preserving edit operation. We demonstrate our repair tool ReVision using a simplified multi-view UML model of a video on demand system, a screencast is provided at http://pi.informatik.uni-siegen.de/projects/SiLift/icse2018/.},
	urldate = {2020-11-15},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {Companion} {Proceeedings}},
	publisher = {Association for Computing Machinery},
	author = {Ohrndorf, Manuel and Pietsch, Christopher and Kelter, Udo and Kehrer, Timo},
	month = may,
	year = {2018},
	keywords = {consistency, history analysis, model repair, recommendations},
	pages = {105--108}
}


@article{HabelHeckelT1996,
	title = {{Graph Grammars with negative application Conditions}},
	volume = {26},
	issn = {0169-2968},
	abstract = {In each graph-grammar approach it is defined how and under which conditions graph productions can be applied to a given graph in order to obtain a derived graph. The conditions under which productions can be applied are called application conditions. Although the generative power of most of the known general graph-grammar approaches is sufficient to generate any recursively enumerable set of graphs, it is often convenient to have specific application conditions for each production. Such application conditions, on the one hand, include context conditions like the existence or non-existence of nodes, edges, or certain subgraphs in the given graph as well as embedding restrictions concerning the morphisms from the left-hand side of the production to the given graph. In this paper, the concept of application conditions introduced by Ehrig and Habel is restricted to contextual conditions, especially negative ones. In addition to the general concept, we state local confluence and the Parallelism Theorem for derivations with application conditions. Finally we study context-free graph grammars with application conditions with respect to their generative power.},
	number = {3,4},
	journal = {Fundamenta Informaticae},
	author = {Habel, Annegret and Heckel, Reiko and Taentzer, Gabriele},
	month = dec,
	year = {1996},
	keywords = {application conditions, contextual conditions, graph grammars, graph transformation systems},
	pages = {287--313}
}



@inproceedings{KoenigStuenkel2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Single {Pushout} {Rewriting} in {Comprehensive} {Systems}},
	isbn = {978-3-030-51372-6},
	doi = {10.1007/978-3-030-51372-6_6},
	abstract = {The elegance of the single-pushout (SPO) approach to graph transformations arises from substituting total morphisms by partial ones in the underlying category. Thus, SPO’s applicability depends on the durability of pushouts after this transition. There is a wide range of work on the question when pushouts exist in categories with partial morphisms starting with the pioneering work of Löwe and Kennaway and ending with an essential characterisation in terms of an exactness property (for the interplay between pullbacks and pushouts) and an adjointness condition (w.r.t. inverse image functions) by Hayman and Heindel.Triple graphs and graph diagrams are frameworks to synchronize two or more updatable data sources by means of internal mappings, which identify common sub-structures. Comprehensive systems generalise these frameworks, treating the network of data sources and their structural inter-relations as a homogeneous comprehensive artifact, in which partial maps identify commonalities. Although this inherent partiality produces amplified complexity, Heindel’s characterisation still yields cocompleteness of the category of comprehensive systems equipped with closed partial morphisms and thus enables computing by SPO graph transformation.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {König, Harald and Stünkel, Patrick},
	editor = {Gadducci, Fabio and Kehrer, Timo},
	year = {2020},
	keywords = {Category theory, Comprehensive system, Hereditary pushout, Partial morphism, Single Pushout Rewriting, Upper adjoint},
	pages = {91--108},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/UHQPKP7U/König and Stünkel - 2020 - Single Pushout Rewriting in Comprehensive Systems.pdf:application/pdf}
}



@article{RobinsonRosolini1988,
	title = {Categories of partial maps},
	volume = {79},
	issn = {0890-5401},
	doi = {10.1016/0890-5401(88)90034-X},
	abstract = {This paper attempts to reconcile the various abstract notions of “category of partial maps” which appear in the literature. First a particular algebraic theory (p-categories) is introduced and a representation theorem proved. This gives the authors a coherent framework in which to place the various other definitions. Both algebraic theories and theories which make essential use of the poset-enriched structure of partial maps are discussed. Proofs of equivalence are given where possible and counterexamples where known. The paper concludes with brief sections on the representation of partial maps and on partial algebras.},
	language = {en},
	number = {2},
	urldate = {2020-11-15},
	journal = {Information and Computation},
	author = {Robinson, E. and Rosolini, G.},
	month = nov,
	year = {1988},
	pages = {95--130},
}

@phdthesis{Heindel2010PhD, 
	title={A Category Theoretical Approach to the Concurrent Semantics of Rewriting: Adhesive Categories and Related Concepts}, 
	url={https://duepublico2.uni-due.de/receive/duepublico_mods_00022389}, 
	abstractNote={This thesis studies formal semantics for a family of rewriting formalisms that have arisen as category theoretical abstractions of the so-called algebraic approaches to graph rewriting. The latter in turn generalize and combine features of term rewriting and Petri nets. Two salient features of (the abstract versions of) graph rewriting are a suitable class of categories which captures the structure of the objects of rewriting, and a notion of independence or concurrency of rewriting steps – as in the theory of Petri nets. Category theoretical abstractions of graph rewriting such as double pushout rewriting encapsulate the complex details of the structures that are to be rewritten by considering them as objects of a suitable abstract category, for example an adhesive one. The main difficulty of the development of appropriate categorical frameworks is the identification of the essential properties of the category of graphs which allow to develop the theory of graph rewriting in an abstract framework. The motivations for such an endeavor are twofold: to arrive at a succint description of the fundamental principles of rewriting systems in general, and to apply well-established verification and analysis techniques of the theory of Petri nets (and also term rewriting systems) to a wide range of distributed and concurrent systems in which states have a “graph-like” structure. The contributions of this thesis thus can be considered as two sides of the same coin: on the one side, concepts and results for Petri nets (and graph grammars) are generalized to an abstract category theoretical setting; on the other side, suitable classes of “graph-like” categories which capture the essential properties of the category of graphs are identified. Two central results are the following: first, (concatenable) processes are faithful partial order representations of equivalence classes of system runs which only differ w.r.t. the rescheduling of causally independent events; second, the unfolding of a system is established as the canonical partial order representation of all possible events (following the work of Winskel). Weakly ω-adhesive categories are introduced as the theoretical foundation for the corresponding formal theorems about processes and unfoldings. The main result states that an unfolding procedure for systems which are given as single pushout grammars in weakly ω-adhesive categories exists and can be characetrised as a right adjoint functor from a category of grammars to the subcategory of occurrence grammars. This result specializes to and improves upon existing results concerning the coreflective semantics of the unfolding of graph grammars and Petri nets (under an individual token interpretation). Moreover, the unfolding procedure is in principle usable as the starting point for static analysis techniques such as McMillan’s finite complete prefix method. Finally, the adequacy of weakly ω-adhesive categories as a categorical framework is argued for by providing a comparison with the notion of topos, which is a standard abstraction of the categories of sets (and graphs).},
	 author={Heindel, Tobias}, 
	 year={2010}, 
	 month={Apr},
   school = {University of Duisburg-Essen}
}



@article{OrejasEhrigP2010,
	title = {Reasoning with graph constraints},
	volume = {22},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-009-0116-9},
	doi = {10.1007/s00165-009-0116-9},
	abstract = {Graph constraints were introduced in the area of graph transformation, in connection with the notion of (negative) application conditions, as a form to limit the applicability of transformation rules. However, we believe that graph constraints may also play a significant role in the area of visual software modelling or in the specification and verification of semi-structured documents or websites (i.e. HTML or XML sets of documents). In this sense, after some discussion on these application areas, we concentrate on the problem of how to prove the consistency of specifications based on this kind of constraints. In particular, we present proof rules for two classes of graph constraints and show that our proof rules are sound and (refutationally) complete for each class. In addition, we study clause subsumption in this context as a form to speed up refutation.},
	language = {en},
	number = {3},
	urldate = {2020-11-15},
	journal = {Formal Aspects of Computing},
	author = {Orejas, Fernando and Ehrig, Hartmut and Prange, Ulrike},
	month = may,
	year = {2010},
	pages = {385--422},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/ENWNKQLR/Orejas et al. - 2010 - Reasoning with graph constraints.pdf:application/pdf}
}



@article{Pennemann2008,
	series = {Proceedings of the {Third} {Workshop} on {Graph} {Transformation} for {Concurrency} and {Verification} ({GT}-{VC} 2007)},
	title = {An {Algorithm} for {Approximating} the {Satisfiability} {Problem} of {High}-level {Conditions}},
	volume = {213},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066108002909},
	doi = {10.1016/j.entcs.2008.04.075},
	abstract = {The satisfiability problem is the fundamental problem in proving the conflict-freeness of specifications, or in finding a counterexample for an invalid statement. In this paper, we present a non-deterministic, monotone algorithm for this undecidable problem on graphical conditions that is both correct and complete, but in general not guaranteed to terminate. For a fragment of high-level conditions, the algorithm terminates, hence it is able to decide. Instead of enumerating all possible objects of a category to approach the problem, the algorithm uses the input condition in a constructive way to progress towards a solution. To this aim, programs over transformation rules with external interfaces are considered. We use the framework of weak adhesive HLR categories. Consequently, the algorithm is applicable to a number of replacement capable structures, such as Petri-Nets, graphs or hypergraphs.},
	language = {en},
	number = {1},
	urldate = {2020-11-15},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Pennemann, Karl-Heinz},
	month = may,
	year = {2008},
	keywords = {first-order satisfiability problem, graph transformation, high-level conditions, high-level programs, weak adhesive HLR categories},
	pages = {75--94},
	file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/Z6VI3SW4/S1571066108002909.html:text/html}
}


@inproceedings{LambersOrejas2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Tableau-{Based} {Reasoning} for {Graph} {Properties}},
	isbn = {978-3-319-09108-2},
	doi = {10.1007/978-3-319-09108-2_2},
	abstract = {Graphs are ubiquitous in Computer Science. For this reason, in many areas, it is very important to have the means to express and reason about graph properties. A simple way is based on defining an appropriate encoding of graphs in terms of classical logic. This approach has been followed by Courcelle. The alternative is the definition of a specialized logic, as done by Habel and Pennemann, who defined a logic of nested graph conditions, where graph properties are formulated explicitly making use of graphs and graph morphisms, and which has the expressive power of Courcelle’s first order logic of graphs. In particular, in his thesis, Pennemann defined and implemented a sound proof system for reasoning in this logic. Moreover, he showed that his tools outperform some standard provers when working over encoded graph conditions.Unfortunately, Pennemann did not prove the completeness of his proof system. In this sense, one of the main contributions of this paper is the solution to this open problem. In particular, we prove the (refutational) completeness of a tableau method based on Pennemann’s rules that provides a specific theorem-proving procedure for this logic. This procedure can be considered our second contribution. Finally, our tableaux are not standard, but we had to define a new notion of nested tableaux that could be useful for other formalisms where formulas have a hierarchical structure like nested graph conditions.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {Lambers, Leen and Orejas, Fernando},
	editor = {Giese, Holger and König, Barbara},
	year = {2014},
	keywords = {Automated deduction, Graph Logic, Graph properties, Graph transformation, Visual modelling},
	pages = {17--32},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/LMMVA9VR/Lambers and Orejas - 2014 - Tableau-Based Reasoning for Graph Properties.pdf:application/pdf}
}


@article{NentwichEmmerichFE2003,
	title = {Flexible consistency checking},
	volume = {12},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/839268.839271},
	doi = {10.1145/839268.839271},
	abstract = {The problem of managing the consistency of heterogeneous, distributed software engineering documents is central to the development of large and complex systems. We show how this problem can be addressed using xlinkit, a lightweight framework for consistency checking that leverages standard Internet technologies. xlinkit provides flexibility, strong diagnostics, and support for distribution and document heterogeneity. We use xlinkit in a comprehensive case study that demonstrates how design, implementation and deployment information of an Enterprise JavaBeans system can be checked for consistency, and rechecked incrementally when changes are made.},
	number = {1},
	urldate = {2020-11-19},
	journal = {ACM Transactions on Software Engineering and Methodology},
	author = {Nentwich, Christian and Emmerich, Wolfgang and Finkelsteiin, Anthony and Ellmer, Ernst},
	month = jan,
	year = {2003},
	keywords = {CASE tools, consistency management, constraint checking, multiple perspectives},
	pages = {28--63},
	file = {Nentwich et al. - 2003 - Flexible consistency checking.pdf:/Users/past/Zotero/storage/B99P74J4/Nentwich et al. - 2003 - Flexible consistency checking.pdf:application/pdf}
}



@inproceedings{MandelCengarle1999,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On the {Expressive} {Power} of {OCL}},
	isbn = {978-3-540-48119-5},
	doi = {10.1007/3-540-48119-2_47},
	abstract = {This paper examines the expressive power of OCL in terms of navigability and computability. First the expressive power of OCL is compared with the relational calculus; it is showed that OCL is not equivalent to the relational calculus. Then an algorithm computing the transitive closure of a binary relation -operation that cannot be encoded in the relational calculus- is expressed in OCL. Finally the equivalence of OCL with a Turing machine is pondered.},
	language = {en},
	booktitle = {{FM}’99 — {Formal} {Methods}},
	publisher = {Springer},
	author = {Mandel, Luis and Cengarle, María Victoria},
	editor = {Wing, Jeannette M. and Woodcock, Jim and Davies, Jim},
	year = {1999},
	keywords = {Query Language, Class Diagram, Object Constraint Language, Expressive Power, Transitive Closure},
	pages = {854--874},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/K59GAKZP/Mandel and Cengarle - 1999 - On the Expressive Power of OCL.pdf:application/pdf}
}

@inproceedings{HabelSandmann2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Graph {Repair} by {Graph} {Programs}},
	isbn = {978-3-030-04771-9},
	doi = {10.1007/978-3-030-04771-9_31},
	abstract = {Model repair is an essential topic in model-driven engineering. We consider the problem of graph repair: Given a graph constraint, we try to construct a graph program, such that the application to any graph yields a graph satisfying the graph constraint. We show the existence of terminating repair programs for a number of satisfiable constraints.},
	language = {en},
	booktitle = {Software {Technologies}: {Applications} and {Foundations}},
	publisher = {Springer International Publishing},
	author = {Habel, Annegret and Sandmann, Christian},
	editor = {Mazzara, Manuel and Ober, Iulian and Salaün, Gwen},
	year = {2018},
	pages = {431--446},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/ZSILQQP6/Habel and Sandmann - 2018 - Graph Repair by Graph Programs.pdf:application/pdf}
}

@phdthesis{Loewe91Phd,
  author    = {Michael L{\"{o}}we},
  title     = {Extended algebraic graph transformation},
  school    = {Technical University of Berlin, Germany},
  year      = {1991},
  url       = {http://d-nb.info/910935696},
  timestamp = {Thu, 01 Dec 2016 13:00:26 +0100},
  biburl    = {https://dblp.org/rec/phd/dnb/Lowe91.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{LoeweTempelmeier2015,
  author    = {Michael L{\"{o}}we and
               Marius Tempelmeier},
  editor    = {Detlef Plump},
  title     = {Single-Pushout Rewriting of Partial Algebras},
  booktitle = {Proceedings of GCM co-located with
               {ICGT} / {STAF}, L'Aquila, Italy},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {1403},
  pages     = {82--96},
  year      = {2015},
  url       = {http://ceur-ws.org/Vol-1403/paper7.pdf},
  timestamp = {Tue, 28 May 2019 16:23:45 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/gg/LoweT15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@TECHREPORT{SKLRFASE20TechRep, 
  author    = {Patrick St{\"{u}}nkel and
               Harald K{\"{o}}nig and
               Yngve Lamo and
               Adrian Rutle},
  title     = {Towards multiple model synchronization
with comprehensive systems: Extended version},
  institution = {University of {A}pplied {S}ciences, FHDW Hannover},
  year = {2020}, url = {https://fhdwdev.ha.bib.de/public/papers/02020-01.pdf},
  issn = {1863-7043},
  journal = {Forschungsbericht der FHDW Hannover},
  volume = {01}
}


@inproceedings{HaymanHeindel2014,
author="Hayman, Jonathan
and Heindel, Tobias",
editor="Giese, Holger
and K{\"o}nig, Barbara",
title="On Pushouts of Partial Maps",
booktitle="Graph Transformation",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="177--191",
isbn="978-3-319-09108-2",
doi= {10.1007/978-3-319-09108-2_12}
}



@article{BurmeisterMonserratRG1999,
title = {Algebraic transformation of unary partial algebras II: Single-pushout approach},
journal = {Theoretical Computer Science},
volume = {216},
number = {1},
pages = {311-362},
year = {1999},
issn = {0304-3975},
doi = {10.1016/S0304-3975(97)00282-X},
author = {P. Burmeister and M. Monserrat and F. Rosselló and G. Valiente},
keywords = {Graph grammars, Algebraic graph transformation, Partial algebras, High-level replacement systems, HLR conditions},
abstract = {The single-pushout approach to graph transformation is extended to the algebraic transformation of partial many-sorted unary algebras. Such a generalization has been motivated by the need to model the transformation of structures which are richer and more complex than graphs and hypergraphs. The main result presented in this article is an algebraic characterization of the single-pushout transformation in the categories of all conformisms, all closed quomorphisms, and all closed-domain closed quomorphisms of unary partial algebras over a given signature, together with a corresponding operational characterization that may serve as a basis for implementation. Moreover, all three categories are shown to satisfy all of the HLR (high-level replacement) conditions for parallelism, taking as occurrences the total morphisms in each category. Another important result presented in this article is the definition of HLR conditions for amalgamation, which are also satisfied by the categories of partial homomorphisms considered here, taking again the corresponding total morphisms as occurrences.}
}



@inproceedings{Loewe2010,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Graph {Rewriting} in {Span}-{Categories}},
  isbn = {978-3-642-15928-2},
  doi = {10.1007/978-3-642-15928-2_15},
  abstract = {There are three variations of algebraic graph rewriting, the double-pushout, the single-pushout, and the sesqui-pushout approach. In this paper, we show that all three approaches can be considered special cases of a general rewriting framework in suitable categories of spans over a graph-like base category. From this new view point, it is possible to provide a general and unifying theory for all approaches. We demonstrate this fact by the investigation of general parallel independence. Besides this, the new and more general framework offers completely new ways of rewriting: Using spans as matches, for example, provides a simple mechanism for universal quantification. The general theory, however, applies to these new types of rewriting as well.},
  language = {en},
  booktitle = {Graph {Transformations}},
  publisher = {Springer},
  author = {Löwe, Michael},
  editor = {Ehrig, Hartmut and Rensink, Arend and Rozenberg, Grzegorz and Schürr, Andy},
  year = {2010},
  keywords = {Algebraic Approach, Graph Grammar, Graph Transformation, Graph Transformation System, Unique Morphism},
  pages = {218--233},
  annote = {Gluing construction, first mention},
  file = {Löwe - 2010 - Graph Rewriting in Span-Categories.pdf:/Users/past/Zotero/storage/2JIKJYD3/Löwe - 2010 - Graph Rewriting in Span-Categories.pdf:application/pdf}
}



@inproceedings{Loewe2012,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Refined {Graph} {Rewriting} in {Span}-{Categories}},
  isbn = {978-3-642-33654-6},
  doi = {10.1007/978-3-642-33654-6_8},
  abstract = {There are three major algebraic approaches to graph transformation, namely the double-pushout (DPO), single-pushout (SPO), and sesqui-pushout approach (SqPO). In this paper, we present a framework that generalises all three approaches. The central issue is a gluing construction, which is a generalisation of the construction introduced in [14]. It has pushout-like properties wrt. composition and decomposition, which allow to reestablish major parts of the theory for the algebraic approaches on a general level. We investigate parallel independence here.},
  language = {en},
  booktitle = {Graph {Transformations}},
  publisher = {Springer},
  author = {Löwe, Michael},
  editor = {Ehrig, Hartmut and Engels, Gregor and Kreowski, Hans-Jörg and Rozenberg, Grzegorz},
  year = {2012},
  pages = {111--125},
  annote = {Refinement of the Gluing construction}
}



@article{EhrigGolasH2013,
  title = {Categorical {Frameworks} for {Graph} {Transformation} and {HLR} {Systems} {Based} on the {DPO} {Approach}},
  volume = {3},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a Creative Commons Attribution License that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.       Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.},
  abstract = {Categorical Frameworks for Graph Transformation and HLR Systems Based on the DPO Approach},
  language = {en},
  number = {102},
  urldate = {2020-12-03},
  journal = {Bulletin of EATCS},
  author = {Ehrig, Hartmut and Golas, Ulrike and Hermann, Frank},
  month = sep,
  year = {2013},
  note = {Number: 102},
  annote = {survey on DPO structures},
}


@proceedings{ICGT2020,
  editor    = {Fabio Gadducci and
               Timo Kehrer},
  title     = {Graph Transformation - 13th International Conference, {ICGT} 2020,
               Held as Part of {STAF} 2020, Bergen, Norway, June 25-26, 2020, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12150},
  publisher = {Springer},
  year      = {2020},
  doi       = {10.1007/978-3-030-51372-6},
  isbn      = {978-3-030-51371-9},
  timestamp = {Fri, 26 Jun 2020 10:05:13 +0200},
  biburl    = {https://dblp.org/rec/conf/gg/2020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{Aken2004,
  title = {Management {Research} {Based} on the {Paradigm} of the {Design} {Sciences}: {The} {Quest} for {Field}-{Tested} and {Grounded} {Technological} {Rules}},
  volume = {41},
  issn = {1467-6486},
  shorttitle = {Management {Research} {Based} on the {Paradigm} of the {Design} {Sciences}},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-6486.2004.00430.x},
  doi = {https://doi.org/10.1111/j.1467-6486.2004.00430.x},
  abstract = {Academic management research has a serious utilization problem. In this field mainstream research tends to be description-driven, based on the paradigm of the ‘explanatory sciences’, like physics and sociology, and resulting in what may be called Organization Theory. This article argues that the relevance problem can be mitigated if such research were to be complemented with prescription-driven research, based on the paradigm of the ‘design sciences’, like Medicine and Engineering, and resulting in what may be called Management Theory. The typical research products in Management Theory would be ‘field-tested and grounded technological rules’. The nature of such rules is discussed as well as the research strategies producing them.},
  language = {en},
  number = {2},
  urldate = {2021-01-08},
  journal = {Journal of Management Studies},
  author = {Aken, Joan E. van},
  year = {2004},
  note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-6486.2004.00430.x},
  pages = {219--246},
  file = {Snapshot:/Users/past/Zotero/storage/99AKST2W/j.1467-6486.2004.00430.html:text/html}
}


@inproceedings{NunamakerChen1990,
  title = {Systems development in information systems research},
  volume = {3},
  doi = {10.1109/HICSS.1990.205401},
  abstract = {The authors critically review systems development in information systems (IS) research. Several classification schemes of research are described and systems development is identified as a developmental, engineering, and formulative type of research. A framework of research is proposed to explain the dual nature of systems development as a research methodology and a research domain in IS research. Progress in several disciplinary areas is reviewed to provide a basis to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, the basic method is applying the systems development research methodology, is then discussed. A framework to classify IS research domain and various research methodologies in studying systems development is presented. It is suggested that systems development and empirical research methodologies are complementary to each other. It is further proposed that an integrated multidimensional and multimethodological approach will generate fruitful research results in IS research.{\textless}{\textgreater}},
  booktitle = {Twenty-{Third} {Annual} {Hawaii} {International} {Conference} on {System} {Sciences}},
  author = {Nunamaker, J. F. and Chen, M.},
  month = jan,
  year = {1990},
  keywords = {classification schemes, Design engineering, Design methodology, Humans, Information systems, information systems research, Management information systems, Production systems, Prototypes, Research and development, research domain, research methodology, software engineering, Software engineering, systems analysis, systems development, Testing},
  pages = {631--640 vol.3},
  annote = {really old citation},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/MIDKWGGJ/205401.html:text/html}
}


@article{WallsWidmeyerGE1992,
  title = {Building an {Information} {System} {Design} {Theory} for {Vigilant} {EIS}},
  volume = {3},
  issn = {1047-7047},
  url = {https://www.jstor.org/stable/23010780},
  abstract = {This paper defines an information system design theory (ISDT) to be a prescriptive theory which integrates normative and descriptive theories into design paths intended to produce more effective information systems. The nature of ISDTs is articulated using Dubin's concept of theory building and Simon's idea of a science of the artificial. An example of an ISDT is presented in the context of Executive Information Systems (EIS). Despite the increasing awareness of the potential of EIS for enhancing executive strategic decision-making effectiveness, there exists little theoretical work which directly guides EIS design. We contend that the underlying theoretical basis of EIS can be addressed through a design theory of vigilant information systems. Vigilance denotes the ability of an information system to help an executive remain alertly watchful for weak signals and discontinuities in the organizational environment relevant to emerging strategic threats and opportunities. Research on managerial information scanning and emerging issue tracking as well as theories of open loop control are synthesized to generate vigilant information system design theory propositions. Transformation of the propositions into testable empirical hypotheses is discussed.},
  number = {1},
  urldate = {2021-01-08},
  journal = {Information Systems Research},
  author = {Walls, Joseph G. and Widmeyer, George R. and El Sawy, Omar A.},
  year = {1992},
  note = {Publisher: INFORMS},
  pages = {36--59},
  annote = {One of the oldest references for Design Science}
}



@article{Papalambros2015,
  title = {Design {Science}: {Why}, {What} and {How}},
  volume = {1},
  issn = {2053-4701},
  shorttitle = {Design {Science}},
  url = {https://www.cambridge.org/core/journals/design-science/article/design-science-why-what-and-how/A575D750B05AE57AAF9E7CA07E44FEF4},
  doi = {10.1017/dsj.2015.1},
  abstract = {},
  language = {en},
  urldate = {2021-01-08},
  journal = {Design Science},
  author = {Papalambros, Panos Y.},
  month = jul,
  year = {2015},
  note = {Publisher: Cambridge University Press},
  file = {Full Text PDF:/Users/past/Zotero/storage/VXFU9UQT/Papalambros - 2015 - Design Science Why, What and How.pdf:application/pdf}
}


@book{Simon1969,
  title = {The {Sciences} of the {Artificial}},
  isbn = {978-0-262-53753-7},
  abstract = {Herbert Simon's classic work on artificial intelligence in the expanded and updated third edition from 1996, with a new introduction by John E. Laird.Herbert Simon's classic and influential The Sciences of the Artificial declares definitively that there can be a science not only of natural phenomena but also of what is artificial. Exploring the commonalities of artificial systems, including economic systems, the business firm, artificial intelligence, complex engineering projects, and social plans, Simon argues that designed systems are a valid field of study, and he proposes a science of design. For this third edition, originally published in 1996, Simon added new material that takes into account advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action.Simon won the Nobel Prize for Economics in 1978 for his research into the decision-making process within economic organizations and the Turing Award (considered by some the computer science equivalent to the Nobel) with Allen Newell in 1975 for contributions to artificial intelligence, the psychology of human cognition, and list processing. The Sciences of the Artificial distills the essence of Simon's thought accessibly and coherently. This reissue of the third edition makes a pioneering work available to a new audience.},
  language = {en},
  publisher = {MIT Press},
  author = {Simon, Herbert A.},
  month = jan,
  year = {1969},
  edition ={third},
  keywords = {Computers / Intelligence (AI) \& Semantics}
}



@article{Markus2002,
  title = {A {Design} {Theory} for {Systems} {That} {Support} {Emergent} {Knowledge} {Processes}},
  volume = {26},
  issn = {0276-7783},
  url = {https://www.jstor.org/stable/4132330},
  abstract = {This paper addresses the design problem of providing IT support for emerging knowledge processes (EKPs). EKPs are organizational activity patterns that exhibit three characteristics in combination: an emergent process of deliberations with no best structure or sequence; requirements for knowledge that are complex (both general and situational), distributed across people, and evolving dynamically; and an actor set that is unpredictable in terms of job roles or prior knowledge. Examples of EKPs include basic research, new product development, strategic business planning, and organization design. EKPs differ qualitatively from semi-structured decision making processes; therefore, they have unique requirements that are not all thoroughly supported by familiar classes of systems, such as executive information systems, expert systems, electronic communication systems, organizational memory systems, or repositories. Further, the development literature on familiar classes of systems does not provide adequate guidance on how to build systems that support EKPs. Consequently, EKPs require a new IS design theory, as explicated by Walls et al. (1992). We created such a theory while designing and deploying a system for the EKP of organization design. The system was demonstrated through subsequent empirical analysis to be successful in supporting the process. Abstracting from the experience of building this system, we developed an IS design theory for EKP support systems. This new IS design theory is an important theoretical contribution, because it both provides guidance to developers and sets an agenda for academic research. EKP design theory makes the development process more tractable for developers by restricting the range of effective features (or rules for selecting features) and the range of effective development practices to a more manageable set EKP design theory also sets an agenda for academic research by articulating theory-based principles that are subject to empirical, as well as practical, validation.},
  number = {3},
  urldate = {2021-01-08},
  journal = {MIS Quarterly},
  author = {Markus, M. Lynne and Majchrzak, Ann and Gasser, Les},
  year = {2002},
  note = {Publisher: Management Information Systems Research Center, University of Minnesota},
  pages = {179--212},
  annote = {The iteration aspect of Design Science}
}



@article{HevnerMarchPR2004,
  title = {Design {Science} in {Information} {Systems} {Research}},
  volume = {28},
  issn = {0276-7783},
  url = {https://www.jstor.org/stable/25148625},
  doi = {10.2307/25148625},
  abstract = {Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.},
  number = {1},
  urldate = {2021-01-07},
  journal = {MIS Quarterly},
  author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
  year = {2004},
  note = {Publisher: Management Information Systems Research Center, University of Minnesota},
  pages = {75--105}
}


@article{Hevner2007,
  title = {A {Three} {Cycle} {View} of {Design} {Science} {Research}},
  volume = {19},
  url = {https://aisel.aisnet.org/sjis/vol19/iss2/4},
  number = {2},
  journal = {Scandinavian Journal of Information Systems},
  author = {Hevner, Alan},
  month = jan,
  year = {2007},
  annote = {The three cycle picture of Design Science}
}




@article{MarchSmith1995,
  title = {Design and natural science research on information technology},
  volume = {15},
  issn = {0167-9236},
  abstract = {Research in IT must address the design tasks faced by practitioners. Real problems must be properly conceptualized and represented, appropriate techniques for their solution must be constructed, and solutions must be implemented and evaluated using appropriate criteria. If significant progress is to be made, IT research must also develop an understanding of how and why IT systems work or do not work. Such an understanding must tie together natural laws governing IT systems with natural laws governing the environments in which they operate. This paper presents a two dimensional framework for research in information technology. The first dimension is based on broad types of design and natural science research activities: build, evaluate, theorize, and justify. The second dimension is based on broad types of outputs produced by design research: representational constructs, models, methods, and instantiations. We argue that both design science and natural science activities are needed to insure that IT research is both relevant and effective.},
  number = {4},
  journal = {Decision Support Systems},
  author = {March, Salvatore T. and Smith, Gerald F.},
  month = dec,
  year = {1995},
  keywords = {Design science, Information system research, Information technology, Natural science},
  pages = {251--266},
  annote = {Identify Design as
build, evaluate, theorize, justify (processes)
as well as
constructs, models, methods, and instantiations (artefacts).
Two kinds of scientific interest in IT: prescriptive and descriptive, knowledge producing vs. knowledge using},
  file = {March and Smith - 1995 - Design and natural science research on information.pdf:/Users/past/Zotero/storage/Z4FEDWP5/March and Smith - 1995 - Design and natural science research on information.pdf:application/pdf}
}



@article{KuechlerVaishnavi2008,
  title = {On theory development in design science research: anatomy of a research project},
  volume = {17},
  issn = {0960-085X, 1476-9344},
  shorttitle = {On theory development in design science research},
  url = {https://link.springer.com/article/10.1057/ejis.2008.40},
  doi = {10.1057/ejis.2008.40},
  abstract = {The common understanding of design science research in information systems (DSRIS) continues to evolve. Only in the broadest terms has there been consensus: that DSRIS involves, in some way, learning through the act of building. However, what is to be built – the definition of the DSRIS artifact – and how it is to be built – the methodology of DSRIS – has drawn increasing discussion in recent years. The relationship of DSRIS to theory continues to make up a significant part of the discussion: how theory should inform DSRIS and whether or not DSRIS can or should be instrumental in developing and refining theory. In this paper, we present the exegesis of a DSRIS research project in which creating a (prescriptive) design theory through the process of developing and testing an information systems artifact is inextricably bound to the testing and refinement of its kernel theory.},
  language = {en},
  number = {5},
  urldate = {2018-01-23},
  journal = {European Journal of Information Systems},
  author = {Kuechler, Bill and Vaishnavi, Vijay},
  month = oct,
  year = {2008},
  pages = {489--504},
  annote = {{\textbackslash}cite\{KuechlerVashnavi2008\}},
  annote = {how Design Science contributes to the extension of kernel theories.},
  file = {Full Text PDF:/Users/past/Zotero/storage/GA6HXBHW/Kuechler and Vaishnavi - 2008 - On theory development in design science research .pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/IB46GZ7N/ejis.2008.html:text/html}
}



@article{Goldkuhl2004,
  title = {Design {Theories} in {Information} {Systems} - {A} {Need} for {Multi}-{Grounding}},
  volume = {6},
  issn = {1532-4516},
  url = {https://aisel.aisnet.org/jitta/vol6/iss2/7},
  number = {2},
  journal = {Journal of Information Technology Theory and Application (JITTA)},
  author = {Goldkuhl, Goran},
  month = jul,
  year = {2004},
  annote = {Relationship between Kernel and Design Theories, the latter require grounding both theoretical and empirical, and internal grounding},
  file = {"Design Theories in Information Systems - A Need for Multi-Grounding" by Goran Goldkuhl:/Users/past/Zotero/storage/RBK2CMQR/7.html:text/html;Goldkuhl - 2004 - Design Theories in Information Systems - A Need fo.pdf:/Users/past/Zotero/storage/V8SKFYU7/Goldkuhl - 2004 - Design Theories in Information Systems - A Need fo.pdf:application/pdf}
}


@article{IvariVenable2009,
  title = {Action research and design science research - {Seemingly} similar but decisively dissimilar},
  url = {https://aisel.aisnet.org/ecis2009/73},
  journal = {ECIS 2009 Proceedings},
  author = {Ivari, Juhani and Venable, John},
  month = jan,
  year = {2009},
}


@inproceedings{Venable2006,
  title = {The {Role} of {Theory} and {Theorising} in {Design} {Science} {Research}},
  abstract = {The literature on Design Science (or Design Research) has been mixed on the inclusion, form, and role of theory and theorising in Design Science. Some authors have explicitly excluded theory development and testing from Design Science, leaving them to the Natural and Social/Behavioural Sciences. Others propose including theory development and testing as part of Design Science. Others propose some ideas for the content of IS Design Theories, although more detailed and clear concepts would be helpful. This paper discusses the need and role for theory in Design Science. It further proposes some ideas for standards for the form and level of detail needed for theories in Design Science. Finally it develops a framework of activities for the interaction of Design Science with research in other scientific paradigms.},
  booktitle = {in: {Design} {Science} {Research} in {Information} {Systems} and {Technology}},
  author = {Venable, John R.},
  year = {2006},
  file = {Citeseer - Full Text PDF:/Users/past/Zotero/storage/9PEJCU5R/Venable - 2006 - The Role of Theory and Theorising in Design Scienc.pdf:application/pdf;Citeseer - Snapshot:/Users/past/Zotero/storage/Y6AC3XES/summary.html:text/html}
}


@book{Petroski1996,
  address = {Cambridge, Mass.},
  title = {Invention by design: how engineers get from thought to thing},
  shorttitle = {Invention by design},
  url = {http://www.aspresolver.com/aspresolver.asp?ENGV;2208082},
  abstract = {Engineering entails more than knowing the way things work. What do economics and ecology, aesthetics and ethics, have to do with the shape of a paper clip, the tab of a beverage can, the cabin design of a turbojet, or the course of a river? How do the idiosyncrasies of individual engineers, companies, and communities leave their mark on projects from Velcro to fax machines to waterworks? Invention by Design offers an insider's look at these political and cultural dimensions of design and development, production and construction.},
  language = {This edition in English.},
  urldate = {2021-01-08},
  publisher = {Harvard University Press},
  author = {Petroski, Henry},
  year = {1996},
  note = {OCLC: 605492286}
}



@book{Dym2013,
  title = {Engineering {Design}: {A} {Project}-{Based} {Introduction}},
  isbn = {978-1-118-80705-7},
  shorttitle = {Engineering {Design}},
  abstract = {Cornerstone Engineering Design combines a wide range of topics such as design, engineering design, project management, team dynamics and project-based learning into a single introductory work. The text focuses particularly on conceptual design, providing a brief, and yet comprehensive introduction to design methodology and project management tools to students early on in their careers.},
  language = {en},
  publisher = {Wiley},
  author = {Dym, Clive L.},
  year = {2013},
  note = {Google-Books-ID: SPnEwAEACAAJ}
}


@article{Ivari2007,
  title = {A {Paradigmatic} {Analysis} of {Information} {Systems} {As} a {Design} {Science}},
  volume = {19},
  url = {https://aisel.aisnet.org/sjis/vol19/iss2/5},
  number = {2},
  journal = {Scandinavian Journal of Information Systems},
  author = {Ivari, Juhani},
  month = jan,
  year = {2007},
  annote = {important essay on design science},
}



@article{KitchenhamPfleegerPJHKR2002,
  title = {Preliminary guidelines for empirical research in software engineering},
  volume = {28},
  issn = {0098-5589},
  url = {https://doi.org/10.1109/TSE.2002.1027796},
  doi = {10.1109/TSE.2002.1027796},
  abstract = {Empirical software engineering research needs research guidelines to improve the research and reporting processes. We propose a preliminary set of research guidelines aimed at stimulating discussion among software researchers. They are based on a review of research guidelines developed for medical researchers and on our own experience in doing and reviewing software engineering research. The guidelines are intended to assist researchers, reviewers, and meta-analysts in designing, conducting, and evaluating empirical studies. Editorial boards of software engineering journals may wish to use our recommendations as a basis for developing guidelines for reviewers and for framing policies for dealing with the design, data collection, and analysis and reporting of empirical studies.},
  number = {8},
  urldate = {2021-01-11},
  journal = {IEEE Transactions on Software Engineering},
  author = {Kitchenham, Barbara A. and Pfleeger, Shari Lawrence and Pickard, Lesley M. and Jones, Peter W. and Hoaglin, David C. and Emam, Khaled El and Rosenberg, Jarrett},
  month = aug,
  year = {2002},
  keywords = {empirical software research, research guidelines, statistical mistakes},
  pages = {721--734},
  file = {Full Text:/Users/past/Zotero/storage/5N2V9IWF/Kitchenham et al. - 2002 - Preliminary guidelines for empirical research in s.pdf:application/pdf}
}



@article{SilverMarkusB1995,
  title = {The {Information} {Technology} {Interaction} {Model}: {A} {Foundation} for the {MBA} {Core} {Course}},
  volume = {19},
  issn = {0276-7783},
  shorttitle = {The {Information} {Technology} {Interaction} {Model}},
  url = {https://www.jstor.org/stable/249600},
  doi = {10.2307/249600},
  abstract = {This paper presents a teaching model that has been used successfully in the MBA core course in information systems at several universities. The model is referred to as the "Information Technology Interaction Model" because it maintains that the consequences of information systems in organizations follow largely from the interaction of the technology with the organization and its environment. The model serves a number of pedagogical purposes: to integrate the various course components, to provide a formal foundation for the course content, to foster practical analytical skills, and to provide a framework for case discussions and student projects. Moreover, the model is intended to acquaint students with the dynamics of information systems in organizations and to help them recognize the benefits, dangers, and limitations of these systems. The paper includes a discussion and examples of how the model can be used for proactive and reactive analyses, and it concludes with observations on the model's effectiveness in the core course.},
  number = {3},
  urldate = {2021-01-08},
  journal = {MIS Quarterly},
  author = {Silver, Mark S. and Markus, M. Lynne and Beath, Cynthia Mathis},
  year = {1995},
  note = {Publisher: Management Information Systems Research Center, University of Minnesota},
  pages = {361--390},
  annote = {Infromation systems are people, organization and technology}
}



@article{Fraassen2010,
  title = {Scientific {Representation}: {Paradoxes} of {Perspective}},
  volume = {70},
  issn = {0003-2638},
  shorttitle = {Scientific {Representation}},
  url = {https://doi.org/10.1093/analys/anq042},
  doi = {10.1093/analys/anq042},
  number = {3},
  urldate = {2021-01-14},
  journal = {Analysis},
  author = {van Fraassen, Bas C.},
  month = jul,
  year = {2010},
  pages = {511--514},
  file = {Snapshot:/Users/past/Zotero/storage/TMLJRGFQ/158437.html:text/html}
}



@book{Feyerabend1993,
  title = {Against {Method}},
  isbn = {978-0-86091-646-8},
  abstract = {Modern philosophy of science has paid great attention to the understanding of scientific 'practice', in contrast to concentration on scientific 'method'. Paul Feyerabend's acclaimed work, which has contributed greatly to this new emphasis, shows the deficiencies of some widespread ideas about the nature of knowledge. He argues that the only feasible explanations of scientific successes are historical explanations, and that anarchism must now replace rationalism in the theory of knowledge.  The third edition of this classic text contains a new preface and additional reflections at various points in which the author takes account both of recent debates on science and on the impact of scientific products and practices on the human community. While disavowing populism or relativism, Feyerabend continues to insist that the voice of the inexpert must be heard. Thus many environmental perils were first identified by non-experts against prevailing assumptions in the scientific community. Feyerabend's challenging reassessment of scientific claims and understandings are as pungent and timely as ever.},
  language = {en},
  publisher = {Verso},
  author = {Feyerabend, Paul},
  year = {1993},
  keywords = {Philosophy / Epistemology}
}



@book{Wittgenstein1922,
  title = {Tractatus {Logico}-{Philosophicus}},
  author = {Wittgenstein, Ludwig},
  year = {1922},
  pulisher = {Annalen der Naturphilosophie}
}



@article{CorbinStrauss1990,
  title = {Grounded theory research: {Procedures}, canons, and evaluative criteria},
  volume = {13},
  issn = {1573-7837},
  shorttitle = {Grounded theory research},
  url = {https://doi.org/10.1007/BF00988593},
  doi = {10.1007/BF00988593},
  abstract = {Using grounded theory as an example, this paper examines three methodological questions that are generally applicable to all qualitative methods. How should the usual scientific canons be reinterpreted for qualitative research? How should researchers report the procedures and canons used in their research? What evaluative criteria should be used in judging the research products? We propose that the criteria should be adapted to fit the procedures of the method. We demonstrate how this can be done for grounded theory and suggest criteria for evaluating studies following this approach. We argue that other qualitative researchers might be similarly specific about their procedures and evaluative criteria.},
  language = {en},
  number = {1},
  urldate = {2019-09-06},
  journal = {Qualitative Sociology},
  author = {Corbin, Juliet M. and Strauss, Anselm},
  month = mar,
  year = {1990},
  keywords = {Qualitative Method, Qualitative Research, Research Product, Social Issue, Social Psychology},
  pages = {3--21},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/8KSJ5QI7/Corbin and Strauss - 1990 - Grounded theory research Procedures, canons, and .pdf:application/pdf}
}


@book{GlaserStrauss1967,
  title = {The {Discovery} of {Grounded} {Theory}: {Strategies} for {Qualitative} {Research}},
  isbn = {978-0-202-36337-0},
  shorttitle = {The {Discovery} of {Grounded} {Theory}},
  abstract = {Most writing on sociological method has been concerned with how accurate facts can be obtained and how theory can thereby be more rigorously tested. In The Discovery of Grounded Theory, Barney Glaser and Anselm Strauss address the equally Important enterprise of how the discovery of theory from data—systematically obtained and analyzed in social research—can be furthered. The discovery of theory from data—grounded theory—is a major task confronting sociology, for such a theory fits empirical situations, and is understandable to sociologists and laymen alike. Most important, it provides relevant predictions, explanations, interpretations, and applications. In Part I of the book, "Generation Theory by Comparative Analysis," the authors present a strategy whereby sociologists can facilitate the discovery of grounded theory, both substantive and formal. This strategy involves the systematic choice and study of several comparison groups. In Part II, The Flexible Use of Data," the generation of theory from qualitative, especially documentary, and quantitative data Is considered. In Part III, "Implications of Grounded Theory," Glaser and Strauss examine the credibility of grounded theory. The Discovery of Grounded Theory is directed toward improving social scientists' capacity for generating theory that will be relevant to their research. While aimed primarily at sociologists, it will be useful to anyone Interested In studying social phenomena—political, educational, economic, industrial— especially If their studies are based on qualitative data.},
  language = {en},
  publisher = {Transaction Publishers},
  author = {Glaser, Barney G. and Strauss, Anselm L.},
  year = {1967},
  keywords = {Social Science / Methodology, Social Science / Research, Social Science / Sociology / General}
}


@book{Newton1687,
  title = {Philosophiæ {Naturalis} {Principia} {Mathematica}},
  author = {Newton, Isaac},
  year = {1687}
}


@inproceedings{BudgenTurnerBK2008,
  title = {Using {Mapping} {Studies} in {Software} {Engineering}},
  volume = {8},
  booktitle = {Proceedings of {PPIG}},
  author = {Budgen, David and Turner, Mark and Brereton, Pearl and Kitchenham, Barbara},
  year = {2008},
  keywords = {evidence based software engineering, systematic mapping studies, methodology},
}

@book{Castells1999,
  title = {The {Information} {Age}, {Volumes} 1-3: {Economy}, {Society} and {Culture}},
  isbn = {978-0-631-21594-3},
  shorttitle = {The {Information} {Age}, {Volumes} 1-3},
  abstract = {The Information Age is a three volume investigation of contemporary global economic, political and social change. It is a work of outstanding penetration, originality and importance. The three volumes are now available to buy as an attractive boxed set.},
  language = {en},
  publisher = {Wiley},
  author = {Castells, Manuel},
  month = jul,
  year = {1999},
  note = {Google-Books-ID: NtNHAQAACAAJ},
  keywords = {Social Science / Sociology / General}
}



@article{DybaKitchenhamJ2005,
  title = {Evidence-based software engineering for practitioners},
  volume = {22},
  issn = {1937-4194},
  doi = {10.1109/MS.2005.6},
  abstract = {Software managers and practitioners often must make decisions about what technologies to employ on their projects. They might be aware of problems with their current development practices (for example, production bottlenecks or numerous defect reports from customers) and want to resolve them. Or, they might have read about a new technology and want to take advantage of its promised benefits. However, practitioners can have difficulty making informed decisions about whether to adopt a new technology because there's little objective evidence to confirm its suitability, limits, qualities, costs, and inherent risks. This can lead to poor decisions about technology adoption. Software engineers might make incorrect decisions about adopting new techniques it they don't consider scientific evidence about the techniques' efficacy. They should consider using procedures similar to ones developed for evidence-based medicine. Software companies are often under pressure to adopt immature technologies because of market and management pressures. We suggest that practitioners consider evidence-based software engineering as a mechanism to support and improve their technology adoption decisions.},
  number = {1},
  journal = {IEEE Software},
  author = {Dyba, T. and Kitchenham, B. A. and Jorgensen, M.},
  month = jan,
  year = {2005},
  note = {Conference Name: IEEE Software},
  keywords = {Appraisal, Appropriate technology, Communications technology, decision making, DP industry, empirical software engineering, Engineering management, evaluation, evidence, evidence-based medicine, evidence-based software engineering, Laboratories, Medical treatment, Production, project management, Project management, risk management, scientific evidence, software companies, software development management, Software engineering, software maintenance, software managers, software quality, Technology management, technology transfer},
  pages = {58--65},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/PV6Y2NYB/1377125.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/EFILK9H7/Dyba et al. - 2005 - Evidence-based software engineering for practition.pdf:application/pdf}
}



@article{StuenkelBargenRL2020,
  title = {{GraphQL} {Federation}: {A} {Model}-{Based} {Approach}},
  volume = {19},
  copyright = {All rights reserved},
  issn = {1660-1769},
  doi = {10.5381/jot.2020.19.2.a18.},
  abstract = {The Graph Query Language (GraphQL) is a framework for de- veloping Web Services, which works on the domain model level rather than the functions. While the declarative nature of this framework has already attracted the interest of practitioners in both academia and industry, it still lacks integration capabilities. This shortcoming has been recognized in the industry; there exists a first tool creating a federation—a virtual integrated system—on top of instrumented systems. Being relatively new, it suffers from a few practical and conceptual shortcomings, such as consolidation of (conflicting) schemas and identification of multiple types. In this paper, we will analyze the federation challenge and propose a solution utilizing multi-view modeling and domain specific modeling. Our approach is accom- panied by a proof-of-concept implementation and provides a model-based presentation of the GraphQL framework.},
  number = {2},
  journal = {Journal of Object Technology},
  author = {Stünkel, Patrick and Bargen, Ole van and Rutle, Adrian and Lamo, Yngve},
  year = {2020},
  pages = {18:1--21},
  month = jul
}



@article{StuenkelKoenigRL2021,
  title = {Multi-{Model} {Evolution} through {Model} {Repair}},
  volume = {20},
  issn = {1660-1769},
  doi = {doi:10.5381/jot.2021.20.1.a2},
  abstract = {esign and development of complex software systems usually comprises multiple inter-related models, i.e. abstract representations of certain aspects of the underlying system. The relations between these models induce global consistency conditions which the models collectively must fulfill. At the same time, these models are subject to frequent changes, and as a result, maintaining their global consistency over time becomes an important issue in model management in general and Model-Driven Software Engineering in particular. In this paper, we present a comprehensive feature model providing an overview of the current state of the art of model management. In this feature model, we further identify the central role of model repair as an implementation pattern for (multi-)model evolution.},
  number = {1},
  journal = {Journal of Object Technology},
  author = {Stünkel, Patrick and König, Harald and Rutle, Adrian and Lamo, Yngve},
  year = {2021},
  pages = {1:1--25},
  month = jan
}


@article{Backus1998,
  title = {The history of {Fortran} {I}, {II}, and {III}},
  volume = {20},
  issn = {1934-1547},
  doi = {10.1109/85.728232},
  abstract = {The article discusses attitudes about "automatic programming", the economics of programming, and existing programming systems, all in the early 1950s. It describes the formation of the Fortran group, its knowledge of existing systems, its plans for Fortran, and the development of the language in 1954. It describes the development of the optimizing compiler for Fortran I, of various language manuals, and of Fortran II and III. It concludes with remarks about later developments and the impact of Fortran and its successors on programming today.},
  number = {4},
  journal = {IEEE Annals of the History of Computing},
  author = {Backus, J.},
  month = oct,
  year = {1998},
  note = {Conference Name: IEEE Annals of the History of Computing},
  keywords = {automatic programming, Automatic programming, Decision support systems, Environmental economics, FORTRAN, Fortran group, Fortran I, Fortran II, Fortran III, history, History, language manuals, optimising compilers, optimizing compiler, Optimizing compilers, programming economics, programming systems},
  pages = {68--78},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/QA9GHE5X/728232.html:text/html}
}



@article{Sammet2000,
  title = {The real creators of {Cobol}},
  volume = {17},
  issn = {1937-4194},
  doi = {10.1109/52.841602},
  abstract = {Contrary to persistent myths, a committee initially created Cobol in 1959, not one person. The article outlines the creation and mission of the committee that developed the language and a few of the major inputs and influences on Cobol's initial development, including the people actually involved. This material is based on documents from the 1959 committee work which are in the possession of the author.},
  number = {2},
  journal = {IEEE Software},
  author = {Sammet, J. E.},
  month = mar,
  year = {2000},
  note = {Conference Name: IEEE Software},
  keywords = {Books, COBOL, Cobol creators, Cobol language, committee work, Computer languages, Data processing, Executive Committee, history, History, initial development, Insurance, Mathematics, Natural languages, societies, Terminology, Vocabulary},
  pages = {30--32},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/62INNI9K/841602.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/QP3GIL6P/Sammet - 2000 - The real creators of Cobol.pdf:application/pdf}
}


@book{Wexelblat1978,
  address = {New York, NY, USA},
  title = {History of {Programming} {Languages}},
  isbn = {0-12-745040-8},
  abstract = {These proceedings of the ACM SIGPLAN History of Programming Languages (HOPL) conference are a record, in the words of those who helped make the history, of a baker's dozen of the languages that set the tone of most of today's programming. It is difficult to describe the feeling that prevailed at the conference. There were no parallel sessions. Some attendees were graduate students, some pioneers, many were practitioners, and there seemed roughly an even division between industrial and academic affiliation. It was the first conference I attended where virtually everyone attended every session.The Conference General Chairman's introduction (page xvii) provides a rationale for the languages chosen and what the speakers were asked to prepare. There was an official Conference Historian. (How can you have a "History of . . ." conference without a historian?) His introduction (page xxi) attempts to present the conference in the perspective of modern history-of-science scholarship.The Keynote Address (page 7) was given by Grace Murray Hopper, Captain, USN, who was present at the birth of the industry and has remained an active participant. Her remarks indicate that a lot of what is considered novel and innovative today may well have first been done by her Remington-Rand Univac crew back in the 1950s.The largest part of this volume is taken up with the languages themselves, in chapters each assembled in the following way:The formal paper from the preprints (with some modifications by the authors).A transcript of the formal conference presentation.A transcript of the discussant's presentation. (There were discussants for APL, COBOL, FORTRAN, LISP, PL/I, and SIMULA only.)A transcript of the question and answer session.The full text of questions submitted in writing by the attendees (some with additional answers provided by the author).Authors' biographies.Summaries of the languages appear in Appendix A.The order of the languages in this book is the order of the talks given at the conference. With the exception of JOSS, the formal papers were published as preprints in ACM SIGPLAN Notices, Vol. 13, No. 8 (August 1978). The papers are reprinted here with the permission of ACM and of the authors. In some cases, changes to the preprints have been made by the authors to correct typographical or factual errors. In a few cases, additional material was added.For ALGOL, two speakers were chosen initially to reflect the European and American points of view. An additional "short note" from another ALGOL pioneer has also been included.The section on JOSS has a slightly different format since, due to a change in planned speaker, no paper for JOSS appeared in the preprints. To provide a broad historical outlook, the speaker was requested to make major revisions, expanding his talk into a formal paper.No two speakers are alike and the transcripts of the talks reflect the differences. Some tended to repeat in the oral presentation the material in the formal preprint; others gave almost completely independent talks. In editing the transcripts, no attempt was made to remove redundancy. As far as possible, all that was said is included here. Editing has removed false starts and hesitations; punctuation has been added to try to clarify involved, run-on sentences. Interpolations are, for the most part, enclosed in brackets. Most sessions began and ended with administrative announcements which are omitted here.Some of the talks were followed by formal presentations by discussants, and the transcripts of these are presented with the same type of editing as was used with the talks.The question and answer sessions were handled at the conference by having written questions submitted to the session chairman during the talk. The chairman selected some of them to ask the speaker; the editing of the speakers' replies is similar to that indicated above.The full text of all questions submitted is included and, in several cases, the authors have annotated this list, either keying the questions to the place in the transcript or the paper where it is answered or answering a question not covered at the conference.Authors were asked to provide a brief biography highlighting their activities before the time period covered by the paper and their more recent work. For the most part, the biographies are the author's own words. In a few cases, the editor had to create a narrative biography from a terse curriculum vitae. If editorial license was carried too far in any case, my apologies. The pictures that accompany the biographies are Candid photographs taken during the conference, and the subjects did not have a chance to select which pictures they preferred.The after-dinner speeches at the conference banquet were devoted to humorous reminiscences and anecdotes about the languages and events during their development. The banquet anecdotes are not included in this volume because, although they are humorous to hear, the voice inflections make a big difference, and they are not necessarily amusing to read.Audio and video tapes of the entire conference are available from ACM Headquarters: 1133 Avenue of the Americas, New York, New York 10036.},
  publisher = {Association for Computing Machinery},
  editor = {Wexelblat, Richard L.},
  year = {1978}
}



@article{Parnas1984,
  title = {Software {Engineering} {Principles}},
  volume = {22},
  issn = {0315-5986},
  url = {https://doi.org/10.1080/03155986.1984.11731932},
  doi = {10.1080/03155986.1984.11731932},
  abstract = {Software engineering, the construction of useful programs, usually involves seve;ral people and programs that will be maintained in several versions. This paper discusses the technical problems that arise from the need to co-ordinate many people in the construction of families of similar, but not identical, programs. The problems that we discuss include using documentation as a software design medium; writing software requirements documents that are complete and precise; the meaning of "structure" in software design; the decomposition of programming projects into work assignments (modules); precise specification of the work assignments (modules); designing systems so that they are easily contracted or extended; designing abstract interfaces for modules; applying the concept of co-operating sequential processes; specifying and summarizing the behaviour of programs. This paper is intended to provide an introductory overview. The bibliography includes more thorough discussions of each topic.},
  number = {4},
  urldate = {2021-02-04},
  journal = {INFOR: Information Systems and Operational Research},
  author = {Parnas, David Lorge},
  month = nov,
  year = {1984},
  pages = {303--316},
}



@article{Brooks1987,
  title = {No {Silver} {Bullet} {Essence} and {Accidents} of {Software} {Engineering}},
  volume = {20},
  issn = {1558-0814},
  doi = {10.1109/MC.1987.1663532},
  number = {4},
  journal = {Computer},
  author = {{Brooks}},
  month = apr,
  year = {1987},
  note = {Conference Name: Computer},
  keywords = {Computer industry, Costs, Diseases, Hardware, Industrial accidents, Project management, Roads, Silver, Software engineering, Technological innovation},
  pages = {10--19},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/RBWS8JH7/1663532.html:text/html}
}



@book{Brooks1995,
  address = {Reading, Mass},
  edition = {2 edition},
  title = {The {Mythical} {Man}-{Month}: {Essays} on {Software} {Engineering}, {Anniversary} {Edition}},
  isbn = {978-0-201-83595-3},
  shorttitle = {The {Mythical} {Man}-{Month}},
  abstract = {Few books on software project management have been as influential and timeless as The Mythical Man-Month. With a blend of software engineering facts and thought-provoking opinions, Fred Brooks offers insight for anyone managing complex projects. These essays draw from his experience as project manager for the IBM System/360 computer family and then for OS/360, its massive software system. Now, 20 years after the initial publication of his book, Brooks has revisited his original ideas and added new thoughts and advice, both for readers already familiar with his work and for readers discovering it for the first time.   The added chapters contain (1) a crisp condensation of all the propositions asserted in the original book, including Brooks' central argument in The Mythical Man-Month: that large programming projects suffer management problems different from small ones due to the division of labor; that the conceptual integrity of the product is therefore critical; and that it is difficult but possible to achieve this unity; (2) Brooks' view of these propositions a generation later; (3) a reprint of his classic 1986 paper "No Silver Bullet"; and (4) today's thoughts on the 1986 assertion, "There will be no silver bullet within ten years."},
  language = {English},
  publisher = {Addison-Wesley Professional},
  author = {Brooks Jr, Frederick P.},
  month = aug,
  year = {1995}
}



@article{Boehm1976,
  title = {Software {Engineering}},
  volume = {25},
  issn = {0018-9340},
  url = {https://doi.org/10.1109/TC.1976.1674590},
  doi = {10.1109/TC.1976.1674590},
  abstract = {This paper provides a definition of the term "software engineering" and a survey of the current state of the art and likely future trends in the field. The survey covers the technology available in the various phases of the software life cycle requirements engineering, design, coding, test, and maintenance and in the overall area of software management and integrated technology-management approaches. It is oriented primarily toward discussing the domain of applicability of techniques (where and when they work), rather than how they work in detail. To cover the latter, an extensive set of 104 references is provided.},
  number = {12},
  urldate = {2019-12-15},
  journal = {IEEE Trans. Comput.},
  author = {Boehm, B. W.},
  month = dec,
  year = {1976},
  keywords = {software development, software engineering, Computer software, data systems, information systems, research and development, software management.},
  pages = {1226--1241},
  annote = {Software Engineering to the general attention of the scientific community},
  file = {Boehm - 1976 - Software Engineering.pdf:/Users/past/Zotero/storage/HS7BUI8B/Boehm - 1976 - Software Engineering.pdf:application/pdf}
}


@article{Dijkstra1989,
  title = {On the cruelty of really teaching computing science},
  volume = {32},
  doi = {10.1145/76380.76381},
  number = {12},
  journal = {Comm. ACM},
  author = {Dijkstra, Edsger Wybe},
  year = {1989},
  pages = {1398--1404},
}


@book{Sommerville2004,
  title = {Software {Engineering}},
  isbn = {978-0-321-21026-5},
  abstract = {Software Engineering presents a broad perspective on software systems engineering, concentrating on widely used techniques for developing large-scale systems. The objectives of this seventh edition are to include new material on iterative software development, component-based software engineering and system architectures, to emphasize that system dependability is not an add-on but should be considered at all stages of the software process, and not to increase the size of the book significantly. To this end the book has been restructured into 6 parts, removing the separate section on evolution as the distinction between development and evolution can be seen as artificial. New chapters have been added on: Socio-technical Systems ? discussing the context of software in a broader system composed of other hardware and software, people, organisations, policies, procedures and laws. Application System Architectures ? to teach students the general structure of application systems such as transaction systems, information systems and embedded control systems. The chapter covers 6 common system architectures with an architectural overview and discussion of the characteristics of these types of system. Iterative Software Development ? looking at prototyping and adding new material on agile methods and extreme programming. Component-based Software Engineering ? introducing the notion of a component, component composition and component frameworks and covering design with reuse. Software Evolution ? revising the presentation of the 6th edition to cover re-engineering and software change in a single chapter. The book supports students taking undergraduate or graduate courses in software engineering, and software engineers in industry needing to update their knowledge.},
  language = {en},
  publisher = {Pearson/Addison-Wesley},
  author = {Sommerville, Ian},
  year = {2004},
  keywords = {Computers / Software Development \& Engineering / General}
}


@book{Beck2000,
  title = {Extreme {Programming} {Explained}: {Embrace} {Change}},
  isbn = {978-0-201-61641-5},
  shorttitle = {Extreme {Programming} {Explained}},
  abstract = {Software development projects can be fun, productive, and even daring. Yet they can consistently deliver value to a business and remain under control.  Extreme Programming (XP) was conceived and developed to address the specific needs of software development conducted by small teams in the face of vague and changing requirements. This new lightweight methodology challenges many conventional tenets, including the long-held assumption that the cost of changing a piece of software necessarily rises dramatically over the course of time. XP recognizes that projects have to work to achieve this reduction in cost and exploit the savings once they have been earned.  Fundamentals of XP include:   Distinguishing between the decisions to be made by business interests and those to be made by project stakeholders.  Writing unit tests before programming and keeping all of the tests running at all times.  Integrating and testing the whole system--several times a day.  Producing all software in pairs, two programmers at one screen.  Starting projects with a simple design that constantly evolves to add needed flexibility and remove unneeded complexity.  Putting a minimal system into production quickly and growing it in whatever directions prove most valuable.   Why is XP so controversial? Some sacred cows don't make the cut in XP:   Don't force team members to specialize and become analysts, architects, programmers, testers, and integrators--every XP programmer participates in all of these critical activities every day.  Don't conduct complete up-front analysis and design--an XP project starts with a quick analysis of the entire system, and XPprogrammers continue to make analysis and design decisions throughout development.  Develop infrastructure and frameworks as you develop your application, not up-front--delivering business value is the heartbeat that drives XP projects.  Don't write and maintain implementation documentation--communication in XP projects occurs face-to-face, or through efficient tests and carefully written code.   You may love XP, or you may hate it, but "Extreme Programming Explained" will force you to take a fresh look at how you develop software.  0201616416B04062001},
  language = {en},
  publisher = {Addison-Wesley Professional},
  author = {Beck, Kent},
  year = {2000},
  keywords = {Computers / Software Development \& Engineering / General}
}



@article{KlareKramerLWBR2021,
  title = {Enabling consistency in view-based system development — {The} {Vitruvius} approach},
  volume = {171},
  issn = {0164-1212},
  url = {https://www.sciencedirect.com/science/article/pii/S0164121220302144},
  doi = {10.1016/j.jss.2020.110815},
  abstract = {During the development of large software-intensive systems, developers use several modeling languages and tools to describe a system from different viewpoints. Model-driven and view-based technologies have made it easier to define domain-specific languages and transformations. Nevertheless, using several languages leads to fragmentation of information, to redundancies in the system description, and eventually to inconsistencies. Inconsistencies have negative impacts on the system’s quality and are costly to fix. Often, there is no support for consistency management across multiple languages. Using a single language is no practicable solution either, as it is overly complex to define, use, and evolve such a language. View-based development is a suitable approach to deal with complex systems, and is widely used in other engineering disciplines. Still, we need to cope with the problems of fragmentation and consistency. In this paper, we present the Vitruvius approach for consistency in view-based modeling. We describe the approach by formalizing the notion of consistency, presenting languages for consistency preservation, and defining a model-driven development process. Furthermore, we show how existing models can be integrated. We have evaluated our approach at two case studies from component-based and embedded automotive software development, using our prototypical implementation based on the Eclipse Modeling Framework.},
  language = {en},
  urldate = {2021-02-26},
  journal = {Journal of Systems and Software},
  author = {Klare, Heiko and Kramer, Max E. and Langhammer, Michael and Werle, Dominik and Burger, Erik and Reussner, Ralf},
  month = jan,
  year = {2021},
  keywords = {Consistency, Model transformations, Model views, Model-driven software development},
  pages = {110815},
  file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/ZKNMMPB2/Klare et al. - 2021 - Enabling consistency in view-based system developm.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/NPYVBNPQ/S0164121220302144.html:text/html}
}


@inproceedings{Burger2013,
  address = {New York, NY, USA},
  series = {{WCOP} '13},
  title = {Flexible views for view-based model-driven development},
  isbn = {978-1-4503-2125-9},
  url = {https://doi.org/10.1145/2465498.2465501},
  doi = {10.1145/2465498.2465501},
  abstract = {Model-driven development processes suffer from growing complexity, which leads to information spread across heterogeneous metamodels as well as drift and erosion between architecture and implementation. In this paper, we present a view-based modeling approach based on Orthographic Software Modeling (OSM), and introduce flexible views as a concept for the creation of custom, user-specific views. The envisioned benefit of the approach is to improve software quality, to increase consistency between the various modeling artifacts in model-driven software development, and to reduce the complexity for software developers.},
  urldate = {2021-02-26},
  booktitle = {Proceedings of the 18th international doctoral symposium on {Components} and architecture},
  publisher = {Association for Computing Machinery},
  author = {Burger, Erik Johannes},
  month = jun,
  year = {2013},
  keywords = {model-driven software development, orthographic software modeling, view-based modeling},
  pages = {25--30},
  annote = {Begin of the Vitruvius approach: Developed a language for defining views.},
  file = {Full Text:/Users/past/Zotero/storage/JFNAG7NN/Burger - 2013 - Flexible views for view-based model-driven develop.pdf:application/pdf}
}


@article{AtkinsonKuehne2002,
  title = {Rearchitecting the {UML} infrastructure},
  volume = {12},
  issn = {1049-3301},
  url = {https://doi.org/10.1145/643120.643123},
  doi = {10.1145/643120.643123},
  abstract = {Metamodeling is one of the core foundations of computer-automated multiparadigm modeling. However, there is currently little agreement about what form the required metamodeling approach should take and precisely what role metamodels should play. This article addresses the problem by first describing some fundamental problems in the industry's leading metamodeling technology, the UML framework, and then explaining how this framework could be rearchitected to overcome these problems. Three main issues are identified in the current framework: the dual classification problem arising from the need to capture both the logical and physical classification of model elements, the class/object duality problem arising from the need to capture both the classlike and objectlike facets of some model elements, and the replication of concepts problem arising from the need to define certain concepts multiple times. Three main proposals for rearchitecting the UML framework to overcome these problems are then presented: the separation of logical and physical classification dimensions, the unification of the class and object facets of model elements, and the enhancement of the instantiation mechanism to allow definitions to transcend multiple levels. The article concludes with a discussion of other practical issues involved in rearchitecting the UML modeling framework in the proposed way.},
  number = {4},
  urldate = {2021-02-26},
  journal = {ACM Transactions on Modeling and Computer Simulation},
  author = {Atkinson, Colin and Kühne, Thomas},
  month = oct,
  year = {2002},
  keywords = {classification, classification dimensions, deep instantiation, Metamodeling, strict metamodeling, UML infrastructure, unified modeling language},
  pages = {290--321}
}



@inproceedings{deLaraGuerra2010,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Deep {Meta}-modelling with {MetaDepth}},
  isbn = {978-3-642-13953-6},
  doi = {10.1007/978-3-642-13953-6_1},
  abstract = {Meta-modelling is at the core of Model-Driven Engineering, where it is used for language engineering and domain modelling. The OMG’s Meta-Object Facility is the standard framework for building and instantiating meta-models. However, in the last few years, several researchers have identified limitations and rigidities in such a scheme, most notably concerning the consideration of only two meta-modelling levels at the same time.In this paper we present MetaDepth, a novel framework that supports a dual linguistic/ontological instantiation and permits building systems with an arbitrary number of meta-levels through deep meta-modelling. The framework implements advanced modelling concepts allowing the specification and evaluation of derived attributes and constraints across multiple meta-levels, linguistic extensions of ontological instance models, transactions, and hosting different constraint and action languages.},
  language = {en},
  booktitle = {Objects, {Models}, {Components}, {Patterns}},
  publisher = {Springer},
  author = {de Lara, Juan and Guerra, Esther},
  editor = {Vitek, Jan},
  year = {2010},
  keywords = {Class Diagram, Concrete Syntax, Language Engineering, Object Diagram, Ontological Instance},
  pages = {1--20},
  file = {Accepted Version:/Users/past/Zotero/storage/SW3Z8KFM/de Lara and Guerra - 2010 - Deep Meta-modelling with MetaDepth.pdf:application/pdf}
}



@article{KienzleMussbacherCD2019,
  title = {A unifying framework for homogeneous model composition},
  volume = {18},
  issn = {1619-1374},
  url = {https://doi.org/10.1007/s10270-018-00707-8},
  doi = {10.1007/s10270-018-00707-8},
  abstract = {The growing use of models for separating concerns in complex systems has lead to a proliferation of model composition operators. These composition operators have traditionally been defined from scratch following various approaches differing in formality, level of detail, chosen paradigm, and styles. Due to the lack of proper foundations for defining model composition (concepts, abstractions, or frameworks), it is difficult to compare or reuse composition operators. In this paper, we stipulate the existence of a unifying framework that reduces all structural composition operators to structural merging, and all composition operators acting on discrete behaviors to event scheduling. We provide convincing evidence of this hypothesis by discussing how structural and behavioral homogeneous model composition operators (i.e., weavers) can be mapped onto this framework. Based on this discussion, we propose a conceptual model of the framework and identify a set of research challenges, which, if addressed, lead to the realization of this framework to support rigorous and efficient engineering of model composition operators for homogeneous and eventually heterogeneous modeling languages.},
  language = {en},
  number = {5},
  urldate = {2020-04-20},
  journal = {Software \& Systems Modeling},
  author = {Kienzle, Jörg and Mussbacher, Gunter and Combemale, Benoit and Deantoni, Julien},
  month = oct,
  year = {2019},
  pages = {3005--3023},
  file = {Submitted Version:/Users/past/Zotero/storage/97PH579P/Kienzle et al. - 2019 - A unifying framework for homogeneous model composi.pdf:application/pdf}
}


@article{Wolter2021,
  title = {Logics of {First}-{Order} {Constraints} -- {A} {Category} {Independent} {Approach}},
  url = {http://arxiv.org/abs/2101.01944},
  abstract = {Reflecting our experiences in areas, like Algebraic Specifications, Abstract Model Theory, Graph Transformations, and Model Driven Software Engineering (MDSE), we present a general, category independent approach to Logics of First-Order Constraints (LFOC). Traditional First-Order Logic, Description Logic and the sketch framework are discussed as examples. We use the concept of institution [Diaconescu08,GoguenBurstall92] as a guideline to describe LFOC's. The main result states that any choice of the six parameters, we are going to describe, gives us a corresponding "institution of constraints" at hand. The "presentations" for an institution of constraints can be characterized as "first-order sketches". As a corresponding variant of the "sketch-entailments" in [Makkai97], we finally introduce "sketch rules" to equip LFOC's with the necessary expressive power.},
  urldate = {2021-02-28},
  journal = {arXiv:2101.01944 [cs]},
  author = {Wolter, Uwe},
  month = jan,
  year = {2021},
  note = {arXiv: 2101.01944},
  keywords = {03B99, 03C95, Computer Science - Logic in Computer Science, Computer Science - Software Engineering, F.4.1, H.1.1},
  annote = {Comment: 23 pages, presented at the 8th Conference on Algebra and Coalgebra in Computer Science (CALCO 2019), London, UK, June 3-6, 2019},
  file = {arXiv Fulltext PDF:/Users/past/Zotero/storage/YBL7J27Q/Wolter - 2021 - Logics of First-Order Constraints -- A Category In.pdf:application/pdf;arXiv.org Snapshot:/Users/past/Zotero/storage/EIA63QRW/2101.html:text/html}
}


@article{ErdogamusMedvidovicP2018,
  title = {50 {Years} of {Software} {Engineering}},
  volume = {35},
  issn = {1937-4194},
  doi = {10.1109/MS.2018.3571240},
  abstract = {This theme issue on software engineering’s 50th anniversary presents a range of contributions—from pioneers and well-established software engineers, to younger contributors whose imprint on the field is perhaps yet to come. These contributions come in a variety of formats that provide a balanced look at our field’s past, present, and likely future. The topics include both timeless ideas that appeared to fade for a while, only to pop up again in a new incarnation, and entirely new paradigms that have disrupted the field.},
  number = {5},
  journal = {IEEE Software},
  author = {Erdogmus, H. and Medvidović, N. and Paulisch, F.},
  month = sep,
  year = {2018},
  note = {Conference Name: IEEE Software},
  keywords = {History, IEEE publishing, software development, software engineering, Software engineering, Special issues and sections},
  pages = {20--24},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/W36TJ4UR/8474511.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/Y4WEYV9Z/Erdogmus et al. - 2018 - 50 Years of Software Engineering.pdf:application/pdf}
}


@incollection{WeidmannFritscheA2020,
  address = {New York, NY, USA},
  title = {A search-based and fault-tolerant approach to concurrent model synchronisation},
  isbn = {978-1-4503-8176-5},
  url = {https://doi.org/10.1145/3426425.3426932},
  abstract = {In collaboration scenarios, we often encounter situations in which semantically interrelated models are changed concurrently. Concurrent model synchronization denotes the task of keeping these models consistent by propagating changes between them. This is challenging as changes can contradict each other and thus be in conflict. A problem with current synchronisation approaches is that they are often nondeterministic, i.e., the order in which changes are propagated is essential for the result. Furthermore, a common limitation is that the involved models must have been in a consistent state at some point, and that the applied changes are at least valid for the domain in which they were made. We propose a hybrid approach based on Triple Graph Grammars (TGGs) and Integer Linear Programming (ILP) to overcome these issues: TGGs are a grammar-based means that supplies us with a superset of possible synchronization solutions, forming a search space from which an optimum solution incorporating user-defined preferences can be chosen by ILP. Therefore, the proposed method combines configurability by comprising expert knowledge via TGGs with the flexible input handling of search-based techniques: By accepting arbitrary graph structures as input models, the approach is tolerant towards errors induced during the modelling process, i.e., it can cope with input models which do not conform to their metamodel or which cannot be generated by the TGG at hand. The approach is implemented in the model transformation tool eMoflon and evaluated regarding scalability for growing model sizes and an increasing number of changes.},
  urldate = {2021-02-11},
  booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} {International} {Conference} on {Software} {Language} {Engineering}},
  publisher = {Association for Computing Machinery},
  author = {Weidmann, Nils and Fritsche, Lars and Anjorin, Anthony},
  month = nov,
  year = {2020},
  keywords = {Triple Graph Grammars, Integer Linear Programming, Concurrent Synchronisation, Fault-Tolerance},
  pages = {56--71},
  annote = {hybrid approach combining TGG with Integer logical programming},
  file = {Full Text PDF:/Users/past/Zotero/storage/6M9ECLXC/Weidmann et al. - 2020 - A search-based and fault-tolerant approach to conc.pdf:application/pdf}
}


@incollection{FritscheKosiolMST2020,
  address = {New York, NY, USA},
  title = {A precedence-driven approach for concurrent model synchronization scenarios using triple graph grammars},
  isbn = {978-1-4503-8176-5},
  url = {https://doi.org/10.1145/3426425.3426931},
  abstract = {Concurrent model synchronization is the task of restoring consistency between two correlated models after they have been changed concurrently and independently. To determine whether such concurrent model changes conflict with each other and to resolve these conflicts taking domain- or user-specific preferences into account is highly challenging. In this paper, we present a framework for concurrent model synchronization algorithms based on Triple Graph Grammars (TGGs). TGGs specify the consistency of correlated models using grammar rules; these rules can be used to derive different consistency restoration operations. Using TGGs, we infer a causal dependency relation for model elements that enables us to detect conflicts non-invasively. Different kinds of conflicts are detected first and resolved by the subsequent conflict resolution process. Users configure the overall synchronization process by orchestrating the application of consistency restoration fragments according to several conflict resolution strategies to achieve individual synchronization goals. As proof of concept, we have implemented this framework in the model transformation tool eMoflon. Our initial evaluation shows that the runtime of our presented approach scales with the size of model changes and conflicts, rather than model size.},
  urldate = {2021-02-11},
  booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} {International} {Conference} on {Software} {Language} {Engineering}},
  publisher = {Association for Computing Machinery},
  author = {Fritsche, Lars and Kosiol, Jens and Möller, Adrian and Schürr, Andy and Taentzer, Gabriele},
  month = nov,
  year = {2020},
  keywords = {triple graph grammars, bidirectional transformation (bx), concurrent model synchronization},
  pages = {39--55},
  annote = {recent practical approach on concurrent synch},
  file = {Full Text PDF:/Users/past/Zotero/storage/HT47LK59/Fritsche et al. - 2020 - A precedence-driven approach for concurrent model .pdf:application/pdf}
}


@inproceedings{OrejasPinoN2020,
  address = {Cham},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Incremental {Concurrent} {Model} {Synchronization} using {Triple} {Graph} {Grammars}},
  isbn = {978-3-030-45234-6},
  doi = {10.1007/978-3-030-45234-6_14},
  abstract = {In the context of software model-driven development, artifacts are specified by several models describing different aspects, e.g., different views, dynamic behavior, structure, distributed information, etc. Then, maintaining and repairing consistency of the whole specification are crucial issues if the models can be separately developed and updated. Model Synchronization is the process of restoring consistency after the update of one or several of the models. In the present work, we approach the case when conflicts may arise due to concurrently updating different models. Specifically, based on the Triple Graph Grammar approach, we propose an incremental algorithm 𝙲𝚂𝚢𝚗𝚌𝚑CSynch{\textbackslash}mathtt\{CSynch\} for solving conflicts and repairing consistency. In addition, we identify and formalize when a synchronizing solution can be considered adequate and show that our procedure 𝙲𝚂𝚢𝚗𝚌𝚑CSynch{\textbackslash}mathtt\{CSynch\} is sound and complete.},
  language = {en},
  booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
  publisher = {Springer International Publishing},
  author = {Orejas, Fernando and Pino, Elvira and Navarro, Marisa},
  editor = {Wehrheim, Heike and Cabot, Jordi},
  year = {2020},
  pages = {273--293},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/PJNVNKGY/Orejas et al. - 2020 - Incremental Concurrent Model Synchronization using.pdf:application/pdf}
}



@inproceedings{MeierWernerKTAABRW2020,
  address = {Cham},
  series = {Communications in {Computer} and {Information} {Science}},
  title = {Classifying {Approaches} for {Constructing} {Single} {Underlying} {Models}},
  isbn = {978-3-030-37873-8},
  doi = {10.1007/978-3-030-37873-8_15},
  abstract = {Multi-view environments for software development allow different views of a software system to be defined to cover the requirements of different stakeholders. One way of ensuring consistency of overlapping information often contained in such views is to project them “on demand” from a Single Underlying Model (SUM). However, there are several ways to construct and adapt such SUMs. This paper presents four archetypal approaches and analyses their advantages and disadvantages based on several new criteria. In addition, guidelines are presented for selecting a suitable SUM construction approach for a specific project.},
  language = {en},
  booktitle = {Model-{Driven} {Engineering} and {Software} {Development}},
  publisher = {Springer International Publishing},
  author = {Meier, Johannes and Werner, Christopher and Klare, Heiko and Tunjic, Christian and Aßmann, Uwe and Atkinson, Colin and Burger, Erik and Reussner, Ralf and Winter, Andreas},
  editor = {Hammoudi, Slimane and Pires, Luís Ferreira and Selić, Bran},
  year = {2020},
  keywords = {Integration, Metamodeling, Model consistency, Projectional, SUM, View-based},
  pages = {350--375},
  annote = {constructing sums is difficult},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/62H7NGYZ/Meier et al. - 2020 - Classifying Approaches for Constructing Single Und.pdf:application/pdf}
}



@incollection{ColmerauerRoussel1996,
  address = {New York, NY, USA},
  title = {The birth of {Prolog}},
  isbn = {978-0-201-89502-5},
  url = {https://doi.org/10.1145/234286.1057820},
  abstract = {The programming language, Prolog, was born of a project aimed not at producing a programm3ing language but at processing natural languages; in this case, French. The project gave rise to a preliminary version of Prolog at the end of 1971 and a more definitive version at the end of 1972. This article gives the history of this project and describes in detail the preliminary and then the final versions of Prolog. The authors also felt it appropriate to describe the Q-systems because it was a language that played a prominent part in Prolog's genesis.},
  urldate = {2021-03-09},
  booktitle = {History of programming languages---{II}},
  publisher = {Association for Computing Machinery},
  author = {Colmerauer, Alain and Roussel, Philippe},
  month = jan,
  year = {1996},
  pages = {331--367},
  file = {Full Text PDF:/Users/past/Zotero/storage/89MTNHH9/Colmerauer and Roussel - 1996 - The birth of Prolog.pdf:application/pdf}
}



@incollection{Goguen1973,
  title = {Categorical foundations for general systems theory},
  booktitle = {Advances in {Cybernetics} and {Systems} {Research}},
  publisher = {Transcripta Books},
  author = {Goguen, Joseph A.},
  editor = {Pichler, F and Trappl, R},
  year = {1973},
  pages = {121--130},
  annote = {Colimits}
}


@inproceedings{BarrigaMandoPRHI2020,
  address = {New York, NY, USA},
  series = {{MODELS} '20},
  title = {A comparative study of reinforcement learning techniques to repair models},
  isbn = {978-1-4503-8135-2},
  url = {https://doi.org/10.1145/3417990.3421395},
  doi = {10.1145/3417990.3421395},
  abstract = {In model-driven software engineering, models are used in all phases of the development process. These models may get broken due to various editions during the modeling process. To repair broken models we have developed PARMOREL, an extensible framework that uses reinforcement learning techniques. So far, we have used our version of the Markov Decision Process (MDP) adapted to the model repair problem and the Q-learning algorithm. In this paper, we revisit our MDP definition, addressing its weaknesses, and proposing a new one. After comparing the results of both MDPs using Q-Learning to repair a sample model, we proceed to compare the performance of Q-Learning with other reinforcement learning algorithms using the new MDP. We compare Q-Learning with four algorithms: Q(λ), Monte Carlo, SARSA and SARSA (λ), and perform a comparative study by repairing a set of broken models. Our results indicate that the new MDP definition and the Q(λ) algorithm can repair with faster performance.},
  urldate = {2020-11-19},
  booktitle = {Proceedings of the 23rd {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}: {Companion} {Proceedings}},
  publisher = {Association for Computing Machinery},
  author = {Barriga, Angela and Mandow, Lawrence and de la Cruz, José Luis Pérez and Rutle, Adrian and Heldal, Rogardt and Iovino, Ludovico},
  month = oct,
  year = {2020},
  keywords = {model repair, markov decision process, reinforcement learning},
  pages = {1--9},
  file = {Full Text PDF:/Users/past/Zotero/storage/X83JKVU4/Barriga et al. - 2020 - A comparative study of reinforcement learning tech.pdf:application/pdf}
}


@inproceedings{KehrerKelterT2013,
  title = {Consistency-preserving edit scripts in model versioning},
  doi = {10.1109/ASE.2013.6693079},
  abstract = {In model-based software development, models are iteratively evolved. To optimally support model evolution, developers need adequate tools for model versioning tasks, including comparison, patching, and merging of models. A significant disadvantage of tools currently available is that they display, and operate with, low-level model changes which refer to internal model representations and which can lead to intermediate inconsistent states. Higher-level consistency-preserving edit operations including refactorings are better suited to explain changes or to resolve conflicts. This paper presents an automatic procedure which transforms a low-level difference into an executable edit script which uses consistency-preserving edit operations only. Edit scripts support consistent model patching and merging on a higher abstraction level. Our approach to edit script generation has been evaluated in a larger real-world case study.},
  booktitle = {2013 28th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
  author = {Kehrer, T. and Kelter, U. and Taentzer, G.},
  month = nov,
  year = {2013},
  keywords = {Abstracts, Adaptation models, automatic procedure, Concrete, configuration management, consistency preserving edit scripts, internal model representations, Merging, model comparison, model merging, model patching, model versioning, Semantics, software development, software tools, Syntactics, Unified modeling language},
  pages = {191--201},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/ASLAVYIV/6693079.html:text/html}
}


@inproceedings{TaentzerOhrndorfLR2017,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Change-{Preserving} {Model} {Repair}},
  isbn = {978-3-662-54494-5},
  doi = {10.1007/978-3-662-54494-5_16},
  abstract = {During modeling activities, inconsistencies can easily occur due to misunderstandings, lack of information or simply mistakes. In this paper, we focus on model inconsistencies that occur due to model editing and cause violation of the meta-model conformance. Although temporarily accepting inconsistencies helps to keep progress, inconsistencies have to be resolved finally. One form of resolution is model repair. Assuming that model changes are state-based, (potentially) performed edit operations can be automatically identified from state differences and further analyzed. As a result, inconsistent changes may be identified causing a need to repair the model. There may exist an overwhelming number of possible repair actions that restore consistency. The edit history may help to identify the relevant repairs. Model inconsistencies are repaired by computing and applying complement edit operations that are needed to re-establish the overall model consistency. In this paper, we clarify under which conditions this kind of model repair can be applied. The soundness of this approach is shown by formalizing it based on the theory of graph transformation. A prototype tool based on the Eclipse Modeling Framework and Henshin is used to conduct an initial evaluation.},
  language = {en},
  booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
  publisher = {Springer},
  author = {Taentzer, Gabriele and Ohrndorf, Manuel and Lamo, Yngve and Rutle, Adrian},
  editor = {Huisman, Marieke and Rubin, Julia},
  year = {2017},
  keywords = {Graph transformation, Model repair, Model-based engineering},
  pages = {283--299},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/2GYLUM68/Taentzer et al. - 2017 - Change-Preserving Model Repair.pdf:application/pdf}
}


@inproceedings{MustafaLabiche2017,
  title = {The {Need} for {Traceability} in {Heterogeneous} {Systems}: {A} {Systematic} {Literature} {Review}},
  volume = {1},
  shorttitle = {The {Need} for {Traceability} in {Heterogeneous} {Systems}},
  doi = {10.1109/COMPSAC.2017.237},
  abstract = {Traceability provides a mean for Software Engineers to track system artifacts at different levels of abstraction to verify and validate system requirements. This paper provides a systematic literature review about modeling traceability in computer systems, particularly, systems that involve artifacts that come from different domains of expertise (i.e., heterogeneous artifacts). Our findings show that there is a lack of research that focus on modeling traceability among heterogeneous artifacts, which reflects in inadequate traceability tools, and that precise semantics for trace links among artifacts is needed. Our findings lead us to highlight the key areas that can enhance research on those directions.},
  booktitle = {2017 {IEEE} 41st {Annual} {Computer} {Software} and {Applications} {Conference} ({COMPSAC})},
  author = {Mustafa, N. and Labiche, Y.},
  month = jul,
  year = {2017},
  note = {ISSN: 0730-3157},
  keywords = {Software, Unified modeling language, Modeling, program verification, Semantics, program diagnostics, Requirements engineering, Tools, systematic literature review, abstraction levels, heterogeneous artifacts, heterogeneous systems, Modeling traceability, semantic, software traceability, system artifacts, system requirements validation, system requirements verification, systematic review, testability, trace links},
  pages = {305--310},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/VK8U2U27/8029622.html:text/html;Mustafa and Labiche - 2017 - The Need for Traceability in Heterogeneous Systems.pdf:/Users/past/Zotero/storage/J794U8CW/Mustafa and Labiche - 2017 - The Need for Traceability in Heterogeneous Systems.pdf:application/pdf}
}


@article{TorkarGorschekFSRK2012,
  title = {Requirements traceability: a systematic review and industry case study},
  volume = {22},
  issn = {0218-1940},
  shorttitle = {Requirements traceability},
  url = {https://www.worldscientific.com/doi/10.1142/S021819401250009X},
  doi = {10.1142/S021819401250009X},
  abstract = {Requirements traceability enables software engineers to trace a requirement from its emergence to its fulfillment. In this paper we examine requirements traceability definitions, challenges, tools and techniques, by the use of a systematic review performing an exhaustive search through the years 1997–2007. We present a number of common definitions, challenges, available tools and techniques (presenting empirical evidence when found), while complementing the results and analysis with a static validation in industry through a series of interviews.},
  number = {03},
  urldate = {2021-03-14},
  journal = {International Journal of Software Engineering and Knowledge Engineering},
  author = {Torkar, Richard and Gorschek, Tony and Feldt, Robert and Svahnberg, Mikael and Raja, Uzair Akbar and Kamran, Kashif},
  month = may,
  year = {2012},
  note = {Publisher: World Scientific Publishing Co.},
  pages = {385--433},
  file = {Snapshot:/Users/past/Zotero/storage/XLHE969X/S021819401250009X.html:text/html}
}


@inproceedings{GotelFinkelstein1994,
  title = {An analysis of the requirements traceability problem},
  doi = {10.1109/ICRE.1994.292398},
  abstract = {Investigates and discusses the underlying nature of the requirements traceability problem. Our work is based on empirical studies, involving over 100 practitioners, and an evaluation of current support. We introduce the distinction between pre-requirements specification (pre-RS) traceability and post-requirements specification (post-RS) traceability to demonstrate why an all-encompassing solution to the problem is unlikely, and to provide a framework through which to understand its multifaceted nature. We report how the majority of the problems attributed to poor requirements traceability are due to inadequate pre-RS traceability and show the fundamental need for improvements. We present an analysis of the main barriers confronting such improvements in practice, identify relevant areas in which advances have been (or can be) made, and make recommendations for research.{\textless}{\textgreater}},
  booktitle = {Proceedings of {IEEE} {International} {Conference} on {Requirements} {Engineering}},
  author = {Gotel, O. C. Z. and Finkelstein, C. W.},
  month = apr,
  year = {1994},
  keywords = {Educational institutions, Guidelines, post-requirements specification traceability, pre-requirements specification traceability, Project management, requirements engineering practice, requirements traceability problem analysis, requirements traceability tools, Research and development, systems analysis},
  pages = {94--101},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/RSU6TCFX/292398.html:text/html;Submitted Version:/Users/past/Zotero/storage/WIT224KD/Gotel and Finkelstein - 1994 - An analysis of the requirements traceability probl.pdf:application/pdf}
}


@article{Booch2018,
  title = {The {History} of {Software} {Engineering}},
  volume = {35},
  issn = {1937-4194},
  doi = {10.1109/MS.2018.3571234},
  abstract = {Grady Booch, one of UML's original authors, offers his perspective on the history of software engineering. This article is part of a theme issue on software engineering's 50th anniversary. The Web Extra, a version of the article with an expanded bibliography, is at https://extras.computer.org/extra/mso2018050108s1.pdf.},
  number = {5},
  journal = {IEEE Software},
  author = {Booch, G.},
  month = sep,
  year = {2018},
  note = {Conference Name: IEEE Software},
  keywords = {software development, Unified Modeling Language, Programming, software engineering, Software engineering, Software development, Internet, History, history, bibliography, Computers, Grady Booch, history of software engineering, UML original authors, Web extra},
  pages = {108--114},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/NPUJGZVF/8474489.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/IEQ9TXZB/Booch - 2018 - The History of Software Engineering.pdf:application/pdf}
}


@article{Broy2018,
  title = {Yesterday, {Today}, and {Tomorrow}: 50 {Years} of {Software} {Engineering}},
  volume = {35},
  issn = {1937-4194},
  shorttitle = {Yesterday, {Today}, and {Tomorrow}},
  doi = {10.1109/MS.2018.290111138},
  abstract = {In 2018, we're now 50 years after the famous groundbreaking conference on software engineering in Garmisch, organized by its chairman F.L. Bauer and his cochairs L. Bolliet and H.J. Helms. This conference introduced the notion and discipline of software engineering. This is a moment to look back at what we've achieved, what we haven't achieved, where we are today, and what challenges lie ahead. This article is part of a theme issue on software engineering's 50th anniversary.},
  number = {5},
  journal = {IEEE Software},
  author = {Broy, M.},
  month = sep,
  year = {2018},
  note = {Conference Name: IEEE Software},
  keywords = {software development, Programming, software engineering, Software engineering, Software systems, Computer architecture, Computer languages, history of software engineering, computer hardware, software crisis, software production},
  pages = {38--43},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/NRB68MM5/8409912.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/7ZJYZDMX/Broy - 2018 - Yesterday, Today, and Tomorrow 50 Years of Softwa.pdf:application/pdf}
}


@article{BasiliBriandBNPS218,
  title = {Software {Engineering} {Research} and {Industry}: {A} {Symbiotic} {Relationship} to {Foster} {Impact}},
  volume = {35},
  issn = {1937-4194},
  shorttitle = {Software {Engineering} {Research} and {Industry}},
  doi = {10.1109/MS.2018.290110216},
  abstract = {Software engineering is not only an increasingly challenging endeavor that goes beyond the intellectual capabilities of any single individual engineer but also an intensely human one. Tools and methods to develop software are employed by engineers of varied backgrounds within a large variety of organizations and application domains. As a result, the variation in challenges and practices in system requirements, architecture, and quality assurance is staggering. Human, domain, and organizational factors define the context within which software engineering methodologies and technologies are to be applied and therefore the context that research needs to account for, if it is to be impactful. This article provides an assessment of the current challenges faced by software engineering research in achieving its potential, a description of the root causes of such challenges, and a proposal for the field to move forward and become more impactful through collaborative research and innovation between public research and industry. This article is part of a theme issue on software engineering's 50th anniversary.},
  number = {5},
  journal = {IEEE Software},
  author = {Basili, V. and Briand, L. and Bianculli, D. and Nejati, S. and Pastore, F. and Sabetzadeh, M.},
  month = sep,
  year = {2018},
  note = {Conference Name: IEEE Software},
  keywords = {software development, empirical software engineering, software engineering, Software engineering, Software development, Context modeling, Collaboration, DP industry, collaborative research, context-driven research, innovation, innovation management, organisational aspects, organizational factors, quality assurance, software engineering industry, software engineering methodologies, software engineering research, software engineering technologies, system requirements},
  pages = {44--49},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/ZYQ4A6FT/8409904.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/29CV23FD/Basili et al. - 2018 - Software Engineering Research and Industry A Symb.pdf:application/pdf}
}


@article{Andreessen2011,
  chapter = {Life and Style},
  title = {Why {Software} {Is} {Eating} {The} {World}},
  issn = {0099-9660},
  url = {https://online.wsj.com/article/SB10001424053111903480904576512250915629460.html},
  abstract = {Far from a bubble, we're watching a new generation of tech start-ups realize the Web's original potential, says Marc Andreessen.},
  language = {en-US},
  urldate = {2021-03-17},
  journal = {Wall Street Journal},
  author = {Andreessen, Marc},
  month = aug,
  year = {2011},
  file = {Snapshot:/Users/past/Zotero/storage/HQZFI4F5/SB10001424053111903480904576512250915629460.html:text/html}
}


@article{Wong2006,
  title = {What {Grounded} the {Airbus} {A380}?},
  shorttitle = {What {Grounded} the {Airbus} {A380}?},
  url = {https://www.cadalyst.com/cad/product-design/what-grounded-airbus-a380-10903},
  abstract = {Company management and CAD software both under fire in an interoperability debacle of jumbo proportions},
  urldate = {2021-03-17},
  journal = {Cadalyst},
  author = {Wong, Kenneth},
  month = dec,
  year = {2006},
  file = {Snapshot:/Users/past/Zotero/storage/5TBQPHYU/what-grounded-airbus-a380-10903.html:text/html}
}


@inproceedings{HaungsFowlerJMG2004,
  address = {New York, NY, USA},
  series = {{OOPSLA} '04},
  title = {Software {Development}: {Arts} \& {Crafts} or {Math} \& {Science}?},
  isbn = {978-1-58113-833-7},
  shorttitle = {Software {Development}},
  url = {http://doi.acm.org/10.1145/1028664.1028720},
  doi = {10.1145/1028664.1028720},
  abstract = {We've have been proposing formal mathematical methods of software development for nearly as long as we've been developing software. CASE tools were a bust, and Gödel long ago nullified any hope of building a system that is both complete and consistent. Model-driven development gets trotted out in a new outfit once every decade as the next "silver bullet," but we're still far from drawing pictures that generate code. Test-driven development almost produces executable specifications, but there's nothing mathematical or provably correct about them. Quality assurance happens during coding, but there's nothing to ensure that the entire system gets built, or that it's what the customer wants. Agile methods propose "emergent design," where BDUF (big design up front) is old-fashioned and limiting. But agile methods work best with small groups of clever people to implement them; they have a hard time scaling. The open-source movement, in which hobbyist programmers write code simply for the love of programming, has produced some of the best software in the industry. Is it good because people love what they're doing and build it for themselves to use? Or is it good because there are hundreds of eyes on the code? Is software development a science or an art? Does it depend on mathematicians or on craftspeople? Are these viewpoints reconcilable?},
  urldate = {2018-03-08},
  booktitle = {Companion to the 19th {Annual} {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming} {Systems}, {Languages}, and {Applications}},
  publisher = {ACM},
  author = {Haungs, Jim and Fowler, Martin and Johnson, Ralph and McConnell, Steve and Gabriel, Richard},
  year = {2004},
  keywords = {software engineering, agile development, extreme programming, formal methods},
  pages = {141--142},
  file = {ACM Full Text PDF:/Users/past/Zotero/storage/EPM9794W/Haungs et al. - 2004 - Software Development Arts & Crafts or Math & Scie.pdf:application/pdf}
}


@inproceedings{Malek2008,
  address = {Berlin, Heidelberg},
  series = {Communications in {Computer} and {Information} {Science}},
  title = {The {Art} of {Creating} {Models} and {Models} {Integration}},
  isbn = {978-3-540-78999-4},
  doi = {10.1007/978-3-540-78999-4_1},
  abstract = {The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.},
  language = {en},
  booktitle = {Model-{Based} {Software} and {Data} {Integration}},
  publisher = {Springer},
  author = {Malek, Miroslaw},
  editor = {Kutsche, Ralf-Detlef and Milanovic, Nikola},
  year = {2008},
  keywords = {Unify Modeling Language, Business Process, Failure Prediction, Radial Basis Function, Support Vector Machine},
  pages = {1--7},
  annote = {The idea of modeling},
  file = {Malek - 2008 - The Art of Creating Models and Models Integration.pdf:/Users/past/Zotero/storage/UEQ9S7LB/Malek - 2008 - The Art of Creating Models and Models Integration.pdf:application/pdf}
}


@incollection{Schichl2004,
  address = {Boston, MA},
  series = {Applied {Optimization}},
  title = {Models and the {History} of {Modeling}},
  isbn = {978-1-4613-0215-5},
  url = {https://doi.org/10.1007/978-1-4613-0215-5_2},
  abstract = {After a very fast tour through 30,000 years of modeling history, we describe the basic ingredients to models in general, and to mathematical models in particular.},
  language = {en},
  urldate = {2021-03-09},
  booktitle = {Modeling {Languages} in {Mathematical} {Optimization}},
  publisher = {Springer US},
  author = {Schichl, Hermann},
  editor = {Kallrath, Josef},
  year = {2004},
  doi = {10.1007/978-1-4613-0215-5_2},
  keywords = {Modeling, model, history of modeling, mathematical model},
  pages = {25--36},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/K7WHBELE/Schichl - 2004 - Models and the History of Modeling.pdf:application/pdf}
}



@book{VolterStahlBHH2013,
  title = {Model-{Driven} {Software} {Development}: {Technology}, {Engineering}, {Management}},
  isbn = {978-1-118-72576-4},
  shorttitle = {Model-{Driven} {Software} {Development}},
  abstract = {Model-Driven Software Development (MDSD) is currently a highly regarded development paradigm among developers and researchers. With the advent of OMG's MDA and Microsoft's Software Factories, the MDSD approach has moved to the centre of the programmer's attention, becoming the focus of conferences such as OOPSLA, JAOO and OOP.  MDSD is about using domain-specific languages to create models that express application structure or behaviour in an efficient and domain-specific way. These models are subsequently transformed into executable code by a sequence of model transformations.  This practical guide for software architects and developers is peppered with practical examples and extensive case studies. International experts deliver: * A comprehensive overview of MDSD and how it relates to industry standards such as MDA and Software Factories. * Technical details on meta modeling, DSL construction, model-to-model and model-to-code transformations, and software architecture. * Invaluable insight into the software development process, plus engineering issues such as versioning, testing and product line engineering. * Essential management knowledge covering economic and organizational topics, from a global perspective.  Get started and benefit from some practical support along the way!},
  language = {en},
  publisher = {John Wiley \& Sons},
  author = {Völter, Markus and Stahl, Thomas and Bettin, Jorn and Haase, Arno and Helsen, Simon},
  month = jun,
  year = {2013},
  note = {Google-Books-ID: 9ww\_D9fAKncC},
  keywords = {Computers / Programming / General, Computers / Software Development \& Engineering / General}
}



@article{NassiShneiderman1973,
  title = {Flowchart techniques for structured programming},
  volume = {8},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/953349.953350},
  doi = {10.1145/953349.953350},
  abstract = {With the advent of structured programming and GOTO-less programming a method is needed to model computation in simply ordered structures, each representing a complete thought possibly defined in terms of other thoughts as yet undefined. A model is needed which prevents unrestricted transfers of control and has a control structure closer to languages amenable to structured programming. We present an attempt at such a model.},
  number = {8},
  urldate = {2021-03-09},
  journal = {ACM SIGPLAN Notices},
  author = {Nassi, I. and Shneiderman, B.},
  month = aug,
  year = {1973},
  pages = {12--26},
  file = {Full Text PDF:/Users/past/Zotero/storage/EA93TYMD/Nassi and Shneiderman - 1973 - Flowchart techniques for structured programming.pdf:application/pdf}
}


@techreport{GoldstineNeumann1947,
  address = {Princeton, New Yersey},
  title = {Planning and coding of problems for an electronic computing instrument},
  number = {Part II, Volume 1-3},
  institution = {Institute for Advanced Study},
  author = {Goldstine, Hermann and von Neumann, John},
  year = {1947},
  annote = {Flowcharts in CS}
}


@inproceedings{FranceRumpe2007,
  title = {Model-driven {Development} of {Complex} {Software}: {A} {Research} {Roadmap}},
  shorttitle = {Model-driven {Development} of {Complex} {Software}},
  doi = {10.1109/FOSE.2007.14},
  abstract = {The term model-driven engineering (MDE) is typically used to describe software development approaches in which abstract models of software systems are created and systematically transformed to concrete implementations. In this paper we give an overview of current research in MDE and discuss some of the major challenges that must be tackled in order to realize the MDE vision of software development. We argue that full realizations of the MDE vision may not be possible in the near to medium-term primarily because of the wicked problems involved. On the other hand, attempting to realize the vision will provide insights that can be used to significantly reduce the gap between evolving software complexity and the technologies used to manage complexity.},
  booktitle = {Future of {Software} {Engineering} ({FOSE} '07)},
  author = {France, Robert and Rumpe, Bernhard},
  month = may,
  year = {2007},
  keywords = {software development, Unified modeling language, Programming, model-driven engineering, Computer science, Model driven engineering, Computer industry, Software systems, Software testing, model-driven development, Reliability engineering, Systems engineering and theory, complex software, software complexity, software metrics, Streaming media},
  pages = {37--54},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/WQP5YZSH/4221611.html:text/html;Submitted Version:/Users/past/Zotero/storage/MWJ9D4LT/France and Rumpe - 2007 - Model-driven Development of Complex Software A Re.pdf:application/pdf}
}


@article{Harel1987,
  title = {Statecharts: a visual formalism for complex systems},
  volume = {8},
  issn = {0167-6423},
  shorttitle = {Statecharts},
  url = {https://www.sciencedirect.com/science/article/pii/0167642387900359},
  doi = {10.1016/0167-6423(87)90035-9},
  abstract = {We present a broad extension of the conventional formalism of state machines and state diagrams, that is relevant to the specification and design of complex discrete-event systems, such as multi-computer real-time systems, communication protocols and digital control units. Our diagrams, which we call statecharts, extend conventional state-transition diagrams with essentially three elements, dealing, respectively, with the notions of hierarchy, concurrency and communication. These transform the language of state diagrams into a highly structured and economical description language. Statecharts are thus compact and expressive—small diagrams can express complex behavior—as well as compositional and modular. When coupled with the capabilities of computerized graphics, statecharts enable viewing the description at different levels of detail, and make even very large specifications manageable and comprehensible. In fact, we intend to demonstrate here that statecharts counter many of the objections raised against conventional state diagrams, and thus appear to render specification by diagrams an attractive and plausible approach. Statecharts can be used either as a stand-alone behavioral description or as part of a more general design methodology that deals also with the system's other aspects, such as functional decomposition and data-flow specification. We also discuss some practical experience that was gained over the last three years in applying the statechart formalism to the specification of a particularly complex system.},
  language = {en},
  number = {3},
  urldate = {2021-03-23},
  journal = {Science of Computer Programming},
  author = {Harel, David},
  month = jun,
  year = {1987},
  pages = {231--274},
  file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/EPWQH2EJ/Harel - 1987 - Statecharts a visual formalism for complex system.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/7WJ3APCD/0167642387900359.html:text/html}
}

@INPROCEEDINGS{Poole2001,
    author = {John D. Poole},
    title = {Model-Driven Architecture: Vision, Standards and Emerging Technologies},
    booktitle = {In In ECOOP 2001, Workshop on Metamodeling and Adaptive Object Models},
    year = {2001}
}


@inproceedings{BjornerHavelund2014,
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {40 {Years} of {Formal} {Methods}},
  isbn = {978-3-319-06410-9},
  abstract = {In this “40 years of formal methods” essay we shall first delineate, Sect. 1, what we mean by method, formal method, computer science, computing science, software engineering, and model-oriented and algebraic methods. Based on this, we shall characterize a spectrum from specification-oriented methods to analysis-oriented methods. Then, Sect. 2, we shall provide a “survey”: which are the ‘prerequisite works’ that have enabled formal methods, Sect. 2.1, and which are, to us, the, by now, classical ‘formal methods’, Sect. 2.2. We then ask ourselves the question: have formal methods for software development, in the sense of this paper been successful? Our answer is, regretfully, no! We motivate this answer, in Sect. 3.2, by discussing eight obstacles or hindrances to the proper integration of formal methods in university research and education as well as in industry practice. This “looking back” is complemented, in Sect. 3.4, by a “looking forward” at some promising developments — besides the alleviation of the (eighth or more) hindrances!},
  language = {en},
  booktitle = {{FM} 2014: {Formal} {Methods}},
  publisher = {Springer International Publishing},
  author = {Bjørner, Dines and Havelund, Klaus},
  editor = {Jones, Cliff and Pihlajasaari, Pekka and Sun, Jun},
  year = {2014},
  keywords = {Formal Method, Message Sequence Chart, Model Checker, Programming Language, Software Engineering},
  pages = {42--61},
  annote = {{\textbackslash}cite\{BjoernerHavelund2014\}}
}


@inproceedings{Abrial2006,
  address = {New York, NY, USA},
  series = {{ICSE} '06},
  title = {Formal methods in industry: achievements, problems, future},
  isbn = {978-1-59593-375-1},
  shorttitle = {Formal methods in industry},
  url = {https://doi.org/10.1145/1134285.1134406},
  doi = {10.1145/1134285.1134406},
  abstract = {Two real projects using the B formal method are quickly presented. They show how some important parts of complex systems can be developed in such a way that the outcome is "correct by construction". A number of factors are then analyzed relating the pros, the cons, and the difficulties in applying this approach in Industry.},
  urldate = {2021-01-26},
  booktitle = {Proceedings of the 28th international conference on {Software} engineering},
  publisher = {Association for Computing Machinery},
  author = {Abrial, Jean-Raymond},
  month = may,
  year = {2006},
  keywords = {correctness, B, development process, formal method, train system},
  pages = {761--768},
  file = {Full Text PDF:/Users/past/Zotero/storage/WIT39R9J/Abrial - 2006 - Formal methods in industry achievements, problems.pdf:application/pdf}
}



@article{Hoare1969,
  title = {An {Axiomatic} {Basis} for {Computer} {Programming}},
  volume = {12},
  issn = {0001-0782},
  url = {http://doi.acm.org/10.1145/363235.363259},
  doi = {10.1145/363235.363259},
  abstract = {In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. This involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. Examples are given of such axioms and rules, and a formal proof of a simple theorem is displayed. Finally, it is argued that important advantage, both theoretical and practical, may follow from a pursuance of these topics.},
  number = {10},
  urldate = {2019-08-27},
  journal = {Commun. ACM},
  author = {Hoare, C. A. R.},
  month = oct,
  year = {1969},
  keywords = {axiomatic method, formal language definition, machine-independent programming, program documentation, programming language design, theory of programming' proofs of programs},
  pages = {576--580}
}


@inproceedings{JoshiHeimdahl2005,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Model-{Based} {Safety} {Analysis} of {Simulink} {Models} {Using} {SCADE} {Design} {Verifier}},
  isbn = {978-3-540-32000-5},
  doi = {10.1007/11563228_10},
  abstract = {Safety analysis techniques have traditionally been performed manually by the safety engineers. Since these analyses are based on an informal model of the system, it is unlikely that these analyses will be complete, consistent, and error-free. Using precise formal models of the system as the basis of the analysis may help reduce errors and provide a more thorough analysis. Further, these models allow automated analysis, which may reduce the manual effort required.The process of creating system models suitable for safety analysis closely parallels the model-based development process that is increasingly used for critical system and software development. By leveraging the existing tools and techniques, we can create formal safety models using tools that are familiar to engineers and we can use the static analysis infrastructure available for these tools. This paper reports our initial experience in using model-based safety analysis on an example system taken from the ARP Safety Assessment guidelines document.},
  language = {en},
  booktitle = {Computer {Safety}, {Reliability}, and {Security}},
  publisher = {Springer},
  author = {Joshi, Anjali and Heimdahl, Mats P. E.},
  editor = {Winther, Rune and Gran, Bjørn Axel and Dahll, Gustav},
  year = {2005},
  keywords = {Failure Mode, Fault Model, Fault Tree, Safety Analysis, Safety Property},
  pages = {122--135},
  file = {Submitted Version:/Users/past/Zotero/storage/2SPJKDSS/Joshi and Heimdahl - 2005 - Model-Based Safety Analysis of Simulink Models Usi.pdf:application/pdf}
}


@article{BucchiaroneCabotPP2020,
  title = {Grand challenges in model-driven engineering: an analysis of the state of the research},
  volume = {19},
  issn = {1619-1374},
  shorttitle = {Grand challenges in model-driven engineering},
  url = {https://doi.org/10.1007/s10270-019-00773-6},
  doi = {10.1007/s10270-019-00773-6},
  abstract = {In 2017 and 2018, two events were held—in Marburg, Germany, and San Vigilio di Marebbe, Italy, respectively—focusing on an analysis of the state of research, state of practice, and state of the art in model-driven engineering (MDE). The events brought together experts from industry, academia, and the open-source community to assess what has changed in research in MDE over the last 10 years, what challenges remain, and what new challenges have arisen. This article reports on the results of those meetings, and presents a set of grand challenges that emerged from discussions and synthesis. These challenges could lead to research initiatives for the community going forward.},
  language = {en},
  number = {1},
  urldate = {2020-09-09},
  journal = {Software and Systems Modeling},
  author = {Bucchiarone, Antonio and Cabot, Jordi and Paige, Richard F. and Pierantonio, Alfonso},
  month = jan,
  year = {2020},
  pages = {5--13},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/MNXD5GXA/Bucchiarone et al. - 2020 - Grand challenges in model-driven engineering an a.pdf:application/pdf}
}


@article{Bentley1986,
  title = {Programming pearls: little languages},
  volume = {29},
  issn = {0001-0782},
  shorttitle = {Programming pearls},
  url = {https://doi.org/10.1145/6424.315691},
  doi = {10.1145/6424.315691},
  number = {8},
  urldate = {2020-03-14},
  journal = {Communications of the ACM},
  author = {Bentley, Jon},
  month = aug,
  year = {1986},
  pages = {711--721},
  annote = {Predecessor of DSLs},
  file = {Full Text PDF:/Users/past/Zotero/storage/BWKREWWT/Bentley - 1986 - Programming pearls little languages.pdf:application/pdf}
}


@book{Voelter2013,
  title = {{DSL} {Engineering}: {Designing}, {Implementing} and {Using} {Domain}-specific {Languages}},
  isbn = {978-1-4812-1858-0},
  shorttitle = {{DSL} {Engineering}},
  abstract = {The definitive resource on domain-specific languages: based on years of real-world experience, relying on modern language workbenches and full of examples. Domain-Specific Languages are programming languages specialized for a particular application domain. By incorporating knowledge about that domain, DSLs can lead to more concise and more analyzable programs, better code quality and increased development speed. This book provides a thorough introduction to DSL, relying on today's state of the art language workbenches. The book has four parts: introduction, DSL design, DSL implementation as well as the role of DSLs in various aspects of software engineering. Part I Introduction: This part introduces DSLs in general and discusses their advantages and drawbacks. It also defines important terms and concepts and introduces the case studies used in the most of the remainder of the book. Part II DSL Design: This part discusses the design of DSLs - independent of implementation techniques. It reviews seven design dimensions, explains a number of reusable language paradigms and points out a number of process-related issues. Part III DSL Implementation: This part provides details about the implementation of DSLs with lots of code. It uses three state-of-the-art but quite different language workbenches: JetBrains MPS, Eclipse Xtext and TU Delft's Spoofax. Part IV DSLs and Software Engineering: This part discusses the use of DSLs for requirements, architecture, implementation and product line engineering, as well as their roles as a developer utility and for implementing business logic. The book is available as a printed version (the one your are looking at) and as a PDF. For details see the book's companion website at http: //dslbook.org},
  language = {en},
  publisher = {CreateSpace Independent Publishing Platform},
  author = {Voelter, Markus},
  year = {2013},
  keywords = {Computers / Software Development \& Engineering / General}
}


@book{Fowler2010,
  title = {Domain-{Specific} {Languages}},
  isbn = {978-0-13-139280-9},
  abstract = {When carefully selected and used, Domain-Specific Languages (DSLs) may simplify complex code, promote effective communication with customers, improve productivity, and unclog development bottlenecks. In  Domain-Specific Languages , noted software development expert Martin Fowler first provides the information software professionals need to decide if and when to utilize DSLs. Then, where DSLs prove suitable, Fowler presents effective techniques for building them, and guides software engineers in choosing the right approaches for their applications.   This book’s techniques may be utilized with most modern object-oriented languages; the author provides numerous examples in Java and C\#, as well as selected examples in Ruby. Wherever possible, chapters are organized to be self-standing, and most reference topics are presented in a familiar patterns format.   Armed with this wide-ranging book, developers will have the knowledge they need to make important decisions about DSLs—and, where appropriate, gain the significant technical and business benefits they offer.   The topics covered include:  How DSLs compare to frameworks and libraries, and when those alternatives are sufficient Using parsers and parser generators, and parsing external DSLs Understanding, comparing, and choosing DSL language constructs  Determining whether to use code generation, and comparing code generation strategies Previewing new language workbench tools for creating DSLs},
  language = {en},
  publisher = {Pearson Education},
  author = {Fowler, Martin},
  month = sep,
  year = {2010},
  note = {Google-Books-ID: ri1muolw\_YwC},
  keywords = {Computers / Programming Languages / General}
}



@book{Laemmel2018,
  title = {Software {Languages}: {Syntax}, {Semantics}, and {Metaprogramming}},
  isbn = {978-3-319-90798-7},
  shorttitle = {Software {Languages}},
  url = {https://www.springer.com/gp/book/9783319907987},
  abstract = {This book identifies, defines and illustrates the fundamental concepts and engineering techniques relevant to applications of software languages in software development. It presents software languages primarily from a software engineering perspective, i.e., it addresses how to parse, analyze, transform, generate, format, and otherwise process software artifacts in different software languages, as they appear in software development. To this end, it covers a wide range of software languages – most notably programming languages, domain-specific languages, modeling languages, exchange formats, and specifically also language definition languages. Further, different languages are leveraged to illustrate software language engineering concepts and techniques. The functional programming language Haskell dominates the book, while the mainstream programming languages Python and Java are additionally used for illustration.By doing this, the book collects and organizes scattered knowledge from software language engineering, focusing on application areas such as software analysis (software reverse engineering), software transformation (software re-engineering), software composition (modularity), and domain-specific languages. It is designed as a textbook for independent study as well as for bachelor’s (advanced level) or master’s university courses in Computer Science. An additional website provides complementary material, for example, lecture slides and videos.This book is a valuable resource for anyone wanting to understand the fundamental concepts and important engineering principles underlying software languages, allowing them to acquire much of the operational intelligence needed for dealing with software languages in software development practice. This is an important skill set for software engineers, as languages are increasingly permeating software development.},
  language = {en},
  urldate = {2021-03-24},
  publisher = {Springer International Publishing},
  author = {Lämmel, Ralf},
  year = {2018},
  doi = {10.1007/978-3-319-90800-7}
}


@inproceedings{Czarnecki2005,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Overview of {Generative} {Software} {Development}},
  isbn = {978-3-540-31482-0},
  doi = {10.1007/11527800_25},
  abstract = {System family engineering seeks to exploit the commonalities among systems from a given problem domain while managing the variabilities among them in a systematic way. In system family engineering, new system variants can be rapidly created based on a set of reusable assets (such as a common architecture, components, models, etc.). Generative software development aims at modeling and implementing system families in such a way that a given system can be automatically generated from a specification written in one or more textual or graphical domain-specific languages. This paper gives an overview of the basic concepts and ideas of generative software development including DSLs, domain and application engineering, generative domain models, networks of domains, and technology projections. The paper also discusses the relationship of generative software development to other emerging areas such as Model Driven Development and Aspect-Oriented Software Development.},
  language = {en},
  booktitle = {Unconventional {Programming} {Paradigms}},
  publisher = {Springer},
  author = {Czarnecki, Krzysztof},
  editor = {Banâtre, Jean-Pierre and Fradet, Pascal and Giavitto, Jean-Louis and Michel, Olivier},
  year = {2005},
  keywords = {Software Product Line, Domain Engineering, Problem Space, Solution Space, System Family},
  pages = {326--341},
  annote = {Generative Software Development which is partly absorbed by SLE and MDE now},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/PVCDE4FJ/Czarnecki - 2005 - Overview of Generative Software Development.pdf:application/pdf}
}


@article{BeckerKoziolekR2009,
  series = {Special {Issue}: {Software} {Performance} - {Modeling} and {Analysis}},
  title = {The {Palladio} component model for model-driven performance prediction},
  volume = {82},
  issn = {0164-1212},
  url = {https://www.sciencedirect.com/science/article/pii/S0164121208001015},
  doi = {10.1016/j.jss.2008.03.066},
  abstract = {One aim of component-based software engineering (CBSE) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in CBSE stems from its specific development process: Software components should be specified and implemented independently from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influencing factors like the hardware platform or the usage profile into account. Our approach uses the Palladio component model (PCM) to specify component-based software architectures in a parametric way. This model offers direct support of the CBSE development process by dividing the model creation among the developer roles. This paper presents our model and a simulation tool based on it, which is capable of making performance predictions. Within a case study, we show that the resulting prediction accuracy is sufficient to support the evaluation of architectural design decisions.},
  language = {en},
  number = {1},
  urldate = {2021-03-24},
  journal = {Journal of Systems and Software},
  author = {Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
  month = jan,
  year = {2009},
  keywords = {Component-based software engineering, Performance prediction, Software architecture},
  pages = {3--22},
  file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/LZRU6E3R/Becker et al. - 2009 - The Palladio component model for model-driven perf.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/73BI4RIT/S0164121208001015.html:text/html}
}


@article{JensenKristensen2015,
  title = {Colored {Petri} nets: a graphical language for formal modeling and validation of concurrent systems},
  volume = {58},
  issn = {0001-0782},
  shorttitle = {Colored {Petri} nets},
  url = {https://doi.org/10.1145/2663340},
  doi = {10.1145/2663340},
  abstract = {Formal executable models enable systematic evaluation of system designs prior to implementation and deployment.},
  number = {6},
  urldate = {2021-03-24},
  journal = {Communications of the ACM},
  author = {Jensen, Kurt and Kristensen, Lars M.},
  month = may,
  year = {2015},
  pages = {61--70},
  file = {Full Text PDF:/Users/past/Zotero/storage/M4AWWB5I/Jensen and Kristensen - 2015 - Colored Petri nets a graphical language for forma.pdf:application/pdf}
}


@inproceedings{WhittleHutchinsonRBH2013,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Industrial {Adoption} of {Model}-{Driven} {Engineering}: {Are} the {Tools} {Really} the {Problem}?},
  isbn = {978-3-642-41533-3},
  shorttitle = {Industrial {Adoption} of {Model}-{Driven} {Engineering}},
  doi = {10.1007/978-3-642-41533-3_1},
  abstract = {An oft-cited reason for lack of adoption of model-driven engineering (MDE) is poor tool support. However, studies have shown that adoption problems are as much to do with social and organizational factors as with tooling issues. This paper discusses the impact of tools on MDE adoption and places tooling within a broader organizational context. The paper revisits previous data on MDE adoption (19 in-depth interviews with MDE practitioners) and re-analyzes the data through the specific lens of MDE tools. In addition, the paper presents new data (20 new interviews in two specific companies) and analyzes it through the same lens. The key contribution of the paper is a taxonomy of tool-related considerations, based on industry data, which can be used to reflect on the tooling landscape as well as inform future research on MDE tools.},
  language = {en},
  booktitle = {Model-{Driven} {Engineering} {Languages} and {Systems}},
  publisher = {Springer},
  author = {Whittle, Jon and Hutchinson, John and Rouncefield, Mark and Burden, Håkan and Heldal, Rogardt},
  editor = {Moreira, Ana and Schätz, Bernhard and Gray, Jeff and Vallecillo, Antonio and Clarke, Peter},
  year = {2013},
  keywords = {model-driven engineering, modeling tools, organizational change},
  pages = {1--17},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/USXN4LZS/Whittle et al. - 2013 - Industrial Adoption of Model-Driven Engineering A.pdf:application/pdf}
}


@inproceedings{MussbacherAmyotBBCCCFHHKSSSW2014,
  address = {Cham},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {The {Relevance} of {Model}-{Driven} {Engineering} {Thirty} {Years} from {Now}},
  isbn = {978-3-319-11653-2},
  doi = {10.1007/978-3-319-11653-2_12},
  abstract = {Although model-driven engineering (MDE) is now an established approach for developing complex software systems, it has not been universally adopted by the software industry. In order to better understand the reasons for this, as well as to identify future opportunities for MDE, we carried out a week-long design thinking experiment with 15 MDE experts. Participants were facilitated to identify the biggest problems with current MDE technologies, to identify grand challenges for society in the near future, and to identify ways that MDE could help to address these challenges. The outcome is a reflection of the current strengths of MDE, an outlook of the most pressing challenges for society at large over the next three decades, and an analysis of key future MDE research opportunities.},
  language = {en},
  booktitle = {Model-{Driven} {Engineering} {Languages} and {Systems}},
  publisher = {Springer International Publishing},
  author = {Mussbacher, Gunter and Amyot, Daniel and Breu, Ruth and Bruel, Jean-Michel and Cheng, Betty H. C. and Collet, Philippe and Combemale, Benoit and France, Robert B. and Heldal, Rogardt and Hill, James and Kienzle, Jörg and Schöttle, Matthias and Steimann, Friedrich and Stikkolorum, Dave and Whittle, Jon},
  editor = {Dingel, Juergen and Schulte, Wolfram and Ramos, Isidro and Abrahão, Silvia and Insfran, Emilio},
  year = {2014},
  keywords = {challenges, Model-driven engineering, research opportunities},
  pages = {183--200},
  file = {Submitted Version:/Users/past/Zotero/storage/AN8BXN97/Mussbacher et al. - 2014 - The Relevance of Model-Driven Engineering Thirty Y.pdf:application/pdf}
}


@book{TOGAF,
  edition = {10th},
  title = {{TOGAF} {Version} 9.1},
  isbn = {978-90-8753-679-4},
  abstract = {TOGAF is a framework - a detailed method and a set of supporting tools - for developing an enterprise architecture, developed by members of The Open Group Architecture Forum. TOGAF Version 9.1 is a maintenance update to TOGAF 9, addressing comments raised since the introduction of TOGAF 9 in 2009. It retains the major features and structure of TOGAF 9, thereby preserving existing investment in TOGAF, and adds further detail and clarification to what is already proven. It may be used freely by any organization wishing to develop an enterprise architecture for use within that organization (subject to the Conditions of Use). This Book is divided into seven parts.},
  publisher = {Van Haren Publishing},
  author = {Haren, Van},
  year = {2011}
}


@book{ITIL,
  address = {GBR},
  edition = {3rd},
  title = {{ITIL} {Foundation} {Handbook}},
  isbn = {978-0-11-331349-5},
  abstract = {Now updated in line with the 2011 syllabus, this quick-reference revision guide has been designed to help students prepare for their foundation exam. It is also a key reference aid for managers, practitioners, vendors and consultants in the workplace and while travelling. This handbook provides an introduction to the ITIL service lifecycle model and an overview of the ITIL qualification structure. It contains a chapter on each of the components of the lifecycle: service strategy, service design, service transition, service operation and continual service improvement. Aligned with the ITIL 2011 publications and syllabus. Provides relevant information, and enough detail and breadth of coverage to enable students to study for their foundation exam. Describes the key principles and practices of IT service management. References relevant sections of the core publications.},
  publisher = {The Stationery Office},
  author = {ITSMF UK},
  year = {2012}
}

@misc{HIMSSInterop,
  title = {Interoperability in {Healthcare}},
  url = {https://www.himss.org/resources/interoperability-healthcare},
  abstract = {Discover key insights about interoperability and better understand how data sharing can make a difference in healthcare.},
  language = {en},
  urldate = {2021-03-30},
  author = {Healthcare Information {and} Management Systems Society, Inc.},
  month = jul,
  year = {2020},
  file = {Snapshot:/Users/past/Zotero/storage/G97AHC65/interoperability-healthcare.html:text/html}
}


@misc{EuropeanInteroperability,
  type = {Text},
  title = {The {New} {European} {Interoperability} {Framework}},
  url = {https://ec.europa.eu/isa2/eif_en},
  abstract = {The New European Interoperability Framework},
  language = {en},
  urldate = {2021-03-29},
  author = {European Commission},
  month = feb,
  year = {2017},
  file = {Snapshot:/Users/past/Zotero/storage/PEVU4APS/eif_en.html:text/html}
}



@incollection{Sheth1999,
  address = {Boston, MA},
  series = {The {Springer} {International} {Series} in {Engineering} and {Computer} {Science}},
  title = {Changing {Focus} on {Interoperability} in {Information} {Systems}:{From} {System}, {Syntax}, {Structure} to {Semantics}},
  isbn = {978-1-4615-5189-8},
  shorttitle = {Changing {Focus} on {Interoperability} in {Information} {Systems}},
  url = {https://doi.org/10.1007/978-1-4615-5189-8_2},
  abstract = {Interoperability has been a basic requirement for the modern information systems environment for over two decades. How have key requirements for interoperability changed over that time? How can we understand the full scope of interoperability issues? What has shaped research on information system interoperability? What key progress has been made? This chapter provides some of the answers to these questions. In particular, it looks at different levels of information system interoperability, while reviewing the changing focus of interoperability research themes, past achievements and new challenges in the emerging global information infrastructure (GII). It divides the research into three generations, and discusses some of achievements of the past. Finally, as we move from managing data to information, and in future knowledge, the need for achieving semantic interoperability is discussed and key components of solutions are introduced.},
  language = {en},
  urldate = {2021-03-29},
  booktitle = {Interoperating {Geographic} {Information} {Systems}},
  publisher = {Springer US},
  author = {Sheth, Amit P.},
  editor = {Goodchild, Michael and Egenhofer, Max and Fegeas, Robin and Kottman, Cliff},
  year = {1999},
  doi = {10.1007/978-1-4615-5189-8_2},
  keywords = {Digital Library, Information Request, Information Source, Information System Architecture, Semantic Interoperability},
  pages = {5--29}
}



@article{Veltman2001,
  title = {Syntactic and semantic interoperability: {New} approaches to knowledge and the semantic web},
  volume = {7},
  issn = {1361-4576},
  shorttitle = {Syntactic and semantic interoperability},
  url = {https://doi.org/10.1080/13614570109516975},
  doi = {10.1080/13614570109516975},
  number = {1},
  urldate = {2021-03-29},
  journal = {New Review of Information Networking},
  author = {Veltman, Kim H.},
  month = jan,
  year = {2001},
  pages = {159--183},
}


@book{PileggiFernandezLlatas2012,
  title = {Semantic {Interoperability}: {Issues}, {Solutions}, {Challenges}},
  isbn = {978-87-92982-82-7},
  shorttitle = {Semantic {Interoperability}},
  abstract = {Semantic technologies are experimenting an increasing popularity in the context of different domains and applications. The understanding of any class of system can be significantly changed under the assumption any system is part of a global ecosystem known as Semantic Web. The Semantic Web would be an evolving extension of current Web model (normally referred as Syntactic Web) that introduces a semantic layer in which semantics, or meaning of information, are formally defined. So, semantics should integrate web-centric standard information infrastructures improving several aspects of interaction among heterogeneous systems. This is because common interoperability models are progressively becoming obsolete if compared with the intrinsic complexity and always more distributed focus that feature modern systems. For example, the basic interoperability model, that assumes the interchange of messages among systems without any interpretation, is simple but effective only in the context of close environments. Also more advanced models, such as the functional interoperability model that integrates basic interoperability model with the ability of interpreting data context under the assumption of a shared schema for data fields accessing, appears not able to provide a full sustainable technologic support for open systems. The Semantic Interoperability model would improve common interoperability models introducing the interpretation of means of data. Semantic interoperability is a concretely applicable interaction model under the assumption of adopting rich data models (commonly called Ontology) composed of concepts within a domain and the relationships among those concepts. In practice, semantic technologies are partially inverting the common view at actor intelligence: intelligence is not implemented (only) by actors but it is implicitly resident in the knowledge model. In other words, schemas contain information and the “code” to interpret it.},
  language = {en},
  publisher = {River Publishers},
  author = {Pileggi, Salvatore F. and Fernandez-Llatas,  Carlos},
  month = mar,
  year = {2012},
  note = {Google-Books-ID: oWy0rk1xassC},
  keywords = {Computers / Computer Science, Technology \& Engineering / Telecommunications}
}



@inproceedings{BarnickelFluegge2010,
  address = {New York, NY, USA},
  series = {{ISWSA} '10},
  title = {Towards a conceptual framework for semantic interoperability in service oriented architectures},
  isbn = {978-1-4503-0475-7},
  url = {https://doi.org/10.1145/1874590.1874602},
  doi = {10.1145/1874590.1874602},
  abstract = {The application of Semantic Web technologies to service-oriented architectures (SOA) has promised to mitigate the problem of achieving semantic interoperability as the formal definition of semantics paves the way for higher automation in the mediation process between heterogeneous services. Recently, many ontology-based approaches for semantic interoperability have been developed. However, it remains difficult to compare the various approaches because only domain-specific conceptual frameworks for semantic interoperability exist. Moreover, in SOA practice ontology-based approaches are not widely adopted but still XML-based solutions are dominant. This paper targets to fill this gap and presents ongoing work towards a general conceptual framework for semantic interoperability in SOA as a foundation for comparative reflection. Based on the framework selected approaches both academic and industry-driven are compared. Furthermore, an inherent trade-off between efficiency and effectiveness in achieving semantic interoperability is identified and a potential alleviation based on semantic mediation on domain level is outlined.},
  urldate = {2021-03-29},
  booktitle = {Proceedings of the 1st {International} {Conference} on {Intelligent} {Semantic} {Web}-{Services} and {Applications}},
  publisher = {Association for Computing Machinery},
  author = {Barnickel, Nils and Fluegge, Matthias},
  month = jun,
  year = {2010},
  keywords = {conceptual framework, ontology mapping, semantic interoperability, semantic mediation, semantic web technologies, service-oriented architectures},
  pages = {1--7},
  annote = {interesting!},
  file = {Full Text PDF:/Users/past/Zotero/storage/JT4FGC6V/Barnickel and Fluegge - 2010 - Towards a conceptual framework for semantic intero.pdf:application/pdf}
}


@inproceedings{AscuncionCamlonSM2010,
  address = {Berlin, Heidelberg},
  series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
  title = {Pragmatic {Interoperability}: {A} {Systematic} {Review} of {Published} {Definitions}},
  isbn = {978-3-642-15509-3},
  shorttitle = {Pragmatic {Interoperability}},
  doi = {10.1007/978-3-642-15509-3_15},
  abstract = {Enabling the interoperability between applications requires agreement in the format and meaning (syntax and semantics) of exchanged data including the ordering of message exchanges. However, today’s researchers argue that these are not enough to achieve a complete, effective and meaningful collaboration – the use of data (pragmatics) is important as well. Pragmatic interoperability requires mutual understanding in the use of data between collaborating systems. However, we observe that the notion of pragmatic interoperability is still largely unsettled, as evidenced by the various proposed definitions and the lack of a canonical understanding. Therefore, our objective is to contribute to a more thorough understanding of this concept through a systematic review of published definitions. Our results show that, indeed, various interpretations of pragmatic interoperability exist. Categorizing the derivable concepts from these definitions, we see two broad groups: system level and business level. Within each of these individual levels, we see some degree of agreement among the definitions. However, comparing the definitions across these levels, we observe no general agreement. At the system level, pragmatic interoperability essentially means sharing the same understanding of the intended and actual use of exchanged system message in a given context. At the business level, pragmatic interoperability goes beyond service use by considering also the compatibility of business intentions, business rules, organizational policies, and the establishment and maintenance of trust and reputation mechanisms between collaborating business parties.},
  language = {en},
  booktitle = {Enterprise {Architecture}, {Integration} and {Interoperability}},
  publisher = {Springer},
  author = {Asuncion, Camlon H. and van Sinderen, Marten J.},
  editor = {Bernus, Peter and Doumeingts, Guy and Fox, Mark},
  year = {2010},
  keywords = {definitions, pragmatic interoperability, systematic review},
  pages = {164--175},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/NZHX65HJ/Asuncion and van Sinderen - 2010 - Pragmatic Interoperability A Systematic Review of.pdf:application/pdf}
}


@inproceedings{PokarevReicherSW2005,
  title = {Semantic and {Pragmatic} {Interoperability}: {A} {Model} for {Understanding}},
  volume = {160},
  booktitle = {Proceedings of the {Open} {Interop} {Workshop} on {Enterprise} {Modelling} and {Ontologies} for {Interoperability}},
  publisher = {CEUR-WS.org},
  author = {Pokarev, S and Reichert, M and Stehen, M. W. A. and Wieringa, R.J.},
  year = {2005}
}


@misc{ISOOSI,
  title = {{ISO}/{IEC} 7498-1:1994},
  shorttitle = {{ISO}/{IEC} 7498-1},
  url = {https://www.iso.org/cms/render/live/en/sites/isoorg/contents/data/standard/02/02/20269.html},
  abstract = {ISO/IEC 7498-1:1994 Information technology — Open Systems Interconnection — Basic Reference Model: The Basic Model},
  language = {en},
  urldate = {2021-03-30},
  author = {ISO/IEC JTC 1 Information technology},
  year = {1994}
}



@book{Kleppmann2017,
  title = {Designing {Data}-{Intensive} {Applications}: {The} {Big} {Ideas} {Behind} {Reliable}, {Scalable}, and {Maintainable} {Systems}},
  isbn = {978-1-4919-0310-0},
  shorttitle = {Designing {Data}-{Intensive} {Applications}},
  abstract = {Data is at the center of many challenges in system design today. Difficult issues need to be figured out, such as scalability, consistency, reliability, efficiency, and maintainability. In addition, we have an overwhelming variety of tools, including relational databases, NoSQL datastores, stream or batch processors, and message brokers. What are the right choices for your application? How do you make sense of all these buzzwords?In this practical and comprehensive guide, author Martin Kleppmann helps you navigate this diverse landscape by examining the pros and cons of various technologies for processing and storing data. Software keeps changing, but the fundamental principles remain the same. With this book, software engineers and architects will learn how to apply those ideas in practice, and how to make full use of data in modern applications.Peer under the hood of the systems you already use, and learn how to use and operate them more effectivelyMake informed decisions by identifying the strengths and weaknesses of different toolsNavigate the trade-offs around consistency, scalability, fault tolerance, and complexityUnderstand the distributed systems research upon which modern databases are builtPeek behind the scenes of major online services, and learn from their architectures},
  language = {en},
  publisher = {"O'Reilly Media, Inc."},
  author = {Kleppmann, Martin},
  month = mar,
  year = {2017},
  note = {Google-Books-ID: p1heDgAAQBAJ},
  keywords = {Computers / Data Modeling \& Design, Computers / Desktop Applications / Databases}
}



@inproceedings{Damodoran2004,
  address = {New York, NY, USA},
  series = {{WWW} {Alt}. '04},
  title = {{B2B} integration over the {Internet} with {XML}: {RosettaNet} successes and challenges},
  isbn = {978-1-58113-912-9},
  shorttitle = {{B2B} integration over the {Internet} with {XML}},
  url = {https://doi.org/10.1145/1013367.1013398},
  doi = {10.1145/1013367.1013398},
  abstract = {The practical experience of RosettaNet in using Web technologies for B2B integration illustrates the transformative power of Web technologies and also highlights challenges for the future. This paper provides an overview of RosettaNet technical standards and discusses the lessons learned from the standardization efforts, in particular, what works and what doesn't. This paper also describes the effort to increase automation of B2B software integration, and thereby to reduce cost.},
  urldate = {2021-03-30},
  booktitle = {Proceedings of the 13th international {World} {Wide} {Web} conference on {Alternate} track papers \& posters},
  publisher = {Association for Computing Machinery},
  author = {Damodaran, Suresh},
  month = may,
  year = {2004},
  keywords = {B2B integration, business process, messaging services, PIP, XML},
  pages = {188--195},
  file = {Full Text PDF:/Users/past/Zotero/storage/CRQGBUGI/Damodaran - 2004 - B2B integration over the Internet with XML Rosett.pdf:application/pdf}
}





@inproceedings{FradeDiGiacomoGLP2012,
  address = {New York, NY, USA},
  series = {I-{SEMANTICS} '12},
  title = {Building semantic interoperability through the federation of semantic asset repositories},
  isbn = {978-1-4503-1112-0},
  url = {https://doi.org/10.1145/2362499.2362528},
  doi = {10.1145/2362499.2362528},
  abstract = {According to the Interoperability Solutions for European Public Administrations (ISA) Programme of the European Commission, interoperability relates to the ability of disparate organisations to interact towards mutually beneficial and agreed goals, involving the sharing of information and knowledge [1]. Semantic assets and the agreements associated with them are essential elements for organisations to understand the meaning of the information they exchange - without them this information would be of little use. In this paper, semantic assets are defined as ontologies, data models, data dictionaries, code lists, XML and RDF schemas which are used for information exchange and that can be reused by implementers of Information Systems, in particular, as part of machine-to-machine interfaces. However, field research has shown that developers, practitioners and researchers working in the field of semantic interoperability in eGovernment tend to reinvent the wheel and semantic assets are rarely reused. In order to encourage and bootstrap the reuse of semantic assets in the EU and beyond, this paper introduces two important initiatives driven by the ISA Programme: the Asset Description Metadata Schema (ADMS) and the ADMS-enabled federation of semantic asset repositories on Joinup.},
  urldate = {2021-03-29},
  booktitle = {Proceedings of the 8th {International} {Conference} on {Semantic} {Systems}},
  publisher = {Association for Computing Machinery},
  author = {Frade, João Rodrigues and Di Giacomo, Debora and Goedertier, Stijn and Loutas, Nikolaos and Peristeras, Vassilios},
  month = sep,
  year = {2012},
  keywords = {ADMS, e-government, metadata management, RDF, semantic interoperability, syndication of content, XML},
  pages = {185--188},
  file = {Full Text PDF:/Users/past/Zotero/storage/C7CNJHUX/Frade et al. - 2012 - Building semantic interoperability through the fed.pdf:application/pdf}
}


@inproceedings{LopesOliveira2011,
  address = {New York, NY, USA},
  series = {{MIXHS} '11},
  title = {A semantic web application framework for health systems interoperability},
  isbn = {978-1-4503-0954-7},
  url = {https://doi.org/10.1145/2064747.2064768},
  doi = {10.1145/2064747.2064768},
  abstract = {Relevant biomedical advances happen daily, and the medical profession relies on this evolution to deliver an improved patient care. In addition, the growing magnitude of data generated by biomedical software and hardware since the initial discovery of the human genome is remarkable in size and variety. Hence, best-of-breed software solutions are at best a couple years behind clinical practice demands. In this paper we detail an innovative Semantic Web interoperability framework, which provides developers with a complete software stack for semantic application deployment. Interoperability is the defining feature of this framework. On the one hand, new instances are able to integrate several types of distributed and heterogeneous data. On the other hand, collected data are made available through a public SPARQL endpoint.},
  urldate = {2021-03-29},
  booktitle = {Proceedings of the first international workshop on {Managing} interoperability and complexity in health systems},
  publisher = {Association for Computing Machinery},
  author = {Lopes, Pedro and Oliveira, José Luís},
  month = oct,
  year = {2011},
  keywords = {bioinformatics, healthcare interoperability, semantic exploration, semantic integration, semantic web},
  pages = {87--90},
  file = {Full Text PDF:/Users/past/Zotero/storage/JQK5SNHN/Lopes and Oliveira - 2011 - A semantic web application framework for health sy.pdf:application/pdf}
}


@article{StuderBenjamins1998,
  title = {Knowledge engineering: {Principles} and methods},
  volume = {25},
  issn = {0169-023X},
  shorttitle = {Knowledge engineering},
  url = {https://www.sciencedirect.com/science/article/pii/S0169023X97000566},
  doi = {10.1016/S0169-023X(97)00056-6},
  abstract = {This paper gives an overview of the development of the field of Knowledge Engineering over the last 15 years. We discuss the paradigm shift from a transfer view to a modeling view and describe two approaches which considerably shaped research in Knowledge Engineering: Role-limiting Methods and Generic Tasks. To illustrate various concepts and methods which evolved in recent years we describe three modeling frameworks: CommonKADS, MIKE and PROTÉGÉ-II. This description is supplemented by discussing some important methodological developments in more detail: specification languages for knowledge-based systems, problem-solving methods and ontologies. We conclude by outlining the relationship of Knowledge Engineering to Software Engineering, Information Integration and Knowledge Management.},
  language = {en},
  number = {1},
  urldate = {2021-03-26},
  journal = {Data \& Knowledge Engineering},
  author = {Studer, Rudi and Benjamins, V. Richard and Fensel, Dieter},
  month = mar,
  year = {1998},
  keywords = {Information integration, Knowledge acquisition, Knowledge Engineering, Ontology, Problem-solving method},
  pages = {161--197},
  file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/QF79SE4M/S0169023X97000566.html:text/html;Submitted Version:/Users/past/Zotero/storage/2NSQQKGK/Studer et al. - 1998 - Knowledge engineering Principles and methods.pdf:application/pdf}
}


@inproceedings{ ,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Bringing {Semantics} to {Web} {Services}: {The} {OWL}-{S} {Approach}},
  isbn = {978-3-540-30581-1},
  shorttitle = {Bringing {Semantics} to {Web} {Services}},
  doi = {10.1007/978-3-540-30581-1_4},
  abstract = {Service interface description languages such as WSDL, and related standards, are evolving rapidly to provide a foundation for interoperation between Web services. At the same time, Semantic Web service technologies, such as the Ontology Web Language for Services (OWL-S), are developing the means by which services can be given richer semantic specifications. Richer semantics can enable fuller, more flexible automation of service provision and use, and support the construction of more powerful tools and methodologies. Both sets of technologies can benefit from complementary uses and cross-fertilization of ideas. This paper shows how to use OWL-S in conjunction with Web service standards, and explains and illustrates the value added by the semantics expressed in OWL-S.},
  language = {en},
  booktitle = {Semantic {Web} {Services} and {Web} {Process} {Composition}},
  publisher = {Springer},
  author = {Martin, David and Paolucci, Massimo and McIlraith, Sheila and Burstein, Mark and McDermott, Drew and McGuinness, Deborah and Parsia, Bijan and Payne, Terry and Sabou, Marta and Solanki, Monika and Srinivasan, Naveen and Sycara, Katia},
  editor = {Cardoso, Jorge and Sheth, Amit},
  year = {2005},
  keywords = {Capability Match, Hierarchical Task Network, Hierarchical Task Network Planning, International Semantic},
  pages = {26--42},
  file = {Accepted Version:/Users/past/Zotero/storage/GDATYICS/Martin et al. - 2005 - Bringing Semantics to Web Services The OWL-S Appr.pdf:application/pdf}
}


@techreport{DiskinStunkel2020TR,
  title = {Sketches, {Queries}, {Views}, and {Kleisli} {Composition}: {Towards} {Universal} {Algebra} of {Diagrammatic} {Operations} with {Pre}- and {Post}-{Conditions}},
  number = {33},
  institution = {McMaster Centre for Software Certification},
  author = {Diskin, Zinovy and Stünkel, Patrick},
  month = may,
  year = {2020}
}


@incollection{SpanoudakisZisman2005,
  title = {Software traceability: a roadmap},
  isbn = {978-981-256-273-9},
  shorttitle = {Software traceability},
  url = {https://www.worldscientific.com/doi/10.1142/9789812775245_0014},
  urldate = {2021-03-14},
  booktitle = {Handbook of {Software} {Engineering} and {Knowledge} {Engineering}},
  publisher = {WORLD SCIENTIFIC},
  author = {Spanoudakis, George and Zisman, Andrea},
  month = aug,
  year = {2005},
  doi = {10.1142/9789812775245_0014},
  pages = {395--428},
  file = {Snapshot:/Users/past/Zotero/storage/CRXIG2MN/9789812775245_0014.html:text/html;Submitted Version:/Users/past/Zotero/storage/U6UW27LV/Spanoudakis and Zisman - 2005 - Software traceability a roadmap.pdf:application/pdf}
}


@article{SpanoudakisFinkelsteinT1999,
  title = {Overlaps in {Requirements} {Engineering}},
  volume = {6},
  issn = {1573-7535},
  url = {https://doi.org/10.1023/A:1008718614166},
  doi = {10.1023/A:1008718614166},
  abstract = {Although overlap between specifications—that is the incorporation of elements which designate common aspects of the system of concern—is a precondition for specification inconsistency, it has only been a side concern in requirements engineering research. This paper is concerned with overlaps. It defines overlap relations in terms of specification interpretations, identifies properties of these relations which are derived from the proposed definition, shows how overlaps may affect the detection of inconsistency; shows how specifications could be rewritten to reflect overlap relations and still be amenable to consistency checking using theorem proving; analyses various methods that have been proposed for identifying overlaps with respect to the proposed definition; and outlines directions for future research.},
  language = {en},
  number = {2},
  urldate = {2020-02-14},
  journal = {Automated Software Engineering},
  author = {Spanoudakis, George and Finkelstein, Anthony and Till, David},
  month = apr,
  year = {1999},
  pages = {171--198},
  annote = {Distinguishes different types of overlaps:
null
total
partial
inclusive},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/PPSDKQPA/Spanoudakis et al. - 1999 - Overlaps in Requirements Engineering.pdf:application/pdf}
}


@book{TaylorMedvidovicD2009,
  title = {Software {Architecture}: {Foundations}, {Theory}, and {Practice}},
  isbn = {978-0-470-16774-8},
  shorttitle = {Software {Architecture}},
  abstract = {Software architecture is foundational to the development of large, practical software-intensive applications. This brand-new text covers all facets of software architecture and how it serves as the intellectual centerpiece of software development and evolution. Critically, this text focuses on supporting creation of real implemented systems. Hence the text details not only modeling techniques, but design, implementation, deployment, and system adaptation -- as well as a host of other topics -- putting the elements in context and comparing and contrasting them with one another. Rather than focusing on one method, notation, tool, or process, this new text/reference widely surveys software architecture techniques, enabling the instructor and practitioner to choose the right tool for the job at hand. Software Architecture is intended for upper-division undergraduate and graduate courses in software architecture, software design, component-based software engineering, and distributed systems; the text may also be used in introductory as well as advanced software engineering courses.},
  language = {en},
  publisher = {John Wiley \& Sons},
  author = {Taylor, Richard N. and Medvidovic, Nenad and Dashofy, Eric},
  month = jan,
  year = {2009},
  note = {Google-Books-ID: npB5DwAAQBAJ},
  keywords = {Computers / Programming / General, Computers / Software Development \& Engineering / General}
}


@article{FranzagoRuscioMM2018,
  title = {Collaborative {Model}-{Driven} {Software} {Engineering}: {A} {Classification} {Framework} and a {Research} {Map}},
  volume = {44},
  issn = {1939-3520},
  shorttitle = {Collaborative {Model}-{Driven} {Software} {Engineering}},
  doi = {10.1109/TSE.2017.2755039},
  abstract = {Context: Collaborative Model-Driven Software Engineering (MDSE) consists of methods and techniques where multiple stakeholders manage, collaborate, and are aware of each others' work on shared models. Objective: Collaborative MDSE is attracting research efforts from different areas, resulting in a variegated scientific body of knowledge. This study aims at identifying, classifying, and understanding existing collaborative MDSE approaches. Method: We designed and conducted a systematic mapping study. Starting from over 3,000 potentially relevant studies, we applied a rigorous selection procedure resulting in 106 selected papers, further clustered into 48 primary studies along a time span of 19 years. We rigorously defined and applied a classification framework and extracted key information from each selected study for subsequent analysis. Results: Our analysis revealed the following main fidings: (i) there is a growing scientific interest on collaborative MDSE in the last years; (ii) multi-view modeling, validation support, reuse, and branching are more rarely covered with respect to other aspects about collaborative MDSE; (iii) different primary studies focus differently on individual dimensions of collaborative MDSE (i.e., model management, collaboration, and communication); (iv) most approaches are language-specific, with a prominence of UML-based approaches; (v) few approaches support the interplay between synchronous and asynchronous collaboration. Conclusion: This study gives a solid foundation for classifying existing and future approaches for collaborative MDSE. Researchers and practitioners can use our results for identifying existing research/technical gaps to attack, better scoping their own contributions, or understanding existing ones.},
  number = {12},
  journal = {IEEE Transactions on Software Engineering},
  author = {Franzago, M. and Ruscio, D. D. and Malavolta, I. and Muccini, H.},
  month = dec,
  year = {2018},
  note = {Conference Name: IEEE Transactions on Software Engineering},
  keywords = {Analytical models, Unified Modeling Language, formal specification, model-driven engineering, Software engineering, Systematics, systematic mapping study, groupware, Collaboration, Stakeholders, asynchronous collaboration, C-MDSE, classification framework, Collaborative MDSE, collaborative MDSE approaches, Collaborative Model-Driven Software Engineering, collaborative software engineering, CoMDSE, CoSE, primary studies, synchronous collaboration, time 19.0 year},
  pages = {1146--1175}
}




@incollection{AsmannZschalerW2006,
  address = {Berlin, Heidelberg},
  title = {Ontologies, {Meta}-models, and the {Model}-{Driven} {Paradigm}},
  isbn = {978-3-540-34518-3},
  url = {https://doi.org/10.1007/3-540-34518-3_9},
  abstract = {9.6 ConclusionsOntologies are no silver bullet. They can be employed in the software process as descriptive standardized domain models, domain-specific languages, and modelling (description) languages. However, they should not be mingled with specifications of software systems. In MDE, both forms of models are needed and complement each other. It is time to develop appropriate mega-models that clarify the role of ontologies in MDE. This chapter has presented one approach; however, this can be only an intermediate step, because we restricted ourselves to the standard IRDS metapyramid. Other, more sophisticated meta-pyramids exist and must be extended to be ontology-aware.},
  language = {en},
  urldate = {2021-03-30},
  booktitle = {Ontologies for {Software} {Engineering} and {Software} {Technology}},
  publisher = {Springer},
  author = {Aßmann, Uwe and Zschaler, Steffen and Wagner, Gerd},
  editor = {Calero, Coral and Ruiz, Francisco and Piattini, Mario},
  year = {2006},
  doi = {10.1007/3-540-34518-3_9},
  keywords = {Object Constraint Language, Object Management Group, Domain Ontology, Dynamic Semantic, Ontology Language},
  pages = {249--273},
  file = {Submitted Version:/Users/past/Zotero/storage/ZXBXBVIK/Aßmann et al. - 2006 - Ontologies, Meta-models, and the Model-Driven Para.pdf:application/pdf}
}


@book{WoodHarperAntillA1985,
  address = {GBR},
  title = {Information systems definition: the {Multiview} approach},
  shorttitle = {Information systems definition},
  publisher = {Blackwell Scientific Publications, Ltd.},
  author = {Wood-Harper, A. T. and Antill, Lyn and Avison, D. E.},
  year = {1985}
}

@inproceedings{DiskinKoenigLM2018,
  address = {Cham},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Toward {Product} {Lines} of {Mathematical} {Models} for {Software} {Model} {Management}},
  isbn = {978-3-319-74730-9},
  doi = {10.1007/978-3-319-74730-9_19},
  abstract = {We present a general view on theoretical aspects of model synchronization and consistency management, and discuss technical challenges in making it sound, and cultural challenges in bringing it to practice.},
  language = {en},
  booktitle = {Software {Technologies}: {Applications} and {Foundations}},
  publisher = {Springer International Publishing},
  author = {Diskin, Zinovy and König, Harald and Lawford, Mark and Maibaum, Tom},
  editor = {Seidl, Martina and Zschaler, Steffen},
  year = {2018},
  pages = {200--216},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/Q5BZ43AC/Diskin et al. - 2018 - Toward Product Lines of Mathematical Models for So.pdf:application/pdf}
}


@inproceedings{BoardmanSauser2006,
  title = {System of {Systems} - the meaning of of},
  doi = {10.1109/SYSOSE.2006.1652284},
  abstract = {We present distinguishing characteristics (i.e. autonomy, belonging, connectivity, diversity, and emergence), that can help us to recognize or to realize a System of Systems (SoS). The principle differentiation that we make between a thing being either a `system' or a SoS focuses on the nature of a system's composition. We will distinctly define this set of distinguishing characteristics which will include a set of cross references from our literature research where we believe others are articulating our chosen differentiating characteristics. We conclude by summarizing the difference in these terms in a fundamental sense, one that impacts their structure, behavior and realization, and the distinction comes from the manner in which parts and relationships are gathered together and therefore in the nature of the emergent whole},
  booktitle = {2006 {IEEE}/{SMC} {International} {Conference} on {System} of {Systems} {Engineering}},
  author = {Boardman, J. and Sauser, B.},
  month = apr,
  year = {2006},
  keywords = {Character recognition, Network topology, Systems engineering and theory, Technological innovation},
  pages = {6 pp.--},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/NQWJNIPW/1652284.html:text/html}
}



@inproceedings{MartinPaolucciMBMMOOSSSS2005,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Bringing {Semantics} to {Web} {Services}: {The} {OWL}-{S} {Approach}},
  isbn = {978-3-540-30581-1},
  shorttitle = {Bringing {Semantics} to {Web} {Services}},
  doi = {10.1007/978-3-540-30581-1_4},
  abstract = {Service interface description languages such as WSDL, and related standards, are evolving rapidly to provide a foundation for interoperation between Web services. At the same time, Semantic Web service technologies, such as the Ontology Web Language for Services (OWL-S), are developing the means by which services can be given richer semantic specifications. Richer semantics can enable fuller, more flexible automation of service provision and use, and support the construction of more powerful tools and methodologies. Both sets of technologies can benefit from complementary uses and cross-fertilization of ideas. This paper shows how to use OWL-S in conjunction with Web service standards, and explains and illustrates the value added by the semantics expressed in OWL-S.},
  language = {en},
  booktitle = {Semantic {Web} {Services} and {Web} {Process} {Composition}},
  publisher = {Springer},
  author = {Martin, David and Paolucci, Massimo and McIlraith, Sheila and Burstein, Mark and McDermott, Drew and McGuinness, Deborah and Parsia, Bijan and Payne, Terry and Sabou, Marta and Solanki, Monika and Srinivasan, Naveen and Sycara, Katia},
  editor = {Cardoso, Jorge and Sheth, Amit},
  year = {2005},
  keywords = {Capability Match, Hierarchical Task Network, Hierarchical Task Network Planning, International Semantic},
  pages = {26--42},
  file = {Accepted Version:/Users/past/Zotero/storage/GDATYICS/Martin et al. - 2005 - Bringing Semantics to Web Services The OWL-S Appr.pdf:application/pdf}
}



@article{BucchiaroneCiccozziLPTTWZ2021,
  title = {What {Is} the {Future} of {Modeling}?},
  volume = {38},
  issn = {1937-4194},
  doi = {10.1109/MS.2020.3041522},
  abstract = {Modeling languages and frameworks have been the key technology for advancing model-driven engineering (MDE) methods and tools. Many industrial and research tools have been realized and are used across many domains. Hence, we think it is the right time to define what should be the future of modeling technologies, especially the requirements for the next generation of modeling frameworks and languages.},
  number = {2},
  journal = {IEEE Software},
  author = {Bucchiarone, Antonio and Ciccozzi, Federico and Lambers, Leen and Pierantonio, Alfonso and Tichy, Matthias and Tisi, Massimo and Wortmann, Andreas and Zaytsev, Vadim},
  month = mar,
  year = {2021},
  note = {Conference Name: IEEE Software},
  keywords = {Model driven engineering, Next generation networking, Software tools},
  pages = {119--127},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/TZCNE6F3/authors.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/JMLFD3XL/Bucchiarone et al. - 2021 - What Is the Future of Modeling.pdf:application/pdf}
}



@inproceedings{NuseibehKramerF1993,
  address = {Washington, DC, USA},
  series = {{ICSE} '93},
  title = {Expressing the relationships between multiple views in requirements specification},
  isbn = {978-0-89791-588-5},
  urldate = {2021-04-19},
  booktitle = {Proceedings of the 15th international conference on {Software} {Engineering}},
  publisher = {IEEE Computer Society Press},
  author = {Nuseibeh, Bashar and Kramer, Jeff and Finkelsteiin, Anthony},
  month = may,
  year = {1993},
  pages = {187--196},
  file = {Nuseibeh et al. - 1993 - Expressing the relationships between multiple view.pdf:/Users/past/Zotero/storage/7P6VNWMR/Nuseibeh et al. - 1993 - Expressing the relationships between multiple view.pdf:application/pdf}
}



@inproceedings{Wasserman1990,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Tool integration in software engineering environments},
  isbn = {978-3-540-46886-8},
  doi = {10.1007/3-540-53452-0_38},
  abstract = {This paper has described the various types of tool integration with the goal of illustrating how diverse tools can be effectively integrated into CASE environments. Issues of data integration, control integration, and presentation integration may be viewed as orthogonal and defining a three-dimensional space in which tool integration occurs. The absence of standards has been shown to be a barrier to integration, as various tool developers remain unable to reach agreement on the appropriate point(s) in this space at which integration should occur. As a result, experience with tool integration has been largely at a tool-to-tool level, with little use of standard tool integration mechanisms.Development of the Software through Pictures environment has provided valuable experience with these issues, and they have served to influence forthcoming changes to the structure of the tools and the overall environment architecture.},
  language = {en},
  booktitle = {Software {Engineering} {Environments}},
  publisher = {Springer},
  author = {Wasserman, Anthony I.},
  editor = {Long, Fred},
  year = {1990},
  keywords = {Broadcast Message, Control Integration, Data Integration, Tool Integration, Window System},
  pages = {137--149}
}


@inproceedings{BezivinDupeJPR2003,
  title = {First experiments with the {ATL} model transformation language: {Transforming} {XSLT} into {XQuery}},
  shorttitle = {First experiments with the {ATL} model transformation language},
  abstract = {ATL (Atlas Transformation Language) has been defined to perform general transformations within the MDA framework (Model Driven Architecture) recently proposed by the OMG. We are currently learning from the first applications developed with this language. The example used here is a transformation from XSLT to XQuery. Since these are two standard notations that don’t pertain to the MDA space, we first need to provide some justification about this work. The global organization of technological spaces presented at the beginning of the paper is intended to answer this first question. Furthermore we propose the original characterization of a technological space as a framework based on a given unique meta-model. After having briefly presented the ATL framework, we describe the XSLT2XQuery transformation. We may then draw several conclusions from this experiment, suggesting possible improvements to general model transformation frameworks. ATL is still evolving since it is supposed to match the forthcoming QVT/RFP recommendation when it is ready. As a consequence, the concrete expression of the transformation presented in this paper may change, but the general ideas should remain stable.},
  booktitle = {2nd {OOPSLA} {Workshop} on {Generative} {Techniques} in the context of {Model} {Driven} {Architecture}},
  author = {Bézivin, Jean and Dupé, Grégoire and Jouault, Frédéric and Pitette, Gilles and Rougui, Jamal Eddine},
  year = {2003},
  annote = {Concept of TechSpaces},
  file = {Citeseer - Full Text PDF:/Users/past/Zotero/storage/VTU4IC8M/Bézivin et al. - 2003 - First experiments with the ATL model transformatio.pdf:application/pdf;Citeseer - Snapshot:/Users/past/Zotero/storage/TAYMCQEF/summary.html:text/html}
}



@article{BernsteinHalevyP2000,
  title = {A vision for management of complex models},
  volume = {29},
  issn = {0163-5808},
  url = {https://doi.org/10.1145/369275.369289},
  doi = {10.1145/369275.369289},
  abstract = {Many problems encountered when building applications of database systems involve the manipulation of models. By "model," we mean a complex structure that represents a design artifact, such as a relational schema, object-oriented interface, UML model, XML DTD, web-site schema, semantic network, complex document, or software configuration. Many uses of models involve managing changes in models and transformations of data from one model into another. These uses require an explicit representation of "mappings" between models. We propose to make database systems easier to use for these applications by making "model" and "model mapping" first-class objects with special operations that simplify their use. We call this capability model management.In addition to making the case for model management, our main contribution is a sketch of a proposed data model. The data model consists of formal, object-oriented structures for representing models and model mappings, and of high-level algebraic operations on those structures, such as matching, differencing, merging, selection, inversion and instantiation. We focus on structure and semantics, not implementation.},
  number = {4},
  urldate = {2021-04-22},
  journal = {ACM SIGMOD Record},
  author = {Bernstein, Phillip A. and Halevy, Alon Y. and Pottinger, Rachel A.},
  month = dec,
  year = {2000},
  pages = {55--63},
  annote = {{\textbackslash}cite\{BernsteinHalevyP2000\}},
  file = {Submitted Version:/Users/past/Zotero/storage/26M4WLUF/Bernstein et al. - 2000 - A vision for management of complex models.pdf:application/pdf}
}


@inproceedings{Favre2003,
  title = {Meta-{Model} and {Model} {Co}-evolution within the {3D} {Software} {Space}},
  abstract = {Software evolution-in-the-large is a challenging issue. While most research work concentrates on the evolution of "programs", large scale software evolution should be driven by much higher levels of abstraction. Software architecture is an example of such abstraction. The notion of co-evolution between architecture and implementation has been identified and studied recently. This paper claims that other abstraction dimensions should also be taken into account, leading to what we call the 3D software space. This conceptual framework is used to reason about evolution-in-the-large phenomena occurring in industry. The meta dimension, which constitutes the core of the MDA approach, is considered as fundamental. This paper makes the distinction between appliware and metaware and put the lights on meta-model and model co-evolution. Conversely to the MDA approach which makes the implicit assumption that meta-models are neat, stable and standardized, in this paper meta-models are considered as complex evolving software artefacts that are most often recovered from existing metaware tools rather than engineered from scratch. In fact, we identified the notion of meta-model and model co-evolution in the context of the evolution of a multimillion LOC component-based software developed by one of the largest software companies in Europe.},
  author = {Favre, Jean-Marie},
  year = {2003},
  booktitle = {International Workshop on Evolution of Large-scale Industrial Software Applications, ELISA 2003, Amsterdam},
  pages = {98--109}
}



@article{LucasMolinaT2009,
  series = {Quality of {UML} {Models}},
  title = {A systematic review of {UML} model consistency management},
  volume = {51},
  issn = {0950-5849},
  url = {http://www.sciencedirect.com/science/article/pii/S0950584909000433},
  doi = {10.1016/j.infsof.2009.04.009},
  abstract = {Information System (IS) development has been beset by consistency problems since its infancy. These problems are greater still in UML software development, and are principally caused by the existence of multiple views (models) for the same system, and may involve potentially contradictory system specifications. Since a considerable amount of work takes place within the scope of model consistency management, this paper presents a systematic literature review (SLR) which was carried out to discover the various current model consistency conceptions, proposals, problems and solutions provided. To do this, a total of 907 papers related to UML model consistency published in literature and extracted from the most relevant scientific sources (IEEE Computer Society, ACM Digital Library, Google Scholar, ScienceDirect, and the SCOPUS Database) were considered, of which 42 papers were eventually analyzed. This systematic literature review resulted in the identification of the current state-of-the-art with regard to UML model consistency management research along with open issues, trends and future research within this scope. A formal approach for the handling of inconsistency problems which fulfils the identified limitations is also briefly presented.},
  number = {12},
  urldate = {2018-06-21},
  journal = {Information and Software Technology},
  author = {Lucas, Francisco J. and Molina, Fernando and Toval, Ambrosio},
  month = dec,
  year = {2009},
  keywords = {UML, Model consistency, Systematic literature review},
  pages = {1631--1645},
  file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/698YAU5I/Lucas et al. - 2009 - A systematic review of UML model consistency manag.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/7RKYV5XX/S0950584909000433.html:text/html}
}



@inproceedings{HuzarKuzniarzRS2005,
  address = {Berlin, Heidelberg},
  series = {{UML}'04},
  title = {Consistency {Problems} in {UML}-based {Software} {Development}},
  isbn = {978-3-540-25081-4},
  url = {http://dx.doi.org/10.1007/978-3-540-31797-5_1},
  doi = {10.1007/978-3-540-31797-5_1},
  abstract = {This survey of the workshop series Consistency Problems in UML-based Software Development aims to help readers to find the guidelines of the papers. First, general considerations about consistency and related problems are discussed. Next, the approaches proposed in the workshop papers to handle the problems are categorized and summarized. The last section includes extended abstracts of the papers from the current workshop.},
  urldate = {2018-06-21},
  booktitle = {Proceedings of the 2004 {International} {Conference} on {UML} {Modeling} {Languages} and {Applications}},
  publisher = {Springer-Verlag},
  author = {Huzar, Zbigniew and Kuzniarz, Ludwik and Reggio, Gianna and Sourrouille, Jean Louis},
  year = {2005},
  pages = {1--12},
  annote = {using also terminology with inter/intra}
}



@inproceedings{Egyed2001,
  title = {Scalable consistency checking between diagrams - the {VIEWINTEGRA} approach},
  doi = {10.1109/ASE.2001.989835},
  abstract = {The Unified Modeling Language (UML) supports a wide range of diagrams for modeling software development concerns. UML diagrams are independent but connected; their meta-model describes them under a common roof. Despite the advances of UML, we found that the problem of ensuring consistency between UML diagrams has not been solved. We have developed an approach for automated consistency checking, called VIEWINTEGRA.. Our approach provides excellent support for active (preventive) and passive (detective) consistency checking. We make use of consistent transformation to translate diagrams into interpretations and we use consistency comparison to compare those interpretations to other diagrams. Our approach was applied to a number of applications where we found the separation of transformation and comparison to be highly beneficial in addressing consistency-checking scalability and usability issues. The paper introduces our UML-based transformation framework, discusses how it aids comparison, and demonstrates how it improves consistency checking.},
  booktitle = {Proceedings 16th {Annual} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE} 2001)},
  author = {Egyed, A.},
  month = nov,
  year = {2001},
  note = {ISSN: 1938-4300},
  keywords = {Unified modeling language, Unified Modeling Language, Programming, Usability, data integrity, Software systems, program diagnostics, specification languages, Scalability, Collaborative work, active consistency checking, automated consistency checking, consistency comparison, consistency-checking scalability, consistent transformation, passive consistency checking, Reverse engineering, software development concerns, UML diagrams, UML-based transformation framework, usability issues, VIEWINTEGRA},
  pages = {387--390},
  annote = {Coined "Heterogeneous Transformations"},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/WWNC5UKR/989835.html:text/html}
}



@inproceedings{Cook2000,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {The {UML} {Family}: {Profiles}, {Prefaces} and {Packages}},
  isbn = {978-3-540-40011-0},
  shorttitle = {The {UML} {Family}},
  doi = {10.1007/3-540-40011-7_18},
  abstract = {This paper overviews the status of UML (Unified Modeling Language) considered as a family of languages, and reviews critically various approaches to defining variants of UML within this family.},
  language = {en},
  booktitle = {{UML} 2000 — {The} {Unified} {Modeling} {Language}},
  publisher = {Springer},
  author = {Cook, Steve},
  editor = {Evans, Andy and Kent, Stuart and Selic, Bran},
  year = {2000},
  keywords = {Abstract Syntax, Concrete Syntax, Enterprise Distribute Object Computing, Language Family, Object Constraint Language},
  pages = {255--264},
  annote = {UML is a family of languages}
}




@inproceedings{Favre2004,
  title = {Towards a basic theory to model model driven engineering},
  abstract = {these concepts related? It is striking to see that, though MDE is supposed to be about precise modelling, MDE core concepts are usually described in natural language or at best, using sketchy UML diagrams. When precise descriptions are provided, it is only to describe a specific technology. But Model Driven Engineering is about supporting multiple Technological Spaces (TS). The concepts of model, metamodel, and transformation must be understood, not only in the context of the MDA TS, but also in the Grammarware TS, the Documentware TS, the Dataware TS, etc. This paper shows how the set theory and language theory could help in understanding essential MDE concepts. A first version of a very rudimentary theory for reasoning about MDE concepts is provided in the form of a megamodel. 1},
  booktitle = {In {Workshop} on {Software} {Model} {Engineering}, {WISME} 2004, joint event with {UML2004}},
  author = {Favre, Jean-marie},
  year = {2004},
  annote = {Set based formalisation of MDA},
  file = {Citeseer - Full Text PDF:/Users/past/Zotero/storage/DK3WZYJ7/Favre - 2004 - Towards a basic theory to model model driven engin.pdf:application/pdf;Citeseer - Snapshot:/Users/past/Zotero/storage/ANGUHQ39/summary.html:text/html}
}



@article{BashirLeeKCF2016,
  title = {{UML} models consistency management: {Guidelines} for software quality manager},
  volume = {36},
  issn = {0268-4012},
  shorttitle = {{UML} models consistency management},
  url = {https://www.sciencedirect.com/science/article/pii/S0268401216303425},
  doi = {10.1016/j.ijinfomgt.2016.05.024},
  abstract = {Unified Modeling Language (UML) has become the de-facto standard to design today’s large-size object-oriented systems. However, focusing on multiple UML diagrams is a main cause of breaching the consistency problem, which ultimately reduces the overall software model’s quality. Consistency management techniques are widely used to ensure the model consistency by correct model-to-model and model-to-code transformation. Consistency management becomes a promising area of research especially for model-driven architecture. In this paper, we extensively review UML consistency management techniques. The proposed techniques have been classified based on the parameters identified from the research literature. Moreover, we performed a qualitative comparison of consistency management techniques in order to identify current research trends, challenges and research gaps in this field of study. Based on the results, we concluded that researchers have not provided more attention on exploring inter-model and semantic consistency problems. Furthermore, state-of-the-art consistency management techniques mostly focus only on three UML diagrams (i.e., class, sequence and state chart) and the remaining UML diagrams have been overlooked. Consequently, due to this incomplete body of knowledge, researchers are unable to take full advantage of overlooked UML diagrams, which may be otherwise useful to handle the consistency management challenge in an efficient manner.},
  language = {en},
  number = {6, Part A},
  urldate = {2021-04-25},
  journal = {International Journal of Information Management},
  author = {Bashir, Raja Sehrab and Lee, Sai Peck and Khan, Saif Ur Rehman and Chang, Victor and Farid, Shahid},
  month = dec,
  year = {2016},
  keywords = {UML model consistency, UML model transformation},
  pages = {883--899},
  file = {Accepted Version:/Users/past/Zotero/storage/ZEPZWRKW/Bashir et al. - 2016 - UML models consistency management Guidelines for .pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/RMWCMDLB/S0268401216303425.html:text/html}
}


@inproceedings{Balzer1991,
  address = {Washington, DC, USA},
  series = {{ICSE} '91},
  title = {Tolerating inconsistency},
  isbn = {978-0-89791-391-1},
  urldate = {2021-04-25},
  booktitle = {Proceedings of the 13th international conference on {Software} engineering},
  publisher = {IEEE Computer Society Press},
  author = {Balzer, Robert},
  month = may,
  year = {1991},
  pages = {158--165}
}


@inproceedings{TorreLabicheG2014,
  address = {New York, NY, USA},
  series = {{EASE} '14},
  title = {{UML} {Consistency} {Rules}: {A} {Systematic} {Mapping} {Study}},
  isbn = {978-1-4503-2476-2},
  shorttitle = {{UML} {Consistency} {Rules}},
  url = {http://doi.acm.org/10.1145/2601248.2601292},
  doi = {10.1145/2601248.2601292},
  abstract = {Context: The Unified Modeling Language (UML), with its 14 different diagram types, is the de-facto standard modeling language for object-oriented modeling and documentation. Since the various UML diagrams describe different aspects of one, and only one, software under development, they are not independent but strongly depend on each other in many ways. In other words, the UML diagrams describing a software product must be consistent. Inconsistencies between these diagrams may be a source of faults in software systems. It is therefore paramount that these inconsistencies be detected, analyzed and hopefully fixed. Objective: The aim of this article is to deliver a comprehensive summary of UML consistency rules as they are described in the literature to date to obtain an extensive and detailed overview of the current research in this area. Method: We performed a Systematic Mapping Study by following well-known guidelines. We selected 95 primary studies from a search with seven search engines performed in December 2012. Results: Different results are worth mentioning. First it appears that researchers tend to discuss very similar consistency rules, over and over again. Most rules are horizontal (98.10\%) and syntactic (88.21\%). The most used diagrams are the class diagram (71.58\%), the sequence diagram (47.37\%) and the state machine diagram (42.11\%). Conclusion: The fact that many rules are duplicated in primary studies confirms the need for a well-accepted list of consistency rules. This paper is a first step in this direction. Results indicate that much more work is needed to develop consistency rules for all 14 UML diagrams, in all dimensions of consistency (e.g., semantic and syntactic on the one hand, horizontal, vertical and evolution on the other hand).},
  urldate = {2018-06-21},
  booktitle = {Proceedings of the 18th {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
  publisher = {ACM},
  author = {Torre, Damiano and Labiche, Yvan and Genero, Marcela},
  year = {2014},
  keywords = {systematic mapping study, UML consistency rules, unified modeling language (UML)},
  pages = {6:1--6:10},
  file = {ACM Full Text PDF:/Users/past/Zotero/storage/R8BCRCUG/Torre et al. - 2014 - UML Consistency Rules A Systematic Mapping Study.pdf:application/pdf}
}


@article{EngelsKuesterHG2001,
  title = {A methodology for specifying and analyzing consistency of object-oriented behavioral models},
  volume = {26},
  issn = {0163-5948},
  url = {https://doi.org/10.1145/503271.503235},
  doi = {10.1145/503271.503235},
  abstract = {Object-oriented modeling favors the modeling of object behavior from different viewpoints and the successive refinement of behavioral models in the development process. This gives rise to consistency problems of behavioral models. The absence of a formal semantics for UML models and the numerous possibilities of employing behavioral models within the development process lead to the rise of a number of different consistency notions. In this paper, we discuss the issue of consistency of behavioral models in the UML and present a general methodology how consistency problems can be dealt with. According to the methodology, those aspects of the models relevant to the consistency are mapped to a semantic domain in which precise consistency tests can be formulated. The choice of the semantic domain and the definition of consistency conditions can be used to construct different consistency notions. We show the applicability of our methodology by giving an example of a concrete consistency problem of concurrent object-oriented models.},
  number = {5},
  urldate = {2021-04-25},
  journal = {ACM SIGSOFT Software Engineering Notes},
  author = {Engels, Gregor and Küster, Jochem M. and Heckel, Reiko and Groenewegen, Luuk},
  month = sep,
  year = {2001},
  keywords = {behavioral consistency, CSP, object-oriented modeling, UML},
  pages = {186--195},
  annote = {syntactic vs. semantic consistency rules
and vertical vs. horizontal}
}


@article{LindvallSandahl1996,
  title = {Practical {Implications} of {Traceability}},
  volume = {26},
  copyright = {Copyright © 1996 John Wiley \& Sons, Ltd.},
  issn = {1097-024X},
  doi = {https://doi.org/10.1002/(SICI)1097-024X(199610)26:10<1161::AID-SPE58>3.0.CO;2-X},
  abstract = {Traceability defined as the ability to trace dependent items within a model and the ability to trace correspondent items in other models is advocated as a desirable property of a software development process. Potential benefits of good traceability are clearer documentation, more focussed development, increased ease of system understanding, and more precise impact analysis of proposed changes. An industry-scale project applying the analysis and design method Objectory has been examined and documented with a number of traceability examples generated from the perspective of a maintainer attempting to understand the system. Four representative examples and a categorization of traceability are presented in this study in order to provide a concrete empirical basis for the application of traceability to systems development.},
  language = {en},
  number = {10},
  urldate = {2021-04-26},
  journal = {Software: Practice and Experience},
  author = {Lindvall, Mikael and Sandahl, Kristian},
  year = {1996},
  keywords = {analysis of object models, case-study, object-oriented analysis and design, objectory, traceability},
  pages = {1161--1180},
  annote = {vertical vs. horizontal classification (between elements of the same model and and between multiple models)},
  file = {Snapshot:/Users/past/Zotero/storage/G7JREAC3/(SICI)1097-024X(199610)26101161AID-SPE583.0.html:text/html}
}



@article{RameshJarke2001,
  title = {Toward reference models for requirements traceability},
  volume = {27},
  issn = {1939-3520},
  doi = {10.1109/32.895989},
  abstract = {Requirements traceability is intended to ensure continued alignment between stakeholder requirements and various outputs of the system development process. To be useful, traces must be organized according to some modeling framework. Indeed, several such frameworks have been proposed, mostly based on theoretical considerations or analysis of other literature. This paper, in contrast, follows an empirical approach. Focus groups and interviews conducted in 26 major software development organizations demonstrate a wide range of traceability practices with distinct low-end and high-end users of traceability. From these observations, reference models comprising the most important kinds of traceability links for various development tasks have been synthesized. The resulting models have been validated in case studies and are incorporated in a number of traceability tools. A detailed case study on the use of the models is presented. Four kinds of traceability link types are identified and critical issues that must be resolved for implementing each type and potential solutions are discussed. Implications for the design of next-generation traceability methods and tools are discussed and illustrated.},
  number = {1},
  journal = {IEEE Transactions on Software Engineering},
  author = {Ramesh, B. and Jarke, M.},
  month = jan,
  year = {2001},
  note = {Conference Name: IEEE Transactions on Software Engineering},
  keywords = {Design engineering, Programming, Computer science, Engineering management, Costs, Best practices, Mathematical model, Prototypes, Standards organizations},
  pages = {58--93},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/R9928JGH/895989.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/5U7ACS7Q/Ramesh and Jarke - 2001 - Toward reference models for requirements traceabil.pdf:application/pdf}
}


@book{Ambler2002,
  address = {New York},
  edition = {1st edition},
  title = {Agile {Modeling}: {Effective} {Practices} for {eXtreme} {Programming} and the {Unified} {Process}},
  isbn = {978-0-471-20282-0},
  shorttitle = {Agile {Modeling}},
  abstract = {The first book to cover Agile Modeling, a new modeling technique created specifically for XP projects eXtreme Programming (XP) has created a buzz in the software development community-much like Design Patterns did several years ago. Although XP presents a methodology for faster software development, many developers find that XP does not allow for modeling time, which is critical to ensure that a project meets its proposed requirements. They have also found that standard modeling techniques that use the Unified Modeling Language (UML) often do not work with this methodology. In this innovative book, Software Development columnist Scott Ambler presents Agile Modeling (AM)-a technique that he created for modeling XP projects using pieces of the UML and Rational's Unified Process (RUP). Ambler clearly explains AM, and shows readers how to incorporate AM, UML, and RUP into their development projects with the help of numerous case studies integrated throughout the book.  AM was created by the author for modeling XP projects-an element lacking in the original XP design The XP community and its creator have embraced AM, which should give this book strong market acceptance  Companion Web site at www.agilemodeling.com features updates, links to XP and AM resources, and ongoing case studies about agile modeling.},
  language = {English},
  publisher = {Wiley},
  author = {Ambler, Scott},
  month = apr,
  year = {2002}
}


@book{Fowler2010DSL,
  title = {Domain-{Specific} {Languages}},
  isbn = {978-0-13-139280-9},
  abstract = {When carefully selected and used, Domain-Specific Languages (DSLs) may simplify complex code, promote effective communication with customers, improve productivity, and unclog development bottlenecks. In  Domain-Specific Languages , noted software development expert Martin Fowler first provides the information software professionals need to decide if and when to utilize DSLs. Then, where DSLs prove suitable, Fowler presents effective techniques for building them, and guides software engineers in choosing the right approaches for their applications.   This book’s techniques may be utilized with most modern object-oriented languages; the author provides numerous examples in Java and C\#, as well as selected examples in Ruby. Wherever possible, chapters are organized to be self-standing, and most reference topics are presented in a familiar patterns format.   Armed with this wide-ranging book, developers will have the knowledge they need to make important decisions about DSLs—and, where appropriate, gain the significant technical and business benefits they offer.   The topics covered include:  How DSLs compare to frameworks and libraries, and when those alternatives are sufficient Using parsers and parser generators, and parsing external DSLs Understanding, comparing, and choosing DSL language constructs  Determining whether to use code generation, and comparing code generation strategies Previewing new language workbench tools for creating DSLs},
  language = {en},
  publisher = {Pearson Education},
  author = {Fowler, Martin},
  month = sep,
  year = {2010},
  keywords = {Computers / Programming Languages / General}
}




@article{AtkinsonKuehne2003,
  title = {Model-driven development: a metamodeling foundation},
  volume = {20},
  issn = {1937-4194},
  shorttitle = {Model-driven development},
  doi = {10.1109/MS.2003.1231149},
  abstract = {Metamodeling is an essential foundation for MDD, but there's little consensus on the precise form it should take and role it should play. The authors analyze the underlying motivation for MDD and then derive a concrete set of requirements that a supporting infrastructure should satisfy. They discuss why the traditional "language definition" interpretation of metamodeling isn't a sufficient foundation and explain how it can be extended to unlock MDD's full potential.},
  number = {5},
  journal = {IEEE Software},
  author = {Atkinson, C. and Kuhne, T.},
  month = sep,
  year = {2003},
  note = {Conference Name: IEEE Software},
  keywords = {Computer science, Humans, Investments, Metamodeling, Object oriented modeling, Personnel, Production, Productivity, Program processors, Programming profession},
  pages = {36--41},
  file = {Atkinson and Kuhne - 2003 - Model-driven development a metamodeling foundatio.pdf:/Users/past/Zotero/storage/MKFH2XJ3/Atkinson and Kuhne - 2003 - Model-driven development a metamodeling foundatio.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/past/Zotero/storage/TIU59ZND/1231149.html:text/html}
}


@article{AtkinsonKuehne2007,
  title = {Reducing accidental complexity in domain models},
  volume = {7},
  issn = {1619-1374},
  url = {https://doi.org/10.1007/s10270-007-0061-0},
  doi = {10.1007/s10270-007-0061-0},
  abstract = {A fundamental principle in engineering, including software engineering, is to minimize the amount of accidental complexity which is introduced into engineering solutions due to mismatches between a problem and the technology used to represent the problem. As model-driven development moves to the center stage of software engineering, it is particularly important that this principle be applied to the technologies used to create and manipulate models, especially models that are intended to be free of solution decisions. At present, however, there is a significant mismatch between the “two level” modeling paradigm used to construct mainstream domain models and the conceptual information such models are required to represent—a mismatch that makes such models more complex than they need be. In this paper, we identify the precise nature of the mismatch, discuss a number of more or less satisfactory workarounds, and show how it can be avoided.},
  language = {en},
  number = {3},
  urldate = {2021-02-26},
  journal = {Software \& Systems Modeling},
  author = {Atkinson, Colin and Kühne, Thomas},
  month = jun,
  year = {2007},
  pages = {345--359},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/BEARYJUY/Atkinson and Kühne - 2008 - Reducing accidental complexity in domain models.pdf:application/pdf}
}



@inproceedings{GerberLawleyRSW2002,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Transformation: {The} {Missing} {Link} of {MDA}},
  isbn = {978-3-540-45832-6},
  shorttitle = {Transformation},
  doi = {10.1007/3-540-45832-8_9},
  abstract = {In this paper we explore the issue of transforming models to models, an essential part of the OMG’s Model Driven Architecture (MDA) vision. Drawing from the literature and our experiences implementing a number of transformations using different technologies, we explore the strengths and weaknesses of the different technologies and identify requirements for a transformation language for performing the kind of model-to-model transformations required to realise the MDA vision.},
  language = {en},
  booktitle = {Graph {Transformation}},
  publisher = {Springer},
  author = {Gerber, Anna and Lawley, Michael and Raymond, Kerry and Steel, Jim and Wood, Andrew},
  editor = {Corradini, Andrea and Ehrig, Hartmut and Kreowski, Hans -Jörg and Rozenberg, Grzegorz},
  year = {2002},
  keywords = {Abstract Syntax, Graph Transformation, Model Transformation, Target Model, Transformation Rule},
  pages = {90--105},
  file = {Full Text:/Users/past/Zotero/storage/VAC9ZFBE/Gerber et al. - 2002 - Transformation The Missing Link of MDA.pdf:application/pdf}
}



@article{AndriesEngelsHHKKPST1996,
  title = {Graph transformation for specification and programming},
  volume = {34},
  issn = {0167-6423},
  url = {https://www.sciencedirect.com/science/article/pii/S0167642398000239},
  doi = {10.1016/S0167-6423(98)00023-9},
  abstract = {The framework of graph transformation combines the potentials and advantages of both, graphs and rules, to a single computational paradigm. In this paper we present some recent developments in applying graph transformation as a rule-based framework for the specification and development of systems, languages, and tools. After reviewing the basic features of graph transformation, we discuss a selection of applications, including the evaluation of functional expressions, the specification of an interactive graphical tool, an example specification for abstract data types, and the definition of a visual database query language. The case studies indicate the need for suitable structuring principles which are independent of a particular graph transformation approach. To this end, we present the concept of a transformation unit, which allows systematic and structured specification and programming based on graph transformation.},
  language = {en},
  number = {1},
  urldate = {2021-05-03},
  journal = {Science of Computer Programming},
  author = {Andries, Marc and Engels, Gregor and Habel, Annegret and Hoffmann, Berthold and Kreowski, Hans-Jörg and Kuske, Sabine and Plump, Detlef and Schürr, Andy and Taentzer, Gabriele},
  month = apr,
  year = {1999},
  keywords = {Graph transformation, Rule-based specification, Structuring, Transformation units},
  pages = {1--54},
  annote = {The idea for GT as a specification framework for model transformations},
  file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/K4K7TV7E/Andries et al. - 1999 - Graph transformation for specification and program.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/QEZ4U9S2/S0167642398000239.html:text/html}
}


@article{CheckikNejatiS2012,
  title = {A relationship-based approach to model integration},
  volume = {8},
  issn = {1614-5054},
  url = {https://doi.org/10.1007/s11334-011-0155-2},
  doi = {10.1007/s11334-011-0155-2},
  abstract = {A key problem in model-based development is integrating a collection of models into a single, larger, specification as a way to construct a functional system, to develop a unified understanding, or to enable automated reasoning about properties of the resulting system. In this article, we suggest that the choice of a particular model integration operator depends on the inter-model relationships that hold between individual models. Based on this observation, we distinguish three key integration operators studied in the literature—merge, composition and weaving—and describe each operator along with the notion of relationship that underlies it. We then focus on the merge activity and provide a detailed look at the factors that one must consider in defining a merge operator, particularly the way in which the relationships should be captured during merge. We illustrate these factors using two merge operators that we have developed in our earlier work for combining models that originate from distributed teams.},
  language = {en},
  number = {1},
  urldate = {2020-10-26},
  journal = {Innovations in Systems and Software Engineering},
  author = {Chechik, Marsha and Nejati, Shiva and Sabetzadeh, Mehrdad},
  month = mar,
  year = {2012},
  pages = {3--18},
  annote = {Interesting paper! Identifies three principal integration operators:
Merge, compose (most relevant for behavioral model, e.g. sequential and parallel), weaving
Defines two mergen operators:
algebraic i.e. colimit and state machine},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/FC6IQDPH/Chechik et al. - 2012 - A relationship-based approach to model integration.pdf:application/pdf}
}



@article{MensVanGorp2006,
  series = {Proceedings of the {International} {Workshop} on {Graph} and {Model} {Transformation} ({GraMoT} 2005)},
  title = {A {Taxonomy} of {Model} {Transformation}},
  volume = {152},
  issn = {1571-0661},
  url = {http://www.sciencedirect.com/science/article/pii/S1571066106001435},
  doi = {10.1016/j.entcs.2005.10.021},
  abstract = {This article proposes a taxonomy of model transformation, based on the discussions of a working group on model transformation of the Dagstuhl seminar on Language Engineering for Model-Driven Software Development. This taxonomy can be used, among others, to help developers in deciding which model transformation language or tool is best suited to carry out a particular model transformation activity.},
  urldate = {2018-05-23},
  journal = {Electronic Notes in Theoretical Computer Science},
  author = {Mens, Tom and Van Gorp, Pieter},
  month = mar,
  year = {2006},
  keywords = {MDE, model transformation, MDD, comparison, taxonomy, \#SURVEY},
  pages = {125--142},
  annote = {{\textbackslash}cite\{MensVanGorp2006\}},
  file = {ScienceDirect Full Text PDF:/Users/past/Zotero/storage/XPQ4HG5A/Mens and Van Gorp - 2006 - A Taxonomy of Model Transformation.pdf:application/pdf;ScienceDirect Snapshot:/Users/past/Zotero/storage/CKP3WY6P/S1571066106001435.html:text/html}
}


@article{VarroBergmannHHRU2016,
  title = {Road to a reactive and incremental model transformation platform: three generations of the {VIATRA} framework},
  volume = {15},
  issn = {1619-1374},
  shorttitle = {Road to a reactive and incremental model transformation platform},
  url = {https://doi.org/10.1007/s10270-016-0530-4},
  doi = {10.1007/s10270-016-0530-4},
  abstract = {The current release of VIATRA provides open-source tool support for an event-driven, reactive model transformation engine built on top of highly scalable incremental graph queries for models with millions of elements and advanced features such as rule-based design space exploration complex event processing or model obfuscation. However, the history of the VIATRA model transformation framework dates back to over 16 years. Starting as an early academic research prototype as part of the M.Sc project of the the first author it first evolved into a Prolog-based engine followed by a family of open-source projects which by now matured into a component integrated into various industrial and open-source tools and deployed over multiple technologies. This invited paper briefly overviews the evolution of the VIATRA/IncQuery family by highlighting key features and illustrating main transformation concepts along an open case study influenced by an industrial project.},
  language = {en},
  number = {3},
  urldate = {2021-04-24},
  journal = {Software \& Systems Modeling},
  author = {Varr\'{o}, D\'{a}niel and Bergmann, G\'{a}bor and Heged\"{u}s, \'{A}bel and Horv\'{a}th, \'{A}kos and R\'{a}th, Istv\'{a}n and Ujhelyi, Zolt\'{a}n},
  month = jul,
  year = {2016},
  pages = {609--629},
  annote = {Comprehensive account of the VIATRA tool and its development. Also contains some interesting sentences about the role of GT for MT},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/PZRGRKZ8/Varró et al. - 2016 - Road to a reactive and incremental model transform.pdf:application/pdf}
}


@inproceedings{KolovosPaigeP2006EOL,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {The {Epsilon} {Object} {Language} ({EOL})},
  isbn = {978-3-540-35910-4},
  doi = {10.1007/11787044_11},
  abstract = {Model-Driven Development requires model management languages and tools for supporting model operations such as editing, consistency checking, and transformation. At the core of these model management techniques is a set of facilities for model navigation and modification. A subset of the Object Constraint Language can be used for some of these tasks, but it has limitations as a general-purpose language to be used in a variety of model management tasks. We present the metamodel independent Epsilon Object Language (EOL) which builds on OCL. EOL can be used both as a standalone generic model management language or as infrastructure on which task-specific languages can be built. We describe how it has been used to construct a selection of languages, such as model merging, comparison, and text generation languages.},
  language = {en},
  booktitle = {Model {Driven} {Architecture} – {Foundations} and {Applications}},
  publisher = {Springer},
  author = {Kolovos, Dimitrios S. and Paige, Richard F. and Polack, Fiona A. C.},
  editor = {Rensink, Arend and Warmer, Jos},
  year = {2006},
  keywords = {Concrete Syntax, Eclipse Modelling Framework, Model Management, Object Constraint Language, Object Management Group},
  pages = {128--142}
}


@inproceedings{JouaultAllilaireBKV2006,
  address = {New York, New York, USA},
  title = {{ATL}: a {QVT}-like transformation language},
  isbn = {1-59593-491-X},
  url = {http://portal.acm.org/citation.cfm?doid=1176617.1176691},
  doi = {10.1145/1176617.1176691},
  booktitle = {Companion to the 21st {ACM} {SIGPLAN} conference on {Object}-oriented programming systems, languages, and applications - {OOPSLA} '06},
  publisher = {ACM Press},
  author = {Jouault, Frédéric and Allilaire, Freddy and Bézivin, Jean and Kurtev, Ivan and Valduriez, Patrick},
  year = {2006},
  keywords = {ATL, model transformation, QVT},
  pages = {719}
}


@inproceedings{AkehurstKent2002,
  address = {Berlin, Heidelberg},
  series = {{UML} '02},
  title = {A {Relational} {Approach} to {Defining} {Transformations} in a {Metamodel}},
  isbn = {978-3-540-44254-7},
  abstract = {Metamodelling is becoming a standard way of defining languages such as the UML. A language definition distinguishes between concrete syntax, abstract syntax and semantics domain. It is possible to define all three using a metamodelling approach, but it is less clear how to define the transformations between them. This paper proposes an approach which uses metamodelling patterns that capture the essence of mathematical relations. It shows how these patterns can be used to define both the relationship between concrete syntax and abstract syntax, and between abstract syntax and semantics domain, for a fragment of UML. A goal of the approach is to provide a complete specification of a language from which intelligent tools can be generated. The extent to which the approach meets this goal is discussed in the paper.},
  urldate = {2021-05-03},
  booktitle = {Proceedings of the 5th {International} {Conference} on {The} {Unified} {Modeling} {Language}},
  publisher = {Springer-Verlag},
  author = {Akehurst, D. H. and Kent, Stuart},
  month = sep,
  year = {2002},
  pages = {243--258},
  file = {Akehurst and Kent - 2002 - A Relational Approach to Defining Transformations .pdf:/Users/past/Zotero/storage/DR6SLDVA/Akehurst and Kent - 2002 - A Relational Approach to Defining Transformations .pdf:application/pdf}
}



@inproceedings{HaasHernandezHPR2005,
  address = {New York, NY, USA},
  series = {{SIGMOD} '05},
  title = {Clio {Grows} {Up}: {From} {Research} {Prototype} to {Industrial} {Tool}},
  isbn = {978-1-59593-060-6},
  shorttitle = {Clio {Grows} {Up}},
  url = {http://doi.acm.org/10.1145/1066157.1066252},
  doi = {10.1145/1066157.1066252},
  abstract = {Clio, the IBM Research system for expressing declarative schema mappings, has progressed in the past few years from a research prototype into a technology that is behind some of IBM's mapping technology. Clio provides a declarative way of specifying schema mappings between either XML or relational schemas. Mappings are compiled into an abstract query graph representation that captures the transformation semantics of the mappings. The query graph can then be serialized into different query languages, depending on the kind of schemas and systems involved in the mapping. Clio currently produces XQuery, XSLT, SQL, and SQL/XML queries. In this paper, we revisit the architecture and algorithms behind Clio. We then discuss some implementation issues, optimizations needed for scalability, and general lessons learned in the road towards creating an industrial-strength tool.},
  urldate = {2019-11-20},
  booktitle = {Proceedings of the 2005 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
  publisher = {ACM},
  author = {Haas, Laura M. and Hern\'{a}ndez, Mauricio A. and Ho, Howard and Popa, Lucian and Roth, Mary},
  year = {2005},
  note = {event-place: Baltimore, Maryland},
  pages = {805--810},
  file = {ACM Full Text PDF:/Users/past/Zotero/storage/B52JNML7/Haas et al. - 2005 - Clio Grows Up From Research Prototype to Industri.pdf:application/pdf}
}


@inproceedings{Favre2006,
  address = {Dagstuhl, Germany},
  series = {Dagstuhl {Seminar} {Proceedings}},
  title = {Megamodelling and {Etymology}},
  url = {http://drops.dagstuhl.de/opus/volltexte/2006/427},
  urldate = {2020-03-04},
  booktitle = {Transformation {Techniques} in {Software} {Engineering}},
  publisher = {Internationales Begegnungs- und Forschungszentrum für Informatik (IBFI), Schloss Dagstuhl, Germany},
  author = {Favre, Jean-Marie},
  editor = {Cordy, James R. and Lämmel, Ralf and Winter, Andreas},
  year = {2006},
  note = {ISSN: 1862-4405
Issue: 05161},
  keywords = {MDE, Model Driven Architecture, Metamodel, Model, Taxonomy, MDD, MDA, Definition, Etymology},
  file = {Full Text PDF:/Users/past/Zotero/storage/JQJ65TRW/Favre - 2006 - Megamodelling and Etymology.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/NZQNMDB6/427.html:text/html}
}


@inproceedings{AllilaireBezivinBJ2006,
  address = {Nantes, France},
  title = {Global {Model} {Management} in {Eclipse} {GMT}/{AM3}},
  url = {https://hal.inria.fr/hal-01272277},
  abstract = {Within the GMT technology project (Generative Modeling Tools), an initial set of tools and artifacts for Global Model Management have recently been released under Eclipse. This paper presents the corresponding AM3 (ATLAS MegaModel Management) goals and contributions. AM3 is intended to provide support for modeling in the large, i.e. managing global resources in the field of MDE (Model-Driven Engineering). These global resources are usually heterogeneous and distributed. To access them without increasing the accidental complexity of MDE, we need to invent new ways to create, store, view, access, and modify the global entities that may be involved in developing a solution. To this intent, the notion of a megamodel (i.e. a model which elements are themselves models) is being used. This paper reports on the goals, the present state, and some future planned evolution of this Eclipse contribution.},
  urldate = {2021-04-22},
  booktitle = {Eclipse {Technology} {eXchange} {Workshop} ({eTX}) - a {ECOOP} 2006 {Satellite} {Event}},
  author = {Allilaire, Freddy and B\'{e}zivin, Jean and Bruneliere, Hugo and Jouault, Fr\'{e}d\'{e}ric},
  month = jul,
  year = {2006},
  file = {HAL PDF Full Text:/Users/past/Zotero/storage/689KZIXI/Allilaire et al. - 2006 - Global Model Management in Eclipse GMTAM3.pdf:application/pdf}
}


@inproceedings{DamWinikoff2010,
  title = {Supporting change propagation in {UML} models},
  doi = {10.1109/ICSM.2010.5609712},
  abstract = {A critical issue in software maintenance and evolution is change propagation: given a primary change that is made in order to meet a new or changed requirement, what additional, secondary, changes are needed? We have previously developed techniques for effectively supporting change propagation within design models of intelligent agent systems. In this paper, we propose how this approach is applied to support change propagation within UML design models. Our approach offers a number of advantages in terms of saving substantial time writing hard-coded rules, ensuring soundness and completeness, and at the same time capturing the cascading nature of change propagation. We will also present and discuss the results of an evaluation performed to assess the scalability of our approach.},
  booktitle = {2010 {IEEE} {International} {Conference} on {Software} {Maintenance}},
  author = {Dam, Hoa Khanh and Winikoff, Michael},
  month = sep,
  year = {2010},
  note = {ISSN: 1063-6773},
  keywords = {Context, Software, Unified modeling language, Unified Modeling Language, Maintenance engineering, software maintenance, Object oriented modeling, Motion pictures, Servers, change propagation, intelligent agent system, software evaluation, UML model},
  pages = {1--10},
  file = {Full Text:/Users/past/Zotero/storage/WFERLJA9/Dam and Winikoff - 2010 - Supporting change propagation in UML models.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/past/Zotero/storage/67NFXLIY/5609712.html:text/html}
}




@inproceedings{BarrigaHeldalIMR2020,
  address = {New York, NY, USA},
  series = {{MODELS} '20},
  title = {An extensible framework for customizable model repair},
  isbn = {978-1-4503-7019-6},
  url = {https://doi.org/10.1145/3365438.3410957},
  doi = {10.1145/3365438.3410957},
  abstract = {In model-driven software engineering, models are used in all phases of the development process. These models may get broken due to various editions during the modeling process. There are a number of existing tools that reduce the burden of manually dealing with correctness issues in models, however, most of these tools do not prioritize customization to follow user requirements nor allow the extension of their components to adapt to different model types. In this paper, we present an extensible model repair framework which enables users to deal with different types of models and to add their own repair preferences to customize the results. The framework uses customizable learning algorithms to automatically find the best sequence of actions for repairing a broken model according to the user preferences. As an example, we customize the framework by including as a preference a model distance metric, which allows the user to choose a more or less conservative repair. Then, we evaluate how this preference extension affects the results of the repair by comparing different distance metric calculations. Our experiment proves that extending the framework makes it more precise and produces models with better quality characteristics.},
  urldate = {2020-11-19},
  booktitle = {Proceedings of the 23rd {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
  publisher = {Association for Computing Machinery},
  author = {Barriga, Angela and Heldal, Rogardt and Iovino, Ludovico and Marthinsen, Magnus and Rutle, Adrian},
  month = oct,
  year = {2020},
  keywords = {model repair, reinforcement learning, model distance, quality evaluation},
  pages = {24--34}
}



@techreport{Meertens1998,
  title = {Designing {Constraint} {Maintainers} for {User} {Interaction}},
  abstract = {This paper is concerned with the question: How to design, given a constraint R, constraint maintainers of it that are "intuitively natural". 1 Basic definitions and notation},
    institution = {CWI, Amsterdam},
  author = {Meertens, Lambert},
  year = {1998}
}


@article{TakahashiMatsuokaMHK1998,
  title = {A {Constraint}-{Based} {Approach} for {Visualization} and {Animation}},
  volume = {3},
  issn = {1572-9354},
  url = {https://doi.org/10.1023/A:1009708715411},
  doi = {10.1023/A:1009708715411},
  abstract = {TRIP systems are tools for visualization and animation. They are based on a constraint-based model of bi-directional translation between abstract data and pictorial data. Using these systems, programmers can visualize abstract data, and animate various algorithms and processes, simply by providing a declarative mapping rule. This paper presents this model for visualization and animation, focusing on the use of constraints, and also presents the TRIP systems with examples of visualization and animation.},
  language = {en},
  number = {1},
  urldate = {2021-04-22},
  journal = {Constraints},
  author = {Takahashi, Shin and Matsuoka, Satoshi and Miyashita, Ken and Hosobe, Hiroshi and Kamada, Tomihisa},
  month = apr,
  year = {1998},
  pages = {61--86},
  file = {Springer Full Text PDF:/Users/past/Zotero/storage/LP7HR6GV/Takahashi et al. - 1998 - A Constraint-Based Approach for Visualization and .pdf:application/pdf}
}

@misc{Newards2006ORMVietnam,
  title={The Vietnam of Computer Science},
  year ={2006},
  author={Ted Neward},
  url ={http://blogs.tedneward.com/post/the-vietnam-of-computer-science/}
}


@article{Hegner2004,
  title = {An {Order}-{Based} {Theory} of {Updates} for {Closed} {Database} {Views}},
  volume = {40},
  issn = {1012-2443, 1573-7470},
  url = {https://link.springer.com/article/10.1023/A:1026158013113},
  doi = {10.1023/A:1026158013113},
  abstract = {The fundamental problem in the design of update strategies for views of database schemata is that of selecting how the view update is to be reflected back to the base schema. This work presents a solution to this problem, based upon the dual philosophies of closed update strategies and order-based database mappings. A closed update strategy is one in which the entire set of updates exhibit natural closure properties, including transitivity and reversibility. The order-based paradigm is a natural one; most database formalisms endow the database states with a natural order structure, under which update by insertion is an increasing operation, and update by deletion is decreasing. Upon augmenting the original constant-complement strategy of Bancilhon and Spyratos – which is an early version of a closed update strategy – with compatible order-based notions, the reflection to the base schema of any update to the view schema which is an insertion, a deletion, or a modification which is realizable as a sequence of insertions and deletions is shown to be unique and independent of the choice of complement. In addition to this uniqueness characterization, the paper also develops a theory which identifies conditions under which a natural, maximal, update strategy exists for a view. This theory is then applied to a ubiquitous example – single-relational schemata constrained by equality-generating dependencies. Within this framework it is shown that for a view defined as a projection of the main relation, the only possibility is that the complement defining the update process is also a projection, and that the reconstruction is based upon functional dependencies.},
  language = {en},
  number = {1-2},
  urldate = {2018-07-19},
  journal = {Annals of Mathematics and Artificial Intelligence},
  author = {Hegner, Stephen J.},
  month = jan,
  year = {2004},
  pages = {63--125},
  file = {Snapshot:/Users/past/Zotero/storage/PTYXLKGN/A1026158013113.html:text/html}
}


@inproceedings{DiskinCzarneckiA2009,
  title = {Model-versioning-in-the-large: {Algebraic} foundations and the tile notation},
  shorttitle = {Model-versioning-in-the-large},
  doi = {10.1109/CVSM.2009.5071715},
  abstract = {Model-versioning-in-the-large is concerned with complex scenarios involving multiple updates and multiple replicas of a model. The paper introduces tile systems as rephrasing of double categories in model versioning terms, and shows that the tile language enables a very general formalization of versioning concepts. The formalization makes the concepts amenable to algebraic analysis and provides a convenient notation for version system designers. It also allows one to formulate algebraic laws that a correct versioning system must or may want to satisfy.},
  booktitle = {2009 {ICSE} {Workshop} on {Comparison} and {Versioning} of {Software} {Models}},
  author = {Diskin, Zinovy and Czarnecki, Krzysztof and Antkiewicz, Michal},
  month = may,
  year = {2009},
  note = {ISSN: null},
  keywords = {Programming, Conferences, Concrete, Visualization, configuration management, algebraic analysis, algebraic foundations, algebraic specification, Equations, Machinery, model-versioning-in-the-large, multiple replicas, Power system modeling, tile notation, Tiles},
  pages = {7--12},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/829TS2YN/5071715.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/88T2QFHY/Diskin et al. - 2009 - Model-versioning-in-the-large Algebraic foundatio.pdf:application/pdf}
}

@inproceedings{Diskin2020,
  title = {General {Supervised} {Learning} as {Change} {Propagation} with {Delta} {Lenses}},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-45231-5_10},
  doi = {10.1007/978-3-030-45231-5_10},
  abstract = {Delta lenses are an established mathematical framework for modelling and designing bidirectional model transformations (Bx). Following the recent observations by Fong et al, the paper extends the...},
  language = {en},
  urldate = {2021-04-12},
  booktitle = {Foundations of {Software} {Science} and {Computation} {Structures}},
  publisher = {Springer, Cham},
  author = {Diskin, Zinovy},
  month = apr,
  year = {2020},
  pages = {177--197},
  file = {Full Text PDF:/Users/past/Zotero/storage/MLJBUCZ5/Diskin - 2020 - General Supervised Learning as Change Propagation .pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/I25477UL/10.html:text/html}
}


@inproceedings{DiskinGomezC2017,
  address = {Berlin, Heidelberg},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Traceability {Mappings} as a {Fundamental} {Instrument} in {Model} {Transformations}},
  isbn = {978-3-662-54494-5},
  doi = {10.1007/978-3-662-54494-5_14},
  abstract = {Technological importance of traceability mappings for model transformations is well-known, but they have often been considered as an auxiliary element generated during the transformation execution and providing accessory information. This paper argues that traceability mappings should instead be regarded as a core aspect of the transformation definition, and a key instrument in the transformation management.We will show how a transformation can be represented as the result of execution of a metamodel mapping, which acts as a special encoding of the transformation definition. Since mappings enjoy Boolean operations (as sets of links) and sequential composition (as sets of directed links), encoding transformations by mappings makes it possible to define these operations for transformations as well, which can be useful for model transformation reuse, compositional design, and chaining.},
  language = {en},
  booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
  publisher = {Springer},
  author = {Diskin, Zinovy and Gómez, Abel and Cabot, Jordi},
  editor = {Huisman, Marieke and Rubin, Julia},
  year = {2017},
  keywords = {Model Transformation, Sequential Composition, Disjoint Union, Traceability Link, Traceability Mapping},
  pages = {247--263},
  file = {Accepted Version:/Users/past/Zotero/storage/ATUC7K8L/Diskin et al. - 2017 - Traceability Mappings as a Fundamental Instrument .pdf:application/pdf}
}




@article{BezivinJouault2006,
  series = {Proceedings of the {International} {Workshop} on {Graph} and {Model} {Transformation} ({GraMoT} 2005)},
  title = {Using {ATL} for {Checking} {Models}},
  volume = {152},
  issn = {1571-0661},
  url = {http://www.sciencedirect.com/science/article/pii/S1571066106001393},
  doi = {10.1016/j.entcs.2006.01.015},
  abstract = {Working with models often requires the ability to assert the compliance of a given model to a given set of constraints. Some tools are able to check OCL invariants on UML models. However, there are very few tools able to do the same for any metamodel. This is quite penalizing for the DSL (Domain Specific Language) approach to model engineering. In this paper we propose a metamodel-independent solution to this problem that uses ATL (Atlas Transformation Language). This solution has been implemented as an Eclipse-based plugin.},
  language = {en},
  urldate = {2020-10-27},
  journal = {Electronic Notes in Theoretical Computer Science},
  author = {Bézivin, Jean and Jouault, Frédéric},
  month = mar,
  year = {2006},
  keywords = {ATL, OCL, checking models, Model Engineering},
  pages = {69--81},
  annote = {Higher order transformations},
  file = {ScienceDirect Snapshot:/Users/past/Zotero/storage/27NM2NT7/S1571066106001393.html:text/html;ScienceDirect Snapshot:/Users/past/Zotero/storage/T3Q2YBL2/S1571066106001393.html:text/html}
}

@inproceedings{LangerMayerhoferWK2014,
author = {Langer, Philip and Mayerhofer, Tanja and Wimmer, Manuel and Kappel, Gerti},
title = {On the Usage of UML: Initial Results of Analyzing Open UML Models},
booktitle = {Modellierung 2014},
year = {2014},
editor = {Fill, Hans-Georg AND Karagiannis, Dimitris AND Reimer, Ulrich} ,
pages = { 289-304 },
publisher = {Gesellschaft für Informatik e.V.},
address = {Bonn}
}



@incollection{BroyCengarleGR2009b,
  title = {Definition of the {System} {Model}},
  booktitle = {{UML} 2 {Semantics} and {Applications}},
  publisher = {John Wiley \& Sons, Ltd},
  author = {Broy, Manfred and Cengarle, María Victoria and Grönniger, Hans and Rumpe, Bernhard},
  editor = {Lano, Kevin},
  pages = {63--91},
  file = {Broy et al. - Definition of the System Model.pdf:/Users/past/Zotero/storage/A3M8P6JD/Broy et al. - Definition of the System Model.pdf:application/pdf},
  year={2009}
}



@incollection{BroyCengarleGR2009a,
  title = {Considerations and {Rationale} for a {UML} {System} {Model}},
  copyright = {Copyright © 2009 John Wiley \& Sons, Inc.},
  isbn = {978-0-470-52262-2},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470522622.ch3},
  abstract = {This chapter contains sections titled: Introduction General Approach to Semantics Structuring the Semantics of UML The Math Behind the System Model What Is the System Model? Usage Scenarios Concluding Remarks Acknowledgments References},
  language = {en},
  urldate = {2021-05-26},
  booktitle = {{UML} 2 {Semantics} and {Applications}},
  publisher = {John Wiley \& Sons, Ltd},
  author = {Broy, Manfred and Cengarle, María Victoria and Grönniger, Hans and Rumpe, Bernhard},
  year = {2009},
  doi = {10.1002/9780470522622.ch3},
  pages = {43--60},
  file = {Full Text:/Users/past/Zotero/storage/9E6FLHWX/Broy et al. - 2009 - Considerations and Rationale for a UML System Mode.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/LXNQT3KJ/9780470522622.html:text/html}
}


@article{Yeung2004,
  title = {Checking {Consistency} between {UML} {Class} and {State} {Models} {Based} on {CSP} and {B}},
  volume = {10},
  abstract = {The B Abstract Machine Notation (AMN) and the notation of Communicating Sequential Processes (CSP) have previously been applied to formalise the UML class and state diagrams, respectively. This paper discusses their integrated use in checking the consistency between the two kinds of UML diagrams based on some recent results of research in integrated formal methods. Through a small information system example, the paper illustrates a clear-cut separation of concerns in employing the two formal methods. Of particular interest is the treatment of recursive calls within a single class of objects.},
  number = {11},
  journal = {Journal of Universal Computer Science},
  author = {Yeung, W.L.},
  month = nov,
  year = {2004},
  pages = {1540--1559}
}



@article{BackusBauerGKMPRSVWWWN1960,
  title = {Report on the algorithmic language {ALGOL} 60},
  volume = {3},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/367236.367262},
  doi = {10.1145/367236.367262},
  number = {5},
  urldate = {2020-03-10},
  journal = {Communications of the ACM},
  author = {Backus, J. W. and Bauer, F. L. and Green, J. and Katz, C. and McCarthy, J. and Perlis, A. J. and Rutishauser, H. and Samelson, K. and Vauquois, B. and Wegstein, J. H. and van Wijngaarden, A. and Woodger, M. and Naur, Peter},
  month = may,
  year = {1960},
  pages = {299--314},
  annote = {First introduction of BNF grmmars},
  file = {Full Text PDF:/Users/past/Zotero/storage/ZX5JZQYA/Backus et al. - 1960 - Report on the algorithmic language ALGOL 60.pdf:application/pdf}
}


@misc{XLink,
  title = {{XML} {Linking} {Language} ({XLink}) {Version} 1.1},
  copyright = {Copyright (C) 2010 W3C (R)},
  url = {https://www.w3.org/TR/xlink11/},
  urldate = {2021-05-27},
  author = {DeRose, Steve and Maler, Eve and Orchard, David and Walsh, Norman},
  month = may,
  year = {2010},
  file = {XML Linking Language (XLink) Version 1.1:/Users/past/Zotero/storage/EHM2PV6W/xlink11.html:text/html}
}


@misc{XQuery,
  title = {{XQuery} 3.1: {An} {XML} {Query} {Language}},
  copyright = {Copyright (C) 2017 W3C (R)},
  url = {https://www.w3.org/TR/xquery-31/},
  urldate = {2021-05-27},
  author = {Robie, Jonathan and Dyck, Michael and Spiegel, Josh},
  month = mar,
  year = {2017},
  file = {XQuery 3.1\: An XML Query Language:/Users/past/Zotero/storage/AYBDT7KJ/xquery-31.html:text/html}
}


@misc{XPath,
  title = {{XML} {Path} {Language} ({XPath}) 3.1},
  url = {https://www.w3.org/TR/xpath-31/},
  urldate = {2021-05-27},
  author = {Robie, Jonathan and Dyck, Michael and Spiegel, Josh},
  month = mar,
  year = {2017},
  file = {XML Path Language (XPath) 3.1:/Users/past/Zotero/storage/JM2QMVUD/xpath-31.html:text/html}
}


@article{BohannonFosterPPS2008,
  title = {Boomerang: resourceful lenses for string data},
  volume = {43},
  issn = {0362-1340},
  shorttitle = {Boomerang},
  url = {https://doi.org/10.1145/1328897.1328487},
  doi = {10.1145/1328897.1328487},
  abstract = {A lens is a bidirectional program. When read from left toright, it denotes an ordinary function that maps inputs to outputs. When read from right to left, it denotes an ''update translator'' that takes an input together with an updated output and produces a new input that reflects the update. Many variants of this idea have been explored in the literature, but none deal fully with ordered data. If, for example, an update changes the order of a list in theoutput, the items in the output list and the chunks of the input that generated them can be misaligned, leading to lost or corrupted data. We attack this problem in the context of bidirectional transformations over strings, the primordial ordered data type. We first propose a collection of bidirectional string lens combinators, based on familiar operations on regular transducers (union, concatenation, Kleene-star) and with a type system based on regular expressions. We then design anew semantic space of dictionary lenses, enriching the lenses of Foster et al. (2007) with support for two additional combinators for marking ''reorderable chunks'' andtheir keys. To demonstrate the effectiveness of these primitives, we describe the design and implementation of Boomerang, a full-blown bidirectional programming language with dictionary lenses at its core. We have used Boomerang to build transformers for complex real-world data format sincluding the SwissProt genomic database. We formalize the essential property of resourcefulness-the correct use of keys to associate chunks in the input and output-by defining a refined semantic space of quasi-oblivious lenses. Several previously studied properties of lenses turn out to have compact characterizations in this space.},
  number = {1},
  urldate = {2021-05-27},
  journal = {ACM SIGPLAN Notices},
  author = {Bohannon, Aaron and Foster, J. Nathan and Pierce, Benjamin C. and Pilkiewicz, Alexandre and Schmitt, Alan},
  month = jan,
  year = {2008},
  keywords = {bidirectional languages, lenses, regular string transducers, regular types, view update problem},
  pages = {407--419},
  file = {Full Text:/Users/past/Zotero/storage/KYETBZ28/Bohannon et al. - 2008 - Boomerang resourceful lenses for string data.pdf:application/pdf}
}



@inproceedings{BohannonPierceV2006,
  address = {New York, NY, USA},
  series = {{PODS} '06},
  title = {Relational lenses: a language for updatable views},
  isbn = {978-1-59593-318-8},
  shorttitle = {Relational lenses},
  url = {https://doi.org/10.1145/1142351.1142399},
  doi = {10.1145/1142351.1142399},
  abstract = {We propose a novel approach to the classical view update problem. The view update problem arises from the fact that modifications to a database view may not correspond uniquely to modifications on the underlying database; we need a means of determining an "update policy" that guides how view updates are reflected in the database. Our approach is to define a bi-directional query language, in which every expression can be read bot(from left to right) as a view definition and (from right to left) as an update policy. The primitives of this language are based on standard relational operators. Its type system, which includes record-level predicates and functional dependencies, plays a crucial role in guaranteeing that update policies are well-behaved, in a precise sense, and that they are total—i.e., able to handle arbitrary changes to the view.},
  urldate = {2021-05-27},
  booktitle = {Proceedings of the twenty-fifth {ACM} {SIGMOD}-{SIGACT}-{SIGART} symposium on {Principles} of database systems},
  publisher = {Association for Computing Machinery},
  author = {Bohannon, Aaron and Pierce, Benjamin C. and Vaughan, Jeffrey A.},
  month = jun,
  year = {2006},
  keywords = {lenses, view update},
  pages = {338--347}
}


@article{FongSpivakT2017,
  title = {Backprop as {Functor}: {A} compositional perspective on supervised learning},
  shorttitle = {Backprop as {Functor}},
  url = {https://arxiv.org/abs/1711.10455},
  language = {en},
  urldate = {2018-07-19},
  author = {Fong, Brendan and Spivak, David I. and Tuyéras, Rémy},
  month = nov,
  year = {2017}
}



@inproceedings{AnanievaGreinerKKLGKKKLKSRRW2020,
  address = {New York, NY, USA},
  series = {{SPLC} '20},
  title = {A conceptual model for unifying variability in space and time},
  isbn = {978-1-4503-7569-6},
  url = {https://doi.org/10.1145/3382025.3414955},
  doi = {10.1145/3382025.3414955},
  abstract = {Software engineering faces the challenge of developing and maintaining systems that are highly variable in space (concurrent variations of the system at a single point in time) and time (sequential variations of the system due to its evolution). Recent research aims to address this need by managing variability in space and time simultaneously. However, such research often relies on nonuniform terminologies and a varying understanding of concepts, as it originates from different communities: software product-line engineering and software configuration management. These issues complicate the communication and comprehension of the concepts involved, impeding the development of techniques to unify variability in space and time. To tackle this problem, we performed an iterative, expert-driven analysis of existing tools to derive the first conceptual model that integrates and unifies terminologies and concepts of both dimensions of variability. In this paper, we present the unification process of concepts for variability in space and time, and the resulting conceptual model itself. We show that the conceptual model achieves high coverage and that its concepts are of appropriate granularity with respect to the tools for managing variability in space, time, or both that we considered. The conceptual model provides a well-defined, uniform terminology that empowers researchers and developers to compare their work, clarifies communication, and prevents redundant developments.},
  urldate = {2021-02-26},
  booktitle = {Proceedings of the 24th {ACM} {Conference} on {Systems} and {Software} {Product} {Line}: {Volume} {A} - {Volume} {A}},
  publisher = {Association for Computing Machinery},
  author = {Ananieva, Sofia and Greiner, Sandra and Kühn, Thomas and Krüger, Jacob and Linsbauer, Lukas and Grüner, Sten and Kehrer, Timo and Klare, Heiko and Koziolek, Anne and Lönn, Henrik and Krieter, Sebastian and Seidl, Christoph and Ramesh, S. and Reussner, Ralf and Westfechtel, Bernhard},
  month = oct,
  year = {2020},
  keywords = {product lines, revision management, variability, version control},
  pages = {1--12},
  file = {Full Text PDF:/Users/past/Zotero/storage/HKWYPZID/Ananieva et al. - 2020 - A conceptual model for unifying variability in spa.pdf:application/pdf}
}

@inproceedings{KehrerPietschKSV2015,
  title={An Adaptable Tool Environment for High-level Differencing of Textual Models},
  author={Kehrer, Timo and Pietsch, Christopher and Kelter, Udo and Str{\"u}ber, Daniel and Vaupel, Steffen},
  booktitle={OCL'15: International Workshop on OCL and Textual Modeling},
  pages={62--72},
  year={2015},
  organization={CEUR-WS.org}
}


@inproceedings{KehrerKelterOS2012,
  title = {Understanding model evolution through semantically lifting model differences with {SiLift}},
  doi = {10.1109/ICSM.2012.6405342},
  abstract = {In model-based software development, models are primary artifacts which iteratively evolve and which have many versions during their lifetime. A clear representation of the changes between different versions of a model is the key to understanding and successfully managing the evolution of a model-based system. However, model comparison tools currently available display model differences on a low level of abstraction, namely in terms of basic graph operations on the abstract syntax graph of a model. These low-level model differences are often hard or even impossible to understand for normal tool users who are not familiar with meta-models. In this paper we present SiLift, a generic tool environment which is able to semantically lift low-level differences of EMF-based models into representations of user-level edit operations.},
  booktitle = {2012 28th {IEEE} {International} {Conference} on {Software} {Maintenance} ({ICSM})},
  author = {Kehrer, Timo and Kelter, Udo and Ohrndorf, Manuel and Sollbach, Tim},
  month = sep,
  year = {2012},
  note = {ISSN: 1063-6773},
  keywords = {Adaptation models, Conferences, difference presentation, Engines, model comparison, model difference, semantic lifting, Semantics, Software, Software engineering, Unified modeling language},
  pages = {638--641},
  file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/BM3TU5TH/6405342.html:text/html}
}



@inproceedings{GleitzeKlareB2021,
  address = {Cham},
  series = {Lecture {Notes} in {Computer} {Science}},
  title = {Finding a {Universal} {Execution} {Strategy} for {Model} {Transformation} {Networks}},
  isbn = {978-3-030-71500-7},
  doi = {10.1007/978-3-030-71500-7_5},
  abstract = {When using multiple models to describe a (software) system, one can use a network of model transformations to keep the models consistent after changes. No strategy exists, however, to orchestrate the execution of transformations if the network has an arbitrary topology. In this paper, we analyse how often and in which order transformations need to be executed. We argue why linear execution bounds are too restrictive to be useful in practice and prove that there is no upper bound for the number of necessary executions. To avoid non-termination, we propose a conservative strategy that makes execution failures easier to understand. These insights help developers and users of transformation networks to understand under which circumstances their networks can terminate. Additionally, the proposed strategy helps them to find the cause when a network cannot restore consistency.},
  language = {en},
  booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
  publisher = {Springer International Publishing},
  author = {Gleitze, Joshua and Klare, Heiko and Burger, Erik},
  editor = {Guerra, Esther and Stoelinga, Mariëlle},
  year = {2021},
  keywords = {model consistency, model transformation networks},
  pages = {87--107}
}



@article{PetersenVakklankaK2015,
	title = {Guidelines for conducting systematic mapping studies in software engineering: {An} update},
	volume = {64},
	issn = {0950-5849},
	shorttitle = {Guidelines for conducting systematic mapping studies in software engineering},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584915000646},
	doi = {10.1016/j.infsof.2015.03.007},
	abstract = {Context
Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines.
Objective
To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly.
Method
We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment).
Results
In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given.
Conclusion
The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
	language = {en},
	urldate = {2021-06-02},
	journal = {Information and Software Technology},
	author = {Petersen, Kai and Vakkalanka, Sairam and Kuzniarz, Ludwik},
	month = aug,
	year = {2015},
	keywords = {Software engineering, Guidelines, Systematic mapping studies},
	pages = {1--18},
	annote = {Distinction between evaluation and validation studies}
}



@inproceedings{MacedoGuimaresC2013,
	title = {Model repair and transformation with {Echo}},
	doi = {10.1109/ASE.2013.6693135},
	abstract = {Models are paramount in model-driven engineering. In a software project many models may coexist, capturing different views of the system or different levels of abstraction. A key and arduous task in this development method is to keep all such models consistent, both with their meta-models (and the respective constraints) and among themselves. This paper describes Echo, a tool that aims at simplifying this task by automating inconsistency detection and repair using a solver based engine. Consistency between different models can be specified by bidirectional model transformations, and is guaranteed to be recovered by minimal updates on the inconsistent models. The tool is freely available as an Eclipse plugin, developed on top of the popular EMF framework, and supports constraints and transformations specified in the OMG standard languages OCL and QVT-R, respectively.},
	booktitle = {2013 28th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE})},
	author = {Macedo, Nuno and Guimarães, Tiago and Cunha, Alcino},
	month = nov,
	year = {2013},
	note = {ISSN: null},
	keywords = {Unified modeling language, Maintenance engineering, model-driven engineering, software maintenance, Computational modeling, Object oriented modeling, Semantics, QVT-R, OCL, Echo, bidirectional model transformations, development method, Eclipse plugin, EMF framework, inconsistency detection automation, meta-models, Metals, model repair, OMG standard languages, software project, solver based engine, Standards},
	pages = {694--697},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/TCFTMPHH/6693135.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/9VAJYTL2/Macedo et al. - 2013 - Model repair and transformation with Echo.pdf:application/pdf}
}


@phdthesis{PinnaPuissant2012,
	type = {{PhD} {Thesis}},
	title = {Resolving {Inconsistencies} in {Model}-{Driven} {Engineering} using {Automated} {Planning}},
	school = {University of Mons},
	author = {Pinna Puissant, Jorge},
	month = sep,
	year = {2012}
}



@inproceedings{Kolovos2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Establishing {Correspondences} between {Models} with the {Epsilon} {Comparison} {Language}},
	isbn = {978-3-642-02674-4},
	doi = {10.1007/978-3-642-02674-4_11},
	abstract = {Model comparison is an essential prerequisite for a number of model management tasks in Model Driven Engineering, such as model differencing and versioning, model and aspect merging and model transformation testing. In this paper we present the Epsilon Comparison Language (ECL), a hybrid rule-based language, built atop the Epsilon platform, which enables developers to implement comparison algorithms at a high level of abstraction and execute them in order to identify matches between elements belonging to models of diverse metamodels and modelling technologies.},
	language = {en},
	booktitle = {Model {Driven} {Architecture} - {Foundations} and {Applications}},
	publisher = {Springer},
	author = {Kolovos, Dimitrios S.},
	editor = {Paige, Richard F. and Hartman, Alan and Rensink, Arend},
	year = {2009},
	pages = {146--157}
}

@inproceedings{Levenshtein1966,
	title = {Binary codes capable of correcting deletions, insertions, and reversals},
	volume = {10},
	booktitle = {Soviet physics doklady},
	publisher = {Soviet Union},
	author = {Levenshtein, Vladimir I.},
	year = {1966},
	note = {Issue: 8},
	pages = {707--710}
}


@inproceedings{AmelunxenKoenigsRS2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{MOFLON}: {A} {Standard}-{Compliant} {Metamodeling} {Framework} with {Graph} {Transformations}},
	isbn = {978-3-540-35910-4},
	shorttitle = {{MOFLON}},
	doi = {10.1007/11787044_27},
	abstract = {The crucial point in Model Driven Architecture (MDA) is that software and system development are based on abstract models that are successively transformed into more specific models, ideally resulting in the desired system. To this end, developers must be enabled to model different aspects like structure, behavior, consistency constraints of the system. This results in a variety of related models, which in turn need tool support on the metalevel. However, there is a lack of tools offering uniform support for metamodel definition, analysis, transformation, and integration. In this paper we present the metamodeling framework MOFLON that addresses these issues by bringing together the latest OMG standards with graph transformations and their formal semantics. MOFLON provides a combination of visual and textual notations and offers powerful modularization concepts. Using MOFLON, developers can generate code for specific tools needed to perform the desired modeling tasks.},
	language = {en},
	booktitle = {Model {Driven} {Architecture} – {Foundations} and {Applications}},
	publisher = {Springer},
	author = {Amelunxen, C. and Königs, A. and Rötschke, T. and Schürr, A.},
	editor = {Rensink, Arend and Warmer, Jos},
	year = {2006},
	keywords = {Graph Transformation, Java Code, Model Transformation, Object Constraint Language, Object Management Group},
	pages = {361--375},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/6WQUHZWZ/Amelunxen et al. - 2006 - MOFLON A Standard-Compliant Metamodeling Framewor.pdf:application/pdf}
}


@article{Knight1989,
	title = {Unification: a multidisciplinary survey},
	volume = {21},
	issn = {0360-0300},
	shorttitle = {Unification},
	url = {https://doi.org/10.1145/62029.62030},
	doi = {10.1145/62029.62030},
	abstract = {The unification problem and several variants are presented. Various algorithms and data structures are discussed. Research on unification arising in several areas of computer science is surveyed; these areas include theorem proving, logic programming, and natural language processing. Sections of the paper include examples that highlight particular uses of unification and the special problems encountered. Other topics covered are resolution, higher order logic, the occur check, infinite terms, feature structures, equational theories, inheritance, parallel algorithms, generalization, lattices, and other applications of unification. The paper is intended for readers with a general computer science background—no specific knowledge of any of the above topics is assumed.},
	number = {1},
	urldate = {2021-06-02},
	journal = {ACM Computing Surveys},
	author = {Knight, Kevin},
	month = mar,
	year = {1989},
	pages = {93--124},
	file = {Full Text PDF:/Users/past/Zotero/storage/G5FTSK7R/Knight - 1989 - Unification a multidisciplinary survey.pdf:application/pdf}
}


@book{Fellbaum1998,
	title = {{WordNet}: {An} {Electronic} {Lexical} {Database}},
	isbn = {978-0-262-06197-1},
	shorttitle = {{WordNet}},
	abstract = {WordNet is an on-line lexical reference system whose design isinspired by current psycholinguistic theories of human lexical memory;version 1.6 is the most up-to-date version of the system.WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets.The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains. Contributors Reem Al-Halimi, Robert C. Berwick, J. F. M. Burg, Martin Chodorow, Christiane Fellbaum, Joachim Grabowski, Sanda Harabagiu, Marti A. Hearst, Graeme Hirst, Douglas A. Jones, Rick Kazman, Karen T. Kohl, Shari Landes, Claudia Leacock, George A. Miller, Katherine J. Miller, Dan Moldovan, Naoyuki Nomura, Uta Priss, Philip Resnik, David St-Onge, Randee Tengi, Reind P. van de Riet, Ellen Voorhees},
	language = {en},
	publisher = {MIT Press},
	author = {Fellbaum, Christiane},
	year = {1998},
	keywords = {Language Arts \& Disciplines / Linguistics / General}
}


@book{WohlinRunesonHORW2012,
	address = {Berlin Heidelberg},
	title = {Experimentation in {Software} {Engineering}},
	isbn = {978-3-642-29043-5},
	url = {https://www.springer.com/gp/book/9783642290435},
	abstract = {Like other sciences and engineering disciplines, software engineering requires a cycle of model building, experimentation, and learning. Experiments are valuable tools for all software engineers who are involved in evaluating and choosing between different methods, techniques, languages and tools. The purpose of Experimentation in Software Engineering is to introduce students, teachers, researchers, and practitioners to empirical studies in software engineering, using controlled experiments. The introduction to experimentation is provided through a process perspective, and the focus is on the steps that we have to go through to perform an experiment. The book is divided into three parts. The first part provides a background of theories and methods used in experimentation. Part II then devotes one chapter to each of the five experiment steps: scoping, planning, execution, analysis, and result presentation. Part III completes the presentation with two examples. Assignments and statistical material are provided in appendixes. Overall the book provides indispensable information regarding empirical studies in particular for experiments, but also for case studies, systematic literature reviews, and surveys. It is a revision of the authors’ book, which was published in 2000. In addition, substantial new material, e.g. concerning systematic literature reviews and case study research, is introduced. The book is self-contained and it is suitable as a course book in undergraduate or graduate studies where the need for empirical studies in software engineering is stressed. Exercises and assignments are included to combine the more theoretical material with practical aspects. Researchers will also benefit from the book, learning more about how to conduct empirical studies, and likewise practitioners may use it as a “cookbook” when evaluating new methods or techniques before implementing them in their organization.},
	language = {en},
	urldate = {2021-06-21},
	publisher = {Springer-Verlag},
	author = {Wohlin, Claes and Runeson, Per and Höst, Martin and Ohlsson, Magnus C. and Regnell, Björn and Wesslén, Anders},
	year = {2012},
	doi = {10.1007/978-3-642-29044-2},
}


@book{Malhotra2016,
	title = {Empirical {Research} in {Software} {Engineering}: {Concepts}, {Analysis}, and {Applications}},
	isbn = {978-1-4987-1973-5},
	shorttitle = {Empirical {Research} in {Software} {Engineering}},
	abstract = {Empirical research has now become an essential component of software engineering yet software practitioners and researchers often lack an understanding of how the empirical procedures and practices are applied in the field. Empirical Research in Software Engineering: Concepts, Analysis, and Applications shows how to implement empirical research pro},
	language = {en},
	publisher = {CRC Press},
	author = {Malhotra, Ruchika},
	month = mar,
	year = {2016},
}


@article{Gogouen1991,
	title = {A categorical manifesto},
	volume = {1},
	issn = {1469-8072, 0960-1295},
	doi = {10.1017/S0960129500000050},
	abstract = {This paper tries to explain why and how category theory is useful in computing science, by giving guidelines for applying seven basic categorical concepts: category, functor, natural transformation, limit, adjoint, colimit and comma category. Some examples, intuition, and references are given for each concept, but completeness is not attempted. Some additional categorical concepts and some suggestions for further research are also mentioned. The paper concludes with some philosophical discussion.},
	language = {en},
	number = {1},
	journal = {Mathematical Structures in Computer Science},
	author = {Goguen, Joseph A.},
	month = mar,
	year = {1991},
	note = {Publisher: Cambridge University Press},
	pages = {49--67},
}



@inproceedings{FrancisGreenGLLMPRST2018,
	address = {New York, NY, USA},
	series = {{SIGMOD} '18},
	title = {Cypher: {An} {Evolving} {Query} {Language} for {Property} {Graphs}},
	isbn = {978-1-4503-4703-7},
	shorttitle = {Cypher},
	url = {https://doi.org/10.1145/3183713.3190657},
	doi = {10.1145/3183713.3190657},
	abstract = {The Cypher property graph query language is an evolving language, originally designed and implemented as part of the Neo4j graph database, and it is currently used by several commercial database products and researchers. We describe Cypher 9, which is the first version of the language governed by the openCypher Implementers Group. We first introduce the language by example, and describe its uses in industry. We then provide a formal semantic definition of the core read-query features of Cypher, including its variant of the property graph data model, and its ASCII Art graph pattern matching mechanism for expressing subgraphs of interest to an application. We compare the features of Cypher to other property graph query languages, and describe extensions, at an advanced stage of development, which will form part of Cypher 10, turning the language into a compositional language which supports graph projections and multiple named graphs.},
	urldate = {2021-07-05},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Francis, Nadime and Green, Alastair and Guagliardo, Paolo and Libkin, Leonid and Lindaaker, Tobias and Marsault, Victor and Plantikow, Stefan and Rydberg, Mats and Selmer, Petra and Taylor, Andrés},
	month = may,
	year = {2018},
	keywords = {cypher, formal semantics, formal specification, graph databases, property graphs, query language},
	pages = {1433--1445},
	file = {Full Text:/Users/past/Zotero/storage/LTL9DD7E/Francis et al. - 2018 - Cypher An Evolving Query Language for Property Gr.pdf:application/pdf},
}



@article{SchultzWisnesky2017,
	title = {Algebraic data integration*},
	volume = {27},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/abs/algebraic-data-integration/AC36B1C39D4C76A18CB54F75B0D26796},
	doi = {10.1017/S0956796817000168},
	abstract = {In this paper, we develop an algebraic approach to data integration by combining techniques from functional programming, category theory, and database theory. In our formalism, database schemas and instances are algebraic (multi-sorted equational) theories of a certain form. Schemas denote categories, and instances denote their initial (term) algebras. The instances on a schema S form a category, S–Inst, and a morphism of schemas F : S → T induces three adjoint data migration functors: Σ
                  F
                : S–Inst → T–Inst, defined by substitution along F, which has a right adjoint Δ
                  F
                : T–Inst → S–Inst, which in turn has a right adjoint Π
                  F
                : S–Inst → T–Inst. We present a query language based on for/where/return syntax where each query denotes a sequence of data migration functors; a pushout-based design pattern for performing data integration using our formalism; and describe the implementation of our formalism in a tool we call AQL (Algebraic Query Language).},
	language = {en},
	urldate = {2021-07-10},
	journal = {Journal of Functional Programming},
	author = {Schultz, Patrick and Wisnesky, Ryan},
	year = {2017}
}


@inproceedings{HermannEhrigE2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Transformation of {Type} {Graphs} with {Inheritance} for {Ensuring} {Security} in {E}-{Government} {Networks}},
	isbn = {978-3-642-00593-0},
	abstract = {E-government services usually process large amounts of confidential data. Therefore, security requirements for the communication between components have to be adhered in a strict way. Hence, it is of main interest that developers can analyze their modularized models of actual systems and that they can detect critical patterns. For this purpose, we present a general and formal framework for critical pattern detection and user-driven correction as well as possibilities for automatic analysis and verification at meta-model level. The technique is based on the formal theory of graph transformation, which we extend to transformations of type graphs with inheritance within a type graph hierarchy. We apply the framework to specify relevant security requirements.The extended theory is shown to fulfil the conditions of a weak adhesive HLR category allowing us to transfer analysis techniques and results shown for this abstract framework of graph transformation. In particular, we discuss how confluence analysis and parallelization can be used to enable parallel critical pattern detection and elimination.},
	language = {en},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hermann, Frank and Ehrig, Hartmut and Ermel, Claudia},
	editor = {Chechik, Marsha and Wirsing, Martin},
	year = {2009},
	keywords = {Graph Transformation, Type Graph, Critical Pair, Proxy Node, Security Requirement},
	pages = {325--339}
}


@article{LoeweKoenigSS2015,
	series = {Selected {Papers} from the {Brazilian} {Symposiums} on {Formal} {Methods} ({SBMF} 2012 and 2013)},
	title = {Algebraic graph transformations with inheritance and abstraction},
	volume = {107-108},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642315000295},
	doi = {10.1016/j.scico.2015.02.004},
	abstract = {In this paper, we propose a new approach to inheritance and abstraction in the context of algebraic graph transformation by providing a suitable categorial framework which reflects the semantics of class-based inheritance in software engineering. Inheritance is modelled by a type graph T that comes equipped with a partial order. Typed graphs are arrows with codomain T which preserve graph structures up to inheritance. Morphisms between typed graphs are “down typing” graph morphisms: An object of class t can be mapped to an object of a subclass of t. Abstract classes are modelled by a subset of vertices of the type graph. We prove that this structure is an adhesive HLR category, i.e. pushouts along extremal monomorphisms are “well-behaved”. This infers validity of classical results such as the Local Church–Rosser Theorem, the Parallelism Theorem, and the Concurrency Theorem.},
	language = {en},
	urldate = {2020-11-26},
	journal = {Science of Computer Programming},
	author = {Löwe, Michael and König, Harald and Schulz, Christoph and Schultchen, Marius},
	month = sep,
	year = {2015},
	keywords = {Graph transformation, Abstraction, Adhesive HLR category, Inheritance},
	pages = {2--18}
}


@inproceedings{GronnigerRingerR2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {System {Model}-{Based} {Definition} of {Modeling} {Language} {Semantics}},
	isbn = {978-3-642-02138-1},
	doi = {10.1007/978-3-642-02138-1_10},
	abstract = {In this paper, we present an approach to define the semantics for object-oriented modeling languages. One important property of this semantics is to support underspecified and incomplete models. To this end, semantics is given as predicates over elements of the semantic domain. This domain is called the system model which is a general declarative characterization of object systems. The system model is very detailed since it captures various relevant structural, behavioral, and interaction aspects. This allows us to re-use the system model as a domain for various kinds of object-oriented modeling languages. As a major consequence, the integration of language semantics is straight-forward. The whole approach is supported by tools that do not constrain the semantics definition’s expressiveness and flexibility while making it machine-checkable.},
	language = {en},
	booktitle = {Formal {Techniques} for {Distributed} {Systems}},
	publisher = {Springer},
	author = {Grönniger, Hans and Ringert, Jan Oliver and Rumpe, Bernhard},
	editor = {Lee, David and Lopes, Antónia and Poetzsch-Heffter, Arnd},
	year = {2009},
	keywords = {Abstract Syntax, Class Diagram, Formal Semantic, Modeling Language, Variation Point},
	pages = {152--166}
}


@article{RensinkKleppe2008,
	title = {On a {Graph}-{Based} {Semantics} for {UML} {Class} and {Object} {Diagrams}},
	volume = {10},
	copyright = {Copyright (c)},
	issn = {1863-2122},
	url = {https://journal.ub.tu-berlin.de/eceasst/article/view/153},
	doi = {10.14279/tuj.eceasst.10.153},
	abstract = {In this paper we propose a formal extension of type graphs with notions that are commonplace in the UML and have long proven their worth in that context: namely, inheritance, multiplicity, containment and the like. We believe the absence of a comprehensive and commonly agreed upon formalisation of these notions to be an important and, unfortunately, often ignored omission. Since our eventual aim (shared by many researchers) is   to give unambiguous, formal semantics to the UML using the theory of graphs and graph transformation, in this paper we propose a set of definitions to repair this omission. With respect to previous work in this direction, our aim is to arrive at more comprehensive and at the same time simpler definitions.},
	language = {en},
	number = {0},
	urldate = {2018-10-03},
	journal = {Electronic Communications of the EASST},
	author = {Rensink, Arend and Kleppe, Anneke},
	month = jul,
	year = {2008}
}


@article{JohnsonRosebrughW2002,
	title = {Entity-relationship-attribute designs and sketches},
	volume = {10},
	issn = {1201-561X},
	url = {https://researchers.mq.edu.au/en/publications/entity-relationship-attribute-designs-and-sketches},
	language = {English},
	number = {1},
	urldate = {2019-09-27},
	journal = {Theory and Applications of Categories},
	author = {Johnson, Michael and Rosebrugh, Robert and Wood, R. J.},
	year = {2002},
	pages = {94--112}
}


@inproceedings{JohnsonRpsebrugh2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Implementing a {Categorical} {Information} {System}},
	isbn = {978-3-540-79980-1},
	doi = {10.1007/978-3-540-79980-1_18},
	abstract = {The authors have proposed using category-theoretic sketches to enhance database design and integration methodologies. The algebraic context is called the Sketch Data Model (SkDM) and mathematically describes databases, views and their updates, and other database concepts. The system described here is a freely available graphical Java environment with a module that compiles a design incorporating algebraically specified constraints into database schemas that interface directly with modern database management systems. It therefore supports, inter alia, rapid prototyping.},
	language = {en},
	booktitle = {Algebraic {Methodology} and {Software} {Technology}},
	publisher = {Springer},
	author = {Johnson, Michael and Rosebrugh, Robert},
	editor = {Meseguer, José and Roşu, Grigore},
	year = {2008},
	keywords = {category theory, graphical database design, Semantic data model},
	pages = {232--237},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/WCUSGPUV/Johnson and Rosebrugh - 2008 - Implementing a Categorical Information System.pdf:application/pdf},
}


@inproceedings{BoronatMeseguer2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Business} {Information} {Processing}},
	title = {Algebraic {Semantics} of {OCL}-{Constrained} {Metamodel} {Specifications}},
	isbn = {978-3-642-02571-6},
	doi = {10.1007/978-3-642-02571-6_7},
	abstract = {In the definition of domain-specific modeling languages a MOF metamodel is used to define the main types of its abstract syntax, and OCL invariants are used to add static semantic constraints. The semantics of a metamodel definition can be given as a model type whose values are well-formed models. A model is said to conform to its metamodel when it is a value of the corresponding model type. However, when OCL invariants are involved, the concept of model conformance has not yet been formally defined in the MOF standard. In this work, the concept of OCL-constrained metamodel conformance is formally defined and used for defining style-preserving software architecture configurations. This concept is supported in MOMENT2, an algebraic framework for MOF metamodeling, where OCL constraints can be used for both static and dynamic analysis.},
	language = {en},
	booktitle = {Objects, {Components}, {Models} and {Patterns}},
	publisher = {Springer},
	author = {Boronat, Artur and Meseguer, José},
	editor = {Oriol, Manuel and Meyer, Bertrand},
	year = {2009},
	keywords = {Membership equational logic, MOF metamodel, OCL invariants, static and dynamic analysis of models},
	pages = {96--115},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/QS7IE88W/Boronat and Meseguer - 2009 - Algebraic Semantics of OCL-Constrained Metamodel S.pdf:application/pdf},
}



@book{Ferreiros2007,
	edition = {2},
	title = {Labyrinth of {Thought}: {A} {History} of {Set} {Theory} and {Its} {Role} in {Modern} {Mathematics}},
	isbn = {978-3-7643-8349-7},
	shorttitle = {Labyrinth of {Thought}},
	url = {https://www.springer.com/gp/book/9783764383497},
	abstract = {Labyrinth of Thought discusses the emergence and development of set theory and the set-theoretic approach to mathematics during the period 1850-1940. Rather than focusing on the pivotal figure of Georg Cantor, it analyzes his work and the emergence of transfinite set theory within the broader context of the rise of modern mathematics. The text has a tripartite structure. Part 1, The Emergence of Sets within Mathematics, surveys the initial motivations for a mathematical notion of a set within several branches of the discipline (geometry, algebra, algebraic number theory, real and complex analysis), emphasizing the role played by Riemann in fostering acceptance of the set-theoretic approach. In Part 2, Entering the Labyrinth, attention turns to the earliest theories of sets, their evolution, and their reception by the mathematical community; prominent are the epoch-making contributions of Cantor and Dedekind, and the complex interactions between them. Part 3, In Search of an Axiom System, studies the four-decade period from the discovery of set-theoretic paradoxes to Gödel’s independence results, an era during which set theory gradually became assimilated into mainstream mathematics; particular attention is given to the interactions between axiomatic set theory and modern systems of formal logic, especially the interplay between set theory and type theory. A new Epilogue for this second edition offers further reflections on the foundations of set theory, including the "dichotomy conception" and the well-known iterative conception. "The author paints on a grand scale. He sees clearly, and he sees whole. The result is a spacious canvas full of intriguing scenes and portraits from the history of set theory, seamlessly juxtaposed to form a fascinating and accurate picture of a vast area of modern mathematics. It is a must-have book for anyone who wishes to gain a balanced picture of this history. It is written in clear and elegant language for the learner, while experts in the area will enjoy seeing this beautiful presentation of what they already know, perhaps arguing about some of the author’s conclusions and choices of material." (Roger Cooke, University of Vermont)},
	language = {en},
	urldate = {2021-07-22},
	publisher = {Birkhäuser Basel},
	author = {Ferreir\'{o}s, Jos\'{e}},
	year = {2007},
	doi = {10.1007/978-3-7643-8350-3}
}





@book{FongSpivak2019,
	edition = {1 edition},
	title = {An {Invitation} to {Applied} {Category} {Theory}: {Seven} {Sketches} in {Compositionality}},
	isbn = {978-1-108-71182-1},
	shorttitle = {An {Invitation} to {Applied} {Category} {Theory}},
	abstract = {Category theory is unmatched in its ability to organize and layer abstractions and to find commonalities between structures of all sorts. No longer the exclusive preserve of pure mathematicians, it is now proving itself to be a powerful tool in science, informatics, and industry. By facilitating communication between communities and building rigorous bridges between disparate worlds, applied category theory has the potential to be a major organizing force. This book offers a self-contained tour of applied category theory. Each chapter follows a single thread motivated by a real-world application and discussed with category-theoretic tools. We see data migration as an adjoint functor, electrical circuits in terms of monoidal categories and operads, and collaborative design via enriched profunctors. All the relevant category theory, from simple to sophisticated, is introduced in an accessible way with many examples and exercises, making this an ideal guide even for those without experience of university-level mathematics.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Fong, Brendan and Spivak, David I.},
	month = aug,
	year = {2019},
}



@article{GolasHabelE2014,
	title = {Multi-amalgamation of rules with application conditions in -adhesive categories},
	volume = {24},
	issn = {0960-1295, 1469-8072},
	url = {https://www.cambridge.org/core/journals/mathematical-structures-in-computer-science/article/abs/multiamalgamation-of-rules-with-application-conditions-in-mathcalm-adhesive-categories/8BFABE4AD4C0427C5CBD8E5E53AD6E72},
	doi = {10.1017/S0960129512000345},
	abstract = {Amalgamation is a well-known concept for graph transformations that is used to model synchronised parallelism of rules with shared subrules and corresponding transformations. This concept is especially important for an adequate formalisation of the operational semantics of statecharts and other visual modelling languages, where typed attributed graphs are used for multiple rules with nested application conditions. However, the theory of amalgamation for the double-pushout approach has so far only been developed on a set-theoretical basis for pairs of standard graph rules without any application conditions.For this reason, in the current paper we present the theory of amalgamation for -adhesive categories, which form a slightly more general framework than (weak) adhesive HLR categories, for a bundle of rules with (nested) application conditions. The two main results are the Complement Rule Theorem, which shows how to construct a minimal complement rule for each subrule, and the Multi-Amalgamation Theorem, which generalises the well-known Parallelism and Amalgamation Theorems to the case of multiple synchronised parallelism. In order to apply the largest amalgamated rule, we use maximal matchings, which are computed according to the actual instance graph. The constructions are illustrated by a small but meaningful running example, while a more complex case study concerning the firing semantics of Petri nets is presented as an introductory example and to provide motivation.},
	language = {en},
	number = {4},
	urldate = {2021-07-26},
	journal = {Mathematical Structures in Computer Science},
	author = {Golas, Ulrike and Habel, Annegret and Ehrig, Hartmut},
	month = aug,
	year = {2014},
	note = {Publisher: Cambridge University Press}
}



@book{SanellaTarlecki2012,
	address = {Berlin Heidelberg},
	series = {Monographs in {Theoretical} {Computer} {Science}. {An} {EATCS} {Series}},
	title = {Foundations of {Algebraic} {Specification} and {Formal} {Software} {Development}},
	isbn = {978-3-642-17335-6},
	url = {https://www.springer.com/de/book/9783642173356},
	abstract = {This book provides foundations for software specification and formal software development from the perspective of work on algebraic specification, concentrating on developing basic concepts and studying their fundamental properties. These foundations are built on a solid mathematical basis, using elements of universal algebra, category theory and logic, and this mathematical toolbox provides a convenient language for precisely formulating the concepts involved in software specification and development. Once formally defined, these notions become subject to mathematical investigation, and this interplay between mathematics and software engineering yields results that are mathematically interesting, conceptually revealing, and practically useful. The theory presented by the authors has its origins in work on algebraic specifications that started in the early 1970s, and their treatment is comprehensive. This book contains five kinds of material: the requisite mathematical foundations; traditional algebraic specifications; elements of the theory of institutions; formal specification and development; and proof methods. While the book is self-contained, mathematical maturity and familiarity with the problems of software engineering is required; and in the examples that directly relate to programming, the authors assume acquaintance with the concepts of functional programming. The book will be of value to researchers and advanced graduate students in the areas of programming and theoretical computer science.},
	language = {en},
	urldate = {2019-08-27},
	publisher = {Springer-Verlag},
	author = {Sannella, Donald and Tarlecki, Andrzej},
	year = {2012},
	annote = {{\textbackslash}cite\{SanellaTarlecki2012\}},
}



@techreport{DiskinStuenkel2021,
	type = {Technical {Report}},
	title = {Sketches, {Queries}, and {Views}: {From} {Term}-{Graphs} to {Diagrammatic} {Term}-{Sketches} ({Revision} of {TR} 2020-33)},
	copyright = {All rights reserved},
	number = {34},
	institution = {McMaster Centre for Software Certification},
	author = {Diskin, Zinovy and Stünkel, Patrick},
	month = may,
	year = {2021},
}



@inproceedings{KramerLanghammerMSB2015,
	address = {New York, NY, USA},
	series = {{CBSE} '15},
	title = {Change-{Driven} {Consistency} for {Component} {Code}, {Architectural} {Models}, and {Contracts}},
	isbn = {978-1-4503-3471-6},
	url = {https://doi.org/10.1145/2737166.2737177},
	doi = {10.1145/2737166.2737177},
	abstract = {During the development of component-based software systems, it is often impractical or even impossible to include all development information into the source code. Instead, specialized languages are used to describe components and systems on different levels of abstraction or from different viewpoints: Component-based architecture models and contracts, for example, can be used to describe the system on a high level of abstraction, and to formally specify component constraints. Because models, contracts, and code contain redundant information, inconsistencies can occur if they are modified independently. Keeping this information consistent manually can require considerable effort, and can lead to costly errors, for example, when security-relevant components are verified against inconsistent contracts. In this paper, we present an approach for keeping component-based architecture models and contracts specified in the Java Modeling Language (JML) consistent with Java source code. We use change-driven incremental transformations and the {\textbackslash}vitruvius framework to automate the consistency preservation where this is possible. Using two case studies, we demonstrate how to detect and propagate changes and refactoring operations to keep models and contracts consistent with the source code.},
	urldate = {2021-07-27},
	booktitle = {Proceedings of the 18th {International} {ACM} {SIGSOFT} {Symposium} on {Component}-{Based} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Kramer, Max E. and Langhammer, Michael and Messinger, Dominik and Seifermann, Stephan and Burger, Erik},
	month = may,
	year = {2015},
	keywords = {co-evolution, formal specification, model-driven engineering},
	pages = {21--26}
}


@phdthesis{Gleitze2017,
	type = {Bachelor {Thesis}},
	title = {A {Declarative} {Language} for {Preserving} {Consistency} of {Multiple} {Models}},
	abstract = {This thesis proposes a new programming language, allowing to create transformations to
keep more than two models consistent. The language uses an intermediate metamodel,
such that any transformation is first executed from an existing model into an intermediate
model, and then into other models.
We start by looking at different possibilities of how consistency of multiple models can
be preserved using only binary transformations. Subsequently, we show advantages of
introducing an intermediate metamodel to the consistency preservation process. To support
consistency preservation with intermediate metamodels, we subsequently introduce
the Commonalities Language. It is allows developers to declare metaclasses of the intermediate
metamodel together with their attributes and references. The mappings from the
intermediate model to other models and back are given directly at the mapped intermediate
metaclasses, attributes, and references. To avoid duplication of logic, bidirectional
expressions can be used for the mappings. Overall, the language aims to be declarative
and make it easy for developers to understand and verify the transformations. We have
developed a prototypical implementation of the it for the Vitruvius framework, which can
be used Eclipse for EMF models. The implementation serves as a proof of concept, but is
not yet sufficiently mature to be used in practice.
The idea of using intermediate metamodels to achieve scalable and modular consistency
preservation for multiple models was already applied successfully to realistic scenarios
in other works. To the best of our knowledge, no existing approach allows defning
an intermediate metamodel together with the transformations for it in the same language.},
	school = {Karlsruhe Institue of Technology},
	author = {Gleitze, Joshua},
	year = {2017}
}




@article{StuenkelKoenig2021TODO,
title = {Single pushout rewriting in comprehensive systems of graph-like structures},
journal = {Theoretical Computer Science},
volume = {884},
pages = {23-43},
year = {2021},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2021.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0304397521004059},
author = {Patrick Stünkel and Harald König},
keywords = {Single pushout rewriting, Partial morphism, Category theory, Hereditary pushout, Upper adjoint, Comprehensive system},
abstract = {The elegance of the single-pushout (SPO) approach to graph transformations arises from substituting total morphisms by partial ones in the underlying category. SPO's applicability depends on the durability of pushouts after this transition. There is a wide range of work on the question when pushouts exist in categories with partial morphisms starting with the pioneering work of Löwe and Kennaway and ending with an essential characterisation in terms of an exactness property (for the interplay between pullbacks and pushouts) and an adjointness condition (w.r.t. inverse image functions) by Hayman and Heindel. Triple graphs and graph diagrams are frameworks to synchronise two or more updatable data sources by means of internal mappings, which identify common sub-structures. Comprehensive systems generalise these frameworks, treating the network of data sources and their structural inter-relations as a homogeneous comprehensive artefact, in which partial maps identify commonalities. Although this inherent partiality produces amplified complexity, we can show that Heindel's characterisation still yields existence of pushouts in the category of comprehensive systems and reflective partial morphisms and thus enables computing by typed SPO graph transformation.}
}


@inproceedings{HeidenreichJohannesSW2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Closing the {Gap} between {Modelling} and {Java}},
	isbn = {978-3-642-12107-4},
	doi = {10.1007/978-3-642-12107-4_25},
	abstract = {Model-Driven Software Development is based on standardised models that are refined, transformed and eventually translated into executable code using code generators. However, creating plain text from well-structured models creates a gap that implies several drawbacks: Developers cannot continue to use their model-based tool machinery, relations between model elements and code fragments are hard to track and there is no easy way to rebuild models from their respective code.This paper presents an approach to bridge this gap for the Java programming language. It defines a full metamodel and text syntax specification for Java, from which a parser and a printer are generated. Through this, Java code can be handled like any other model. The implementation is validated with large test sets, example applications are shown, and future directions of research are discussed.},
	language = {en},
	booktitle = {Software {Language} {Engineering}},
	publisher = {Springer},
	author = {Heidenreich, Florian and Johannes, Jendrik and Seifert, Mirko and Wende, Christian},
	editor = {van den Brand, Mark and Gašević, Dragan and Gray, Jeff},
	year = {2010},
	keywords = {Eclipse Modelling Framework, Java Code, Java Program, Modelling Language, Object Constraint Language},
	pages = {374--383}
}



@article{StuenkelKoenigLR2021a,
	title = {Comprehensive {Systems}: {A} formal foundation for {Multi}-{Model} {Consistency} {Management}},
	copyright = {All rights reserved},
	issn = {1433-299X},
	shorttitle = {Comprehensive {Systems}},
	url = {https://doi.org/10.1007/s00165-021-00555-2},
	doi = {10.1007/s00165-021-00555-2},
	abstract = {Model management is a central activity in Software Engineering. The most challenging aspect of model management is to keep inter-related models consistent with each other while they evolve. As a consequence, there is a lot of scientific activity in this area, which has produced an extensive body of knowledge, methods, results and tools. The majority of these approaches, however, are limited to binary inter-model relations; i.e. the synchronisation of exactly two models. Yet, not every multi-ary relation can be factored into a family of  binary relations. In this paper, we propose and investigate a novel comprehensive system construction, which is able to represent multi-ary relations among multiple models in an integrated manner and thus serves as a formalfoundation for artefacts used in consistency management activities involving multiple models. The construction is based on the definition of partial commonalities among a set of models using the same language, which is used to denote the (local) models. The main theoretical results of this paper are proofs of the facts that comprehensive systems are an admissible environment for (i) applying formal means of consistency verification (diagrammatic predicate framework), (ii) performing algebraic graph transformation (weak adhesive HLR category), and (iii) that they generalise the underlying setting of graph diagrams and triple graph grammars.},
	language = {en},
	urldate = {2021-07-30},
	journal = {Formal Aspects of Computing},
	author = {Stünkel, Patrick and König, Harald and Lamo, Yngve and Rutle, Adrian},
	month = jul,
	year = {2021}
}


@inproceedings{KurtevBezevinA2002,
	title = {Technological spaces: {An} initial appraisal},
	shorttitle = {Technological spaces},
	abstract = {Abstract. In this paper, we propose a high level view of technological spaces (TS) and relations among these spaces. A technological space is a working context with a set of associated concepts, body of knowledge, tools, required skills, and possibilities. It is often associated to a given user community with shared know-how, educational support, common literature and even workshop and conference regular meetings. Although it is difficult to give a precise definition, some TSs can be easily identified, e.g. the},
	booktitle = {{CoopIS}, {DOA}'2002 {Federated} {Conferences}, {Industrial} track},
	author = {Kurtev, Ivan and Bézivin, Jean and Aksit, Mehmet},
	year = {2002}
}



@article{TaentzerEhrigGLL2005,
	title = {Model {Transformation} by {Graph} {Transformation} : {A} {Comparative} {Study}},
	issn = {19666608},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.2827&rep=rep1&type=pdf},
	abstract = {Graph transformation has been widely used for expressing model transformations. Especially transformations of visual models can be naturally formulated by graph transformations, since graphs are well suited to describe the underlying structures of models. Based on a common sample model transformation, four different model transformation approaches are presented which all perform graph transformations. At first, a basic solution is presented and crucial points of model transformations are indicated. Subsequent solutions focus mainly on the indicated problems. Finally, a first comparison of the chosen approaches to model transformation is presented where the main ingredients of each approach are summarized},
	journal = {Model Transformations in Practice Workshop at MODELS 2005, Montego},
	author = {Taentzer, Gabriele and Ehrig, Karsten and Guerra, Esther and Lara, Juan De and Levendovszky, Tihamér and Prange, Ulrike and Varro, Daniel and Varro-Gyapay, Szilvia},
	year = {2005},
	annote = {{\textbackslash}cite\{TaentzerEhrigGLL2005\}},
}



@article{StuenkelKoenig2021,
	title = {Single pushout rewriting in comprehensive systems of graph-like structures},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397521004059},
	doi = {10.1016/j.tcs.2021.07.002},
	abstract = {The elegance of the single-pushout (SPO) approach to graph transformations arises from substituting total morphisms by partial ones in the underlying category. SPO's applicability depends on the durability of pushouts after this transition. There is a wide range of work on the question when pushouts exist in categories with partial morphisms starting with the pioneering work of Löwe and Kennaway and ending with an essential characterisation in terms of an exactness property (for the interplay between pullbacks and pushouts) and an adjointness condition (w.r.t. inverse image functions) by Hayman and Heindel. Triple graphs and graph diagrams are frameworks to synchronise two or more updatable data sources by means of internal mappings, which identify common sub-structures. Comprehensive systems generalise these frameworks, treating the network of data sources and their structural inter-relations as a homogeneous comprehensive artefact, in which partial maps identify commonalities. Although this inherent partiality produces amplified complexity, we can show that Heindel's characterisation still yields existence of pushouts in the category of comprehensive systems and reflective partial morphisms and thus enables computing by typed SPO graph transformation.},
	language = {en},
	urldate = {2021-07-27},
	journal = {Theoretical Computer Science},
	author = {Stünkel, Patrick and König, Harald},
	month = jul,
	year = {2021},
	keywords = {Category theory, Comprehensive system, Hereditary pushout, Partial morphism, Upper adjoint, Single pushout rewriting}
}



@inproceedings{CorradiniDuvalEPR2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{AGREE} – {Algebraic} {Graph} {Rewriting} with {Controlled} {Embedding}},
	isbn = {978-3-319-21145-9},
	abstract = {The several algebraic approaches to graph transformation proposed in the literature all ensure that if an item is preserved by a rule, so are its connections with the context graph where it is embedded. But there are applications in which it is desirable to specify different embeddings. For example when cloning an item, there may be a need to handle the original and the copy in different ways. We propose a conservative extension of classical algebraic approaches to graph transformation, for the case of monic matches, where rules allow one to specify how the embedding of preserved items should be carried out.},
	language = {en},
	booktitle = {Graph {Transformation}},
	publisher = {Springer International Publishing},
	author = {Corradini, Andrea and Duval, Dominique and Echahed, Rachid and Prost, Frederic and Ribeiro, Leila},
	editor = {Parisi-Presicce, Francesco and Westfechtel, Bernhard},
	year = {2015},
	keywords = {Graph Transformation, Type Graph, Algebraic Approach, Black Node, Grey Node},
	pages = {35--51}
}


@article{StuenkelKoenigLR2021a,
	title = {Comprehensive {Systems}: {A} formal foundation for {Multi}-{Model} {Consistency} {Management}},
	issn = {1433-299X},
	shorttitle = {Comprehensive {Systems}},
	url = {https://doi.org/10.1007/s00165-021-00555-2},
	doi = {10.1007/s00165-021-00555-2},
	abstract = {Model management is a central activity in Software Engineering. The most challenging aspect of model management is to keep inter-related models consistent with each other while they evolve. As a consequence, there is a lot of scientific activity in this area, which has produced an extensive body of knowledge, methods, results and tools. The majority of these approaches, however, are limited to binary inter-model relations; i.e. the synchronisation of exactly two models. Yet, not every multi-ary relation can be factored into a family of  binary relations. In this paper, we propose and investigate a novel comprehensive system construction, which is able to represent multi-ary relations among multiple models in an integrated manner and thus serves as a formalfoundation for artefacts used in consistency management activities involving multiple models. The construction is based on the definition of partial commonalities among a set of models using the same language, which is used to denote the (local) models. The main theoretical results of this paper are proofs of the facts that comprehensive systems are an admissible environment for (i) applying formal means of consistency verification (diagrammatic predicate framework), (ii) performing algebraic graph transformation (weak adhesive HLR category), and (iii) that they generalise the underlying setting of graph diagrams and triple graph grammars.},
	language = {en},
	urldate = {2021-07-30},
	journal = {Formal Aspects of Computing},
	author = {Stünkel, Patrick and König, Harald and Lamo, Yngve and Rutle, Adrian},
	month = jul,
	year = {2021},
	annote = {{\textbackslash}cite\{StuenkelKoenigLR2021a\}}
}


@misc{wwwGraphqlFHIR,
	title = {Graphql - {FHIR} v4.0.1},
	url = {http://hl7.org/fhir/graphql.html},
	urldate = {2021-07-08},
	author = {, HL7.org}
}


@article{AwadidNurcan2019,
	title = {Consistency requirements in business process modeling: a thorough overview},
	volume = {18},
	issn = {1619-1374},
	shorttitle = {Consistency requirements in business process modeling},
	url = {https://doi.org/10.1007/s10270-017-0629-2},
	doi = {10.1007/s10270-017-0629-2},
	abstract = {The field of business process modeling has been beset by inter-model consistency problems which are mainly due to the existence of multiple variants of the same business process, for instance when models have been produced by different actors, or through the time by a same (or different) actor(s), as well as the possibility of its modeling from discrete and complementary perspectives (using different lenses). Accordingly, our overall aim in this paper is to provide a thorough overview of consistency requirements in business process modeling, which is strongly needed not only for the sake of a comprehensive investigation of this challenging subject, but also for the sake of empowering significant contributions to it. In order to do so, we opted for a systematic literature review of consistency among business process models as starting point and basis to attain the intended overview and to guide our contributions in this field.},
	language = {en},
	number = {2},
	urldate = {2020-03-20},
	journal = {Software \& Systems Modeling},
	author = {Awadid, Afef and Nurcan, Selmin},
	month = apr,
	year = {2019},
	pages = {1097--1115},
	annote = {Inter-Model Consistency for BPMN}
}



@inproceedings{TorresVandenBrandS2019,
	title = {Model {Management} {Tools} for {Models} of {Different} {Domains}: {A} {Systematic} {Literature} {Review}},
	shorttitle = {Model {Management} {Tools} for {Models} of {Different} {Domains}},
	doi = {10.1109/SYSCON.2019.8836869},
	abstract = {Objective: The goal of this study is to present an overview of industrial and academic approaches to cross-domain model management. We aim at identifying industrial and academic tools for cross-domain model management and describing the inconsistency types addressed by them as well as strategies the users of the tools employ to keep consistency between models of different domains. Method: We conducted a systematic literature review. Using the keyword-based search on Google Scholar we analyzed 515 potentially relevant studies; after applying inclusion and exclusion criteria 88 papers were selected for further analysis. Results: The main findings/contributions are: (i) a list of available tools used to support model management; (ii) approximately 31\% of the tools can provide consistency model checking on models of different domains and approximately 24\% on the same domain; (iii) available strategies to keep the consistency between models of different domains are not mature enough; (iv) explicit modeling dependencies between models is not common in the industry. However, it is considered as a requirement by academia if one wishes to manage inconsistency between models of different domains. Conclusion: This study presents an overview of industrial practices and academic approaches about the cross-domain model management. The results presented in this study can be used as a starting point for future research on model management topics, and also for further improvement of actual model management tools.},
	booktitle = {2019 {IEEE} {International} {Systems} {Conference} ({SysCon})},
	author = {Torres, Weslley and Brand, Mark van den and Serebrenik, Alexander},
	month = apr,
	year = {2019},
	note = {ISSN: 2472-9647},
	keywords = {Bibliographies, Google, Model Management, Model-Based Systems Engineering, Modeling, Product lifecycle management, Systematic Literature Review, Systematics, Systems Engineering, Tools},
	pages = {1--8}
}



@inproceedings{AhmadNadeem2010,
	title = {Consistency checking of {UML} models using {Description} {Logics}: {A} critical review},
	shorttitle = {Consistency checking of {UML} models using {Description} {Logics}},
	doi = {10.1109/ICET.2010.5638468},
	abstract = {Software design is often modeled as a collection of UML diagrams. Different UML diagrams depicting overlapping behaviour of the system, refinement of models and the evolving nature of software, may lead to inconsistencies in UML diagrams. Inconsistencies in the software model specification might result in the development of incoherent and conflicting system. Current UML tools provide unsatisfactory support for maintaining the consistency between UML diagrams. To identify the inconsistencies and conflicts in UML models, formal languages such as Description Logics (DL) have proved to be useful. This paper evaluates the existing DL based approaches to UML consistency checking. Our analysis shows that the existing DL based approaches are automated, but cover only a limited subset of UML diagrams and inconsistency types.},
	booktitle = {2010 6th {International} {Conference} on {Emerging} {Technologies} ({ICET})},
	author = {Ahmad, M. Aziz and Nadeem, A.},
	month = oct,
	year = {2010},
	keywords = {software design, UML, Unified modeling language, Unified Modeling Language, checkpointing, Cognition, Computational modeling, consistency checking, Consistency Checking, data integrity, Description Logic, description logics, formal languages, formal logic, Object oriented modeling, Protocols, Reasoning on UML models, Semantics, software model specification, Syntactics, UML Inconsistencies classification, UML models},
	pages = {310--315}
}



@inproceedings{TabatabaeiKadirI2008,
	title = {A {Comparative} {Evaluation} of {State}-of-the-{Art} {Approaches} for {Web} {Service} {Composition}},
	doi = {10.1109/ICSEA.2008.68},
	abstract = {In today's Web environment, many enterprises decide to implement and publish their applications on the Internet using Web services technology. In many cases, a single service is not sufficient to fulfill the user's request. To solve this problem, services should be combined together. Therefore, composition of Web services is one of the recent critical issues. A number of approaches have been presented, to tackle this problem. In this paper, we categorize these approaches into four categories (workflow-based, AI-planning based, syntactic-based, and semantic-based). Then, we compare these approaches based on some criteria (like QoS, scalability, and correctness). Investigation of that classification will help researchers who are working on service composition to deliver more applicable solutions.},
	booktitle = {2008 {The} {Third} {International} {Conference} on {Software} {Engineering} {Advances}},
	author = {Tabatabaei, Sayed Gholam Hassan and Kadir, Wan Mohd Nasir Wan and Ibrahim, Suhaimi},
	month = oct,
	year = {2008},
	keywords = {Application software, Computer science, HTN-DL, Information systems, OWL-S, QoS, Scalability, Software design, Software engineering, Software systems, Turing machines, Web and internet services, Web Service Composition, Web services, WSMO},
	pages = {488--493},
	file = {IEEE Xplore Abstract Record:/Users/past/Zotero/storage/4PCR3HZQ/4668150.html:text/html;IEEE Xplore Full Text PDF:/Users/past/Zotero/storage/4MLH58PS/Tabatabaei et al. - 2008 - A Comparative Evaluation of State-of-the-Art Appro.pdf:application/pdf},
}



@inproceedings{AbukwaikRombach2017,
	address = {New York, NY, USA},
	series = {{EASE}'17},
	title = {Software {Interoperability} {Analysis} in {Practice}: {A} {Survey}},
	isbn = {978-1-4503-4804-1},
	shorttitle = {Software {Interoperability} {Analysis} in {Practice}},
	url = {https://doi.org/10.1145/3084226.3084255},
	doi = {10.1145/3084226.3084255},
	abstract = {Software interoperability property plays a vital role in enabling interoperation in todayfis system-of-systems, cyber-physical systems, ecosystems, etc. Despite the critical role of interoperability analysis in enabling a successful and meaningful software interoperation, it is still facing challenges that impede performing it effectively and efficiently. We performed an online survey of software engineers with software integration experiences to identify the main difficulties of performing interoperability analysis. The results confirm that the state of available practical support and current input artifacts used during the analysis are significantly perceived as important difficulties. Respondents claim a lack of guidelines and best practices for applying interoperability analysis and claim insufficiency of shared information about interoperable software units. This indicates the need for providing directive and rigorous guidelines for practitioners to follow and to enrich the content of shared documents about interoperable software units.},
	urldate = {2021-08-18},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Abukwaik, Hadil and Rombach, Dieter},
	month = jun,
	year = {2017},
	keywords = {Conceptual interoperability, interoperability analysis, survey},
	pages = {12--20}
}


@article{McIllraithSonZ2001,
	title = {Semantic {Web} {Services}},
	volume = {16},
	issn = {1541-1672},
	url = {https://doi.org/10.1109/5254.920599},
	doi = {10.1109/5254.920599},
	abstract = {The Web is evolving from a repository for text and images to a service provider-including information-providing services and services that have some effect on the world. Furthermore, today's Web was designed primarily for human use, but we are seeing increased automation of Web service interoperation, primarily in B2B and E-Commerce applications. Fundamental to reliable, large-scale interoperation of services by computer programs or agents is the need to make Web service properties, capabilities, interfaces, and effects understandable to computers-to create Semantic Web Services.In this article, the authors propose a vision and a partial realization of precisely this. They propose markup of Web services in the DAML family of semantic Web markup languages. Their markup of Web services enables a wide variety of agent technologies for automated Web service discovery, execution, composition, and interoperation. They present one logic-based agent technology for service composition, predicated on the use of reusable, task-specific, high-level generic procedures and user-specific customizing constraints.},
	number = {2},
	urldate = {2021-03-30},
	journal = {IEEE Intelligent Systems},
	author = {McIlraith, Sheila A. and Son, Tran Cao and Zeng, Honglei},
	month = mar,
	year = {2001},
	keywords = {service composition, Web services, agents, artificial intelligence, DAML, markup language, semantic Web},
	pages = {46--53}
}



@article{DongHussainC2013,
	title = {Semantic {Web} {Service} matchmakers: state of the art and challenges},
	volume = {25},
	issn = {1532-0634},
	shorttitle = {Semantic {Web} {Service} matchmakers},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.2886},
	doi = {10.1002/cpe.2886},
	abstract = {SUMMARYWeb services provide a standard means for the interoperable operations between electronic devices in a network. The mission of Web service discovery is to seek an appropriate Web service for a service requester on the basis of the service descriptions in Web service advertisements and the service requester's requirements. Nevertheless, the standard language used for encoding service descriptions does not have the capacity to specify the capabilities of a Web service, leading to the problem of ambiguity in the service discovery process. This brings up the vision of Semantic Web Services and Semantic Web Service discovery, which make use of the Semantic Web technologies to enrich the semantics of service descriptions for service discovery. Semantic Web Service matchmakers are the programs or frameworks designed to implement the task of Semantic Web Service discovery and have drawn a significant amount of attention from both academia and industry from the start of this century. In this paper, we conduct a survey of the contemporary Semantic Web Service matchmakers in order to obtain an overview of the state of the art in this research area. We summarize six technical dimensions from the past literature and analyze the typical Semantic Web Service matchmakers mostly developed during the past 4 or 5 years in terms of the six dimensions. By means of this analysis, we gain an understanding of the current research and summarize a series of potential issues to that would provide the foundation for future research in this area.Copyright © 2012 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {7},
	urldate = {2021-08-20},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Dong, Hai and Hussain, Farookh Khadeer and Chang, Elizabeth},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.2886},
	keywords = {Semantic Web Service discovery, Semantic Web Service matchmakers, Semantic Web Service selection, Semantic Web Services, Web services},
	pages = {961--988}
}



@incollection{BibkaisTsinarakiGSC2013,
	address = {Berlin, Heidelberg},
	series = {Studies in {Computational} {Intelligence}},
	title = {The {XML} and {Semantic} {Web} {Worlds}: {Technologies}, {Interoperability} and {Integration}: {A} {Survey} of the {State} of the {Art}},
	isbn = {978-3-642-28977-4},
	shorttitle = {The {XML} and {Semantic} {Web} {Worlds}},
	url = {https://doi.org/10.1007/978-3-642-28977-4_12},
	abstract = {In the context of the emergent Web of Data, a large number of organizations, institutes and companies (e.g., DBpedia,ACM, IEEE, IBM, NASA,BBC,etc.) adopt the Linked Data practices and publish their data utilizing Semantic Web (SW) technologies. On the other hand, the dominant standard for information exchange in the Web today is XML. Many international standards (e.g., Dublin Core, MPEG-7,METS, TEI, IEEE LOM,etc.) have been expressed in XML Schema resulting to a large number of XML datasets. The SW and XML worlds and their developed infrastructures are based on different data models, semantics and query languages. Thus, it is crucial to provide interoperability and integration mechanisms to bridge the gap between the SW and XML worlds.In this chapter, we give an overview and a comparison of the technologies and the standards adopted by the XML and SW worlds. In addition, we outline the latest efforts from the W3C groups, including the latest working drafts and recommendations (e.g., OWL 2, SPARQL 1.1, XML Schema 1.1, etc.). Moreover, we present a survey of the research approaches which aim to provide interoperability and integration between the XML and SW worlds. Finally, we present the SPARQL2XQuery and XS2OWL Frameworks, which bridge the gap and create an interoperable environment between the two worlds. These Frameworks provide mechanisms for: (a) Query translation (SPARQL to XQuery translation); (b) Mapping specification and generation (Ontology to XML Schema mapping); and (c) Schema transformation (XML Schema to OWL transformation).},
	language = {en},
	urldate = {2021-08-20},
	booktitle = {Semantic {Hyper}/{Multimedia} {Adaptation}: {Schemes} and {Applications}},
	publisher = {Springer},
	author = {Bikakis, Nikos and Tsinaraki, Chrisa and Gioldasis, Nektarios and Stavrakantonakis, Ioannis and Christodoulakis, Stavros},
	editor = {Anagnostopoulos, Ioannis E. and Bieliková, Mária and Mylonas, Phivos and Tsapatsoulis, Nicolas},
	year = {2013},
	doi = {10.1007/978-3-642-28977-4_12},
	keywords = {Digital Library, Query Translation, Resource Description Framework, Resource Description Framework Data, Resource Description Framework Graph},
	pages = {319--360},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/CDICQD7L/Bikakis et al. - 2013 - The XML and Semantic Web Worlds Technologies, Int.pdf:application/pdf},
}


@article{BharadwajCoobinehLS1992,
	title = {Model management systems: {A} survey},
	volume = {38},
	issn = {1572-9338},
	shorttitle = {Model management systems},
	url = {https://doi.org/10.1007/BF02283650},
	doi = {10.1007/BF02283650},
	abstract = {This paper provides a survey of model management literature within the mathematical modeling domain. The first part of the survey is a review and a summary of the literature. After giving some basic definitions of modeling, modeling life cycle, and model management, two representative algebraic modeling languages followed by three approaches to modeling are introduced. These approaches are database, graph-based, and knowledge-based. The discussion is followed by a review of two specialized model management systems. The second part of the survey is a categorization of various modeling systems based on the modeling functions they provide and some of their features. These functions include life cycle support and model base administration. The degree of model independence provided by model management systems and the implemented environment systems is also summarized. The last part of the paper provides directions for future research.},
	language = {en},
	number = {1},
	urldate = {2020-10-26},
	journal = {Annals of Operations Research},
	author = {Bharadwaj, Anandhi and Choobineh, Joobin and Lo, Amber and Shetty, Bala},
	month = dec,
	year = {1992},
	pages = {17--67}
}



@inproceedings{EtzlstorferKapsammerSS2018,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Surveying {Co}-evolution in {Modeling} {Ecosystems}},
	isbn = {978-3-319-94764-8},
	doi = {10.1007/978-3-319-94764-8_15},
	abstract = {Metamodels, defining the determinant concepts of a domain, constitute the core components in Model-Driven Engineering. Together with their depending artifacts, e.g., models and transformations, they form modeling ecosystems. To be operable, it is essential for a modeling ecosystem to be in a valid state with respect to the various interdependencies between the metamodel and its depending artifacts as well as among the depending artifacts. Consequently, in case of metamodel evolution, caused by, e.g., changing requirements, the depending artifacts have to be co-evolved accordingly to keep the system in a valid state. With respect to modeling ecosystems, special effort has to be laid to a consistent co-evolution across the different kinds of artifacts and their relationships. Although several approaches for the co-evolution of depending artifacts have been proposed, there was no special focus on an ecosystem-wide perspective of co-evolution, yet. Therefore, this paper focuses on co-evolution in modeling ecosystems by discussing the various components of a modeling ecosystem and their relationships, depicting the respective co-evolution process, proposing an evaluation framework for co-evolution, and applying this framework to current approaches. Based on this evaluation we derive lessons learned and present future research directions.},
	language = {en},
	booktitle = {Model-{Driven} {Engineering} and {Software} {Development}},
	publisher = {Springer International Publishing},
	author = {Etzlstorfer, Jürgen and Kapsammer, Elisabeth and Schwinger, Wieland and Schönböck, Johannes},
	editor = {Pires, Luís Ferreira and Hammoudi, Slimane and Selic, Bran},
	year = {2018},
	keywords = {Co-evolution, Evolution, Model-driven engineering, Modeling ecosystem},
	pages = {354--376},
	file = {Springer Full Text PDF:/Users/past/Zotero/storage/6TW4HSP2/Etzlstorfer et al. - 2018 - Surveying Co-evolution in Modeling Ecosystems.pdf:application/pdf},
}



@book{Fowler2012b,
	series = {Addison-{Wesley} {Signature} {Series} ({Fowler})},
	title = {Patterns of {Enterprise} {Application} {Architecture}},
	isbn = {978-0-13-306521-3},
	publisher = {Pearson Education},
	author = {Fowler, M.},
	year = {2012},
}

@misc{JPA,
 title = {Jakarta EE: Jakarta Persistence 3.0},
 author = {Jakarta Persistence Team},
 url = {https://jakarta.ee/specifications/persistence/3.0/},
 year = {2020}
}


@book{Melnik2004PhD,
	address = {Berlin Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Generic {Model} {Management}: {Concepts} and {Algorithms}},
	isbn = {978-3-540-21980-4},
	shorttitle = {Generic {Model} {Management}},
	url = {https://www.springer.com/gp/book/9783540219804},
	abstract = {Many challenging problems in information systems engineering involve the manipulation of complex metadata artifacts or models, such as database schema, interface specifications, or object diagrams, and mappings between models. Applications solving metadata manipulation problems are complex and hard to build. The goal of generic model management is to reduce the amount of programming needed to solve such problems by providing a database infrastructure in which a set of high-level algebraic operators are applied to models and mappings as a whole rather than to their individual building blocks. This book presents a systematic study of the concepts and algorithms for generic model management. The first prototype of a generic model management system is described, the algebraic operators are introduced and analyzed, and novel algorithms for implementing them are developed. Using the prototype system and the operators presented, solutions are developed for several practically relevant problems, such as change propagation and reintegration.},
	language = {en},
	urldate = {2021-08-23},
	publisher = {Springer-Verlag},
	author = {Melnik, Sergey},
	year = {2004},
	doi = {10.1007/b97859}
}


@article{EilenbergMacLane1945,
	title = {General {Theory} of {Natural} {Equivalences}},
	volume = {58},
	issn = {0002-9947},
	doi = {10.2307/1990284},
	number = {2},
	urldate = {2019-11-20},
	journal = {Transactions of the American Mathematical Society},
	author = {Eilenberg, Samuel and MacLane, Saunders},
	year = {1945},
	pages = {231--294}
}


@book{Kroemer2007,
	series = {Science {Networks}. {Historical} {Studies}},
	title = {Tool and {Object}: {A} {History} and {Philosophy} of {Category} {Theory}},
	isbn = {978-3-7643-7523-2},
	shorttitle = {Tool and {Object}},
	abstract = {The book is first of all a history of category theory from the beginnings to A. Grothendieck and F.W. Lawvere. Category theory was an important conceptual tool in 20th century mathematics whose influence on some mathematical subdisciplines (above all algebraic topology and algebraic geometry) is analyzed. Category theory also has an important philosophical aspect: on the one hand its set-theoretical foundation is less obvious than for other mathematical theories, and on the other hand it unifies conceptually a large part of modern mathematics and may therefore be considered as somewhat fundamental itself. The role of this philosophical aspect in the historical development is the second focus of the book. Relying on the historical analysis, the author develops a philosophical interpretation of the theory of his own, intending to get closer to how mathematicians conceive the significance of their activity than traditional schools of philosophy of science. The book is the first monography exclusively devoted to the history of category theory. To a substantial extent it considers aspects never studied before. The author uses (and justifies the use of) a methodology combining historical and philosophical approaches. The analysis is not confined to general remarks, but goes into considerable mathematical detail. Hence, the book provides an exceptionally thorough case study compared with other works on history or philosophy of mathematics. The philosophical position developed here (inspired by Peircean pragmatism and Wittgenstein) is an interesting alternative to traditional approaches in philosophy of mathematics like platonism, formalism and intuitionism.},
	language = {en},
	urldate = {2019-12-10},
	publisher = {Birkhäuser Basel},
	author = {Krömer, Ralph},
	year = {2007},
	doi = {10.1007/978-3-7643-7524-9}
}



@book{Lawvere2009,
	address = {Cambridge},
	edition = {2},
	title = {Conceptual {Mathematics}: {A} {First} {Introduction} to {Categories}},
	isbn = {978-0-521-71916-2},
	shorttitle = {Conceptual {Mathematics}},
	url = {https://www.cambridge.org/core/books/conceptual-mathematics/00772F4CC3D4268200C5EC86B39D415A},
	abstract = {In the last 60 years, the use of the notion of category has led to a remarkable unification and simplification of mathematics. Conceptual Mathematics introduces this tool for the learning, development, and use of mathematics, to beginning students and also to practising mathematical scientists. This book provides a skeleton key that makes explicit some concepts and procedures that are common to all branches of pure and applied mathematics. The treatment does not presuppose knowledge of specific fields, but rather develops, from basic definitions, such elementary categories as discrete dynamical systems and directed graphs; the fundamental ideas are then illuminated by examples in these categories. This second edition provides links with more advanced topics of possible study. In the new appendices and annotated bibliography the reader will find concise introductions to adjoint functors and geometrical structures, as well as sketches of relevant historical developments.},
	urldate = {2021-08-23},
	publisher = {Cambridge University Press},
	author = {Lawvere, F. William and Schanuel, Stephen H.},
	year = {2009},
	doi = {10.1017/CBO9780511804199}
}

@article{Lambek1980,
  title={From $\lambda$-calculus to cartesian closed categories},
  author={Lambek, Joachim},
  journal={To HB Curry: essays on combinatory logic, lambda calculus and formalism},
  pages={375--402},
  year={1980},
  publisher={Academic Press}
}


@article{Moggi1991,
	series = {Selections from 1989 {IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	title = {Notions of computation and monads},
	volume = {93},
	issn = {0890-5401},
	url = {https://www.sciencedirect.com/science/article/pii/0890540191900524},
	doi = {10.1016/0890-5401(91)90052-4},
	abstract = {The λ-calculus is considered a useful mathematical tool in the study of programming languages, since programs can be identified with λ-terms. However, if one goes further and uses βη-conversion to prove equivalence of programs, then a gross simplification is introduced (programs are identified with total functions from values to values) that may jeopardise the applicability of theoretical results. In this paper we introduce calculi, based on a categorical semantics for computations, that provide a correct basis for proving equivalence of programs for a wide range of notions of computation.},
	language = {en},
	number = {1},
	urldate = {2021-08-23},
	journal = {Information and Computation},
	author = {Moggi, Eugenio},
	month = jul,
	year = {1991},
	pages = {55--92}
}


@book{Milewski2019,
	title = {Category {Theory} for {Programmers}},
	isbn = {978-0-464-18364-8},
	abstract = {This is the Scala edition of Category Theory for Programmers by Bartosz Milewski. This book contains code snippets in both Haskell and Scala.},
	language = {en},
	publisher = {Blurb, Incorporated},
	author = {Milewski, Bartosz},
	month = aug,
	year = {2019}
}

@inproceedings{Winskel1984,
author = {Winskel, Glynn},
title = {Categories of Models for Concurrency},
year = {1984},
isbn = {3540156704},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Seminar on Concurrency, Carnegie-Mellon University},
pages = {246–267},
numpages = {22}
}


@book{CoeckeKissinger2017,
	title = {Picturing {Quantum} {Processes}},
	isbn = {978-1-107-10422-8},
	abstract = {The unique features of the quantum world are explained in this book through the language of diagrams, setting out an innovative visual method for presenting complex theories. Requiring only basic mathematical literacy, this book employs a unique formalism that builds an intuitive understanding of quantum features while eliminating the need for complex calculations. This entirely diagrammatic presentation of quantum theory represents the culmination of ten years of research, uniting classical techniques in linear algebra and Hilbert spaces with cutting-edge developments in quantum computation and foundations. Written in an entertaining and user-friendly style and including more than one hundred exercises, this book is an ideal first course in quantum theory, foundations, and computation for students from undergraduate to PhD level, as well as an opportunity for researchers from a broad range of fields, from physics to biology, linguistics, and cognitive science, to discover a new set of tools for studying processes and interaction.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Coecke, Bob and Kissinger, Aleks},
	month = mar,
	year = {2017},
	note = {Google-Books-ID: I9gcDgAAQBAJ}
}


@inproceedings{MelnikGarciaMolinaR2002,
	title = {Similarity flooding: a versatile graph matching algorithm and its application to schema matching},
	shorttitle = {Similarity flooding},
	doi = {10.1109/ICDE.2002.994702},
	abstract = {Matching elements of two data schemas or two data instances plays a key role in data warehousing, e-business, or even biochemical applications. In this paper we present a matching algorithm based on a fixpoint computation that is usable across different scenarios. The algorithm takes two graphs (schemas, catalogs, or other data structures) as input, and produces as output a mapping between corresponding nodes of the graphs. Depending on the matching goal, a subset of the mapping is chosen using filters. After our algorithm runs, we expect a human to check and if necessary adjust the results. As a matter of fact, we evaluate the 'accuracy' of the algorithm by counting the number of needed adjustments. We conducted a user study, in which our accuracy metric was used to estimate the labor savings that the users could obtain by utilizing our algorithm to obtain an initial matching. Finally, we illustrate how our matching algorithm is deployed as one of several high-level operators in an implemented testbed for managing information models and mappings.},
	booktitle = {Proceedings 18th {International} {Conference} on {Data} {Engineering}},
	author = {Melnik, S. and Garcia-Molina, H. and Rahm, E.},
	month = feb,
	year = {2002},
	note = {ISSN: 1063-6382},
	keywords = {Biochemistry, Bioinformatics, Catalogs, Data structures, Floods, Humans, Information management, Matched filters, Testing, Warehousing},
	pages = {117--128}
}


@inproceedings{SabetzadehEasterbrook2003,
	title = {Analysis of inconsistency in graph-based viewpoints: a category-theoretical approach},
	shorttitle = {Analysis of inconsistency in graph-based viewpoints},
	doi = {10.1109/ASE.2003.1240290},
	abstract = {Eliciting the requirements for a proposed system typically involves different stakeholders with different expertise, responsibilities, and perspectives. Viewpoints-based approaches have been proposed as a way to manage incomplete and inconsistent models gathered from multiple sources. In this paper, we propose a category-theoretical framework for the analysis of fuzzy viewpoints. Informally, a fuzzy viewpoint is graph in which the elements of a lattice are used to specify the amount of knowledge available about the details of nodes and edges. By defining an appropriate notion of morphism between fuzzy viewpoints, we construct categories of fuzzy viewpoints and prove that these categories are (finitely) complete. We then show how colimits can be employed to merge the viewpoints and detect the inconsistencies that arise independent of any particular choice of viewpoint semantics. We illustrate an application of the framework through a case-study showing how fuzzy viewpoints can serve as a requirements elicitation tool in reactive systems.},
	booktitle = {18th {IEEE} {International} {Conference} on {Automated} {Software} {Engineering}, 2003. {Proceedings}.},
	author = {Sabetzadeh, M. and Easterbrook, S.},
	month = oct,
	year = {2003},
	note = {ISSN: 1938-4300},
	keywords = {Application software, Computer science, Fuzzy sets, Fuzzy systems, Information analysis, Lattices, Logic, Merging, Programming, Software engineering},
	pages = {12--21}
}


@techreport{SolheimStoelen2007,
	title = {Technology {Research} {Explained}},
	number = {A313},
	institution = {SINTEF},
	author = {Solheim, Ida and St{\o}len, Ketil},
	month = mar,
	year = {2007},
	pages = {22},
}



@article{AdamekHerrlich1986,
	title = {Cartesian closed categories, quasitopoi and topological universes},
	volume = {27},
	issn = {0010-2628 (print)},
	url = {https://dml.cz/handle/10338.dmlcz/106447},
	language = {eng},
	number = {2},
	urldate = {2021-08-30},
	journal = {Commentationes Mathematicae Universitatis Carolinae},
	author = {Adámek, Jiří and Herrlich, Horst},
	year = {1986},
	note = {Publisher: Charles University in Prague, Faculty of Mathematics and Physics},
	pages = {235--257},
	file = {Full Text PDF:/Users/past/Zotero/storage/7Y3TAZZP/Adámek and Herrlich - 1986 - Cartesian closed categories, quasitopoi and topolo.pdf:application/pdf;Snapshot:/Users/past/Zotero/storage/NVV5B9MW/106447.html:text/html},
}


@inproceedings{Benabou1967,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Mathematics}},
	title = {Introduction to bicategories},
	isbn = {978-3-540-35545-8},
	doi = {10.1007/BFb0074299},
	language = {en},
	booktitle = {Reports of the {Midwest} {Category} {Seminar}},
	publisher = {Springer},
	author = {Bénabou, Jean},
	editor = {Bénabou, J. and Davis, R. and Dold, A. and Isbell, J. and MacLane, S. and Oberst, U. and Roos, J. -E.},
	year = {1967},
	keywords = {Abelian Category, Commutative Diagram, Inverse Image, Inverse Limit, Natural Transformation},
	pages = {1--77}
}




@techreport{ElaasarBriand2004,
	title = {An overview of {UML} consistency management},
	number = {SCE-04-18},
	institution = {Carleton University},
	author = {Elaasar, Maged and Briand, Lionel},
	year = {2004},
	file = {Elaasar and Briand - 2004 - An overview of UML consistency management.pdf:/Users/past/Zotero/storage/4FFCEGZZ/Elaasar and Briand - 2004 - An overview of UML consistency management.pdf:application/pdf},
}



@inproceedings{GalavoGoknil2007,
	title = {Survey of {Traceability} {Approaches} in {Model}-{Driven} {Engineering}},
	doi = {10.1109/EDOC.2007.42},
	abstract = {Models have been used in various engineering fields to help managing complexity and represent information in different abstraction levels, according to specific notations and stakeholder's viewpoints. Model-Driven Engineering (MDE) gives the basic principles for the use of models as primary artefacts throughout the software development phases and presents characteristics that simplify the engineering of software in various domains, such as Enterprise Computing Systems. Hence, for its successful application, MDE processes must consider traceability practices. They help the understanding, capturing, tracking and verification of software artefacts and their relationships and dependencies with other artefacts during the software life-cycle. In this survey, we discuss the state-of-the-art in traceability approaches in MDE and assess them with respect to five general comparison criteria: representation, mapping, scalability, change impact analysis and tool support. As a complementary result, we have identified some open issues that can be better explored by traceability in MDE.},
	booktitle = {11th {IEEE} {International} {Enterprise} {Distributed} {Object} {Computing} {Conference} ({EDOC} 2007)},
	author = {Galvao, Ismenia and Goknil, Arda},
	month = oct,
	year = {2007},
	note = {ISSN: 1541-7719},
	keywords = {Application software, Computer science, Distributed computing, Engineering management, Model driven engineering, Programming, Reverse engineering, Scalability, Software engineering, Software systems},
	pages = {313--313}
}


@article{BatotGerardC2021,
	title = {A {Survey}-driven {Feature} {Model} for {Software} {Traceability} {Approaches}},
	url = {https://hal.archives-ouvertes.fr/hal-03267077},
	abstract = {Traceability is the capability to represent, understand and analyze the relationships between software artefacts. Traceability is at the core of many software engineering activities. This is a blessing in disguise as traceability research is scattered among various research subfields which impairs a global view and integration of the different innovations around the recording, identification and management of traces. This also limits the adoption of traceability solutions in industry. In this sense, the goal of this paper is to present a characterization of the traceability mechanism as a feature model depicting the shared and variable elements in any traceability proposal. The features in the model are derived from a survey of papers related to traceability published in the literature. We believe this feature model is useful to assess and compare different proposals and provide a common terminology and background that could speed up the creation of new ones on top of them. Beyond the feature model, the survey we conducted also help us to identify a number of challenges to be solved in order to move traceability forward, especially in a context where, due to the increasing importance of AI techniques in Software Engineering, traces are more important than ever in order to be able to reproduce and explain AI decisions.},
	urldate = {2021-09-01},
	journal = {Software and Systems Modeling},
	author = {Batot, Edouard Romari and Gérard, Sébastien and Cabot, Jordi},
	year = {2021},
	note = {Publisher: Springer Verlag},
	keywords = {Explainability, Feature Model, Model-Driven Development, Software Engineering, Traceability}
}


@article{WinklerPilgrim2010,
	title = {A survey of traceability in requirements engineering and model-driven development},
	volume = {9},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-009-0145-0},
	doi = {10.1007/s10270-009-0145-0},
	abstract = {Traceability—the ability to follow the life of software artifacts—is a topic of great interest to software developers in general, and to requirements engineers and model-driven developers in particular. This article aims to bring those stakeholders together by providing an overview of the current state of traceability research and practice in both areas. As part of an extensive literature survey, we identify commonalities and differences in these areas and uncover several unresolved challenges which affect both domains. A good common foundation for further advances regarding these challenges appears to be a combination of the formal basis and the automated recording opportunities of MDD on the one hand, and the more holistic view of traceability in the requirements engineering domain on the other hand.},
	language = {en},
	number = {4},
	urldate = {2021-09-01},
	journal = {Software \& Systems Modeling},
	author = {Winkler, Stefan and von Pilgrim, Jens},
	month = sep,
	year = {2010},
	pages = {529--565}
}



@article{SantiagoJiminezVDBM2012,
	series = {Special {Section} on {Software} {Reliability} and {Security}},
	title = {Model-{Driven} {Engineering} as a new landscape for traceability management: {A} systematic literature review},
	volume = {54},
	issn = {0950-5849},
	shorttitle = {Model-{Driven} {Engineering} as a new landscape for traceability management},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584912001346},
	doi = {10.1016/j.infsof.2012.07.008},
	abstract = {Context
Model-Driven Engineering provides a new landscape for dealing with traceability in software development.
Objective
Our goal is to analyze the current state of the art in traceability management in the context of Model-Driven Engineering.
Method
We use the systematic literature review based on the guidelines proposed by Kitchenham. We propose five research questions and six quality assessments.
Results
Of the 157 relevant studies identified, 29 have been considered primary studies. These studies have resulted in 17 proposals.
Conclusion
The evaluation shows that the most addressed operations are storage, CRUD and visualization, while the most immature operations are exchange and analysis traceability information.},
	language = {en},
	number = {12},
	urldate = {2021-09-01},
	journal = {Information and Software Technology},
	author = {Santiago, Iv{\'a}n and Jim{\'e}nez, Alvaro and Vara, Juan Manuel and De Castro, Valeria and Bollati, Ver{\'o}nica A. and Marcos, Esperanza},
	month = dec,
	year = {2012},
	keywords = {Model-Driven Engineering, Systematic literature review, Traceability},
	pages = {1340--1356}
}



@article{MuramTranZ2017,
	title = {Systematic {Review} of {Software} {Behavioral} {Model} {Consistency} {Checking}},
	volume = {50},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3037755},
	doi = {10.1145/3037755},
	abstract = {In software development, models are often used to represent multiple views of the same system. Such models need to be properly related to each other in order to provide a consistent description of the developed system. Models may contain contradictory system specifications, for instance, when they evolve independently. Therefore, it is very crucial to ensure that models conform to each other. In this context, we focus on consistency checking of behavior models. Several techniques and approaches have been proposed in the existing literature to support behavioral model consistency checking. This article presents a Systematic Literature Review (SLR) that was carried out to obtain an overview of the various consistency concepts, problems, and solutions proposed regarding behavior models. In our study, the identification and selection of the primary studies was based on a well-planned search strategy. The search process identified a total of 1770 studies, out of which 96 have been thoroughly analyzed according to our predefined SLR protocol. The SLR aims to highlight the state-of-the-art of software behavior model consistency checking and identify potential gaps for future research. Based on research topics in selected studies, we have identified seven main categories: targeted software models, types of consistency checking, consistency checking techniques, inconsistency handling, type of study and evaluation, automation support, and practical impact. The findings of the systematic review also reveal suggestions for future research, such as improving the quality of study design and conducting evaluations, and application of research outcomes in industrial settings. For this purpose, appropriate strategy for inconsistency handling, better tool support for consistency checking and/or development tool integration should be considered in future studies.},
	number = {2},
	urldate = {2020-10-26},
	journal = {ACM Computing Surveys},
	author = {Muram, Faiz ul and Tran, Huy and Zdun, Uwe},
	month = apr,
	year = {2017},
	keywords = {consistency checking, consistency types, Software behavioral model, systematic literature review},
	pages = {17:1--17:39}
}


